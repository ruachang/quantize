{"Layers": [{
  "Name": "Reformatting CopyNode for Network Input input",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "input",
    "Location": "Device",
    "Dimensions": [1,1,60,60],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted input",
    "Location": "Device",
    "Dimensions": [1,1,60,60],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "QuantizeLinear_206",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Reformatted input",
    "Location": "Device",
    "Dimensions": [1,1,60,60],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,60,60],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_2",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Reformatted input",
    "Location": "Device",
    "Dimensions": [1,1,60,60],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "109",
    "Location": "Device",
    "Dimensions": [1,1,60,60],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Slice_203",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "317",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Slice_352",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "466",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_502",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "616",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Slice_652",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "766",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_802",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "916",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_952",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1066",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_1102",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1216",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_1252",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1366",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_1402",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1516",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_1552",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1666",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Slice_1702",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1816",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_1852",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1966",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_2002",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2116",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_2152",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2266",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Slice_2302",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2416",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Slice_2452",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "309",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2566",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "SLICE",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "conv1.0.weight + QuantizeLinear_8 + Conv_12",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "109",
    "Location": "Device",
    "Dimensions": [1,1,60,60],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "124",
    "Location": "Device",
    "Dimensions": [1,64,58,58],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1",
  "TacticValue": "0x9fc2bcaa51428a78"
},{
  "Name": "conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "317",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "332",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_1 + QuantizeLinear_361 + Conv_365",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "466",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "481",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_2 + QuantizeLinear_511 + Conv_515",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "616",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "631",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_3 + QuantizeLinear_661 + Conv_665",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "766",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "781",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_4 + QuantizeLinear_811 + Conv_815",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "916",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "931",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_5 + QuantizeLinear_961 + Conv_965",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1066",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1081",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_6 + QuantizeLinear_1111 + Conv_1115",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1216",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1231",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_7 + QuantizeLinear_1261 + Conv_1265",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1366",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1381",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_8 + QuantizeLinear_1411 + Conv_1415",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1516",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1531",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_9 + QuantizeLinear_1561 + Conv_1565",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1666",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1681",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_10 + QuantizeLinear_1711 + Conv_1715",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1816",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1831",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_11 + QuantizeLinear_1861 + Conv_1865",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1966",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1981",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_12 + QuantizeLinear_2011 + Conv_2015",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2116",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2131",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_13 + QuantizeLinear_2161 + Conv_2165",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2266",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2281",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_14 + QuantizeLinear_2311 + Conv_2315",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2416",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2431",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv4.0.weight_clone_15 + QuantizeLinear_2461 + Conv_2465",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2566",
    "Location": "Device",
    "Dimensions": [1,1,24,24],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2581",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 576},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xee2fce9480a52be7"
},{
  "Name": "conv1.3.weight + QuantizeLinear_23 + Conv_27",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "124",
    "Location": "Device",
    "Dimensions": [1,64,58,58],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "137",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x2f34f689bfca5071"
},{
  "Name": "conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "332",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "345",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_1 + QuantizeLinear_376 + Conv_380",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "481",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "494",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_2 + QuantizeLinear_526 + Conv_530",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "631",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "644",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_3 + QuantizeLinear_676 + Conv_680",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "781",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "794",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_4 + QuantizeLinear_826 + Conv_830",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "931",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "944",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_5 + QuantizeLinear_976 + Conv_980",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1081",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1094",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_6 + QuantizeLinear_1126 + Conv_1130",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1231",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1244",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_7 + QuantizeLinear_1276 + Conv_1280",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1381",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1394",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_8 + QuantizeLinear_1426 + Conv_1430",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1531",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1544",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_9 + QuantizeLinear_1576 + Conv_1580",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1681",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1694",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_10 + QuantizeLinear_1726 + Conv_1730",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1831",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1844",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_11 + QuantizeLinear_1876 + Conv_1880",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1981",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1994",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_12 + QuantizeLinear_2026 + Conv_2030",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2131",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2144",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_13 + QuantizeLinear_2176 + Conv_2180",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2281",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2294",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_14 + QuantizeLinear_2326 + Conv_2330",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2431",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2444",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "conv4.3.weight_clone_15 + QuantizeLinear_2476 + Conv_2480",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2581",
    "Location": "Device",
    "Dimensions": [1,64,22,22],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2594",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x671c943720ba8655"
},{
  "Name": "MaxPool_30",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "137",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "140",
    "Location": "Device",
    "Dimensions": [1,64,28,28],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_234",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "345",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "348",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_383",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "494",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "497",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_533",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "644",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "647",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_683",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "794",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "797",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_833",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "944",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "947",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_983",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1094",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1097",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_1133",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1244",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1247",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_1283",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1394",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1397",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_1433",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1544",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1547",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_1583",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1694",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1697",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_1733",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1844",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1847",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_1883",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1994",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1997",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_2033",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2144",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2147",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_2183",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2294",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2297",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_2333",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2444",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2447",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "MaxPool_2483",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2594",
    "Location": "Device",
    "Dimensions": [1,64,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2597",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "conv2.0.weight + QuantizeLinear_39 + Conv_43",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "140",
    "Location": "Device",
    "Dimensions": [1,64,28,28],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "155",
    "Location": "Device",
    "Dimensions": [1,128,26,26],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "348",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "363",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_1 + QuantizeLinear_392 + Conv_396",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "497",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "512",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_2 + QuantizeLinear_542 + Conv_546",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "647",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "662",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_3 + QuantizeLinear_692 + Conv_696",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "797",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "812",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_4 + QuantizeLinear_842 + Conv_846",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "947",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "962",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_5 + QuantizeLinear_992 + Conv_996",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1097",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1112",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_6 + QuantizeLinear_1142 + Conv_1146",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1247",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1262",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_7 + QuantizeLinear_1292 + Conv_1296",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1397",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1412",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_8 + QuantizeLinear_1442 + Conv_1446",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1547",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1562",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_9 + QuantizeLinear_1592 + Conv_1596",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1697",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1712",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_10 + QuantizeLinear_1742 + Conv_1746",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1847",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1862",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_11 + QuantizeLinear_1892 + Conv_1896",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1997",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2012",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_12 + QuantizeLinear_2042 + Conv_2046",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2147",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2162",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_13 + QuantizeLinear_2192 + Conv_2196",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2297",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2312",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_14 + QuantizeLinear_2342 + Conv_2346",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2447",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2462",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv5.0.weight_clone_15 + QuantizeLinear_2492 + Conv_2496",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2597",
    "Location": "Device",
    "Dimensions": [1,64,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2612",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "conv2.3.weight + QuantizeLinear_54 + Conv_58",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "155",
    "Location": "Device",
    "Dimensions": [1,128,26,26],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "167",
    "Location": "Device",
    "Dimensions": [1,128,24,24],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "363",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "375",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_1 + QuantizeLinear_407 + Conv_411",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "512",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "524",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_2 + QuantizeLinear_557 + Conv_561",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "662",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "674",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_3 + QuantizeLinear_707 + Conv_711",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "812",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "824",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_4 + QuantizeLinear_857 + Conv_861",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "962",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "974",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_5 + QuantizeLinear_1007 + Conv_1011",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1112",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1124",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_6 + QuantizeLinear_1157 + Conv_1161",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1262",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1274",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_7 + QuantizeLinear_1307 + Conv_1311",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1412",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1424",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_8 + QuantizeLinear_1457 + Conv_1461",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1562",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1574",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_9 + QuantizeLinear_1607 + Conv_1611",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1712",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1724",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_10 + QuantizeLinear_1757 + Conv_1761",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1862",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1874",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_11 + QuantizeLinear_1907 + Conv_1911",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2012",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2024",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_12 + QuantizeLinear_2057 + Conv_2061",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2162",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2174",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_13 + QuantizeLinear_2207 + Conv_2211",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2312",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2324",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_14 + QuantizeLinear_2357 + Conv_2361",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2462",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2474",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "conv5.3.weight_clone_15 + QuantizeLinear_2507 + Conv_2511",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2612",
    "Location": "Device",
    "Dimensions": [1,128,8,8],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2624",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "MaxPool_61",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "167",
    "Location": "Device",
    "Dimensions": [1,128,24,24],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "168",
    "Location": "Device",
    "Dimensions": [1,128,12,12],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll1_tThreads128",
  "TacticValue": "0x53862c46aa5b4c2b"
},{
  "Name": "QuantizeLinear_71",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "168",
    "Location": "Device",
    "Dimensions": [1,128,12,12],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "182",
    "Location": "Device",
    "Dimensions": [1,128,12,12],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_265",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "375",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "376",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_414",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "524",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "525",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_564",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "674",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "675",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_714",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "824",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "825",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_864",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "974",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "975",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_1014",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1124",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1125",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_1164",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1274",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1275",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_1314",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1424",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1425",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_1464",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1574",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1575",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_1614",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1724",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1725",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_1764",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1874",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1875",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_1914",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2024",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2025",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_2064",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2174",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2175",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_2214",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2324",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2325",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_2364",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2474",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2475",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "MaxPool_2514",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2624",
    "Location": "Device",
    "Dimensions": [1,128,6,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2625",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256",
  "TacticValue": "0x60eceb67eff69444"
},{
  "Name": "ReduceMean_266",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "376",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "377",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_267",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "376",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "378",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_415",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "525",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "526",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_416",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "525",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "527",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_565",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "675",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "676",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_566",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "675",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "677",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_715",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "825",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "826",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_716",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "825",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "827",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_865",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "975",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "976",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_866",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "975",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "977",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_1015",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1125",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1126",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_1016",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1125",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1127",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_1165",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1275",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1276",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_1166",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1275",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1277",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_1315",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1425",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1426",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_1316",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1425",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1427",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_1465",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1575",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1576",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_1466",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1575",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1577",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_1615",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1725",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1726",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_1616",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1725",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1727",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_1765",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1875",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1876",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_1766",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "1875",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1877",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_1915",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2025",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2026",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_1916",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2025",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2027",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_2065",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2175",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2176",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_2066",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2175",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2177",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_2215",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2325",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2326",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_2216",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2325",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2327",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_2365",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2475",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2476",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_2366",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2475",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2477",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMean_2515",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2625",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2626",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_2516",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "2625",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2627",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "conv3.0.weight + QuantizeLinear_77 + Conv_81",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "182",
    "Location": "Device",
    "Dimensions": [1,128,12,12],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "197",
    "Location": "Device",
    "Dimensions": [1,256,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 294912},
  "Bias": {"Type": "Float", "Count": 256},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4749124f62d8bd23"
},{
  "Name": "QuantizeLinear_271_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "378",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "382",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_271_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "377",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_268_377_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_268_377_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_268_377_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "382",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_420_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "527",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "531",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_420_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "526",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_417_526_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_417_526_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_417_526_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "531",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_570_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "677",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "681",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_570_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "676",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_567_676_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Concat_567_676_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_567_676_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "681",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_720_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "827",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "831",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_720_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "826",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_717_826_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Concat_717_826_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_717_826_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "831",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_870_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "977",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "981",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_870_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "976",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_867_976_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_867_976_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_867_976_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "981",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1020_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1127",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1131",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1020_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1126",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_1017_1126_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_1017_1126_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_1017_1126_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1131",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1170_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1277",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1281",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1170_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1276",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_1167_1276_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_1167_1276_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_1167_1276_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1281",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1320_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1427",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1431",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1320_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1426",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_1317_1426_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Concat_1317_1426_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_1317_1426_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1431",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "QuantizeLinear_1470_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1577",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1581",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1470_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1576",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_1467_1576_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_1467_1576_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_1467_1576_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1581",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "QuantizeLinear_1620_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1727",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1731",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1620_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1726",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_1617_1726_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Concat_1617_1726_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_1617_1726_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1731",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1770_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1877",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1881",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1770_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1876",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_1767_1876_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Concat_1767_1876_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_1767_1876_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1881",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "QuantizeLinear_1920_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2027",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2031",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_1920_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2026",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_1917_2026_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_1917_2026_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_1917_2026_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2031",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_2070_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2177",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2181",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_2070_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2176",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_2067_2176_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_2067_2176_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_2067_2176_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2181",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_2220_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2327",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2331",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_2220_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2326",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_2217_2326_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_2217_2326_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_2217_2326_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2331",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "QuantizeLinear_2370_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2477",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2481",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_2370_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2476",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_2367_2476_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_2367_2476_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_2367_2476_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2481",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_2520_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2627",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2631",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_2520_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2626",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_2517_2626_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_2517_2626_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_2517_2626_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2631",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Resize_68",
  "LayerType": "Resize",
  "Inputs": [
  {
    "Name": "168",
    "Location": "Device",
    "Dimensions": [1,128,12,12],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "179",
    "Location": "Device",
    "Dimensions": [1,128,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Resize",
  "ResizeMode": "NEAREST",
  "ResizeScales": [0, 0, 0, 0, 0, 0, 0, 0],
  "ExcludeOutside": 0,
  "CubicCoeff": -0.75,
  "CoordTransform": "kASYMMETRIC",
  "ResizeSelector": "kFORMULA",
  "NNRounding": "kFLOOR",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "382",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "392",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_1 + QuantizeLinear_426 + Conv_430",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "531",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "541",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_2 + QuantizeLinear_576 + Conv_580",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "681",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "691",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_3 + QuantizeLinear_726 + Conv_730",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "831",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "841",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_4 + QuantizeLinear_876 + Conv_880",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "981",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "991",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_5 + QuantizeLinear_1026 + Conv_1030",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1131",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1141",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_6 + QuantizeLinear_1176 + Conv_1180",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1281",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1291",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_7 + QuantizeLinear_1326 + Conv_1330",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1431",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1441",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_8 + QuantizeLinear_1476 + Conv_1480",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1581",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1591",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_9 + QuantizeLinear_1626 + Conv_1630",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1731",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1741",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_10 + QuantizeLinear_1776 + Conv_1780",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1881",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1891",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_11 + QuantizeLinear_1926 + Conv_1930",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2031",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2041",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_12 + QuantizeLinear_2076 + Conv_2080",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2181",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2191",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_13 + QuantizeLinear_2226 + Conv_2230",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2331",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2341",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_14 + QuantizeLinear_2376 + Conv_2380",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2481",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2491",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "patchattention_spatial.conv1.weight_clone_15 + QuantizeLinear_2526 + Conv_2530",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2631",
    "Location": "Device",
    "Dimensions": [1,2,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2641",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "conv3.3.weight + QuantizeLinear_92 + Conv_96",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "197",
    "Location": "Device",
    "Dimensions": [1,256,10,10],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "209",
    "Location": "Device",
    "Dimensions": [1,256,8,8],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 1,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x85c1a5f7f239cf84"
},{
  "Name": "PWN(Sigmoid_282, Mul_283)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "392",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "376",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "394",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_431, Mul_432)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "541",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "525",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "543",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_581, Mul_582)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "691",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "675",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "693",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_731, Mul_732)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "841",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "825",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "843",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_881, Mul_882)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "991",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "975",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "993",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_1031, Mul_1032)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "1141",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1125",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1143",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_1181, Mul_1182)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "1291",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1275",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1293",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_1331, Mul_1332)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "1441",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1425",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1443",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_1481, Mul_1482)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "1591",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1575",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1593",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_1631, Mul_1632)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "1741",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1725",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1743",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_1781, Mul_1782)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "1891",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1875",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1893",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_1931, Mul_1932)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "2041",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2025",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2043",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_2081, Mul_2082)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "2191",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2175",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2193",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_2231, Mul_2232)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "2341",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2325",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2343",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_2381, Mul_2382)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "2491",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2475",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2493",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "PWN(Sigmoid_2531, Mul_2532)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "2641",
    "Location": "Device",
    "Dimensions": [1,1,3,3],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2625",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2643",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "GlobalAveragePool_284",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "394",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "395",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_315",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "394",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "423",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_433",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "543",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "544",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_464",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "543",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "572",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_583",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "693",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "694",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_614",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "693",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "722",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_733",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "843",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "844",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_764",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "843",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "872",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_883",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "993",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "994",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_914",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "993",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1022",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_1033",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1143",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1144",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_1064",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1143",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1172",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_1183",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1293",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1294",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_1214",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1293",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1322",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_1333",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1443",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1444",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_1364",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1443",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1472",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "GlobalAveragePool_1483",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1593",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1594",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_1514",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1593",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1622",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "GlobalAveragePool_1633",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1743",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1744",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_1664",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1743",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1772",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_1783",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1893",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1894",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_1814",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1893",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1922",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_1933",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2043",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2044",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_1964",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2043",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2072",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "GlobalAveragePool_2083",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2193",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2194",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_2114",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2193",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2222",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_2233",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2343",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2344",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_2264",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2343",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2372",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_2383",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2493",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2494",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_2414",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2493",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2522",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "GlobalAveragePool_2533",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2643",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2644",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "QuantizeLinear_2564",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2643",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2672",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "QuantizeLinear_287",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "395",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "398",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_312",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "423",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "426",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_436",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "544",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "547",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_461",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "572",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "575",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_586",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "694",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "697",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_611",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "722",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "725",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_736",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "844",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "847",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_761",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "872",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "875",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_886",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "994",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "997",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_911",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1022",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1025",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_1036",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1144",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1147",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_1061",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1172",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1175",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_1186",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1294",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1297",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_1211",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1322",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1325",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_1336",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1444",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1447",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_1361",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1472",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1475",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "QuantizeLinear_1486",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1594",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1597",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_1511",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1622",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1625",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba"
},{
  "Name": "QuantizeLinear_1636",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1744",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1747",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "MaxPool_1661",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1772",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1775",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_1786",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "1894",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "1897",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_1811",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "1922",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1925",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_1936",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2044",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2047",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_1961",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2072",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2075",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_2086",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2194",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2197",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "MaxPool_2111",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2222",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2225",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_2236",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2344",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2347",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_2261",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2372",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2375",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_2386",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2494",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2497",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_2411",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2522",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2525",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "QuantizeLinear_2536",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2644",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2647",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_2561",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2672",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2675",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [3,3],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "MaxPool_99",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "209",
    "Location": "Device",
    "Dimensions": [1,256,8,8],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "211",
    "Location": "Device",
    "Dimensions": [1,256,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll7_tThreads256",
  "TacticValue": "0xbd4519190f75e7e9"
},{
  "Name": "179 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "179",
    "Location": "Device",
    "Dimensions": [1,128,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "211",
    "Location": "Device",
    "Dimensions": [1,128,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "398",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "412",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "426",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "440",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "547",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "561",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "575",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "589",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "697",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "711",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "725",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "739",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "847",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "861",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "875",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "889",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "997",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1011",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1025",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1039",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1147",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1161",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1175",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1189",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1297",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1311",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1325",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1339",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1447",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1461",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_15 + QuantizeLinear_1370 + Conv_1374 + Relu_1375",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1475",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1489",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1597",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1611",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_17 + QuantizeLinear_1520 + Conv_1524 + Relu_1525",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1625",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1639",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1747",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1761",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1775",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1789",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1897",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1911",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1925",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1939",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2047",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2061",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2075",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2089",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2197",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2211",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2225",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2239",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2347",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2361",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2375",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2389",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2497",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2511",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2525",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2539",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2647",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2661",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2675",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2689",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 8,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x596666386c88024b"
},{
  "Name": "ReduceMean_101",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "211",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "212",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "AVG",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "ReduceMax_102",
  "LayerType": "Reduce",
  "Inputs": [
  {
    "Name": "211",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "213",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reduce",
  "Operation": "MAX",
  "ReduceAxes": [0,1,0,0],
  "KeepDimensions": 1,
  "TacticValue": "0x0000000000000005"
},{
  "Name": "QuantizeLinear_106_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "213",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "217",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "QuantizeLinear_106_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "212",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Concat_103_212_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Concat_103_212_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Concat_103_212_clone_0",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "217",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "412",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "422",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_1 + QuantizeLinear_335 + Conv_339",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "440",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "450",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_2 + QuantizeLinear_456 + Conv_460",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "561",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "571",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_3 + QuantizeLinear_484 + Conv_488",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "589",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "599",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_4 + QuantizeLinear_606 + Conv_610",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "711",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "721",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_5 + QuantizeLinear_634 + Conv_638",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "739",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "749",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_6 + QuantizeLinear_756 + Conv_760",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "861",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "871",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_7 + QuantizeLinear_784 + Conv_788",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "889",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "899",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_8 + QuantizeLinear_906 + Conv_910",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1011",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1021",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_9 + QuantizeLinear_934 + Conv_938",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1039",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1049",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_10 + QuantizeLinear_1056 + Conv_1060",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1161",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1171",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_11 + QuantizeLinear_1084 + Conv_1088",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1189",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1199",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_12 + QuantizeLinear_1206 + Conv_1210",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1311",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1321",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_13 + QuantizeLinear_1234 + Conv_1238",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1339",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1349",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_14 + QuantizeLinear_1356 + Conv_1360",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1461",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1471",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_15 + QuantizeLinear_1384 + Conv_1388",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1489",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1499",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_16 + QuantizeLinear_1506 + Conv_1510",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1611",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1621",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_17 + QuantizeLinear_1534 + Conv_1538",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1639",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1649",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_18 + QuantizeLinear_1656 + Conv_1660",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1761",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1771",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_19 + QuantizeLinear_1684 + Conv_1688",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1789",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1799",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_20 + QuantizeLinear_1806 + Conv_1810",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1911",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1921",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_21 + QuantizeLinear_1834 + Conv_1838",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "1939",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "1949",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_22 + QuantizeLinear_1956 + Conv_1960",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2061",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2071",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_23 + QuantizeLinear_1984 + Conv_1988",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2089",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2099",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_24 + QuantizeLinear_2106 + Conv_2110",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2211",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2221",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_25 + QuantizeLinear_2134 + Conv_2138",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2239",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2249",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_26 + QuantizeLinear_2256 + Conv_2260",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2361",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2371",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_27 + QuantizeLinear_2284 + Conv_2288",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2389",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2399",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_28 + QuantizeLinear_2406 + Conv_2410",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2511",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2521",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_29 + QuantizeLinear_2434 + Conv_2438",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2539",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2549",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_30 + QuantizeLinear_2556 + Conv_2560",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2661",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2671",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "patchattention_channel.fc.2.weight_clone_31 + QuantizeLinear_2584 + Conv_2588",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2689",
    "Location": "Device",
    "Dimensions": [1,8,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "2699",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1024},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190"
},{
  "Name": "attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "217",
    "Location": "Device",
    "Dimensions": [1,2,4,4],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "227",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 98},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1",
  "TacticValue": "0x1b0534177b414e71"
},{
  "Name": "PWN(Sigmoid_117, Mul_118)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "227",
    "Location": "Device",
    "Dimensions": [1,1,4,4],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "211",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "229",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg1, var3);"],
  "TacticValue": "0x0000000000000001"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_340, Sigmoid_341), Mul_342)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "422",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_340, Sigmoid_341), Mul_342)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_340, Sigmoid_341), Mul_342)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "450",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_340, Sigmoid_341), Mul_342)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_340, Sigmoid_341), Mul_342)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_340, Sigmoid_341), Mul_342)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_340, Sigmoid_341), Mul_342)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "394",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_489, Sigmoid_490), Mul_491)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "571",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_489, Sigmoid_490), Mul_491)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_489, Sigmoid_490), Mul_491)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "599",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_489, Sigmoid_490), Mul_491)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_489, Sigmoid_490), Mul_491)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_489, Sigmoid_490), Mul_491)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_489, Sigmoid_490), Mul_491)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "543",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_639, Sigmoid_640), Mul_641)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "721",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_639, Sigmoid_640), Mul_641)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_639, Sigmoid_640), Mul_641)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "749",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_639, Sigmoid_640), Mul_641)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_639, Sigmoid_640), Mul_641)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_639, Sigmoid_640), Mul_641)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_639, Sigmoid_640), Mul_641)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "693",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_789, Sigmoid_790), Mul_791)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "871",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_789, Sigmoid_790), Mul_791)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_789, Sigmoid_790), Mul_791)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "899",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_789, Sigmoid_790), Mul_791)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_789, Sigmoid_790), Mul_791)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_789, Sigmoid_790), Mul_791)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_789, Sigmoid_790), Mul_791)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "843",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_939, Sigmoid_940), Mul_941)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1021",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_939, Sigmoid_940), Mul_941)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_939, Sigmoid_940), Mul_941)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1049",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_939, Sigmoid_940), Mul_941)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_939, Sigmoid_940), Mul_941)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_939, Sigmoid_940), Mul_941)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_939, Sigmoid_940), Mul_941)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "993",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1171",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1199",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1143",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1321",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1349",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1293",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1471",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1499",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1443",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1621",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1649",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1593",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1771",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1799",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1743",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1921",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "1949",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "1893",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2071",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2099",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2043",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2221",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2249",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2193",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2371",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2399",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2343",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2521",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2549",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2493",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2671",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "2699",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591)",
    "Location": "Device",
    "Dimensions": [1,128,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "2643",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,128,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x000000000000001c"
},{
  "Name": "GlobalAveragePool_119",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "229",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "230",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [4,4],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average_FastDiv",
  "TacticValue": "0x933eceba7b866d59"
},{
  "Name": "QuantizeLinear_150",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "229",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "258",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "QuantizeLinear_122",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "230",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "233",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8"
},{
  "Name": "MaxPool_147",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "258",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "261",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [4,4],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [4,4],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX",
  "TacticValue": "0x1f6c40e3e09ec730"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "233",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "247",
    "Location": "Device",
    "Dimensions": [1,24,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 24,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 9216},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x31de506085a332d4"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "261",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "275",
    "Location": "Device",
    "Dimensions": [1,24,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 24,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 9216},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "HasBias": 0,
  "HasReLU": 1,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x31de506085a332d4"
},{
  "Name": "attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "247",
    "Location": "Device",
    "Dimensions": [1,24,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "257",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 9216},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xdc1f355deb032b87"
},{
  "Name": "attention_channel.fc.2.weight_clone_1 + QuantizeLinear_170 + Conv_174",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "275",
    "Location": "Device",
    "Dimensions": [1,24,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "285",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 9216},
  "Bias": {"Type": "Float", "Count": 0},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 0,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32",
  "TacticValue": "0xdc1f355deb032b87"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_175, Sigmoid_176), Mul_177)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "257",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_175, Sigmoid_176), Mul_177)",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_175, Sigmoid_176), Mul_177)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "285",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_175, Sigmoid_176), Mul_177)",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "PWN(PWN(Add_175, Sigmoid_176), Mul_177)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(PWN(Add_175, Sigmoid_176), Mul_177)",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to PWN(PWN(Add_175, Sigmoid_176), Mul_177)",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "229",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "288",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 3,
  "InputArgs": ["arg0", "arg1", "arg2"],
  "NbOutputVars": 1,
  "OutputVars": ["var5"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 6,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);", "auto const var1 = pwgen::iMul(literal4, var0);", "auto const var2 = pwgen::iTanh(var1);", "auto const var3 = pwgen::iMul(var2, literal4);", "auto const var4 = pwgen::iPlus(var3, literal4);", "auto const var5 = pwgen::iMul(arg2, var4);"],
  "TacticValue": "0x0000000000000003"
},{
  "Name": "GlobalAveragePool_178",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "288",
    "Location": "Device",
    "Dimensions": [1,384,4,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "289",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [4,4],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average_FastDiv",
  "TacticValue": "0x933eceba7b866d59"
},{
  "Name": "QuantizeLinear_183",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "289",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "291",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "291",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise]",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise]",
    "Location": "Device",
    "Dimensions": [1,384,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 203) [ElementWise]_out_tensor",
    "Location": "Device",
    "Dimensions": [1,6,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 6,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2304},
  "Bias": {"Type": "Float", "Count": 6},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 1,
  "HasReLU": 0,
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x5e4f6d7c83746fd6"
},{
  "Name": "GlobalAveragePool_2593",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "2703",
    "Location": "Device",
    "Dimensions": [1,2048,3,3],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2704",
    "Location": "Device",
    "Dimensions": [1,2048,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9",
  "TacticValue": "0x964fa580cb69303d"
},{
  "Name": "copied_squeeze_after_(Unnamed Layer* 203) [ElementWise]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 203) [ElementWise]_out_tensor",
    "Location": "Device",
    "Dimensions": [1,6,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "output",
    "Location": "Device",
    "Dimensions": [1,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
},{
  "Name": "QuantizeLinear_2598",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "2704",
    "Location": "Device",
    "Dimensions": [1,2048,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2706",
    "Location": "Device",
    "Dimensions": [1,2048,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000"
},{
  "Name": "classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "2706",
    "Location": "Device",
    "Dimensions": [1,2048,1,1],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 2500) [ElementWise]_out_tensor",
    "Location": "Device",
    "Dimensions": [1,6,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 6,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 12288},
  "Bias": {"Type": "Float", "Count": 6},
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "HasBias": 1,
  "HasReLU": 0,
  "TacticName": "sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu",
  "TacticValue": "0xc073b0053ce90eac"
},{
  "Name": "copied_squeeze_after_(Unnamed Layer* 2500) [ElementWise]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 2500) [ElementWise]_out_tensor",
    "Location": "Device",
    "Dimensions": [1,6,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "2719",
    "Location": "Device",
    "Dimensions": [1,6],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000"
}],
"Bindings": ["input"
,"output"
,"2719"
]}
