&&&& RUNNING TensorRT.trtexec [TensorRT v8503] # trtexec --verbose --nvtxMode=verbose --buildOnly --workspace=8192 --onnx=/home/developers/liuchang/quantize/py-quant-ptq/param_test/int8_histogram_percentile99.9999_mffcnn.onnx --saveEngine=/home/developers/liuchang/quantize/py-quant-ptq/param_test/int8_histogram_percentile99.9999_mffcnn.onnx.engine --timingCacheFile=./timing.cache --profilingVerbosity=detailed --int8
[03/01/2023-10:40:44] [W] --workspace flag has been deprecated by --memPoolSize flag.
[03/01/2023-10:40:44] [W] --nvtxMode flag has been deprecated by --profilingVerbosity flag.
[03/01/2023-10:40:44] [I] === Model Options ===
[03/01/2023-10:40:44] [I] Format: ONNX
[03/01/2023-10:40:44] [I] Model: /home/developers/liuchang/quantize/py-quant-ptq/param_test/int8_histogram_percentile99.9999_mffcnn.onnx
[03/01/2023-10:40:44] [I] Output:
[03/01/2023-10:40:44] [I] === Build Options ===
[03/01/2023-10:40:44] [I] Max batch: explicit batch
[03/01/2023-10:40:44] [I] Memory Pools: workspace: 8192 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[03/01/2023-10:40:44] [I] minTiming: 1
[03/01/2023-10:40:44] [I] avgTiming: 8
[03/01/2023-10:40:44] [I] Precision: FP32+INT8
[03/01/2023-10:40:44] [I] LayerPrecisions: 
[03/01/2023-10:40:44] [I] Calibration: Dynamic
[03/01/2023-10:40:44] [I] Refit: Disabled
[03/01/2023-10:40:44] [I] Sparsity: Disabled
[03/01/2023-10:40:44] [I] Safe mode: Disabled
[03/01/2023-10:40:44] [I] DirectIO mode: Disabled
[03/01/2023-10:40:44] [I] Restricted mode: Disabled
[03/01/2023-10:40:44] [I] Build only: Enabled
[03/01/2023-10:40:44] [I] Save engine: /home/developers/liuchang/quantize/py-quant-ptq/param_test/int8_histogram_percentile99.9999_mffcnn.onnx.engine
[03/01/2023-10:40:44] [I] Load engine: 
[03/01/2023-10:40:44] [I] Profiling verbosity: 2
[03/01/2023-10:40:44] [I] Tactic sources: Using default tactic sources
[03/01/2023-10:40:44] [I] timingCacheMode: global
[03/01/2023-10:40:44] [I] timingCacheFile: ./timing.cache
[03/01/2023-10:40:44] [I] Heuristic: Disabled
[03/01/2023-10:40:44] [I] Preview Features: Use default preview flags.
[03/01/2023-10:40:44] [I] Input(s)s format: fp32:CHW
[03/01/2023-10:40:44] [I] Output(s)s format: fp32:CHW
[03/01/2023-10:40:44] [I] Input build shapes: model
[03/01/2023-10:40:44] [I] Input calibration shapes: model
[03/01/2023-10:40:44] [I] === System Options ===
[03/01/2023-10:40:44] [I] Device: 0
[03/01/2023-10:40:44] [I] DLACore: 
[03/01/2023-10:40:44] [I] Plugins:
[03/01/2023-10:40:44] [I] === Inference Options ===
[03/01/2023-10:40:44] [I] Batch: Explicit
[03/01/2023-10:40:44] [I] Input inference shapes: model
[03/01/2023-10:40:44] [I] Iterations: 10
[03/01/2023-10:40:44] [I] Duration: 3s (+ 200ms warm up)
[03/01/2023-10:40:44] [I] Sleep time: 0ms
[03/01/2023-10:40:44] [I] Idle time: 0ms
[03/01/2023-10:40:44] [I] Streams: 1
[03/01/2023-10:40:44] [I] ExposeDMA: Disabled
[03/01/2023-10:40:44] [I] Data transfers: Enabled
[03/01/2023-10:40:44] [I] Spin-wait: Disabled
[03/01/2023-10:40:44] [I] Multithreading: Disabled
[03/01/2023-10:40:44] [I] CUDA Graph: Disabled
[03/01/2023-10:40:44] [I] Separate profiling: Disabled
[03/01/2023-10:40:44] [I] Time Deserialize: Disabled
[03/01/2023-10:40:44] [I] Time Refit: Disabled
[03/01/2023-10:40:44] [I] NVTX verbosity: 2
[03/01/2023-10:40:44] [I] Persistent Cache Ratio: 0
[03/01/2023-10:40:44] [I] Inputs:
[03/01/2023-10:40:44] [I] === Reporting Options ===
[03/01/2023-10:40:44] [I] Verbose: Enabled
[03/01/2023-10:40:44] [I] Averages: 10 inferences
[03/01/2023-10:40:44] [I] Percentiles: 90,95,99
[03/01/2023-10:40:44] [I] Dump refittable layers:Disabled
[03/01/2023-10:40:44] [I] Dump output: Disabled
[03/01/2023-10:40:44] [I] Profile: Disabled
[03/01/2023-10:40:44] [I] Export timing to JSON file: 
[03/01/2023-10:40:44] [I] Export output to JSON file: 
[03/01/2023-10:40:44] [I] Export profile to JSON file: 
[03/01/2023-10:40:44] [I] 
[03/01/2023-10:40:44] [I] === Device Information ===
[03/01/2023-10:40:44] [I] Selected Device: NVIDIA GeForce RTX 3080 Ti
[03/01/2023-10:40:44] [I] Compute Capability: 8.6
[03/01/2023-10:40:44] [I] SMs: 80
[03/01/2023-10:40:44] [I] Compute Clock Rate: 1.665 GHz
[03/01/2023-10:40:44] [I] Device Global Memory: 12053 MiB
[03/01/2023-10:40:44] [I] Shared Memory per SM: 100 KiB
[03/01/2023-10:40:44] [I] Memory Bus Width: 384 bits (ECC disabled)
[03/01/2023-10:40:44] [I] Memory Clock Rate: 9.501 GHz
[03/01/2023-10:40:44] [I] 
[03/01/2023-10:40:44] [I] TensorRT version: 8.5.3
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::fMHA_V2 version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::fMHCA version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::GroupNorm version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::LayerNorm version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::Proposal version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::SeqLen2Spatial version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::SplitGeLU version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::Split version 1
[03/01/2023-10:40:44] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[03/01/2023-10:40:44] [I] [TRT] [MemUsageChange] Init CUDA: CPU +327, GPU +0, now: CPU 338, GPU 427 (MiB)
[03/01/2023-10:40:44] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.5.3
[03/01/2023-10:40:44] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.5.3
[03/01/2023-10:40:47] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +441, GPU +118, now: CPU 832, GPU 545 (MiB)
[03/01/2023-10:40:47] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars
[03/01/2023-10:40:47] [I] Start parsing network model
[03/01/2023-10:40:47] [I] [TRT] ----------------------------------------------------------------
[03/01/2023-10:40:47] [I] [TRT] Input filename:   /home/developers/liuchang/quantize/py-quant-ptq/param_test/int8_histogram_percentile99.9999_mffcnn.onnx
[03/01/2023-10:40:47] [I] [TRT] ONNX IR version:  0.0.6
[03/01/2023-10:40:47] [I] [TRT] Opset version:    13
[03/01/2023-10:40:47] [I] [TRT] Producer name:    pytorch
[03/01/2023-10:40:47] [I] [TRT] Producer version: 1.8
[03/01/2023-10:40:47] [I] [TRT] Domain:           
[03/01/2023-10:40:47] [I] [TRT] Model version:    0
[03/01/2023-10:40:47] [I] [TRT] Doc string:       
[03/01/2023-10:40:47] [I] [TRT] ----------------------------------------------------------------
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::fMHA_V2 version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::fMHCA version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::GroupNorm version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 2
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::LayerNorm version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::SeqLen2Spatial version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::SplitGeLU version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::Split version 1
[03/01/2023-10:40:47] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[03/01/2023-10:40:47] [V] [TRT] Adding network input: input with dtype: float32, dimensions: (1, 1, 60, 60)
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: input for ONNX tensor: input
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.0.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.1.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.1.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.1.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.3.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.4.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.4.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv1.4.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.0.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.1.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.1.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.1.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.3.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.4.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.4.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv2.4.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.0.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.1.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.1.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.1.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.3.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.4.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.4.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv3.4.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: attention_spatial.conv1.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: attention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: attention_channel.fc.2.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: classfier1.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: classfier1.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.0.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.1.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.1.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.1.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.3.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.4.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.4.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv4.4.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.0.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.1.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.1.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.1.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.3.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.4.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.4.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: conv5.4.running_var
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: patchattention_spatial.conv1.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: patchattention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: patchattention_channel.fc.2.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: classfier2.weight
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: classfier2.bias
[03/01/2023-10:40:47] [V] [TRT] Importing initializer: 2720
[03/01/2023-10:40:47] [W] [TRT] onnx2trt_utils.cpp:377: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_0 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_0 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_0 [Constant] outputs: [107 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_1 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_1 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_1 [Constant] outputs: [108 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_2 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: input
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 107
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 108
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_2 [QuantizeLinear] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [107 -> ()[FLOAT]], [108 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 107 for ONNX node: 107
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 108 for ONNX node: 108
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 109 for ONNX tensor: 109
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_2 [QuantizeLinear] outputs: [109 -> (1, 1, 60, 60)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_3 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_3 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_3 [Constant] outputs: [110 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_4 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_4 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_4 [Constant] outputs: [111 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_5 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 109
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 110
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 111
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_5 [DequantizeLinear] inputs: [109 -> (1, 1, 60, 60)[FLOAT]], [110 -> ()[FLOAT]], [111 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 110 for ONNX node: 110
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 111 for ONNX node: 111
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 112 for ONNX tensor: 112
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_5 [DequantizeLinear] outputs: [112 -> (1, 1, 60, 60)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_6 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_6 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_6 [Constant] outputs: [113 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_7 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_7 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_7 [Constant] outputs: [114 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_8 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 113
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 114
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_8 [QuantizeLinear] inputs: [conv1.0.weight -> (64, 1, 3, 3)[FLOAT]], [113 -> ()[FLOAT]], [114 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv1.0.weight for ONNX node: conv1.0.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 113 for ONNX node: 113
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 114 for ONNX node: 114
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 115 for ONNX tensor: 115
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_8 [QuantizeLinear] outputs: [115 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_9 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_9 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_9 [Constant] outputs: [116 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_10 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_10 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_10 [Constant] outputs: [117 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_11 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 115
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 116
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 117
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_11 [DequantizeLinear] inputs: [115 -> (64, 1, 3, 3)[FLOAT]], [116 -> ()[FLOAT]], [117 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 116 for ONNX node: 116
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 117 for ONNX node: 117
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 118 for ONNX tensor: 118
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_11 [DequantizeLinear] outputs: [118 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_12 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 112
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 118
[03/01/2023-10:40:47] [V] [TRT] Conv_12 [Conv] inputs: [112 -> (1, 1, 60, 60)[FLOAT]], [118 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_12 for ONNX node: Conv_12
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 119 for ONNX tensor: 119
[03/01/2023-10:40:47] [V] [TRT] Conv_12 [Conv] outputs: [119 -> (1, 64, 58, 58)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_13 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 119
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.1.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.1.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_13 [BatchNormalization] inputs: [119 -> (1, 64, 58, 58)[FLOAT]], [conv1.1.weight -> (64)[FLOAT]], [conv1.1.bias -> (64)[FLOAT]], [conv1.1.running_mean -> (64)[FLOAT]], [conv1.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_13 for ONNX node: BatchNormalization_13
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 120 for ONNX tensor: 120
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_13 [BatchNormalization] outputs: [120 -> (1, 64, 58, 58)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_14 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 120
[03/01/2023-10:40:47] [V] [TRT] Relu_14 [Relu] inputs: [120 -> (1, 64, 58, 58)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_14 for ONNX node: Relu_14
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 121 for ONNX tensor: 121
[03/01/2023-10:40:47] [V] [TRT] Relu_14 [Relu] outputs: [121 -> (1, 64, 58, 58)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_15 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_15 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_15 [Constant] outputs: [122 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_16 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_16 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_16 [Constant] outputs: [123 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_17 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 121
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 122
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 123
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_17 [QuantizeLinear] inputs: [121 -> (1, 64, 58, 58)[FLOAT]], [122 -> ()[FLOAT]], [123 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 122 for ONNX node: 122
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 123 for ONNX node: 123
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 124 for ONNX tensor: 124
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_17 [QuantizeLinear] outputs: [124 -> (1, 64, 58, 58)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_18 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_18 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_18 [Constant] outputs: [125 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_19 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_19 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_19 [Constant] outputs: [126 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_20 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 124
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 125
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 126
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_20 [DequantizeLinear] inputs: [124 -> (1, 64, 58, 58)[FLOAT]], [125 -> ()[FLOAT]], [126 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 125 for ONNX node: 125
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 126 for ONNX node: 126
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 127 for ONNX tensor: 127
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_20 [DequantizeLinear] outputs: [127 -> (1, 64, 58, 58)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_21 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_21 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_21 [Constant] outputs: [128 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_22 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_22 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_22 [Constant] outputs: [129 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_23 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.3.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 128
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 129
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_23 [QuantizeLinear] inputs: [conv1.3.weight -> (64, 64, 3, 3)[FLOAT]], [128 -> ()[FLOAT]], [129 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv1.3.weight for ONNX node: conv1.3.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 128 for ONNX node: 128
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 129 for ONNX node: 129
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 130 for ONNX tensor: 130
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_23 [QuantizeLinear] outputs: [130 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_24 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_24 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_24 [Constant] outputs: [131 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_25 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_25 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_25 [Constant] outputs: [132 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_26 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 130
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 131
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 132
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_26 [DequantizeLinear] inputs: [130 -> (64, 64, 3, 3)[FLOAT]], [131 -> ()[FLOAT]], [132 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 131 for ONNX node: 131
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 132 for ONNX node: 132
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 133 for ONNX tensor: 133
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_26 [DequantizeLinear] outputs: [133 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_27 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 127
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 133
[03/01/2023-10:40:47] [V] [TRT] Conv_27 [Conv] inputs: [127 -> (1, 64, 58, 58)[FLOAT]], [133 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_27 for ONNX node: Conv_27
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 134 for ONNX tensor: 134
[03/01/2023-10:40:47] [V] [TRT] Conv_27 [Conv] outputs: [134 -> (1, 64, 56, 56)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_28 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 134
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.4.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.4.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv1.4.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_28 [BatchNormalization] inputs: [134 -> (1, 64, 56, 56)[FLOAT]], [conv1.4.weight -> (64)[FLOAT]], [conv1.4.bias -> (64)[FLOAT]], [conv1.4.running_mean -> (64)[FLOAT]], [conv1.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_28 for ONNX node: BatchNormalization_28
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 135 for ONNX tensor: 135
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_28 [BatchNormalization] outputs: [135 -> (1, 64, 56, 56)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_29 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 135
[03/01/2023-10:40:47] [V] [TRT] Relu_29 [Relu] inputs: [135 -> (1, 64, 56, 56)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_29 for ONNX node: Relu_29
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 136 for ONNX tensor: 136
[03/01/2023-10:40:47] [V] [TRT] Relu_29 [Relu] outputs: [136 -> (1, 64, 56, 56)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_30 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 136
[03/01/2023-10:40:47] [V] [TRT] MaxPool_30 [MaxPool] inputs: [136 -> (1, 64, 56, 56)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_30 for ONNX node: MaxPool_30
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 137 for ONNX tensor: 137
[03/01/2023-10:40:47] [V] [TRT] MaxPool_30 [MaxPool] outputs: [137 -> (1, 64, 28, 28)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_31 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_31 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_31 [Constant] outputs: [138 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_32 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_32 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_32 [Constant] outputs: [139 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_33 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 137
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 138
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 139
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_33 [QuantizeLinear] inputs: [137 -> (1, 64, 28, 28)[FLOAT]], [138 -> ()[FLOAT]], [139 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 138 for ONNX node: 138
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 139 for ONNX node: 139
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 140 for ONNX tensor: 140
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_33 [QuantizeLinear] outputs: [140 -> (1, 64, 28, 28)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_34 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_34 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_34 [Constant] outputs: [141 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_35 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_35 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_35 [Constant] outputs: [142 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_36 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 140
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 141
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 142
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_36 [DequantizeLinear] inputs: [140 -> (1, 64, 28, 28)[FLOAT]], [141 -> ()[FLOAT]], [142 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 141 for ONNX node: 141
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 142 for ONNX node: 142
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 143 for ONNX tensor: 143
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_36 [DequantizeLinear] outputs: [143 -> (1, 64, 28, 28)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_37 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_37 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_37 [Constant] outputs: [144 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_38 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_38 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_38 [Constant] outputs: [145 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_39 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 144
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 145
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_39 [QuantizeLinear] inputs: [conv2.0.weight -> (128, 64, 3, 3)[FLOAT]], [144 -> ()[FLOAT]], [145 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv2.0.weight for ONNX node: conv2.0.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 144 for ONNX node: 144
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 145 for ONNX node: 145
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 146 for ONNX tensor: 146
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_39 [QuantizeLinear] outputs: [146 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_40 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_40 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_40 [Constant] outputs: [147 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_41 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_41 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_41 [Constant] outputs: [148 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_42 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 146
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 147
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 148
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_42 [DequantizeLinear] inputs: [146 -> (128, 64, 3, 3)[FLOAT]], [147 -> ()[FLOAT]], [148 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 147 for ONNX node: 147
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 148 for ONNX node: 148
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 149 for ONNX tensor: 149
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_42 [DequantizeLinear] outputs: [149 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_43 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 143
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 149
[03/01/2023-10:40:47] [V] [TRT] Conv_43 [Conv] inputs: [143 -> (1, 64, 28, 28)[FLOAT]], [149 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_43 for ONNX node: Conv_43
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 150 for ONNX tensor: 150
[03/01/2023-10:40:47] [V] [TRT] Conv_43 [Conv] outputs: [150 -> (1, 128, 26, 26)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_44 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 150
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.1.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.1.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_44 [BatchNormalization] inputs: [150 -> (1, 128, 26, 26)[FLOAT]], [conv2.1.weight -> (128)[FLOAT]], [conv2.1.bias -> (128)[FLOAT]], [conv2.1.running_mean -> (128)[FLOAT]], [conv2.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_44 for ONNX node: BatchNormalization_44
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 151 for ONNX tensor: 151
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_44 [BatchNormalization] outputs: [151 -> (1, 128, 26, 26)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_45 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 151
[03/01/2023-10:40:47] [V] [TRT] Relu_45 [Relu] inputs: [151 -> (1, 128, 26, 26)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_45 for ONNX node: Relu_45
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 152 for ONNX tensor: 152
[03/01/2023-10:40:47] [V] [TRT] Relu_45 [Relu] outputs: [152 -> (1, 128, 26, 26)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_46 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_46 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_46 [Constant] outputs: [153 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_47 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_47 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_47 [Constant] outputs: [154 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_48 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 152
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 153
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 154
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_48 [QuantizeLinear] inputs: [152 -> (1, 128, 26, 26)[FLOAT]], [153 -> ()[FLOAT]], [154 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 153 for ONNX node: 153
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 154 for ONNX node: 154
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 155 for ONNX tensor: 155
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_48 [QuantizeLinear] outputs: [155 -> (1, 128, 26, 26)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_49 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_49 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_49 [Constant] outputs: [156 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_50 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_50 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_50 [Constant] outputs: [157 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_51 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 155
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 156
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 157
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_51 [DequantizeLinear] inputs: [155 -> (1, 128, 26, 26)[FLOAT]], [156 -> ()[FLOAT]], [157 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 156 for ONNX node: 156
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 157 for ONNX node: 157
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 158 for ONNX tensor: 158
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_51 [DequantizeLinear] outputs: [158 -> (1, 128, 26, 26)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_52 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_52 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_52 [Constant] outputs: [159 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_53 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_53 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_53 [Constant] outputs: [160 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_54 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.3.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 159
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 160
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_54 [QuantizeLinear] inputs: [conv2.3.weight -> (128, 128, 3, 3)[FLOAT]], [159 -> ()[FLOAT]], [160 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv2.3.weight for ONNX node: conv2.3.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 159 for ONNX node: 159
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 160 for ONNX node: 160
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 161 for ONNX tensor: 161
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_54 [QuantizeLinear] outputs: [161 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_55 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_55 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_55 [Constant] outputs: [162 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_56 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_56 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_56 [Constant] outputs: [163 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_57 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 161
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 162
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 163
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_57 [DequantizeLinear] inputs: [161 -> (128, 128, 3, 3)[FLOAT]], [162 -> ()[FLOAT]], [163 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 162 for ONNX node: 162
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 163 for ONNX node: 163
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 164 for ONNX tensor: 164
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_57 [DequantizeLinear] outputs: [164 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_58 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 158
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 164
[03/01/2023-10:40:47] [V] [TRT] Conv_58 [Conv] inputs: [158 -> (1, 128, 26, 26)[FLOAT]], [164 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_58 for ONNX node: Conv_58
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 165 for ONNX tensor: 165
[03/01/2023-10:40:47] [V] [TRT] Conv_58 [Conv] outputs: [165 -> (1, 128, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_59 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 165
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.4.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.4.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv2.4.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_59 [BatchNormalization] inputs: [165 -> (1, 128, 24, 24)[FLOAT]], [conv2.4.weight -> (128)[FLOAT]], [conv2.4.bias -> (128)[FLOAT]], [conv2.4.running_mean -> (128)[FLOAT]], [conv2.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_59 for ONNX node: BatchNormalization_59
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 166 for ONNX tensor: 166
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_59 [BatchNormalization] outputs: [166 -> (1, 128, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_60 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 166
[03/01/2023-10:40:47] [V] [TRT] Relu_60 [Relu] inputs: [166 -> (1, 128, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_60 for ONNX node: Relu_60
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 167 for ONNX tensor: 167
[03/01/2023-10:40:47] [V] [TRT] Relu_60 [Relu] outputs: [167 -> (1, 128, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_61 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 167
[03/01/2023-10:40:47] [V] [TRT] MaxPool_61 [MaxPool] inputs: [167 -> (1, 128, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_61 for ONNX node: MaxPool_61
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 168 for ONNX tensor: 168
[03/01/2023-10:40:47] [V] [TRT] MaxPool_61 [MaxPool] outputs: [168 -> (1, 128, 12, 12)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Shape_62 [Shape]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 168
[03/01/2023-10:40:47] [V] [TRT] Shape_62 [Shape] inputs: [168 -> (1, 128, 12, 12)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Shape_62 for ONNX node: Shape_62
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 170 for ONNX tensor: 170
[03/01/2023-10:40:47] [V] [TRT] Shape_62 [Shape] outputs: [170 -> (4)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_63 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_63 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_63 [Constant] outputs: [171 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_64 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_64 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_64 [Constant] outputs: [172 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_65 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_65 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_65 [Constant] outputs: [173 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Slice_66 [Slice]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 170
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 172
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 173
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 171
[03/01/2023-10:40:47] [V] [TRT] Slice_66 [Slice] inputs: [170 -> (4)[INT32]], [172 -> (1)[INT32]], [173 -> (1)[INT32]], [171 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Slice_66 for ONNX node: Slice_66
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 174 for ONNX tensor: 174
[03/01/2023-10:40:47] [V] [TRT] Slice_66 [Slice] outputs: [174 -> (2)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Concat_67 [Concat]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 174
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 2720
[03/01/2023-10:40:47] [V] [TRT] Concat_67 [Concat] inputs: [174 -> (2)[INT32]], [2720 -> (2)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 2720 for ONNX node: 2720
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Concat_67 for ONNX node: Concat_67
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 176 for ONNX tensor: 176
[03/01/2023-10:40:47] [V] [TRT] Concat_67 [Concat] outputs: [176 -> (4)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Resize_68 [Resize]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 168
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 176
[03/01/2023-10:40:47] [V] [TRT] Resize_68 [Resize] inputs: [168 -> (1, 128, 12, 12)[FLOAT]], [optional input, not set], [optional input, not set], [176 -> (4)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Resize_68 for ONNX node: Resize_68
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 179 for ONNX tensor: 179
[03/01/2023-10:40:47] [V] [TRT] Resize_68 [Resize] outputs: [179 -> (1, 128, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_69 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_69 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_69 [Constant] outputs: [180 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_70 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_70 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_70 [Constant] outputs: [181 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_71 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 168
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 180
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 181
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_71 [QuantizeLinear] inputs: [168 -> (1, 128, 12, 12)[FLOAT]], [180 -> ()[FLOAT]], [181 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 180 for ONNX node: 180
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 181 for ONNX node: 181
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 182 for ONNX tensor: 182
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_71 [QuantizeLinear] outputs: [182 -> (1, 128, 12, 12)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_72 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_72 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_72 [Constant] outputs: [183 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_73 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_73 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_73 [Constant] outputs: [184 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_74 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 182
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 183
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 184
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_74 [DequantizeLinear] inputs: [182 -> (1, 128, 12, 12)[FLOAT]], [183 -> ()[FLOAT]], [184 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 183 for ONNX node: 183
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 184 for ONNX node: 184
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 185 for ONNX tensor: 185
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_74 [DequantizeLinear] outputs: [185 -> (1, 128, 12, 12)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_75 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_75 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_75 [Constant] outputs: [186 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_76 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_76 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_76 [Constant] outputs: [187 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_77 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 186
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 187
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_77 [QuantizeLinear] inputs: [conv3.0.weight -> (256, 128, 3, 3)[FLOAT]], [186 -> ()[FLOAT]], [187 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv3.0.weight for ONNX node: conv3.0.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 186 for ONNX node: 186
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 187 for ONNX node: 187
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 188 for ONNX tensor: 188
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_77 [QuantizeLinear] outputs: [188 -> (256, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_78 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_78 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_78 [Constant] outputs: [189 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_79 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_79 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_79 [Constant] outputs: [190 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_80 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 188
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 189
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 190
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_80 [DequantizeLinear] inputs: [188 -> (256, 128, 3, 3)[FLOAT]], [189 -> ()[FLOAT]], [190 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 189 for ONNX node: 189
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 190 for ONNX node: 190
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 191 for ONNX tensor: 191
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_80 [DequantizeLinear] outputs: [191 -> (256, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_81 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 185
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 191
[03/01/2023-10:40:47] [V] [TRT] Conv_81 [Conv] inputs: [185 -> (1, 128, 12, 12)[FLOAT]], [191 -> (256, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_81 for ONNX node: Conv_81
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 192 for ONNX tensor: 192
[03/01/2023-10:40:47] [V] [TRT] Conv_81 [Conv] outputs: [192 -> (1, 256, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_82 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 192
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.1.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.1.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_82 [BatchNormalization] inputs: [192 -> (1, 256, 10, 10)[FLOAT]], [conv3.1.weight -> (256)[FLOAT]], [conv3.1.bias -> (256)[FLOAT]], [conv3.1.running_mean -> (256)[FLOAT]], [conv3.1.running_var -> (256)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_82 for ONNX node: BatchNormalization_82
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 193 for ONNX tensor: 193
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_82 [BatchNormalization] outputs: [193 -> (1, 256, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_83 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 193
[03/01/2023-10:40:47] [V] [TRT] Relu_83 [Relu] inputs: [193 -> (1, 256, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_83 for ONNX node: Relu_83
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 194 for ONNX tensor: 194
[03/01/2023-10:40:47] [V] [TRT] Relu_83 [Relu] outputs: [194 -> (1, 256, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_84 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_84 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_84 [Constant] outputs: [195 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_85 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_85 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_85 [Constant] outputs: [196 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_86 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 194
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 195
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 196
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_86 [QuantizeLinear] inputs: [194 -> (1, 256, 10, 10)[FLOAT]], [195 -> ()[FLOAT]], [196 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 195 for ONNX node: 195
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 196 for ONNX node: 196
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 197 for ONNX tensor: 197
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_86 [QuantizeLinear] outputs: [197 -> (1, 256, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_87 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_87 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_87 [Constant] outputs: [198 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_88 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_88 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_88 [Constant] outputs: [199 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_89 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 197
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 198
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 199
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_89 [DequantizeLinear] inputs: [197 -> (1, 256, 10, 10)[FLOAT]], [198 -> ()[FLOAT]], [199 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 198 for ONNX node: 198
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 199 for ONNX node: 199
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 200 for ONNX tensor: 200
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_89 [DequantizeLinear] outputs: [200 -> (1, 256, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_90 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_90 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_90 [Constant] outputs: [201 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_91 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_91 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_91 [Constant] outputs: [202 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_92 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.3.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 201
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 202
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_92 [QuantizeLinear] inputs: [conv3.3.weight -> (256, 256, 3, 3)[FLOAT]], [201 -> ()[FLOAT]], [202 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv3.3.weight for ONNX node: conv3.3.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 201 for ONNX node: 201
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 202 for ONNX node: 202
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 203 for ONNX tensor: 203
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_92 [QuantizeLinear] outputs: [203 -> (256, 256, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_93 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_93 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_93 [Constant] outputs: [204 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_94 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_94 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_94 [Constant] outputs: [205 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_95 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 203
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 204
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 205
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_95 [DequantizeLinear] inputs: [203 -> (256, 256, 3, 3)[FLOAT]], [204 -> ()[FLOAT]], [205 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 204 for ONNX node: 204
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 205 for ONNX node: 205
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 206 for ONNX tensor: 206
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_95 [DequantizeLinear] outputs: [206 -> (256, 256, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_96 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 200
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 206
[03/01/2023-10:40:47] [V] [TRT] Conv_96 [Conv] inputs: [200 -> (1, 256, 10, 10)[FLOAT]], [206 -> (256, 256, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_96 for ONNX node: Conv_96
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 207 for ONNX tensor: 207
[03/01/2023-10:40:47] [V] [TRT] Conv_96 [Conv] outputs: [207 -> (1, 256, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_97 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 207
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.4.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.4.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv3.4.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_97 [BatchNormalization] inputs: [207 -> (1, 256, 8, 8)[FLOAT]], [conv3.4.weight -> (256)[FLOAT]], [conv3.4.bias -> (256)[FLOAT]], [conv3.4.running_mean -> (256)[FLOAT]], [conv3.4.running_var -> (256)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_97 for ONNX node: BatchNormalization_97
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 208 for ONNX tensor: 208
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_97 [BatchNormalization] outputs: [208 -> (1, 256, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_98 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 208
[03/01/2023-10:40:47] [V] [TRT] Relu_98 [Relu] inputs: [208 -> (1, 256, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_98 for ONNX node: Relu_98
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 209 for ONNX tensor: 209
[03/01/2023-10:40:47] [V] [TRT] Relu_98 [Relu] outputs: [209 -> (1, 256, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_99 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 209
[03/01/2023-10:40:47] [V] [TRT] MaxPool_99 [MaxPool] inputs: [209 -> (1, 256, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_99 for ONNX node: MaxPool_99
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 210 for ONNX tensor: 210
[03/01/2023-10:40:47] [V] [TRT] MaxPool_99 [MaxPool] outputs: [210 -> (1, 256, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Concat_100 [Concat]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 210
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 179
[03/01/2023-10:40:47] [V] [TRT] Concat_100 [Concat] inputs: [210 -> (1, 256, 4, 4)[FLOAT]], [179 -> (1, 128, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Concat_100 for ONNX node: Concat_100
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 211 for ONNX tensor: 211
[03/01/2023-10:40:47] [V] [TRT] Concat_100 [Concat] outputs: [211 -> (1, 384, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: ReduceMean_101 [ReduceMean]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 211
[03/01/2023-10:40:47] [V] [TRT] ReduceMean_101 [ReduceMean] inputs: [211 -> (1, 384, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: ReduceMean_101 for ONNX node: ReduceMean_101
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 212 for ONNX tensor: 212
[03/01/2023-10:40:47] [V] [TRT] ReduceMean_101 [ReduceMean] outputs: [212 -> (1, 1, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: ReduceMax_102 [ReduceMax]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 211
[03/01/2023-10:40:47] [V] [TRT] ReduceMax_102 [ReduceMax] inputs: [211 -> (1, 384, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: ReduceMax_102 for ONNX node: ReduceMax_102
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 213 for ONNX tensor: 213
[03/01/2023-10:40:47] [V] [TRT] ReduceMax_102 [ReduceMax] outputs: [213 -> (1, 1, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Concat_103 [Concat]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 212
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 213
[03/01/2023-10:40:47] [V] [TRT] Concat_103 [Concat] inputs: [212 -> (1, 1, 4, 4)[FLOAT]], [213 -> (1, 1, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Concat_103 for ONNX node: Concat_103
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 214 for ONNX tensor: 214
[03/01/2023-10:40:47] [V] [TRT] Concat_103 [Concat] outputs: [214 -> (1, 2, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_104 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_104 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_104 [Constant] outputs: [215 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_105 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_105 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_105 [Constant] outputs: [216 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_106 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 214
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 215
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 216
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_106 [QuantizeLinear] inputs: [214 -> (1, 2, 4, 4)[FLOAT]], [215 -> ()[FLOAT]], [216 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 215 for ONNX node: 215
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 216 for ONNX node: 216
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 217 for ONNX tensor: 217
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_106 [QuantizeLinear] outputs: [217 -> (1, 2, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_107 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_107 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_107 [Constant] outputs: [218 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_108 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_108 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_108 [Constant] outputs: [219 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_109 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 217
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 218
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 219
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_109 [DequantizeLinear] inputs: [217 -> (1, 2, 4, 4)[FLOAT]], [218 -> ()[FLOAT]], [219 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 218 for ONNX node: 218
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 219 for ONNX node: 219
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 220 for ONNX tensor: 220
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_109 [DequantizeLinear] outputs: [220 -> (1, 2, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_110 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_110 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_110 [Constant] outputs: [221 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_111 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_111 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_111 [Constant] outputs: [222 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_112 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: attention_spatial.conv1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 221
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 222
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_112 [QuantizeLinear] inputs: [attention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [221 -> ()[FLOAT]], [222 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: attention_spatial.conv1.weight for ONNX node: attention_spatial.conv1.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 221 for ONNX node: 221
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 222 for ONNX node: 222
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 223 for ONNX tensor: 223
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_112 [QuantizeLinear] outputs: [223 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_113 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_113 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_113 [Constant] outputs: [224 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_114 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_114 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_114 [Constant] outputs: [225 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_115 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 223
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 224
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 225
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_115 [DequantizeLinear] inputs: [223 -> (1, 2, 7, 7)[FLOAT]], [224 -> ()[FLOAT]], [225 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 224 for ONNX node: 224
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 225 for ONNX node: 225
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 226 for ONNX tensor: 226
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_115 [DequantizeLinear] outputs: [226 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_116 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 220
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 226
[03/01/2023-10:40:47] [V] [TRT] Conv_116 [Conv] inputs: [220 -> (1, 2, 4, 4)[FLOAT]], [226 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_116 for ONNX node: Conv_116
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 227 for ONNX tensor: 227
[03/01/2023-10:40:47] [V] [TRT] Conv_116 [Conv] outputs: [227 -> (1, 1, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Sigmoid_117 [Sigmoid]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 227
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_117 [Sigmoid] inputs: [227 -> (1, 1, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Sigmoid_117 for ONNX node: Sigmoid_117
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 228 for ONNX tensor: 228
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_117 [Sigmoid] outputs: [228 -> (1, 1, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Mul_118 [Mul]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 211
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 228
[03/01/2023-10:40:47] [V] [TRT] Mul_118 [Mul] inputs: [211 -> (1, 384, 4, 4)[FLOAT]], [228 -> (1, 1, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Mul_118 for ONNX node: Mul_118
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 229 for ONNX tensor: 229
[03/01/2023-10:40:47] [V] [TRT] Mul_118 [Mul] outputs: [229 -> (1, 384, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: GlobalAveragePool_119 [GlobalAveragePool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 229
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool_119 [GlobalAveragePool] inputs: [229 -> (1, 384, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:47] [V] [TRT] Registering layer: GlobalAveragePool_119 for ONNX node: GlobalAveragePool_119
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 230 for ONNX tensor: 230
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool_119 [GlobalAveragePool] outputs: [230 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_120 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_120 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_120 [Constant] outputs: [231 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_121 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_121 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_121 [Constant] outputs: [232 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_122 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 230
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 231
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 232
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_122 [QuantizeLinear] inputs: [230 -> (1, 384, 1, 1)[FLOAT]], [231 -> ()[FLOAT]], [232 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 231 for ONNX node: 231
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 232 for ONNX node: 232
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 233 for ONNX tensor: 233
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_122 [QuantizeLinear] outputs: [233 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_123 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_123 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_123 [Constant] outputs: [234 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_124 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_124 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_124 [Constant] outputs: [235 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_125 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 233
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 234
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 235
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_125 [DequantizeLinear] inputs: [233 -> (1, 384, 1, 1)[FLOAT]], [234 -> ()[FLOAT]], [235 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 234 for ONNX node: 234
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 235 for ONNX node: 235
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 236 for ONNX tensor: 236
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_125 [DequantizeLinear] outputs: [236 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_126 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_126 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_126 [Constant] outputs: [237 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_127 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_127 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_127 [Constant] outputs: [238 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_128 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: attention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 237
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 238
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_128 [QuantizeLinear] inputs: [attention_channel.fc.0.weight -> (24, 384, 1, 1)[FLOAT]], [237 -> ()[FLOAT]], [238 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: attention_channel.fc.0.weight for ONNX node: attention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 237 for ONNX node: 237
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 238 for ONNX node: 238
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 239 for ONNX tensor: 239
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_128 [QuantizeLinear] outputs: [239 -> (24, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_129 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_129 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_129 [Constant] outputs: [240 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_130 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_130 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_130 [Constant] outputs: [241 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_131 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 239
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 240
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 241
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_131 [DequantizeLinear] inputs: [239 -> (24, 384, 1, 1)[FLOAT]], [240 -> ()[FLOAT]], [241 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 240 for ONNX node: 240
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 241 for ONNX node: 241
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 242 for ONNX tensor: 242
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_131 [DequantizeLinear] outputs: [242 -> (24, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_132 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 236
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 242
[03/01/2023-10:40:47] [V] [TRT] Conv_132 [Conv] inputs: [236 -> (1, 384, 1, 1)[FLOAT]], [242 -> (24, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_132 for ONNX node: Conv_132
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 243 for ONNX tensor: 243
[03/01/2023-10:40:47] [V] [TRT] Conv_132 [Conv] outputs: [243 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_133 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 243
[03/01/2023-10:40:47] [V] [TRT] Relu_133 [Relu] inputs: [243 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_133 for ONNX node: Relu_133
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 244 for ONNX tensor: 244
[03/01/2023-10:40:47] [V] [TRT] Relu_133 [Relu] outputs: [244 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_134 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_134 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_134 [Constant] outputs: [245 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_135 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_135 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_135 [Constant] outputs: [246 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_136 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 244
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 245
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 246
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_136 [QuantizeLinear] inputs: [244 -> (1, 24, 1, 1)[FLOAT]], [245 -> ()[FLOAT]], [246 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 245 for ONNX node: 245
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 246 for ONNX node: 246
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 247 for ONNX tensor: 247
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_136 [QuantizeLinear] outputs: [247 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_137 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_137 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_137 [Constant] outputs: [248 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_138 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_138 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_138 [Constant] outputs: [249 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_139 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 247
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 248
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 249
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_139 [DequantizeLinear] inputs: [247 -> (1, 24, 1, 1)[FLOAT]], [248 -> ()[FLOAT]], [249 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 248 for ONNX node: 248
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 249 for ONNX node: 249
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 250 for ONNX tensor: 250
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_139 [DequantizeLinear] outputs: [250 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_140 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_140 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_140 [Constant] outputs: [251 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_141 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_141 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_141 [Constant] outputs: [252 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_142 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: attention_channel.fc.2.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 251
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 252
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_142 [QuantizeLinear] inputs: [attention_channel.fc.2.weight -> (384, 24, 1, 1)[FLOAT]], [251 -> ()[FLOAT]], [252 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: attention_channel.fc.2.weight for ONNX node: attention_channel.fc.2.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 251 for ONNX node: 251
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 252 for ONNX node: 252
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 253 for ONNX tensor: 253
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_142 [QuantizeLinear] outputs: [253 -> (384, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_143 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_143 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_143 [Constant] outputs: [254 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_144 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_144 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_144 [Constant] outputs: [255 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_145 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 253
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 254
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 255
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_145 [DequantizeLinear] inputs: [253 -> (384, 24, 1, 1)[FLOAT]], [254 -> ()[FLOAT]], [255 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 254 for ONNX node: 254
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 255 for ONNX node: 255
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 256 for ONNX tensor: 256
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_145 [DequantizeLinear] outputs: [256 -> (384, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_146 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 250
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 256
[03/01/2023-10:40:47] [V] [TRT] Conv_146 [Conv] inputs: [250 -> (1, 24, 1, 1)[FLOAT]], [256 -> (384, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_146 for ONNX node: Conv_146
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 257 for ONNX tensor: 257
[03/01/2023-10:40:47] [V] [TRT] Conv_146 [Conv] outputs: [257 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_147 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 229
[03/01/2023-10:40:47] [V] [TRT] MaxPool_147 [MaxPool] inputs: [229 -> (1, 384, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_147 for ONNX node: MaxPool_147
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 258 for ONNX tensor: 258
[03/01/2023-10:40:47] [V] [TRT] MaxPool_147 [MaxPool] outputs: [258 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_148 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_148 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_148 [Constant] outputs: [259 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_149 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_149 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_149 [Constant] outputs: [260 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_150 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 258
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 259
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 260
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_150 [QuantizeLinear] inputs: [258 -> (1, 384, 1, 1)[FLOAT]], [259 -> ()[FLOAT]], [260 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 259 for ONNX node: 259
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 260 for ONNX node: 260
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 261 for ONNX tensor: 261
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_150 [QuantizeLinear] outputs: [261 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_151 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_151 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_151 [Constant] outputs: [262 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_152 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_152 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_152 [Constant] outputs: [263 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_153 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 261
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 262
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 263
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_153 [DequantizeLinear] inputs: [261 -> (1, 384, 1, 1)[FLOAT]], [262 -> ()[FLOAT]], [263 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 262 for ONNX node: 262
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 263 for ONNX node: 263
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 264 for ONNX tensor: 264
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_153 [DequantizeLinear] outputs: [264 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_154 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_154 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_154 [Constant] outputs: [265 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_155 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_155 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_155 [Constant] outputs: [266 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_156 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: attention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 265
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 266
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_156 [QuantizeLinear] inputs: [attention_channel.fc.0.weight -> (24, 384, 1, 1)[FLOAT]], [265 -> ()[FLOAT]], [266 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 265 for ONNX node: 265
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 266 for ONNX node: 266
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 267 for ONNX tensor: 267
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_156 [QuantizeLinear] outputs: [267 -> (24, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_157 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_157 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_157 [Constant] outputs: [268 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_158 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_158 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_158 [Constant] outputs: [269 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_159 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 267
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 268
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 269
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_159 [DequantizeLinear] inputs: [267 -> (24, 384, 1, 1)[FLOAT]], [268 -> ()[FLOAT]], [269 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 268 for ONNX node: 268
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 269 for ONNX node: 269
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 270 for ONNX tensor: 270
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_159 [DequantizeLinear] outputs: [270 -> (24, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_160 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 264
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 270
[03/01/2023-10:40:47] [V] [TRT] Conv_160 [Conv] inputs: [264 -> (1, 384, 1, 1)[FLOAT]], [270 -> (24, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_160 for ONNX node: Conv_160
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 271 for ONNX tensor: 271
[03/01/2023-10:40:47] [V] [TRT] Conv_160 [Conv] outputs: [271 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_161 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 271
[03/01/2023-10:40:47] [V] [TRT] Relu_161 [Relu] inputs: [271 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_161 for ONNX node: Relu_161
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 272 for ONNX tensor: 272
[03/01/2023-10:40:47] [V] [TRT] Relu_161 [Relu] outputs: [272 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_162 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_162 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_162 [Constant] outputs: [273 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_163 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_163 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_163 [Constant] outputs: [274 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_164 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 272
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 273
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 274
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_164 [QuantizeLinear] inputs: [272 -> (1, 24, 1, 1)[FLOAT]], [273 -> ()[FLOAT]], [274 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 273 for ONNX node: 273
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 274 for ONNX node: 274
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 275 for ONNX tensor: 275
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_164 [QuantizeLinear] outputs: [275 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_165 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_165 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_165 [Constant] outputs: [276 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_166 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_166 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_166 [Constant] outputs: [277 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_167 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 275
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 276
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 277
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_167 [DequantizeLinear] inputs: [275 -> (1, 24, 1, 1)[FLOAT]], [276 -> ()[FLOAT]], [277 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 276 for ONNX node: 276
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 277 for ONNX node: 277
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 278 for ONNX tensor: 278
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_167 [DequantizeLinear] outputs: [278 -> (1, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_168 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_168 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_168 [Constant] outputs: [279 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_169 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_169 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_169 [Constant] outputs: [280 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_170 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: attention_channel.fc.2.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 279
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 280
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_170 [QuantizeLinear] inputs: [attention_channel.fc.2.weight -> (384, 24, 1, 1)[FLOAT]], [279 -> ()[FLOAT]], [280 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 279 for ONNX node: 279
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 280 for ONNX node: 280
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 281 for ONNX tensor: 281
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_170 [QuantizeLinear] outputs: [281 -> (384, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_171 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_171 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_171 [Constant] outputs: [282 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_172 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_172 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_172 [Constant] outputs: [283 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_173 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 281
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 282
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 283
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_173 [DequantizeLinear] inputs: [281 -> (384, 24, 1, 1)[FLOAT]], [282 -> ()[FLOAT]], [283 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 282 for ONNX node: 282
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 283 for ONNX node: 283
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 284 for ONNX tensor: 284
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_173 [DequantizeLinear] outputs: [284 -> (384, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_174 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 278
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 284
[03/01/2023-10:40:47] [V] [TRT] Conv_174 [Conv] inputs: [278 -> (1, 24, 1, 1)[FLOAT]], [284 -> (384, 24, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_174 for ONNX node: Conv_174
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 285 for ONNX tensor: 285
[03/01/2023-10:40:47] [V] [TRT] Conv_174 [Conv] outputs: [285 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Add_175 [Add]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 257
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 285
[03/01/2023-10:40:47] [V] [TRT] Add_175 [Add] inputs: [257 -> (1, 384, 1, 1)[FLOAT]], [285 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Add_175 for ONNX node: Add_175
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 286 for ONNX tensor: 286
[03/01/2023-10:40:47] [V] [TRT] Add_175 [Add] outputs: [286 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Sigmoid_176 [Sigmoid]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 286
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_176 [Sigmoid] inputs: [286 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Sigmoid_176 for ONNX node: Sigmoid_176
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 287 for ONNX tensor: 287
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_176 [Sigmoid] outputs: [287 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Mul_177 [Mul]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 229
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 287
[03/01/2023-10:40:47] [V] [TRT] Mul_177 [Mul] inputs: [229 -> (1, 384, 4, 4)[FLOAT]], [287 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Mul_177 for ONNX node: Mul_177
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 288 for ONNX tensor: 288
[03/01/2023-10:40:47] [V] [TRT] Mul_177 [Mul] outputs: [288 -> (1, 384, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: GlobalAveragePool_178 [GlobalAveragePool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 288
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool_178 [GlobalAveragePool] inputs: [288 -> (1, 384, 4, 4)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:47] [V] [TRT] Registering layer: GlobalAveragePool_178 for ONNX node: GlobalAveragePool_178
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 289 for ONNX tensor: 289
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool_178 [GlobalAveragePool] outputs: [289 -> (1, 384, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_179 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_179 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_179 [Constant] outputs: [290 -> (2)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Reshape_180 [Reshape]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 289
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 290
[03/01/2023-10:40:47] [V] [TRT] Reshape_180 [Reshape] inputs: [289 -> (1, 384, 1, 1)[FLOAT]], [290 -> (2)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Reshape_180 for ONNX node: Reshape_180
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 291 for ONNX tensor: 291
[03/01/2023-10:40:47] [V] [TRT] Reshape_180 [Reshape] outputs: [291 -> (1, 384)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_181 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_181 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_181 [Constant] outputs: [292 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_182 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_182 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_182 [Constant] outputs: [293 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_183 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 291
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 292
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 293
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_183 [QuantizeLinear] inputs: [291 -> (1, 384)[FLOAT]], [292 -> ()[FLOAT]], [293 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 292 for ONNX node: 292
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 293 for ONNX node: 293
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 294 for ONNX tensor: 294
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_183 [QuantizeLinear] outputs: [294 -> (1, 384)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_184 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_184 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_184 [Constant] outputs: [295 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_185 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_185 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_185 [Constant] outputs: [296 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_186 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 294
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 295
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 296
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_186 [DequantizeLinear] inputs: [294 -> (1, 384)[FLOAT]], [295 -> ()[FLOAT]], [296 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 295 for ONNX node: 295
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 296 for ONNX node: 296
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 297 for ONNX tensor: 297
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_186 [DequantizeLinear] outputs: [297 -> (1, 384)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_187 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_187 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_187 [Constant] outputs: [298 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_188 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_188 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_188 [Constant] outputs: [299 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_189 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: classfier1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 298
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 299
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_189 [QuantizeLinear] inputs: [classfier1.weight -> (6, 384)[FLOAT]], [298 -> ()[FLOAT]], [299 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: classfier1.weight for ONNX node: classfier1.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 298 for ONNX node: 298
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 299 for ONNX node: 299
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 300 for ONNX tensor: 300
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_189 [QuantizeLinear] outputs: [300 -> (6, 384)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_190 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_190 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_190 [Constant] outputs: [301 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_191 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_191 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_191 [Constant] outputs: [302 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_192 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 300
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 301
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 302
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_192 [DequantizeLinear] inputs: [300 -> (6, 384)[FLOAT]], [301 -> ()[FLOAT]], [302 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 301 for ONNX node: 301
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 302 for ONNX node: 302
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 303 for ONNX tensor: 303
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_192 [DequantizeLinear] outputs: [303 -> (6, 384)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Gemm_193 [Gemm]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 297
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 303
[03/01/2023-10:40:47] [V] [TRT] Searching for input: classfier1.bias
[03/01/2023-10:40:47] [V] [TRT] Gemm_193 [Gemm] inputs: [297 -> (1, 384)[FLOAT]], [303 -> (6, 384)[FLOAT]], [classfier1.bias -> (6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Using opA: 0 opB: 1
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Gemm_193 for ONNX node: Gemm_193
[03/01/2023-10:40:47] [V] [TRT] Registering layer: classfier1.bias for ONNX node: classfier1.bias
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: output_64 for ONNX tensor: output
[03/01/2023-10:40:47] [V] [TRT] Gemm_193 [Gemm] outputs: [output -> (1, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_194 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_194 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_194 [Constant] outputs: [305 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_195 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_195 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_195 [Constant] outputs: [306 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_196 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_196 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_196 [Constant] outputs: [307 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_197 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_197 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_197 [Constant] outputs: [308 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Slice_198 [Slice]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: input
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 306
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 307
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 305
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 308
[03/01/2023-10:40:47] [V] [TRT] Slice_198 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [306 -> (1)[INT32]], [307 -> (1)[INT32]], [305 -> (1)[INT32]], [308 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Slice_198 for ONNX node: Slice_198
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 309 for ONNX tensor: 309
[03/01/2023-10:40:47] [V] [TRT] Slice_198 [Slice] outputs: [309 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_199 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_199 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_199 [Constant] outputs: [310 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_200 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_200 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_200 [Constant] outputs: [311 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_201 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_201 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_201 [Constant] outputs: [312 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_202 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_202 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_202 [Constant] outputs: [313 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Slice_203 [Slice]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 309
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 311
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 312
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 310
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 313
[03/01/2023-10:40:47] [V] [TRT] Slice_203 [Slice] inputs: [309 -> (1, 1, 24, 60)[FLOAT]], [311 -> (1)[INT32]], [312 -> (1)[INT32]], [310 -> (1)[INT32]], [313 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Slice_203 for ONNX node: Slice_203
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 314 for ONNX tensor: 314
[03/01/2023-10:40:47] [V] [TRT] Slice_203 [Slice] outputs: [314 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_204 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_204 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_204 [Constant] outputs: [315 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_205 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_205 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_205 [Constant] outputs: [316 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_206 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 314
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 315
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 316
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_206 [QuantizeLinear] inputs: [314 -> (1, 1, 24, 24)[FLOAT]], [315 -> ()[FLOAT]], [316 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 315 for ONNX node: 315
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 316 for ONNX node: 316
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 317 for ONNX tensor: 317
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_206 [QuantizeLinear] outputs: [317 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_207 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_207 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_207 [Constant] outputs: [318 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_208 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_208 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_208 [Constant] outputs: [319 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_209 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 317
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 318
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 319
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_209 [DequantizeLinear] inputs: [317 -> (1, 1, 24, 24)[FLOAT]], [318 -> ()[FLOAT]], [319 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 318 for ONNX node: 318
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 319 for ONNX node: 319
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 320 for ONNX tensor: 320
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_209 [DequantizeLinear] outputs: [320 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_210 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_210 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_210 [Constant] outputs: [321 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_211 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_211 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_211 [Constant] outputs: [322 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_212 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 321
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 322
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_212 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [321 -> ()[FLOAT]], [322 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv4.0.weight for ONNX node: conv4.0.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 321 for ONNX node: 321
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 322 for ONNX node: 322
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 323 for ONNX tensor: 323
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_212 [QuantizeLinear] outputs: [323 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_213 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_213 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_213 [Constant] outputs: [324 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_214 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_214 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_214 [Constant] outputs: [325 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_215 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 323
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 324
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 325
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_215 [DequantizeLinear] inputs: [323 -> (64, 1, 3, 3)[FLOAT]], [324 -> ()[FLOAT]], [325 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 324 for ONNX node: 324
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 325 for ONNX node: 325
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 326 for ONNX tensor: 326
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_215 [DequantizeLinear] outputs: [326 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_216 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 320
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 326
[03/01/2023-10:40:47] [V] [TRT] Conv_216 [Conv] inputs: [320 -> (1, 1, 24, 24)[FLOAT]], [326 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_216 for ONNX node: Conv_216
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 327 for ONNX tensor: 327
[03/01/2023-10:40:47] [V] [TRT] Conv_216 [Conv] outputs: [327 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_217 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 327
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_217 [BatchNormalization] inputs: [327 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_217 for ONNX node: BatchNormalization_217
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 328 for ONNX tensor: 328
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_217 [BatchNormalization] outputs: [328 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_218 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 328
[03/01/2023-10:40:47] [V] [TRT] Relu_218 [Relu] inputs: [328 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_218 for ONNX node: Relu_218
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 329 for ONNX tensor: 329
[03/01/2023-10:40:47] [V] [TRT] Relu_218 [Relu] outputs: [329 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_219 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_219 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_219 [Constant] outputs: [330 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_220 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_220 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_220 [Constant] outputs: [331 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_221 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 329
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 330
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 331
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_221 [QuantizeLinear] inputs: [329 -> (1, 64, 22, 22)[FLOAT]], [330 -> ()[FLOAT]], [331 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 330 for ONNX node: 330
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 331 for ONNX node: 331
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 332 for ONNX tensor: 332
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_221 [QuantizeLinear] outputs: [332 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_222 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_222 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_222 [Constant] outputs: [333 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_223 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_223 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_223 [Constant] outputs: [334 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_224 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 332
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 333
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 334
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_224 [DequantizeLinear] inputs: [332 -> (1, 64, 22, 22)[FLOAT]], [333 -> ()[FLOAT]], [334 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 333 for ONNX node: 333
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 334 for ONNX node: 334
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 335 for ONNX tensor: 335
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_224 [DequantizeLinear] outputs: [335 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_225 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_225 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_225 [Constant] outputs: [336 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_226 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_226 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_226 [Constant] outputs: [337 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_227 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 336
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 337
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_227 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [336 -> ()[FLOAT]], [337 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv4.3.weight for ONNX node: conv4.3.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 336 for ONNX node: 336
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 337 for ONNX node: 337
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 338 for ONNX tensor: 338
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_227 [QuantizeLinear] outputs: [338 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_228 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_228 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_228 [Constant] outputs: [339 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_229 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_229 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_229 [Constant] outputs: [340 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_230 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 338
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 339
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 340
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_230 [DequantizeLinear] inputs: [338 -> (64, 64, 3, 3)[FLOAT]], [339 -> ()[FLOAT]], [340 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 339 for ONNX node: 339
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 340 for ONNX node: 340
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 341 for ONNX tensor: 341
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_230 [DequantizeLinear] outputs: [341 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_231 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 335
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 341
[03/01/2023-10:40:47] [V] [TRT] Conv_231 [Conv] inputs: [335 -> (1, 64, 22, 22)[FLOAT]], [341 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_231 for ONNX node: Conv_231
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 342 for ONNX tensor: 342
[03/01/2023-10:40:47] [V] [TRT] Conv_231 [Conv] outputs: [342 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_232 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 342
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_232 [BatchNormalization] inputs: [342 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_232 for ONNX node: BatchNormalization_232
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 343 for ONNX tensor: 343
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_232 [BatchNormalization] outputs: [343 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_233 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 343
[03/01/2023-10:40:47] [V] [TRT] Relu_233 [Relu] inputs: [343 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_233 for ONNX node: Relu_233
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 344 for ONNX tensor: 344
[03/01/2023-10:40:47] [V] [TRT] Relu_233 [Relu] outputs: [344 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_234 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 344
[03/01/2023-10:40:47] [V] [TRT] MaxPool_234 [MaxPool] inputs: [344 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_234 for ONNX node: MaxPool_234
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 345 for ONNX tensor: 345
[03/01/2023-10:40:47] [V] [TRT] MaxPool_234 [MaxPool] outputs: [345 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_235 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_235 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_235 [Constant] outputs: [346 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_236 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_236 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_236 [Constant] outputs: [347 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_237 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 345
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 346
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 347
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_237 [QuantizeLinear] inputs: [345 -> (1, 64, 10, 10)[FLOAT]], [346 -> ()[FLOAT]], [347 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 346 for ONNX node: 346
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 347 for ONNX node: 347
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 348 for ONNX tensor: 348
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_237 [QuantizeLinear] outputs: [348 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_238 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_238 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_238 [Constant] outputs: [349 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_239 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_239 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_239 [Constant] outputs: [350 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_240 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 348
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 349
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 350
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_240 [DequantizeLinear] inputs: [348 -> (1, 64, 10, 10)[FLOAT]], [349 -> ()[FLOAT]], [350 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 349 for ONNX node: 349
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 350 for ONNX node: 350
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 351 for ONNX tensor: 351
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_240 [DequantizeLinear] outputs: [351 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_241 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_241 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_241 [Constant] outputs: [352 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_242 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_242 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_242 [Constant] outputs: [353 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_243 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 352
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 353
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_243 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [352 -> ()[FLOAT]], [353 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv5.0.weight for ONNX node: conv5.0.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 352 for ONNX node: 352
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 353 for ONNX node: 353
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 354 for ONNX tensor: 354
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_243 [QuantizeLinear] outputs: [354 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_244 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_244 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_244 [Constant] outputs: [355 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_245 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_245 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_245 [Constant] outputs: [356 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_246 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 354
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 355
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 356
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_246 [DequantizeLinear] inputs: [354 -> (128, 64, 3, 3)[FLOAT]], [355 -> ()[FLOAT]], [356 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 355 for ONNX node: 355
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 356 for ONNX node: 356
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 357 for ONNX tensor: 357
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_246 [DequantizeLinear] outputs: [357 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_247 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 351
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 357
[03/01/2023-10:40:47] [V] [TRT] Conv_247 [Conv] inputs: [351 -> (1, 64, 10, 10)[FLOAT]], [357 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_247 for ONNX node: Conv_247
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 358 for ONNX tensor: 358
[03/01/2023-10:40:47] [V] [TRT] Conv_247 [Conv] outputs: [358 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_248 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 358
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_248 [BatchNormalization] inputs: [358 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_248 for ONNX node: BatchNormalization_248
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 359 for ONNX tensor: 359
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_248 [BatchNormalization] outputs: [359 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_249 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 359
[03/01/2023-10:40:47] [V] [TRT] Relu_249 [Relu] inputs: [359 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_249 for ONNX node: Relu_249
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 360 for ONNX tensor: 360
[03/01/2023-10:40:47] [V] [TRT] Relu_249 [Relu] outputs: [360 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_250 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_250 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_250 [Constant] outputs: [361 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_251 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_251 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_251 [Constant] outputs: [362 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_252 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 360
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 361
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 362
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_252 [QuantizeLinear] inputs: [360 -> (1, 128, 8, 8)[FLOAT]], [361 -> ()[FLOAT]], [362 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 361 for ONNX node: 361
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 362 for ONNX node: 362
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 363 for ONNX tensor: 363
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_252 [QuantizeLinear] outputs: [363 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_253 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_253 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_253 [Constant] outputs: [364 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_254 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_254 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_254 [Constant] outputs: [365 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_255 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 363
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 364
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 365
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_255 [DequantizeLinear] inputs: [363 -> (1, 128, 8, 8)[FLOAT]], [364 -> ()[FLOAT]], [365 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 364 for ONNX node: 364
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 365 for ONNX node: 365
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 366 for ONNX tensor: 366
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_255 [DequantizeLinear] outputs: [366 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_256 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_256 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_256 [Constant] outputs: [367 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_257 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_257 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_257 [Constant] outputs: [368 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_258 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 367
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 368
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_258 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [367 -> ()[FLOAT]], [368 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: conv5.3.weight for ONNX node: conv5.3.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 367 for ONNX node: 367
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 368 for ONNX node: 368
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 369 for ONNX tensor: 369
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_258 [QuantizeLinear] outputs: [369 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_259 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_259 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_259 [Constant] outputs: [370 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_260 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_260 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_260 [Constant] outputs: [371 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_261 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 369
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 370
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 371
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_261 [DequantizeLinear] inputs: [369 -> (128, 128, 3, 3)[FLOAT]], [370 -> ()[FLOAT]], [371 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 370 for ONNX node: 370
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 371 for ONNX node: 371
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 372 for ONNX tensor: 372
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_261 [DequantizeLinear] outputs: [372 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_262 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 366
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 372
[03/01/2023-10:40:47] [V] [TRT] Conv_262 [Conv] inputs: [366 -> (1, 128, 8, 8)[FLOAT]], [372 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_262 for ONNX node: Conv_262
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 373 for ONNX tensor: 373
[03/01/2023-10:40:47] [V] [TRT] Conv_262 [Conv] outputs: [373 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_263 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 373
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_263 [BatchNormalization] inputs: [373 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_263 for ONNX node: BatchNormalization_263
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 374 for ONNX tensor: 374
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_263 [BatchNormalization] outputs: [374 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_264 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 374
[03/01/2023-10:40:47] [V] [TRT] Relu_264 [Relu] inputs: [374 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_264 for ONNX node: Relu_264
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 375 for ONNX tensor: 375
[03/01/2023-10:40:47] [V] [TRT] Relu_264 [Relu] outputs: [375 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_265 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 375
[03/01/2023-10:40:47] [V] [TRT] MaxPool_265 [MaxPool] inputs: [375 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_265 for ONNX node: MaxPool_265
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 376 for ONNX tensor: 376
[03/01/2023-10:40:47] [V] [TRT] MaxPool_265 [MaxPool] outputs: [376 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: ReduceMean_266 [ReduceMean]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 376
[03/01/2023-10:40:47] [V] [TRT] ReduceMean_266 [ReduceMean] inputs: [376 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: ReduceMean_266 for ONNX node: ReduceMean_266
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 377 for ONNX tensor: 377
[03/01/2023-10:40:47] [V] [TRT] ReduceMean_266 [ReduceMean] outputs: [377 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: ReduceMax_267 [ReduceMax]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 376
[03/01/2023-10:40:47] [V] [TRT] ReduceMax_267 [ReduceMax] inputs: [376 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: ReduceMax_267 for ONNX node: ReduceMax_267
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 378 for ONNX tensor: 378
[03/01/2023-10:40:47] [V] [TRT] ReduceMax_267 [ReduceMax] outputs: [378 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Concat_268 [Concat]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 377
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 378
[03/01/2023-10:40:47] [V] [TRT] Concat_268 [Concat] inputs: [377 -> (1, 1, 3, 3)[FLOAT]], [378 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Concat_268 for ONNX node: Concat_268
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 379 for ONNX tensor: 379
[03/01/2023-10:40:47] [V] [TRT] Concat_268 [Concat] outputs: [379 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_269 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_269 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_269 [Constant] outputs: [380 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_270 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_270 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_270 [Constant] outputs: [381 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_271 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 379
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 380
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 381
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_271 [QuantizeLinear] inputs: [379 -> (1, 2, 3, 3)[FLOAT]], [380 -> ()[FLOAT]], [381 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 380 for ONNX node: 380
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 381 for ONNX node: 381
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 382 for ONNX tensor: 382
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_271 [QuantizeLinear] outputs: [382 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_272 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_272 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_272 [Constant] outputs: [383 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_273 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_273 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_273 [Constant] outputs: [384 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_274 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 382
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 383
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 384
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_274 [DequantizeLinear] inputs: [382 -> (1, 2, 3, 3)[FLOAT]], [383 -> ()[FLOAT]], [384 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 383 for ONNX node: 383
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 384 for ONNX node: 384
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 385 for ONNX tensor: 385
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_274 [DequantizeLinear] outputs: [385 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_275 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_275 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_275 [Constant] outputs: [386 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_276 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_276 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_276 [Constant] outputs: [387 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_277 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 386
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 387
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_277 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [386 -> ()[FLOAT]], [387 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: patchattention_spatial.conv1.weight for ONNX node: patchattention_spatial.conv1.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 386 for ONNX node: 386
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 387 for ONNX node: 387
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 388 for ONNX tensor: 388
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_277 [QuantizeLinear] outputs: [388 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_278 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_278 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_278 [Constant] outputs: [389 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_279 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_279 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_279 [Constant] outputs: [390 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_280 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 388
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 389
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 390
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_280 [DequantizeLinear] inputs: [388 -> (1, 2, 7, 7)[FLOAT]], [389 -> ()[FLOAT]], [390 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 389 for ONNX node: 389
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 390 for ONNX node: 390
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 391 for ONNX tensor: 391
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_280 [DequantizeLinear] outputs: [391 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_281 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 385
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 391
[03/01/2023-10:40:47] [V] [TRT] Conv_281 [Conv] inputs: [385 -> (1, 2, 3, 3)[FLOAT]], [391 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_281 for ONNX node: Conv_281
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 392 for ONNX tensor: 392
[03/01/2023-10:40:47] [V] [TRT] Conv_281 [Conv] outputs: [392 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Sigmoid_282 [Sigmoid]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 392
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_282 [Sigmoid] inputs: [392 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Sigmoid_282 for ONNX node: Sigmoid_282
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 393 for ONNX tensor: 393
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_282 [Sigmoid] outputs: [393 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Mul_283 [Mul]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 376
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 393
[03/01/2023-10:40:47] [V] [TRT] Mul_283 [Mul] inputs: [376 -> (1, 128, 3, 3)[FLOAT]], [393 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Mul_283 for ONNX node: Mul_283
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 394 for ONNX tensor: 394
[03/01/2023-10:40:47] [V] [TRT] Mul_283 [Mul] outputs: [394 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: GlobalAveragePool_284 [GlobalAveragePool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 394
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool_284 [GlobalAveragePool] inputs: [394 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:47] [V] [TRT] Registering layer: GlobalAveragePool_284 for ONNX node: GlobalAveragePool_284
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 395 for ONNX tensor: 395
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool_284 [GlobalAveragePool] outputs: [395 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_285 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_285 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_285 [Constant] outputs: [396 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_286 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_286 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_286 [Constant] outputs: [397 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_287 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 395
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 396
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 397
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_287 [QuantizeLinear] inputs: [395 -> (1, 128, 1, 1)[FLOAT]], [396 -> ()[FLOAT]], [397 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 396 for ONNX node: 396
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 397 for ONNX node: 397
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 398 for ONNX tensor: 398
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_287 [QuantizeLinear] outputs: [398 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_288 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_288 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_288 [Constant] outputs: [399 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_289 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_289 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_289 [Constant] outputs: [400 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_290 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 398
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 399
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 400
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_290 [DequantizeLinear] inputs: [398 -> (1, 128, 1, 1)[FLOAT]], [399 -> ()[FLOAT]], [400 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 399 for ONNX node: 399
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 400 for ONNX node: 400
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 401 for ONNX tensor: 401
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_290 [DequantizeLinear] outputs: [401 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_291 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_291 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_291 [Constant] outputs: [402 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_292 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_292 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_292 [Constant] outputs: [403 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_293 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 402
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 403
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_293 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [402 -> ()[FLOAT]], [403 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: patchattention_channel.fc.0.weight for ONNX node: patchattention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 402 for ONNX node: 402
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 403 for ONNX node: 403
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 404 for ONNX tensor: 404
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_293 [QuantizeLinear] outputs: [404 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_294 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_294 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_294 [Constant] outputs: [405 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_295 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_295 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_295 [Constant] outputs: [406 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_296 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 404
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 405
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 406
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_296 [DequantizeLinear] inputs: [404 -> (8, 128, 1, 1)[FLOAT]], [405 -> ()[FLOAT]], [406 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 405 for ONNX node: 405
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 406 for ONNX node: 406
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 407 for ONNX tensor: 407
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_296 [DequantizeLinear] outputs: [407 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_297 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 401
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 407
[03/01/2023-10:40:47] [V] [TRT] Conv_297 [Conv] inputs: [401 -> (1, 128, 1, 1)[FLOAT]], [407 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_297 for ONNX node: Conv_297
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 408 for ONNX tensor: 408
[03/01/2023-10:40:47] [V] [TRT] Conv_297 [Conv] outputs: [408 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_298 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 408
[03/01/2023-10:40:47] [V] [TRT] Relu_298 [Relu] inputs: [408 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_298 for ONNX node: Relu_298
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 409 for ONNX tensor: 409
[03/01/2023-10:40:47] [V] [TRT] Relu_298 [Relu] outputs: [409 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_299 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_299 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_299 [Constant] outputs: [410 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_300 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_300 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_300 [Constant] outputs: [411 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_301 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 409
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 410
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 411
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_301 [QuantizeLinear] inputs: [409 -> (1, 8, 1, 1)[FLOAT]], [410 -> ()[FLOAT]], [411 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 410 for ONNX node: 410
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 411 for ONNX node: 411
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 412 for ONNX tensor: 412
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_301 [QuantizeLinear] outputs: [412 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_302 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_302 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_302 [Constant] outputs: [413 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_303 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_303 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_303 [Constant] outputs: [414 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_304 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 412
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 413
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 414
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_304 [DequantizeLinear] inputs: [412 -> (1, 8, 1, 1)[FLOAT]], [413 -> ()[FLOAT]], [414 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 413 for ONNX node: 413
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 414 for ONNX node: 414
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 415 for ONNX tensor: 415
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_304 [DequantizeLinear] outputs: [415 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_305 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_305 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_305 [Constant] outputs: [416 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_306 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_306 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_306 [Constant] outputs: [417 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_307 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 416
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 417
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_307 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [416 -> ()[FLOAT]], [417 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: patchattention_channel.fc.2.weight for ONNX node: patchattention_channel.fc.2.weight
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 416 for ONNX node: 416
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 417 for ONNX node: 417
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 418 for ONNX tensor: 418
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_307 [QuantizeLinear] outputs: [418 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_308 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_308 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_308 [Constant] outputs: [419 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_309 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_309 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_309 [Constant] outputs: [420 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_310 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 418
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 419
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 420
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_310 [DequantizeLinear] inputs: [418 -> (128, 8, 1, 1)[FLOAT]], [419 -> ()[FLOAT]], [420 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 419 for ONNX node: 419
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 420 for ONNX node: 420
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 421 for ONNX tensor: 421
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_310 [DequantizeLinear] outputs: [421 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_311 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 415
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 421
[03/01/2023-10:40:47] [V] [TRT] Conv_311 [Conv] inputs: [415 -> (1, 8, 1, 1)[FLOAT]], [421 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_311 for ONNX node: Conv_311
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 422 for ONNX tensor: 422
[03/01/2023-10:40:47] [V] [TRT] Conv_311 [Conv] outputs: [422 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_312 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 394
[03/01/2023-10:40:47] [V] [TRT] MaxPool_312 [MaxPool] inputs: [394 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_312 for ONNX node: MaxPool_312
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 423 for ONNX tensor: 423
[03/01/2023-10:40:47] [V] [TRT] MaxPool_312 [MaxPool] outputs: [423 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_313 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_313 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_313 [Constant] outputs: [424 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_314 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_314 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_314 [Constant] outputs: [425 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_315 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 423
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 424
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 425
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_315 [QuantizeLinear] inputs: [423 -> (1, 128, 1, 1)[FLOAT]], [424 -> ()[FLOAT]], [425 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 424 for ONNX node: 424
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 425 for ONNX node: 425
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 426 for ONNX tensor: 426
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_315 [QuantizeLinear] outputs: [426 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_316 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_316 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_316 [Constant] outputs: [427 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_317 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_317 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_317 [Constant] outputs: [428 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_318 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 426
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 427
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 428
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_318 [DequantizeLinear] inputs: [426 -> (1, 128, 1, 1)[FLOAT]], [427 -> ()[FLOAT]], [428 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 427 for ONNX node: 427
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 428 for ONNX node: 428
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 429 for ONNX tensor: 429
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_318 [DequantizeLinear] outputs: [429 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_319 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_319 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_319 [Constant] outputs: [430 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_320 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_320 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_320 [Constant] outputs: [431 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_321 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 430
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 431
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_321 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [430 -> ()[FLOAT]], [431 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 430 for ONNX node: 430
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 431 for ONNX node: 431
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 432 for ONNX tensor: 432
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_321 [QuantizeLinear] outputs: [432 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_322 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_322 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_322 [Constant] outputs: [433 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_323 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_323 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_323 [Constant] outputs: [434 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_324 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 432
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 433
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 434
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_324 [DequantizeLinear] inputs: [432 -> (8, 128, 1, 1)[FLOAT]], [433 -> ()[FLOAT]], [434 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 433 for ONNX node: 433
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 434 for ONNX node: 434
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 435 for ONNX tensor: 435
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_324 [DequantizeLinear] outputs: [435 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_325 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 429
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 435
[03/01/2023-10:40:47] [V] [TRT] Conv_325 [Conv] inputs: [429 -> (1, 128, 1, 1)[FLOAT]], [435 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_325 for ONNX node: Conv_325
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 436 for ONNX tensor: 436
[03/01/2023-10:40:47] [V] [TRT] Conv_325 [Conv] outputs: [436 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_326 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 436
[03/01/2023-10:40:47] [V] [TRT] Relu_326 [Relu] inputs: [436 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_326 for ONNX node: Relu_326
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 437 for ONNX tensor: 437
[03/01/2023-10:40:47] [V] [TRT] Relu_326 [Relu] outputs: [437 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_327 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_327 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_327 [Constant] outputs: [438 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_328 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_328 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_328 [Constant] outputs: [439 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_329 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 437
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 438
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 439
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_329 [QuantizeLinear] inputs: [437 -> (1, 8, 1, 1)[FLOAT]], [438 -> ()[FLOAT]], [439 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 438 for ONNX node: 438
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 439 for ONNX node: 439
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 440 for ONNX tensor: 440
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_329 [QuantizeLinear] outputs: [440 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_330 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_330 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_330 [Constant] outputs: [441 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_331 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_331 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_331 [Constant] outputs: [442 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_332 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 440
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 441
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 442
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_332 [DequantizeLinear] inputs: [440 -> (1, 8, 1, 1)[FLOAT]], [441 -> ()[FLOAT]], [442 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 441 for ONNX node: 441
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 442 for ONNX node: 442
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 443 for ONNX tensor: 443
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_332 [DequantizeLinear] outputs: [443 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_333 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_333 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_333 [Constant] outputs: [444 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_334 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_334 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_334 [Constant] outputs: [445 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_335 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 444
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 445
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_335 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [444 -> ()[FLOAT]], [445 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 444 for ONNX node: 444
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 445 for ONNX node: 445
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 446 for ONNX tensor: 446
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_335 [QuantizeLinear] outputs: [446 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_336 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_336 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_336 [Constant] outputs: [447 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_337 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_337 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_337 [Constant] outputs: [448 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_338 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 446
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 447
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 448
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_338 [DequantizeLinear] inputs: [446 -> (128, 8, 1, 1)[FLOAT]], [447 -> ()[FLOAT]], [448 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 447 for ONNX node: 447
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 448 for ONNX node: 448
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 449 for ONNX tensor: 449
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_338 [DequantizeLinear] outputs: [449 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_339 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 443
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 449
[03/01/2023-10:40:47] [V] [TRT] Conv_339 [Conv] inputs: [443 -> (1, 8, 1, 1)[FLOAT]], [449 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_339 for ONNX node: Conv_339
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 450 for ONNX tensor: 450
[03/01/2023-10:40:47] [V] [TRT] Conv_339 [Conv] outputs: [450 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Add_340 [Add]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 422
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 450
[03/01/2023-10:40:47] [V] [TRT] Add_340 [Add] inputs: [422 -> (1, 128, 1, 1)[FLOAT]], [450 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Add_340 for ONNX node: Add_340
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 451 for ONNX tensor: 451
[03/01/2023-10:40:47] [V] [TRT] Add_340 [Add] outputs: [451 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Sigmoid_341 [Sigmoid]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 451
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_341 [Sigmoid] inputs: [451 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Sigmoid_341 for ONNX node: Sigmoid_341
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 452 for ONNX tensor: 452
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_341 [Sigmoid] outputs: [452 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Mul_342 [Mul]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 394
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 452
[03/01/2023-10:40:47] [V] [TRT] Mul_342 [Mul] inputs: [394 -> (1, 128, 3, 3)[FLOAT]], [452 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Mul_342 for ONNX node: Mul_342
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 453 for ONNX tensor: 453
[03/01/2023-10:40:47] [V] [TRT] Mul_342 [Mul] outputs: [453 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_343 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_343 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_343 [Constant] outputs: [454 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_344 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_344 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_344 [Constant] outputs: [455 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_345 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_345 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_345 [Constant] outputs: [456 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_346 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_346 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_346 [Constant] outputs: [457 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Slice_347 [Slice]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: input
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 455
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 456
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 454
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 457
[03/01/2023-10:40:47] [V] [TRT] Slice_347 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [455 -> (1)[INT32]], [456 -> (1)[INT32]], [454 -> (1)[INT32]], [457 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Slice_347 for ONNX node: Slice_347
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 458 for ONNX tensor: 458
[03/01/2023-10:40:47] [V] [TRT] Slice_347 [Slice] outputs: [458 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_348 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_348 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_348 [Constant] outputs: [459 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_349 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_349 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_349 [Constant] outputs: [460 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_350 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_350 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_350 [Constant] outputs: [461 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_351 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_351 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_351 [Constant] outputs: [462 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Slice_352 [Slice]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 458
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 460
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 461
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 459
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 462
[03/01/2023-10:40:47] [V] [TRT] Slice_352 [Slice] inputs: [458 -> (1, 1, 24, 60)[FLOAT]], [460 -> (1)[INT32]], [461 -> (1)[INT32]], [459 -> (1)[INT32]], [462 -> (1)[INT32]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Slice_352 for ONNX node: Slice_352
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 463 for ONNX tensor: 463
[03/01/2023-10:40:47] [V] [TRT] Slice_352 [Slice] outputs: [463 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_353 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_353 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_353 [Constant] outputs: [464 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_354 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_354 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_354 [Constant] outputs: [465 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_355 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 463
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 464
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 465
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_355 [QuantizeLinear] inputs: [463 -> (1, 1, 24, 24)[FLOAT]], [464 -> ()[FLOAT]], [465 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 464 for ONNX node: 464
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 465 for ONNX node: 465
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 466 for ONNX tensor: 466
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_355 [QuantizeLinear] outputs: [466 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_356 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_356 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_356 [Constant] outputs: [467 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_357 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_357 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_357 [Constant] outputs: [468 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_358 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 466
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 467
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 468
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_358 [DequantizeLinear] inputs: [466 -> (1, 1, 24, 24)[FLOAT]], [467 -> ()[FLOAT]], [468 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 467 for ONNX node: 467
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 468 for ONNX node: 468
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 469 for ONNX tensor: 469
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_358 [DequantizeLinear] outputs: [469 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_359 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_359 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_359 [Constant] outputs: [470 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_360 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_360 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_360 [Constant] outputs: [471 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_361 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 470
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 471
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_361 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [470 -> ()[FLOAT]], [471 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 470 for ONNX node: 470
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 471 for ONNX node: 471
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 472 for ONNX tensor: 472
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_361 [QuantizeLinear] outputs: [472 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_362 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_362 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_362 [Constant] outputs: [473 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_363 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_363 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_363 [Constant] outputs: [474 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_364 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 472
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 473
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 474
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_364 [DequantizeLinear] inputs: [472 -> (64, 1, 3, 3)[FLOAT]], [473 -> ()[FLOAT]], [474 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 473 for ONNX node: 473
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 474 for ONNX node: 474
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 475 for ONNX tensor: 475
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_364 [DequantizeLinear] outputs: [475 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_365 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 469
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 475
[03/01/2023-10:40:47] [V] [TRT] Conv_365 [Conv] inputs: [469 -> (1, 1, 24, 24)[FLOAT]], [475 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_365 for ONNX node: Conv_365
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 476 for ONNX tensor: 476
[03/01/2023-10:40:47] [V] [TRT] Conv_365 [Conv] outputs: [476 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_366 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 476
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_366 [BatchNormalization] inputs: [476 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_366 for ONNX node: BatchNormalization_366
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 477 for ONNX tensor: 477
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_366 [BatchNormalization] outputs: [477 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_367 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 477
[03/01/2023-10:40:47] [V] [TRT] Relu_367 [Relu] inputs: [477 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_367 for ONNX node: Relu_367
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 478 for ONNX tensor: 478
[03/01/2023-10:40:47] [V] [TRT] Relu_367 [Relu] outputs: [478 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_368 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_368 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_368 [Constant] outputs: [479 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_369 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_369 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_369 [Constant] outputs: [480 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_370 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 478
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 479
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 480
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_370 [QuantizeLinear] inputs: [478 -> (1, 64, 22, 22)[FLOAT]], [479 -> ()[FLOAT]], [480 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 479 for ONNX node: 479
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 480 for ONNX node: 480
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 481 for ONNX tensor: 481
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_370 [QuantizeLinear] outputs: [481 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_371 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_371 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_371 [Constant] outputs: [482 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_372 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_372 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_372 [Constant] outputs: [483 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_373 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 481
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 482
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 483
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_373 [DequantizeLinear] inputs: [481 -> (1, 64, 22, 22)[FLOAT]], [482 -> ()[FLOAT]], [483 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 482 for ONNX node: 482
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 483 for ONNX node: 483
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 484 for ONNX tensor: 484
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_373 [DequantizeLinear] outputs: [484 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_374 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_374 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_374 [Constant] outputs: [485 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_375 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_375 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_375 [Constant] outputs: [486 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_376 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 485
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 486
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_376 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [485 -> ()[FLOAT]], [486 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 485 for ONNX node: 485
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 486 for ONNX node: 486
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 487 for ONNX tensor: 487
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_376 [QuantizeLinear] outputs: [487 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_377 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_377 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_377 [Constant] outputs: [488 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_378 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_378 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_378 [Constant] outputs: [489 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_379 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 487
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 488
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 489
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_379 [DequantizeLinear] inputs: [487 -> (64, 64, 3, 3)[FLOAT]], [488 -> ()[FLOAT]], [489 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 488 for ONNX node: 488
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 489 for ONNX node: 489
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 490 for ONNX tensor: 490
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_379 [DequantizeLinear] outputs: [490 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_380 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 484
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 490
[03/01/2023-10:40:47] [V] [TRT] Conv_380 [Conv] inputs: [484 -> (1, 64, 22, 22)[FLOAT]], [490 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_380 for ONNX node: Conv_380
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 491 for ONNX tensor: 491
[03/01/2023-10:40:47] [V] [TRT] Conv_380 [Conv] outputs: [491 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_381 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 491
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_381 [BatchNormalization] inputs: [491 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_381 for ONNX node: BatchNormalization_381
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 492 for ONNX tensor: 492
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_381 [BatchNormalization] outputs: [492 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_382 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 492
[03/01/2023-10:40:47] [V] [TRT] Relu_382 [Relu] inputs: [492 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_382 for ONNX node: Relu_382
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 493 for ONNX tensor: 493
[03/01/2023-10:40:47] [V] [TRT] Relu_382 [Relu] outputs: [493 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_383 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 493
[03/01/2023-10:40:47] [V] [TRT] MaxPool_383 [MaxPool] inputs: [493 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_383 for ONNX node: MaxPool_383
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 494 for ONNX tensor: 494
[03/01/2023-10:40:47] [V] [TRT] MaxPool_383 [MaxPool] outputs: [494 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_384 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_384 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_384 [Constant] outputs: [495 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_385 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_385 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_385 [Constant] outputs: [496 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_386 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 494
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 495
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 496
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_386 [QuantizeLinear] inputs: [494 -> (1, 64, 10, 10)[FLOAT]], [495 -> ()[FLOAT]], [496 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 495 for ONNX node: 495
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 496 for ONNX node: 496
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 497 for ONNX tensor: 497
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_386 [QuantizeLinear] outputs: [497 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_387 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_387 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_387 [Constant] outputs: [498 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_388 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_388 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_388 [Constant] outputs: [499 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_389 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 497
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 498
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 499
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_389 [DequantizeLinear] inputs: [497 -> (1, 64, 10, 10)[FLOAT]], [498 -> ()[FLOAT]], [499 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 498 for ONNX node: 498
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 499 for ONNX node: 499
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 500 for ONNX tensor: 500
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_389 [DequantizeLinear] outputs: [500 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_390 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_390 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_390 [Constant] outputs: [501 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_391 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_391 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_391 [Constant] outputs: [502 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_392 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 501
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 502
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_392 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [501 -> ()[FLOAT]], [502 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 501 for ONNX node: 501
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 502 for ONNX node: 502
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 503 for ONNX tensor: 503
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_392 [QuantizeLinear] outputs: [503 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_393 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_393 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_393 [Constant] outputs: [504 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_394 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_394 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_394 [Constant] outputs: [505 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_395 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 503
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 504
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 505
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_395 [DequantizeLinear] inputs: [503 -> (128, 64, 3, 3)[FLOAT]], [504 -> ()[FLOAT]], [505 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 504 for ONNX node: 504
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 505 for ONNX node: 505
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 506 for ONNX tensor: 506
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_395 [DequantizeLinear] outputs: [506 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_396 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 500
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 506
[03/01/2023-10:40:47] [V] [TRT] Conv_396 [Conv] inputs: [500 -> (1, 64, 10, 10)[FLOAT]], [506 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_396 for ONNX node: Conv_396
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 507 for ONNX tensor: 507
[03/01/2023-10:40:47] [V] [TRT] Conv_396 [Conv] outputs: [507 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_397 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 507
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_397 [BatchNormalization] inputs: [507 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_397 for ONNX node: BatchNormalization_397
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 508 for ONNX tensor: 508
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_397 [BatchNormalization] outputs: [508 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_398 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 508
[03/01/2023-10:40:47] [V] [TRT] Relu_398 [Relu] inputs: [508 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_398 for ONNX node: Relu_398
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 509 for ONNX tensor: 509
[03/01/2023-10:40:47] [V] [TRT] Relu_398 [Relu] outputs: [509 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_399 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_399 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_399 [Constant] outputs: [510 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_400 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_400 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_400 [Constant] outputs: [511 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_401 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 509
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 510
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 511
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_401 [QuantizeLinear] inputs: [509 -> (1, 128, 8, 8)[FLOAT]], [510 -> ()[FLOAT]], [511 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 510 for ONNX node: 510
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 511 for ONNX node: 511
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 512 for ONNX tensor: 512
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_401 [QuantizeLinear] outputs: [512 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_402 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_402 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_402 [Constant] outputs: [513 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_403 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_403 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_403 [Constant] outputs: [514 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_404 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 512
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 513
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 514
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_404 [DequantizeLinear] inputs: [512 -> (1, 128, 8, 8)[FLOAT]], [513 -> ()[FLOAT]], [514 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 513 for ONNX node: 513
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 514 for ONNX node: 514
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 515 for ONNX tensor: 515
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_404 [DequantizeLinear] outputs: [515 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_405 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_405 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_405 [Constant] outputs: [516 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_406 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_406 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_406 [Constant] outputs: [517 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_407 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 516
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 517
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_407 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [516 -> ()[FLOAT]], [517 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 516 for ONNX node: 516
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 517 for ONNX node: 517
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 518 for ONNX tensor: 518
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_407 [QuantizeLinear] outputs: [518 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_408 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_408 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_408 [Constant] outputs: [519 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_409 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_409 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_409 [Constant] outputs: [520 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_410 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 518
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 519
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 520
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_410 [DequantizeLinear] inputs: [518 -> (128, 128, 3, 3)[FLOAT]], [519 -> ()[FLOAT]], [520 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 519 for ONNX node: 519
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 520 for ONNX node: 520
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 521 for ONNX tensor: 521
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_410 [DequantizeLinear] outputs: [521 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_411 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 515
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 521
[03/01/2023-10:40:47] [V] [TRT] Conv_411 [Conv] inputs: [515 -> (1, 128, 8, 8)[FLOAT]], [521 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_411 for ONNX node: Conv_411
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 522 for ONNX tensor: 522
[03/01/2023-10:40:47] [V] [TRT] Conv_411 [Conv] outputs: [522 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: BatchNormalization_412 [BatchNormalization]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 522
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:47] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_412 [BatchNormalization] inputs: [522 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: BatchNormalization_412 for ONNX node: BatchNormalization_412
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 523 for ONNX tensor: 523
[03/01/2023-10:40:47] [V] [TRT] BatchNormalization_412 [BatchNormalization] outputs: [523 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_413 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 523
[03/01/2023-10:40:47] [V] [TRT] Relu_413 [Relu] inputs: [523 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_413 for ONNX node: Relu_413
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 524 for ONNX tensor: 524
[03/01/2023-10:40:47] [V] [TRT] Relu_413 [Relu] outputs: [524 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_414 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 524
[03/01/2023-10:40:47] [V] [TRT] MaxPool_414 [MaxPool] inputs: [524 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_414 for ONNX node: MaxPool_414
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 525 for ONNX tensor: 525
[03/01/2023-10:40:47] [V] [TRT] MaxPool_414 [MaxPool] outputs: [525 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: ReduceMean_415 [ReduceMean]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 525
[03/01/2023-10:40:47] [V] [TRT] ReduceMean_415 [ReduceMean] inputs: [525 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: ReduceMean_415 for ONNX node: ReduceMean_415
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 526 for ONNX tensor: 526
[03/01/2023-10:40:47] [V] [TRT] ReduceMean_415 [ReduceMean] outputs: [526 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: ReduceMax_416 [ReduceMax]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 525
[03/01/2023-10:40:47] [V] [TRT] ReduceMax_416 [ReduceMax] inputs: [525 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: ReduceMax_416 for ONNX node: ReduceMax_416
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 527 for ONNX tensor: 527
[03/01/2023-10:40:47] [V] [TRT] ReduceMax_416 [ReduceMax] outputs: [527 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Concat_417 [Concat]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 526
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 527
[03/01/2023-10:40:47] [V] [TRT] Concat_417 [Concat] inputs: [526 -> (1, 1, 3, 3)[FLOAT]], [527 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Concat_417 for ONNX node: Concat_417
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 528 for ONNX tensor: 528
[03/01/2023-10:40:47] [V] [TRT] Concat_417 [Concat] outputs: [528 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_418 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_418 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_418 [Constant] outputs: [529 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_419 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_419 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_419 [Constant] outputs: [530 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_420 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 528
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 529
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 530
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_420 [QuantizeLinear] inputs: [528 -> (1, 2, 3, 3)[FLOAT]], [529 -> ()[FLOAT]], [530 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 529 for ONNX node: 529
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 530 for ONNX node: 530
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 531 for ONNX tensor: 531
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_420 [QuantizeLinear] outputs: [531 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_421 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_421 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_421 [Constant] outputs: [532 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_422 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_422 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_422 [Constant] outputs: [533 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_423 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 531
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 532
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 533
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_423 [DequantizeLinear] inputs: [531 -> (1, 2, 3, 3)[FLOAT]], [532 -> ()[FLOAT]], [533 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 532 for ONNX node: 532
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 533 for ONNX node: 533
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 534 for ONNX tensor: 534
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_423 [DequantizeLinear] outputs: [534 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_424 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_424 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_424 [Constant] outputs: [535 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_425 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_425 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_425 [Constant] outputs: [536 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_426 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 535
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 536
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_426 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [535 -> ()[FLOAT]], [536 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 535 for ONNX node: 535
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 536 for ONNX node: 536
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 537 for ONNX tensor: 537
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_426 [QuantizeLinear] outputs: [537 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_427 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_427 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_427 [Constant] outputs: [538 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_428 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_428 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_428 [Constant] outputs: [539 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_429 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 537
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 538
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 539
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_429 [DequantizeLinear] inputs: [537 -> (1, 2, 7, 7)[FLOAT]], [538 -> ()[FLOAT]], [539 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 538 for ONNX node: 538
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 539 for ONNX node: 539
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 540 for ONNX tensor: 540
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_429 [DequantizeLinear] outputs: [540 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_430 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 534
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 540
[03/01/2023-10:40:47] [V] [TRT] Conv_430 [Conv] inputs: [534 -> (1, 2, 3, 3)[FLOAT]], [540 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_430 for ONNX node: Conv_430
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 541 for ONNX tensor: 541
[03/01/2023-10:40:47] [V] [TRT] Conv_430 [Conv] outputs: [541 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Sigmoid_431 [Sigmoid]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 541
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_431 [Sigmoid] inputs: [541 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Sigmoid_431 for ONNX node: Sigmoid_431
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 542 for ONNX tensor: 542
[03/01/2023-10:40:47] [V] [TRT] Sigmoid_431 [Sigmoid] outputs: [542 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Mul_432 [Mul]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 525
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 542
[03/01/2023-10:40:47] [V] [TRT] Mul_432 [Mul] inputs: [525 -> (1, 128, 3, 3)[FLOAT]], [542 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Mul_432 for ONNX node: Mul_432
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 543 for ONNX tensor: 543
[03/01/2023-10:40:47] [V] [TRT] Mul_432 [Mul] outputs: [543 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: GlobalAveragePool_433 [GlobalAveragePool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 543
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool_433 [GlobalAveragePool] inputs: [543 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:47] [V] [TRT] Registering layer: GlobalAveragePool_433 for ONNX node: GlobalAveragePool_433
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 544 for ONNX tensor: 544
[03/01/2023-10:40:47] [V] [TRT] GlobalAveragePool_433 [GlobalAveragePool] outputs: [544 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_434 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_434 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_434 [Constant] outputs: [545 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_435 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_435 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_435 [Constant] outputs: [546 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_436 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 544
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 545
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 546
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_436 [QuantizeLinear] inputs: [544 -> (1, 128, 1, 1)[FLOAT]], [545 -> ()[FLOAT]], [546 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 545 for ONNX node: 545
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 546 for ONNX node: 546
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 547 for ONNX tensor: 547
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_436 [QuantizeLinear] outputs: [547 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_437 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_437 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_437 [Constant] outputs: [548 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_438 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_438 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_438 [Constant] outputs: [549 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_439 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 547
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 548
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 549
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_439 [DequantizeLinear] inputs: [547 -> (1, 128, 1, 1)[FLOAT]], [548 -> ()[FLOAT]], [549 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 548 for ONNX node: 548
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 549 for ONNX node: 549
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 550 for ONNX tensor: 550
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_439 [DequantizeLinear] outputs: [550 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_440 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_440 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_440 [Constant] outputs: [551 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_441 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_441 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_441 [Constant] outputs: [552 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_442 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 551
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 552
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_442 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [551 -> ()[FLOAT]], [552 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 551 for ONNX node: 551
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 552 for ONNX node: 552
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 553 for ONNX tensor: 553
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_442 [QuantizeLinear] outputs: [553 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_443 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_443 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_443 [Constant] outputs: [554 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_444 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_444 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_444 [Constant] outputs: [555 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_445 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 553
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 554
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 555
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_445 [DequantizeLinear] inputs: [553 -> (8, 128, 1, 1)[FLOAT]], [554 -> ()[FLOAT]], [555 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 554 for ONNX node: 554
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 555 for ONNX node: 555
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 556 for ONNX tensor: 556
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_445 [DequantizeLinear] outputs: [556 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_446 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 550
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 556
[03/01/2023-10:40:47] [V] [TRT] Conv_446 [Conv] inputs: [550 -> (1, 128, 1, 1)[FLOAT]], [556 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_446 for ONNX node: Conv_446
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 557 for ONNX tensor: 557
[03/01/2023-10:40:47] [V] [TRT] Conv_446 [Conv] outputs: [557 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Relu_447 [Relu]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 557
[03/01/2023-10:40:47] [V] [TRT] Relu_447 [Relu] inputs: [557 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Relu_447 for ONNX node: Relu_447
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 558 for ONNX tensor: 558
[03/01/2023-10:40:47] [V] [TRT] Relu_447 [Relu] outputs: [558 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_448 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_448 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_448 [Constant] outputs: [559 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_449 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_449 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_449 [Constant] outputs: [560 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_450 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 558
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 559
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 560
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_450 [QuantizeLinear] inputs: [558 -> (1, 8, 1, 1)[FLOAT]], [559 -> ()[FLOAT]], [560 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 559 for ONNX node: 559
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 560 for ONNX node: 560
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 561 for ONNX tensor: 561
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_450 [QuantizeLinear] outputs: [561 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_451 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_451 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_451 [Constant] outputs: [562 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_452 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_452 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_452 [Constant] outputs: [563 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_453 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 561
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 562
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 563
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_453 [DequantizeLinear] inputs: [561 -> (1, 8, 1, 1)[FLOAT]], [562 -> ()[FLOAT]], [563 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 562 for ONNX node: 562
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 563 for ONNX node: 563
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 564 for ONNX tensor: 564
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_453 [DequantizeLinear] outputs: [564 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_454 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_454 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_454 [Constant] outputs: [565 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_455 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_455 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_455 [Constant] outputs: [566 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_456 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 565
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 566
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_456 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [565 -> ()[FLOAT]], [566 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 565 for ONNX node: 565
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 566 for ONNX node: 566
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 567 for ONNX tensor: 567
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_456 [QuantizeLinear] outputs: [567 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_457 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_457 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_457 [Constant] outputs: [568 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_458 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_458 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_458 [Constant] outputs: [569 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_459 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 567
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 568
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 569
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_459 [DequantizeLinear] inputs: [567 -> (128, 8, 1, 1)[FLOAT]], [568 -> ()[FLOAT]], [569 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 568 for ONNX node: 568
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 569 for ONNX node: 569
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 570 for ONNX tensor: 570
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_459 [DequantizeLinear] outputs: [570 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Conv_460 [Conv]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 564
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 570
[03/01/2023-10:40:47] [V] [TRT] Conv_460 [Conv] inputs: [564 -> (1, 8, 1, 1)[FLOAT]], [570 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:47] [V] [TRT] Registering layer: Conv_460 for ONNX node: Conv_460
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 571 for ONNX tensor: 571
[03/01/2023-10:40:47] [V] [TRT] Conv_460 [Conv] outputs: [571 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: MaxPool_461 [MaxPool]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 543
[03/01/2023-10:40:47] [V] [TRT] MaxPool_461 [MaxPool] inputs: [543 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: MaxPool_461 for ONNX node: MaxPool_461
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 572 for ONNX tensor: 572
[03/01/2023-10:40:47] [V] [TRT] MaxPool_461 [MaxPool] outputs: [572 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_462 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_462 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_462 [Constant] outputs: [573 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_463 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_463 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_463 [Constant] outputs: [574 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_464 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 572
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 573
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 574
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_464 [QuantizeLinear] inputs: [572 -> (1, 128, 1, 1)[FLOAT]], [573 -> ()[FLOAT]], [574 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 573 for ONNX node: 573
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 574 for ONNX node: 574
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 575 for ONNX tensor: 575
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_464 [QuantizeLinear] outputs: [575 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_465 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_465 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_465 [Constant] outputs: [576 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_466 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_466 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_466 [Constant] outputs: [577 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_467 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 575
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 576
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 577
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_467 [DequantizeLinear] inputs: [575 -> (1, 128, 1, 1)[FLOAT]], [576 -> ()[FLOAT]], [577 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 576 for ONNX node: 576
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 577 for ONNX node: 577
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 578 for ONNX tensor: 578
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_467 [DequantizeLinear] outputs: [578 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_468 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_468 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_468 [Constant] outputs: [579 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_469 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_469 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_469 [Constant] outputs: [580 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: QuantizeLinear_470 [QuantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 579
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 580
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_470 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [579 -> ()[FLOAT]], [580 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 579 for ONNX node: 579
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 580 for ONNX node: 580
[03/01/2023-10:40:47] [V] [TRT] Registering tensor: 581 for ONNX tensor: 581
[03/01/2023-10:40:47] [V] [TRT] QuantizeLinear_470 [QuantizeLinear] outputs: [581 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_471 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_471 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_471 [Constant] outputs: [582 -> ()[FLOAT]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: Constant_472 [Constant]
[03/01/2023-10:40:47] [V] [TRT] Constant_472 [Constant] inputs: 
[03/01/2023-10:40:47] [V] [TRT] Constant_472 [Constant] outputs: [583 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Parsing node: DequantizeLinear_473 [DequantizeLinear]
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 581
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 582
[03/01/2023-10:40:47] [V] [TRT] Searching for input: 583
[03/01/2023-10:40:47] [V] [TRT] DequantizeLinear_473 [DequantizeLinear] inputs: [581 -> (8, 128, 1, 1)[FLOAT]], [582 -> ()[FLOAT]], [583 -> ()[INT8]], 
[03/01/2023-10:40:47] [V] [TRT] Registering layer: 582 for ONNX node: 582
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 583 for ONNX node: 583
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 584 for ONNX tensor: 584
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_473 [DequantizeLinear] outputs: [584 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_474 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 578
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 584
[03/01/2023-10:40:48] [V] [TRT] Conv_474 [Conv] inputs: [578 -> (1, 128, 1, 1)[FLOAT]], [584 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_474 for ONNX node: Conv_474
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 585 for ONNX tensor: 585
[03/01/2023-10:40:48] [V] [TRT] Conv_474 [Conv] outputs: [585 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_475 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 585
[03/01/2023-10:40:48] [V] [TRT] Relu_475 [Relu] inputs: [585 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_475 for ONNX node: Relu_475
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 586 for ONNX tensor: 586
[03/01/2023-10:40:48] [V] [TRT] Relu_475 [Relu] outputs: [586 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_476 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_476 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_476 [Constant] outputs: [587 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_477 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_477 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_477 [Constant] outputs: [588 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_478 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 586
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 587
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 588
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_478 [QuantizeLinear] inputs: [586 -> (1, 8, 1, 1)[FLOAT]], [587 -> ()[FLOAT]], [588 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 587 for ONNX node: 587
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 588 for ONNX node: 588
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 589 for ONNX tensor: 589
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_478 [QuantizeLinear] outputs: [589 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_479 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_479 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_479 [Constant] outputs: [590 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_480 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_480 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_480 [Constant] outputs: [591 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_481 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 589
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 590
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 591
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_481 [DequantizeLinear] inputs: [589 -> (1, 8, 1, 1)[FLOAT]], [590 -> ()[FLOAT]], [591 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 590 for ONNX node: 590
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 591 for ONNX node: 591
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 592 for ONNX tensor: 592
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_481 [DequantizeLinear] outputs: [592 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_482 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_482 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_482 [Constant] outputs: [593 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_483 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_483 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_483 [Constant] outputs: [594 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_484 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 593
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 594
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_484 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [593 -> ()[FLOAT]], [594 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 593 for ONNX node: 593
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 594 for ONNX node: 594
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 595 for ONNX tensor: 595
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_484 [QuantizeLinear] outputs: [595 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_485 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_485 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_485 [Constant] outputs: [596 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_486 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_486 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_486 [Constant] outputs: [597 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_487 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 595
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 596
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 597
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_487 [DequantizeLinear] inputs: [595 -> (128, 8, 1, 1)[FLOAT]], [596 -> ()[FLOAT]], [597 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 596 for ONNX node: 596
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 597 for ONNX node: 597
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 598 for ONNX tensor: 598
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_487 [DequantizeLinear] outputs: [598 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_488 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 592
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 598
[03/01/2023-10:40:48] [V] [TRT] Conv_488 [Conv] inputs: [592 -> (1, 8, 1, 1)[FLOAT]], [598 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_488 for ONNX node: Conv_488
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 599 for ONNX tensor: 599
[03/01/2023-10:40:48] [V] [TRT] Conv_488 [Conv] outputs: [599 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Add_489 [Add]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 571
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 599
[03/01/2023-10:40:48] [V] [TRT] Add_489 [Add] inputs: [571 -> (1, 128, 1, 1)[FLOAT]], [599 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Add_489 for ONNX node: Add_489
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 600 for ONNX tensor: 600
[03/01/2023-10:40:48] [V] [TRT] Add_489 [Add] outputs: [600 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Sigmoid_490 [Sigmoid]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 600
[03/01/2023-10:40:48] [V] [TRT] Sigmoid_490 [Sigmoid] inputs: [600 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Sigmoid_490 for ONNX node: Sigmoid_490
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 601 for ONNX tensor: 601
[03/01/2023-10:40:48] [V] [TRT] Sigmoid_490 [Sigmoid] outputs: [601 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Mul_491 [Mul]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 543
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 601
[03/01/2023-10:40:48] [V] [TRT] Mul_491 [Mul] inputs: [543 -> (1, 128, 3, 3)[FLOAT]], [601 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Mul_491 for ONNX node: Mul_491
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 602 for ONNX tensor: 602
[03/01/2023-10:40:48] [V] [TRT] Mul_491 [Mul] outputs: [602 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Concat_492 [Concat]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 453
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 602
[03/01/2023-10:40:48] [V] [TRT] Concat_492 [Concat] inputs: [453 -> (1, 128, 3, 3)[FLOAT]], [602 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Concat_492 for ONNX node: Concat_492
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 603 for ONNX tensor: 603
[03/01/2023-10:40:48] [V] [TRT] Concat_492 [Concat] outputs: [603 -> (1, 256, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_493 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_493 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_493 [Constant] outputs: [604 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_494 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_494 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_494 [Constant] outputs: [605 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_495 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_495 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_495 [Constant] outputs: [606 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_496 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_496 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_496 [Constant] outputs: [607 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Slice_497 [Slice]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: input
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 605
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 606
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 604
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 607
[03/01/2023-10:40:48] [V] [TRT] Slice_497 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [605 -> (1)[INT32]], [606 -> (1)[INT32]], [604 -> (1)[INT32]], [607 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Slice_497 for ONNX node: Slice_497
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 608 for ONNX tensor: 608
[03/01/2023-10:40:48] [V] [TRT] Slice_497 [Slice] outputs: [608 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_498 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_498 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_498 [Constant] outputs: [609 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_499 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_499 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_499 [Constant] outputs: [610 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_500 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_500 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_500 [Constant] outputs: [611 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_501 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_501 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_501 [Constant] outputs: [612 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Slice_502 [Slice]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 608
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 610
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 611
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 609
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 612
[03/01/2023-10:40:48] [V] [TRT] Slice_502 [Slice] inputs: [608 -> (1, 1, 24, 60)[FLOAT]], [610 -> (1)[INT32]], [611 -> (1)[INT32]], [609 -> (1)[INT32]], [612 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Slice_502 for ONNX node: Slice_502
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 613 for ONNX tensor: 613
[03/01/2023-10:40:48] [V] [TRT] Slice_502 [Slice] outputs: [613 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_503 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_503 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_503 [Constant] outputs: [614 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_504 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_504 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_504 [Constant] outputs: [615 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_505 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 613
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 614
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 615
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_505 [QuantizeLinear] inputs: [613 -> (1, 1, 24, 24)[FLOAT]], [614 -> ()[FLOAT]], [615 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 614 for ONNX node: 614
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 615 for ONNX node: 615
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 616 for ONNX tensor: 616
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_505 [QuantizeLinear] outputs: [616 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_506 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_506 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_506 [Constant] outputs: [617 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_507 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_507 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_507 [Constant] outputs: [618 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_508 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 616
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 617
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 618
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_508 [DequantizeLinear] inputs: [616 -> (1, 1, 24, 24)[FLOAT]], [617 -> ()[FLOAT]], [618 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 617 for ONNX node: 617
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 618 for ONNX node: 618
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 619 for ONNX tensor: 619
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_508 [DequantizeLinear] outputs: [619 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_509 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_509 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_509 [Constant] outputs: [620 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_510 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_510 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_510 [Constant] outputs: [621 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_511 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 620
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 621
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_511 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [620 -> ()[FLOAT]], [621 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 620 for ONNX node: 620
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 621 for ONNX node: 621
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 622 for ONNX tensor: 622
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_511 [QuantizeLinear] outputs: [622 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_512 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_512 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_512 [Constant] outputs: [623 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_513 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_513 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_513 [Constant] outputs: [624 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_514 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 622
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 623
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 624
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_514 [DequantizeLinear] inputs: [622 -> (64, 1, 3, 3)[FLOAT]], [623 -> ()[FLOAT]], [624 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 623 for ONNX node: 623
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 624 for ONNX node: 624
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 625 for ONNX tensor: 625
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_514 [DequantizeLinear] outputs: [625 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_515 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 619
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 625
[03/01/2023-10:40:48] [V] [TRT] Conv_515 [Conv] inputs: [619 -> (1, 1, 24, 24)[FLOAT]], [625 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_515 for ONNX node: Conv_515
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 626 for ONNX tensor: 626
[03/01/2023-10:40:48] [V] [TRT] Conv_515 [Conv] outputs: [626 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: BatchNormalization_516 [BatchNormalization]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 626
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_516 [BatchNormalization] inputs: [626 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: BatchNormalization_516 for ONNX node: BatchNormalization_516
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 627 for ONNX tensor: 627
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_516 [BatchNormalization] outputs: [627 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_517 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 627
[03/01/2023-10:40:48] [V] [TRT] Relu_517 [Relu] inputs: [627 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_517 for ONNX node: Relu_517
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 628 for ONNX tensor: 628
[03/01/2023-10:40:48] [V] [TRT] Relu_517 [Relu] outputs: [628 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_518 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_518 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_518 [Constant] outputs: [629 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_519 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_519 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_519 [Constant] outputs: [630 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_520 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 628
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 629
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 630
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_520 [QuantizeLinear] inputs: [628 -> (1, 64, 22, 22)[FLOAT]], [629 -> ()[FLOAT]], [630 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 629 for ONNX node: 629
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 630 for ONNX node: 630
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 631 for ONNX tensor: 631
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_520 [QuantizeLinear] outputs: [631 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_521 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_521 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_521 [Constant] outputs: [632 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_522 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_522 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_522 [Constant] outputs: [633 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_523 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 631
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 632
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 633
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_523 [DequantizeLinear] inputs: [631 -> (1, 64, 22, 22)[FLOAT]], [632 -> ()[FLOAT]], [633 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 632 for ONNX node: 632
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 633 for ONNX node: 633
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 634 for ONNX tensor: 634
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_523 [DequantizeLinear] outputs: [634 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_524 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_524 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_524 [Constant] outputs: [635 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_525 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_525 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_525 [Constant] outputs: [636 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_526 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 635
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 636
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_526 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [635 -> ()[FLOAT]], [636 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 635 for ONNX node: 635
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 636 for ONNX node: 636
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 637 for ONNX tensor: 637
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_526 [QuantizeLinear] outputs: [637 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_527 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_527 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_527 [Constant] outputs: [638 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_528 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_528 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_528 [Constant] outputs: [639 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_529 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 637
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 638
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 639
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_529 [DequantizeLinear] inputs: [637 -> (64, 64, 3, 3)[FLOAT]], [638 -> ()[FLOAT]], [639 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 638 for ONNX node: 638
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 639 for ONNX node: 639
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 640 for ONNX tensor: 640
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_529 [DequantizeLinear] outputs: [640 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_530 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 634
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 640
[03/01/2023-10:40:48] [V] [TRT] Conv_530 [Conv] inputs: [634 -> (1, 64, 22, 22)[FLOAT]], [640 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_530 for ONNX node: Conv_530
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 641 for ONNX tensor: 641
[03/01/2023-10:40:48] [V] [TRT] Conv_530 [Conv] outputs: [641 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: BatchNormalization_531 [BatchNormalization]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 641
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_531 [BatchNormalization] inputs: [641 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: BatchNormalization_531 for ONNX node: BatchNormalization_531
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 642 for ONNX tensor: 642
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_531 [BatchNormalization] outputs: [642 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_532 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 642
[03/01/2023-10:40:48] [V] [TRT] Relu_532 [Relu] inputs: [642 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_532 for ONNX node: Relu_532
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 643 for ONNX tensor: 643
[03/01/2023-10:40:48] [V] [TRT] Relu_532 [Relu] outputs: [643 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: MaxPool_533 [MaxPool]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 643
[03/01/2023-10:40:48] [V] [TRT] MaxPool_533 [MaxPool] inputs: [643 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: MaxPool_533 for ONNX node: MaxPool_533
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 644 for ONNX tensor: 644
[03/01/2023-10:40:48] [V] [TRT] MaxPool_533 [MaxPool] outputs: [644 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_534 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_534 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_534 [Constant] outputs: [645 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_535 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_535 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_535 [Constant] outputs: [646 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_536 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 644
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 645
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 646
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_536 [QuantizeLinear] inputs: [644 -> (1, 64, 10, 10)[FLOAT]], [645 -> ()[FLOAT]], [646 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 645 for ONNX node: 645
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 646 for ONNX node: 646
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 647 for ONNX tensor: 647
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_536 [QuantizeLinear] outputs: [647 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_537 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_537 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_537 [Constant] outputs: [648 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_538 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_538 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_538 [Constant] outputs: [649 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_539 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 647
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 648
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 649
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_539 [DequantizeLinear] inputs: [647 -> (1, 64, 10, 10)[FLOAT]], [648 -> ()[FLOAT]], [649 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 648 for ONNX node: 648
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 649 for ONNX node: 649
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 650 for ONNX tensor: 650
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_539 [DequantizeLinear] outputs: [650 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_540 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_540 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_540 [Constant] outputs: [651 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_541 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_541 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_541 [Constant] outputs: [652 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_542 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 651
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 652
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_542 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [651 -> ()[FLOAT]], [652 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 651 for ONNX node: 651
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 652 for ONNX node: 652
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 653 for ONNX tensor: 653
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_542 [QuantizeLinear] outputs: [653 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_543 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_543 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_543 [Constant] outputs: [654 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_544 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_544 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_544 [Constant] outputs: [655 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_545 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 653
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 654
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 655
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_545 [DequantizeLinear] inputs: [653 -> (128, 64, 3, 3)[FLOAT]], [654 -> ()[FLOAT]], [655 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 654 for ONNX node: 654
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 655 for ONNX node: 655
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 656 for ONNX tensor: 656
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_545 [DequantizeLinear] outputs: [656 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_546 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 650
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 656
[03/01/2023-10:40:48] [V] [TRT] Conv_546 [Conv] inputs: [650 -> (1, 64, 10, 10)[FLOAT]], [656 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_546 for ONNX node: Conv_546
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 657 for ONNX tensor: 657
[03/01/2023-10:40:48] [V] [TRT] Conv_546 [Conv] outputs: [657 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: BatchNormalization_547 [BatchNormalization]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 657
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_547 [BatchNormalization] inputs: [657 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: BatchNormalization_547 for ONNX node: BatchNormalization_547
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 658 for ONNX tensor: 658
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_547 [BatchNormalization] outputs: [658 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_548 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 658
[03/01/2023-10:40:48] [V] [TRT] Relu_548 [Relu] inputs: [658 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_548 for ONNX node: Relu_548
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 659 for ONNX tensor: 659
[03/01/2023-10:40:48] [V] [TRT] Relu_548 [Relu] outputs: [659 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_549 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_549 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_549 [Constant] outputs: [660 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_550 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_550 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_550 [Constant] outputs: [661 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_551 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 659
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 660
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 661
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_551 [QuantizeLinear] inputs: [659 -> (1, 128, 8, 8)[FLOAT]], [660 -> ()[FLOAT]], [661 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 660 for ONNX node: 660
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 661 for ONNX node: 661
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 662 for ONNX tensor: 662
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_551 [QuantizeLinear] outputs: [662 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_552 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_552 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_552 [Constant] outputs: [663 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_553 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_553 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_553 [Constant] outputs: [664 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_554 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 662
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 663
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 664
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_554 [DequantizeLinear] inputs: [662 -> (1, 128, 8, 8)[FLOAT]], [663 -> ()[FLOAT]], [664 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 663 for ONNX node: 663
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 664 for ONNX node: 664
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 665 for ONNX tensor: 665
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_554 [DequantizeLinear] outputs: [665 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_555 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_555 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_555 [Constant] outputs: [666 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_556 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_556 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_556 [Constant] outputs: [667 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_557 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 666
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 667
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_557 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [666 -> ()[FLOAT]], [667 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 666 for ONNX node: 666
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 667 for ONNX node: 667
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 668 for ONNX tensor: 668
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_557 [QuantizeLinear] outputs: [668 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_558 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_558 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_558 [Constant] outputs: [669 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_559 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_559 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_559 [Constant] outputs: [670 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_560 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 668
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 669
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 670
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_560 [DequantizeLinear] inputs: [668 -> (128, 128, 3, 3)[FLOAT]], [669 -> ()[FLOAT]], [670 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 669 for ONNX node: 669
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 670 for ONNX node: 670
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 671 for ONNX tensor: 671
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_560 [DequantizeLinear] outputs: [671 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_561 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 665
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 671
[03/01/2023-10:40:48] [V] [TRT] Conv_561 [Conv] inputs: [665 -> (1, 128, 8, 8)[FLOAT]], [671 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_561 for ONNX node: Conv_561
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 672 for ONNX tensor: 672
[03/01/2023-10:40:48] [V] [TRT] Conv_561 [Conv] outputs: [672 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: BatchNormalization_562 [BatchNormalization]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 672
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_562 [BatchNormalization] inputs: [672 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: BatchNormalization_562 for ONNX node: BatchNormalization_562
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 673 for ONNX tensor: 673
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_562 [BatchNormalization] outputs: [673 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_563 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 673
[03/01/2023-10:40:48] [V] [TRT] Relu_563 [Relu] inputs: [673 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_563 for ONNX node: Relu_563
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 674 for ONNX tensor: 674
[03/01/2023-10:40:48] [V] [TRT] Relu_563 [Relu] outputs: [674 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: MaxPool_564 [MaxPool]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 674
[03/01/2023-10:40:48] [V] [TRT] MaxPool_564 [MaxPool] inputs: [674 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: MaxPool_564 for ONNX node: MaxPool_564
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 675 for ONNX tensor: 675
[03/01/2023-10:40:48] [V] [TRT] MaxPool_564 [MaxPool] outputs: [675 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: ReduceMean_565 [ReduceMean]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 675
[03/01/2023-10:40:48] [V] [TRT] ReduceMean_565 [ReduceMean] inputs: [675 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: ReduceMean_565 for ONNX node: ReduceMean_565
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 676 for ONNX tensor: 676
[03/01/2023-10:40:48] [V] [TRT] ReduceMean_565 [ReduceMean] outputs: [676 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: ReduceMax_566 [ReduceMax]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 675
[03/01/2023-10:40:48] [V] [TRT] ReduceMax_566 [ReduceMax] inputs: [675 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: ReduceMax_566 for ONNX node: ReduceMax_566
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 677 for ONNX tensor: 677
[03/01/2023-10:40:48] [V] [TRT] ReduceMax_566 [ReduceMax] outputs: [677 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Concat_567 [Concat]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 676
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 677
[03/01/2023-10:40:48] [V] [TRT] Concat_567 [Concat] inputs: [676 -> (1, 1, 3, 3)[FLOAT]], [677 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Concat_567 for ONNX node: Concat_567
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 678 for ONNX tensor: 678
[03/01/2023-10:40:48] [V] [TRT] Concat_567 [Concat] outputs: [678 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_568 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_568 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_568 [Constant] outputs: [679 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_569 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_569 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_569 [Constant] outputs: [680 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_570 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 678
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 679
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 680
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_570 [QuantizeLinear] inputs: [678 -> (1, 2, 3, 3)[FLOAT]], [679 -> ()[FLOAT]], [680 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 679 for ONNX node: 679
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 680 for ONNX node: 680
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 681 for ONNX tensor: 681
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_570 [QuantizeLinear] outputs: [681 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_571 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_571 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_571 [Constant] outputs: [682 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_572 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_572 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_572 [Constant] outputs: [683 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_573 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 681
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 682
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 683
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_573 [DequantizeLinear] inputs: [681 -> (1, 2, 3, 3)[FLOAT]], [682 -> ()[FLOAT]], [683 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 682 for ONNX node: 682
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 683 for ONNX node: 683
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 684 for ONNX tensor: 684
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_573 [DequantizeLinear] outputs: [684 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_574 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_574 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_574 [Constant] outputs: [685 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_575 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_575 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_575 [Constant] outputs: [686 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_576 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 685
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 686
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_576 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [685 -> ()[FLOAT]], [686 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 685 for ONNX node: 685
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 686 for ONNX node: 686
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 687 for ONNX tensor: 687
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_576 [QuantizeLinear] outputs: [687 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_577 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_577 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_577 [Constant] outputs: [688 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_578 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_578 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_578 [Constant] outputs: [689 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_579 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 687
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 688
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 689
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_579 [DequantizeLinear] inputs: [687 -> (1, 2, 7, 7)[FLOAT]], [688 -> ()[FLOAT]], [689 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 688 for ONNX node: 688
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 689 for ONNX node: 689
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 690 for ONNX tensor: 690
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_579 [DequantizeLinear] outputs: [690 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_580 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 684
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 690
[03/01/2023-10:40:48] [V] [TRT] Conv_580 [Conv] inputs: [684 -> (1, 2, 3, 3)[FLOAT]], [690 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_580 for ONNX node: Conv_580
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 691 for ONNX tensor: 691
[03/01/2023-10:40:48] [V] [TRT] Conv_580 [Conv] outputs: [691 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Sigmoid_581 [Sigmoid]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 691
[03/01/2023-10:40:48] [V] [TRT] Sigmoid_581 [Sigmoid] inputs: [691 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Sigmoid_581 for ONNX node: Sigmoid_581
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 692 for ONNX tensor: 692
[03/01/2023-10:40:48] [V] [TRT] Sigmoid_581 [Sigmoid] outputs: [692 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Mul_582 [Mul]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 675
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 692
[03/01/2023-10:40:48] [V] [TRT] Mul_582 [Mul] inputs: [675 -> (1, 128, 3, 3)[FLOAT]], [692 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Mul_582 for ONNX node: Mul_582
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 693 for ONNX tensor: 693
[03/01/2023-10:40:48] [V] [TRT] Mul_582 [Mul] outputs: [693 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: GlobalAveragePool_583 [GlobalAveragePool]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 693
[03/01/2023-10:40:48] [V] [TRT] GlobalAveragePool_583 [GlobalAveragePool] inputs: [693 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:48] [V] [TRT] Registering layer: GlobalAveragePool_583 for ONNX node: GlobalAveragePool_583
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 694 for ONNX tensor: 694
[03/01/2023-10:40:48] [V] [TRT] GlobalAveragePool_583 [GlobalAveragePool] outputs: [694 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_584 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_584 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_584 [Constant] outputs: [695 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_585 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_585 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_585 [Constant] outputs: [696 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_586 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 694
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 695
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 696
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_586 [QuantizeLinear] inputs: [694 -> (1, 128, 1, 1)[FLOAT]], [695 -> ()[FLOAT]], [696 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 695 for ONNX node: 695
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 696 for ONNX node: 696
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 697 for ONNX tensor: 697
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_586 [QuantizeLinear] outputs: [697 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_587 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_587 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_587 [Constant] outputs: [698 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_588 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_588 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_588 [Constant] outputs: [699 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_589 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 697
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 698
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 699
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_589 [DequantizeLinear] inputs: [697 -> (1, 128, 1, 1)[FLOAT]], [698 -> ()[FLOAT]], [699 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 698 for ONNX node: 698
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 699 for ONNX node: 699
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 700 for ONNX tensor: 700
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_589 [DequantizeLinear] outputs: [700 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_590 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_590 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_590 [Constant] outputs: [701 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_591 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_591 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_591 [Constant] outputs: [702 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_592 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 701
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 702
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_592 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [701 -> ()[FLOAT]], [702 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 701 for ONNX node: 701
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 702 for ONNX node: 702
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 703 for ONNX tensor: 703
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_592 [QuantizeLinear] outputs: [703 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_593 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_593 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_593 [Constant] outputs: [704 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_594 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_594 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_594 [Constant] outputs: [705 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_595 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 703
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 704
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 705
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_595 [DequantizeLinear] inputs: [703 -> (8, 128, 1, 1)[FLOAT]], [704 -> ()[FLOAT]], [705 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 704 for ONNX node: 704
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 705 for ONNX node: 705
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 706 for ONNX tensor: 706
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_595 [DequantizeLinear] outputs: [706 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_596 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 700
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 706
[03/01/2023-10:40:48] [V] [TRT] Conv_596 [Conv] inputs: [700 -> (1, 128, 1, 1)[FLOAT]], [706 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_596 for ONNX node: Conv_596
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 707 for ONNX tensor: 707
[03/01/2023-10:40:48] [V] [TRT] Conv_596 [Conv] outputs: [707 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_597 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 707
[03/01/2023-10:40:48] [V] [TRT] Relu_597 [Relu] inputs: [707 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_597 for ONNX node: Relu_597
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 708 for ONNX tensor: 708
[03/01/2023-10:40:48] [V] [TRT] Relu_597 [Relu] outputs: [708 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_598 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_598 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_598 [Constant] outputs: [709 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_599 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_599 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_599 [Constant] outputs: [710 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_600 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 708
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 709
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 710
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_600 [QuantizeLinear] inputs: [708 -> (1, 8, 1, 1)[FLOAT]], [709 -> ()[FLOAT]], [710 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 709 for ONNX node: 709
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 710 for ONNX node: 710
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 711 for ONNX tensor: 711
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_600 [QuantizeLinear] outputs: [711 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_601 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_601 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_601 [Constant] outputs: [712 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_602 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_602 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_602 [Constant] outputs: [713 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_603 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 711
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 712
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 713
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_603 [DequantizeLinear] inputs: [711 -> (1, 8, 1, 1)[FLOAT]], [712 -> ()[FLOAT]], [713 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 712 for ONNX node: 712
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 713 for ONNX node: 713
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 714 for ONNX tensor: 714
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_603 [DequantizeLinear] outputs: [714 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_604 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_604 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_604 [Constant] outputs: [715 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_605 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_605 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_605 [Constant] outputs: [716 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_606 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 715
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 716
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_606 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [715 -> ()[FLOAT]], [716 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 715 for ONNX node: 715
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 716 for ONNX node: 716
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 717 for ONNX tensor: 717
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_606 [QuantizeLinear] outputs: [717 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_607 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_607 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_607 [Constant] outputs: [718 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_608 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_608 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_608 [Constant] outputs: [719 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_609 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 717
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 718
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 719
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_609 [DequantizeLinear] inputs: [717 -> (128, 8, 1, 1)[FLOAT]], [718 -> ()[FLOAT]], [719 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 718 for ONNX node: 718
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 719 for ONNX node: 719
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 720 for ONNX tensor: 720
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_609 [DequantizeLinear] outputs: [720 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_610 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 714
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 720
[03/01/2023-10:40:48] [V] [TRT] Conv_610 [Conv] inputs: [714 -> (1, 8, 1, 1)[FLOAT]], [720 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_610 for ONNX node: Conv_610
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 721 for ONNX tensor: 721
[03/01/2023-10:40:48] [V] [TRT] Conv_610 [Conv] outputs: [721 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: MaxPool_611 [MaxPool]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 693
[03/01/2023-10:40:48] [V] [TRT] MaxPool_611 [MaxPool] inputs: [693 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: MaxPool_611 for ONNX node: MaxPool_611
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 722 for ONNX tensor: 722
[03/01/2023-10:40:48] [V] [TRT] MaxPool_611 [MaxPool] outputs: [722 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_612 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_612 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_612 [Constant] outputs: [723 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_613 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_613 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_613 [Constant] outputs: [724 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_614 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 722
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 723
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 724
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_614 [QuantizeLinear] inputs: [722 -> (1, 128, 1, 1)[FLOAT]], [723 -> ()[FLOAT]], [724 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 723 for ONNX node: 723
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 724 for ONNX node: 724
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 725 for ONNX tensor: 725
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_614 [QuantizeLinear] outputs: [725 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_615 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_615 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_615 [Constant] outputs: [726 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_616 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_616 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_616 [Constant] outputs: [727 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_617 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 725
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 726
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 727
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_617 [DequantizeLinear] inputs: [725 -> (1, 128, 1, 1)[FLOAT]], [726 -> ()[FLOAT]], [727 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 726 for ONNX node: 726
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 727 for ONNX node: 727
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 728 for ONNX tensor: 728
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_617 [DequantizeLinear] outputs: [728 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_618 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_618 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_618 [Constant] outputs: [729 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_619 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_619 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_619 [Constant] outputs: [730 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_620 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 729
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 730
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_620 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [729 -> ()[FLOAT]], [730 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 729 for ONNX node: 729
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 730 for ONNX node: 730
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 731 for ONNX tensor: 731
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_620 [QuantizeLinear] outputs: [731 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_621 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_621 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_621 [Constant] outputs: [732 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_622 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_622 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_622 [Constant] outputs: [733 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_623 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 731
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 732
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 733
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_623 [DequantizeLinear] inputs: [731 -> (8, 128, 1, 1)[FLOAT]], [732 -> ()[FLOAT]], [733 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 732 for ONNX node: 732
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 733 for ONNX node: 733
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 734 for ONNX tensor: 734
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_623 [DequantizeLinear] outputs: [734 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_624 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 728
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 734
[03/01/2023-10:40:48] [V] [TRT] Conv_624 [Conv] inputs: [728 -> (1, 128, 1, 1)[FLOAT]], [734 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_624 for ONNX node: Conv_624
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 735 for ONNX tensor: 735
[03/01/2023-10:40:48] [V] [TRT] Conv_624 [Conv] outputs: [735 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_625 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 735
[03/01/2023-10:40:48] [V] [TRT] Relu_625 [Relu] inputs: [735 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_625 for ONNX node: Relu_625
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 736 for ONNX tensor: 736
[03/01/2023-10:40:48] [V] [TRT] Relu_625 [Relu] outputs: [736 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_626 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_626 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_626 [Constant] outputs: [737 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_627 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_627 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_627 [Constant] outputs: [738 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_628 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 736
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 737
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 738
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_628 [QuantizeLinear] inputs: [736 -> (1, 8, 1, 1)[FLOAT]], [737 -> ()[FLOAT]], [738 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 737 for ONNX node: 737
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 738 for ONNX node: 738
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 739 for ONNX tensor: 739
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_628 [QuantizeLinear] outputs: [739 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_629 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_629 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_629 [Constant] outputs: [740 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_630 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_630 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_630 [Constant] outputs: [741 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_631 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 739
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 740
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 741
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_631 [DequantizeLinear] inputs: [739 -> (1, 8, 1, 1)[FLOAT]], [740 -> ()[FLOAT]], [741 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 740 for ONNX node: 740
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 741 for ONNX node: 741
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 742 for ONNX tensor: 742
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_631 [DequantizeLinear] outputs: [742 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_632 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_632 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_632 [Constant] outputs: [743 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_633 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_633 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_633 [Constant] outputs: [744 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_634 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 743
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 744
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_634 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [743 -> ()[FLOAT]], [744 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 743 for ONNX node: 743
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 744 for ONNX node: 744
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 745 for ONNX tensor: 745
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_634 [QuantizeLinear] outputs: [745 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_635 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_635 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_635 [Constant] outputs: [746 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_636 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_636 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_636 [Constant] outputs: [747 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_637 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 745
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 746
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 747
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_637 [DequantizeLinear] inputs: [745 -> (128, 8, 1, 1)[FLOAT]], [746 -> ()[FLOAT]], [747 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 746 for ONNX node: 746
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 747 for ONNX node: 747
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 748 for ONNX tensor: 748
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_637 [DequantizeLinear] outputs: [748 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_638 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 742
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 748
[03/01/2023-10:40:48] [V] [TRT] Conv_638 [Conv] inputs: [742 -> (1, 8, 1, 1)[FLOAT]], [748 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_638 for ONNX node: Conv_638
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 749 for ONNX tensor: 749
[03/01/2023-10:40:48] [V] [TRT] Conv_638 [Conv] outputs: [749 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Add_639 [Add]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 721
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 749
[03/01/2023-10:40:48] [V] [TRT] Add_639 [Add] inputs: [721 -> (1, 128, 1, 1)[FLOAT]], [749 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Add_639 for ONNX node: Add_639
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 750 for ONNX tensor: 750
[03/01/2023-10:40:48] [V] [TRT] Add_639 [Add] outputs: [750 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Sigmoid_640 [Sigmoid]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 750
[03/01/2023-10:40:48] [V] [TRT] Sigmoid_640 [Sigmoid] inputs: [750 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Sigmoid_640 for ONNX node: Sigmoid_640
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 751 for ONNX tensor: 751
[03/01/2023-10:40:48] [V] [TRT] Sigmoid_640 [Sigmoid] outputs: [751 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Mul_641 [Mul]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 693
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 751
[03/01/2023-10:40:48] [V] [TRT] Mul_641 [Mul] inputs: [693 -> (1, 128, 3, 3)[FLOAT]], [751 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Mul_641 for ONNX node: Mul_641
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 752 for ONNX tensor: 752
[03/01/2023-10:40:48] [V] [TRT] Mul_641 [Mul] outputs: [752 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Concat_642 [Concat]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 603
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 752
[03/01/2023-10:40:48] [V] [TRT] Concat_642 [Concat] inputs: [603 -> (1, 256, 3, 3)[FLOAT]], [752 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Concat_642 for ONNX node: Concat_642
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 753 for ONNX tensor: 753
[03/01/2023-10:40:48] [V] [TRT] Concat_642 [Concat] outputs: [753 -> (1, 384, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_643 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_643 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_643 [Constant] outputs: [754 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_644 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_644 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_644 [Constant] outputs: [755 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_645 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_645 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_645 [Constant] outputs: [756 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_646 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_646 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_646 [Constant] outputs: [757 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Slice_647 [Slice]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: input
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 755
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 756
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 754
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 757
[03/01/2023-10:40:48] [V] [TRT] Slice_647 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [755 -> (1)[INT32]], [756 -> (1)[INT32]], [754 -> (1)[INT32]], [757 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Slice_647 for ONNX node: Slice_647
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 758 for ONNX tensor: 758
[03/01/2023-10:40:48] [V] [TRT] Slice_647 [Slice] outputs: [758 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_648 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_648 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_648 [Constant] outputs: [759 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_649 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_649 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_649 [Constant] outputs: [760 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_650 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_650 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_650 [Constant] outputs: [761 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_651 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_651 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_651 [Constant] outputs: [762 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Slice_652 [Slice]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 758
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 760
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 761
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 759
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 762
[03/01/2023-10:40:48] [V] [TRT] Slice_652 [Slice] inputs: [758 -> (1, 1, 24, 60)[FLOAT]], [760 -> (1)[INT32]], [761 -> (1)[INT32]], [759 -> (1)[INT32]], [762 -> (1)[INT32]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Slice_652 for ONNX node: Slice_652
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 763 for ONNX tensor: 763
[03/01/2023-10:40:48] [V] [TRT] Slice_652 [Slice] outputs: [763 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_653 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_653 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_653 [Constant] outputs: [764 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_654 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_654 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_654 [Constant] outputs: [765 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_655 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 763
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 764
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 765
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_655 [QuantizeLinear] inputs: [763 -> (1, 1, 24, 24)[FLOAT]], [764 -> ()[FLOAT]], [765 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 764 for ONNX node: 764
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 765 for ONNX node: 765
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 766 for ONNX tensor: 766
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_655 [QuantizeLinear] outputs: [766 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_656 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_656 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_656 [Constant] outputs: [767 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_657 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_657 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_657 [Constant] outputs: [768 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_658 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 766
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 767
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 768
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_658 [DequantizeLinear] inputs: [766 -> (1, 1, 24, 24)[FLOAT]], [767 -> ()[FLOAT]], [768 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 767 for ONNX node: 767
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 768 for ONNX node: 768
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 769 for ONNX tensor: 769
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_658 [DequantizeLinear] outputs: [769 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_659 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_659 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_659 [Constant] outputs: [770 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_660 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_660 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_660 [Constant] outputs: [771 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_661 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 770
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 771
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_661 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [770 -> ()[FLOAT]], [771 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 770 for ONNX node: 770
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 771 for ONNX node: 771
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 772 for ONNX tensor: 772
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_661 [QuantizeLinear] outputs: [772 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_662 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_662 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_662 [Constant] outputs: [773 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_663 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_663 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_663 [Constant] outputs: [774 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_664 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 772
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 773
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 774
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_664 [DequantizeLinear] inputs: [772 -> (64, 1, 3, 3)[FLOAT]], [773 -> ()[FLOAT]], [774 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 773 for ONNX node: 773
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 774 for ONNX node: 774
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 775 for ONNX tensor: 775
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_664 [DequantizeLinear] outputs: [775 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_665 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 769
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 775
[03/01/2023-10:40:48] [V] [TRT] Conv_665 [Conv] inputs: [769 -> (1, 1, 24, 24)[FLOAT]], [775 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_665 for ONNX node: Conv_665
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 776 for ONNX tensor: 776
[03/01/2023-10:40:48] [V] [TRT] Conv_665 [Conv] outputs: [776 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: BatchNormalization_666 [BatchNormalization]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 776
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_666 [BatchNormalization] inputs: [776 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: BatchNormalization_666 for ONNX node: BatchNormalization_666
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 777 for ONNX tensor: 777
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_666 [BatchNormalization] outputs: [777 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_667 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 777
[03/01/2023-10:40:48] [V] [TRT] Relu_667 [Relu] inputs: [777 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_667 for ONNX node: Relu_667
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 778 for ONNX tensor: 778
[03/01/2023-10:40:48] [V] [TRT] Relu_667 [Relu] outputs: [778 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_668 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_668 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_668 [Constant] outputs: [779 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_669 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_669 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_669 [Constant] outputs: [780 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_670 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 778
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 779
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 780
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_670 [QuantizeLinear] inputs: [778 -> (1, 64, 22, 22)[FLOAT]], [779 -> ()[FLOAT]], [780 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 779 for ONNX node: 779
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 780 for ONNX node: 780
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 781 for ONNX tensor: 781
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_670 [QuantizeLinear] outputs: [781 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_671 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_671 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_671 [Constant] outputs: [782 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_672 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_672 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_672 [Constant] outputs: [783 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_673 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 781
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 782
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 783
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_673 [DequantizeLinear] inputs: [781 -> (1, 64, 22, 22)[FLOAT]], [782 -> ()[FLOAT]], [783 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 782 for ONNX node: 782
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 783 for ONNX node: 783
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 784 for ONNX tensor: 784
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_673 [DequantizeLinear] outputs: [784 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_674 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_674 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_674 [Constant] outputs: [785 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_675 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_675 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_675 [Constant] outputs: [786 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_676 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 785
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 786
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_676 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [785 -> ()[FLOAT]], [786 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 785 for ONNX node: 785
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 786 for ONNX node: 786
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 787 for ONNX tensor: 787
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_676 [QuantizeLinear] outputs: [787 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_677 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_677 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_677 [Constant] outputs: [788 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_678 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_678 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_678 [Constant] outputs: [789 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_679 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 787
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 788
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 789
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_679 [DequantizeLinear] inputs: [787 -> (64, 64, 3, 3)[FLOAT]], [788 -> ()[FLOAT]], [789 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 788 for ONNX node: 788
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 789 for ONNX node: 789
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 790 for ONNX tensor: 790
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_679 [DequantizeLinear] outputs: [790 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_680 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 784
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 790
[03/01/2023-10:40:48] [V] [TRT] Conv_680 [Conv] inputs: [784 -> (1, 64, 22, 22)[FLOAT]], [790 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_680 for ONNX node: Conv_680
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 791 for ONNX tensor: 791
[03/01/2023-10:40:48] [V] [TRT] Conv_680 [Conv] outputs: [791 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: BatchNormalization_681 [BatchNormalization]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 791
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_681 [BatchNormalization] inputs: [791 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: BatchNormalization_681 for ONNX node: BatchNormalization_681
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 792 for ONNX tensor: 792
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_681 [BatchNormalization] outputs: [792 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_682 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 792
[03/01/2023-10:40:48] [V] [TRT] Relu_682 [Relu] inputs: [792 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_682 for ONNX node: Relu_682
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 793 for ONNX tensor: 793
[03/01/2023-10:40:48] [V] [TRT] Relu_682 [Relu] outputs: [793 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: MaxPool_683 [MaxPool]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 793
[03/01/2023-10:40:48] [V] [TRT] MaxPool_683 [MaxPool] inputs: [793 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: MaxPool_683 for ONNX node: MaxPool_683
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 794 for ONNX tensor: 794
[03/01/2023-10:40:48] [V] [TRT] MaxPool_683 [MaxPool] outputs: [794 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_684 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_684 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_684 [Constant] outputs: [795 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_685 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_685 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_685 [Constant] outputs: [796 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_686 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 794
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 795
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 796
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_686 [QuantizeLinear] inputs: [794 -> (1, 64, 10, 10)[FLOAT]], [795 -> ()[FLOAT]], [796 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 795 for ONNX node: 795
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 796 for ONNX node: 796
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 797 for ONNX tensor: 797
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_686 [QuantizeLinear] outputs: [797 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_687 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_687 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_687 [Constant] outputs: [798 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_688 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_688 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_688 [Constant] outputs: [799 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_689 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 797
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 798
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 799
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_689 [DequantizeLinear] inputs: [797 -> (1, 64, 10, 10)[FLOAT]], [798 -> ()[FLOAT]], [799 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 798 for ONNX node: 798
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 799 for ONNX node: 799
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 800 for ONNX tensor: 800
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_689 [DequantizeLinear] outputs: [800 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_690 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_690 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_690 [Constant] outputs: [801 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_691 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_691 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_691 [Constant] outputs: [802 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_692 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 801
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 802
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_692 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [801 -> ()[FLOAT]], [802 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 801 for ONNX node: 801
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 802 for ONNX node: 802
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 803 for ONNX tensor: 803
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_692 [QuantizeLinear] outputs: [803 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_693 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_693 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_693 [Constant] outputs: [804 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_694 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_694 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_694 [Constant] outputs: [805 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_695 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 803
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 804
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 805
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_695 [DequantizeLinear] inputs: [803 -> (128, 64, 3, 3)[FLOAT]], [804 -> ()[FLOAT]], [805 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 804 for ONNX node: 804
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 805 for ONNX node: 805
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 806 for ONNX tensor: 806
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_695 [DequantizeLinear] outputs: [806 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_696 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 800
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 806
[03/01/2023-10:40:48] [V] [TRT] Conv_696 [Conv] inputs: [800 -> (1, 64, 10, 10)[FLOAT]], [806 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_696 for ONNX node: Conv_696
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 807 for ONNX tensor: 807
[03/01/2023-10:40:48] [V] [TRT] Conv_696 [Conv] outputs: [807 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: BatchNormalization_697 [BatchNormalization]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 807
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_697 [BatchNormalization] inputs: [807 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: BatchNormalization_697 for ONNX node: BatchNormalization_697
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 808 for ONNX tensor: 808
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_697 [BatchNormalization] outputs: [808 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_698 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 808
[03/01/2023-10:40:48] [V] [TRT] Relu_698 [Relu] inputs: [808 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_698 for ONNX node: Relu_698
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 809 for ONNX tensor: 809
[03/01/2023-10:40:48] [V] [TRT] Relu_698 [Relu] outputs: [809 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_699 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_699 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_699 [Constant] outputs: [810 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_700 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_700 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_700 [Constant] outputs: [811 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_701 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 809
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 810
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 811
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_701 [QuantizeLinear] inputs: [809 -> (1, 128, 8, 8)[FLOAT]], [810 -> ()[FLOAT]], [811 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 810 for ONNX node: 810
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 811 for ONNX node: 811
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 812 for ONNX tensor: 812
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_701 [QuantizeLinear] outputs: [812 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_702 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_702 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_702 [Constant] outputs: [813 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_703 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_703 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_703 [Constant] outputs: [814 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_704 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 812
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 813
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 814
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_704 [DequantizeLinear] inputs: [812 -> (1, 128, 8, 8)[FLOAT]], [813 -> ()[FLOAT]], [814 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 813 for ONNX node: 813
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 814 for ONNX node: 814
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 815 for ONNX tensor: 815
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_704 [DequantizeLinear] outputs: [815 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_705 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_705 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_705 [Constant] outputs: [816 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_706 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_706 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_706 [Constant] outputs: [817 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_707 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 816
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 817
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_707 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [816 -> ()[FLOAT]], [817 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 816 for ONNX node: 816
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 817 for ONNX node: 817
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 818 for ONNX tensor: 818
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_707 [QuantizeLinear] outputs: [818 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_708 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_708 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_708 [Constant] outputs: [819 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_709 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_709 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_709 [Constant] outputs: [820 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_710 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 818
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 819
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 820
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_710 [DequantizeLinear] inputs: [818 -> (128, 128, 3, 3)[FLOAT]], [819 -> ()[FLOAT]], [820 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 819 for ONNX node: 819
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 820 for ONNX node: 820
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 821 for ONNX tensor: 821
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_710 [DequantizeLinear] outputs: [821 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_711 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 815
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 821
[03/01/2023-10:40:48] [V] [TRT] Conv_711 [Conv] inputs: [815 -> (1, 128, 8, 8)[FLOAT]], [821 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_711 for ONNX node: Conv_711
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 822 for ONNX tensor: 822
[03/01/2023-10:40:48] [V] [TRT] Conv_711 [Conv] outputs: [822 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: BatchNormalization_712 [BatchNormalization]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 822
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:48] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_712 [BatchNormalization] inputs: [822 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: BatchNormalization_712 for ONNX node: BatchNormalization_712
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 823 for ONNX tensor: 823
[03/01/2023-10:40:48] [V] [TRT] BatchNormalization_712 [BatchNormalization] outputs: [823 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_713 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 823
[03/01/2023-10:40:48] [V] [TRT] Relu_713 [Relu] inputs: [823 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_713 for ONNX node: Relu_713
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 824 for ONNX tensor: 824
[03/01/2023-10:40:48] [V] [TRT] Relu_713 [Relu] outputs: [824 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: MaxPool_714 [MaxPool]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 824
[03/01/2023-10:40:48] [V] [TRT] MaxPool_714 [MaxPool] inputs: [824 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: MaxPool_714 for ONNX node: MaxPool_714
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 825 for ONNX tensor: 825
[03/01/2023-10:40:48] [V] [TRT] MaxPool_714 [MaxPool] outputs: [825 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: ReduceMean_715 [ReduceMean]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 825
[03/01/2023-10:40:48] [V] [TRT] ReduceMean_715 [ReduceMean] inputs: [825 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: ReduceMean_715 for ONNX node: ReduceMean_715
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 826 for ONNX tensor: 826
[03/01/2023-10:40:48] [V] [TRT] ReduceMean_715 [ReduceMean] outputs: [826 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: ReduceMax_716 [ReduceMax]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 825
[03/01/2023-10:40:48] [V] [TRT] ReduceMax_716 [ReduceMax] inputs: [825 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: ReduceMax_716 for ONNX node: ReduceMax_716
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 827 for ONNX tensor: 827
[03/01/2023-10:40:48] [V] [TRT] ReduceMax_716 [ReduceMax] outputs: [827 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Concat_717 [Concat]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 826
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 827
[03/01/2023-10:40:48] [V] [TRT] Concat_717 [Concat] inputs: [826 -> (1, 1, 3, 3)[FLOAT]], [827 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Concat_717 for ONNX node: Concat_717
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 828 for ONNX tensor: 828
[03/01/2023-10:40:48] [V] [TRT] Concat_717 [Concat] outputs: [828 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_718 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_718 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_718 [Constant] outputs: [829 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_719 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_719 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_719 [Constant] outputs: [830 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_720 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 828
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 829
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 830
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_720 [QuantizeLinear] inputs: [828 -> (1, 2, 3, 3)[FLOAT]], [829 -> ()[FLOAT]], [830 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 829 for ONNX node: 829
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 830 for ONNX node: 830
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 831 for ONNX tensor: 831
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_720 [QuantizeLinear] outputs: [831 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_721 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_721 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_721 [Constant] outputs: [832 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_722 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_722 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_722 [Constant] outputs: [833 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_723 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 831
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 832
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 833
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_723 [DequantizeLinear] inputs: [831 -> (1, 2, 3, 3)[FLOAT]], [832 -> ()[FLOAT]], [833 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 832 for ONNX node: 832
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 833 for ONNX node: 833
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 834 for ONNX tensor: 834
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_723 [DequantizeLinear] outputs: [834 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_724 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_724 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_724 [Constant] outputs: [835 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_725 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_725 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_725 [Constant] outputs: [836 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_726 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 835
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 836
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_726 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [835 -> ()[FLOAT]], [836 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 835 for ONNX node: 835
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 836 for ONNX node: 836
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 837 for ONNX tensor: 837
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_726 [QuantizeLinear] outputs: [837 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_727 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_727 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_727 [Constant] outputs: [838 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_728 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_728 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_728 [Constant] outputs: [839 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_729 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 837
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 838
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 839
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_729 [DequantizeLinear] inputs: [837 -> (1, 2, 7, 7)[FLOAT]], [838 -> ()[FLOAT]], [839 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 838 for ONNX node: 838
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 839 for ONNX node: 839
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 840 for ONNX tensor: 840
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_729 [DequantizeLinear] outputs: [840 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_730 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 834
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 840
[03/01/2023-10:40:48] [V] [TRT] Conv_730 [Conv] inputs: [834 -> (1, 2, 3, 3)[FLOAT]], [840 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_730 for ONNX node: Conv_730
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 841 for ONNX tensor: 841
[03/01/2023-10:40:48] [V] [TRT] Conv_730 [Conv] outputs: [841 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Sigmoid_731 [Sigmoid]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 841
[03/01/2023-10:40:48] [V] [TRT] Sigmoid_731 [Sigmoid] inputs: [841 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Sigmoid_731 for ONNX node: Sigmoid_731
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 842 for ONNX tensor: 842
[03/01/2023-10:40:48] [V] [TRT] Sigmoid_731 [Sigmoid] outputs: [842 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Mul_732 [Mul]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 825
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 842
[03/01/2023-10:40:48] [V] [TRT] Mul_732 [Mul] inputs: [825 -> (1, 128, 3, 3)[FLOAT]], [842 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Mul_732 for ONNX node: Mul_732
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 843 for ONNX tensor: 843
[03/01/2023-10:40:48] [V] [TRT] Mul_732 [Mul] outputs: [843 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: GlobalAveragePool_733 [GlobalAveragePool]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 843
[03/01/2023-10:40:48] [V] [TRT] GlobalAveragePool_733 [GlobalAveragePool] inputs: [843 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:48] [V] [TRT] Registering layer: GlobalAveragePool_733 for ONNX node: GlobalAveragePool_733
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 844 for ONNX tensor: 844
[03/01/2023-10:40:48] [V] [TRT] GlobalAveragePool_733 [GlobalAveragePool] outputs: [844 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_734 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_734 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_734 [Constant] outputs: [845 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_735 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_735 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_735 [Constant] outputs: [846 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_736 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 844
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 845
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 846
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_736 [QuantizeLinear] inputs: [844 -> (1, 128, 1, 1)[FLOAT]], [845 -> ()[FLOAT]], [846 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 845 for ONNX node: 845
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 846 for ONNX node: 846
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 847 for ONNX tensor: 847
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_736 [QuantizeLinear] outputs: [847 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_737 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_737 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_737 [Constant] outputs: [848 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_738 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_738 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_738 [Constant] outputs: [849 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_739 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 847
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 848
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 849
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_739 [DequantizeLinear] inputs: [847 -> (1, 128, 1, 1)[FLOAT]], [848 -> ()[FLOAT]], [849 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 848 for ONNX node: 848
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 849 for ONNX node: 849
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 850 for ONNX tensor: 850
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_739 [DequantizeLinear] outputs: [850 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_740 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_740 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_740 [Constant] outputs: [851 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_741 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_741 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_741 [Constant] outputs: [852 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_742 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 851
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 852
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_742 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [851 -> ()[FLOAT]], [852 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 851 for ONNX node: 851
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 852 for ONNX node: 852
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 853 for ONNX tensor: 853
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_742 [QuantizeLinear] outputs: [853 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_743 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_743 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_743 [Constant] outputs: [854 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_744 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_744 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_744 [Constant] outputs: [855 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_745 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 853
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 854
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 855
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_745 [DequantizeLinear] inputs: [853 -> (8, 128, 1, 1)[FLOAT]], [854 -> ()[FLOAT]], [855 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 854 for ONNX node: 854
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 855 for ONNX node: 855
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 856 for ONNX tensor: 856
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_745 [DequantizeLinear] outputs: [856 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_746 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 850
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 856
[03/01/2023-10:40:48] [V] [TRT] Conv_746 [Conv] inputs: [850 -> (1, 128, 1, 1)[FLOAT]], [856 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_746 for ONNX node: Conv_746
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 857 for ONNX tensor: 857
[03/01/2023-10:40:48] [V] [TRT] Conv_746 [Conv] outputs: [857 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_747 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 857
[03/01/2023-10:40:48] [V] [TRT] Relu_747 [Relu] inputs: [857 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_747 for ONNX node: Relu_747
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 858 for ONNX tensor: 858
[03/01/2023-10:40:48] [V] [TRT] Relu_747 [Relu] outputs: [858 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_748 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_748 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_748 [Constant] outputs: [859 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_749 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_749 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_749 [Constant] outputs: [860 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_750 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 858
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 859
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 860
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_750 [QuantizeLinear] inputs: [858 -> (1, 8, 1, 1)[FLOAT]], [859 -> ()[FLOAT]], [860 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 859 for ONNX node: 859
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 860 for ONNX node: 860
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 861 for ONNX tensor: 861
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_750 [QuantizeLinear] outputs: [861 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_751 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_751 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_751 [Constant] outputs: [862 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_752 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_752 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_752 [Constant] outputs: [863 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_753 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 861
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 862
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 863
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_753 [DequantizeLinear] inputs: [861 -> (1, 8, 1, 1)[FLOAT]], [862 -> ()[FLOAT]], [863 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 862 for ONNX node: 862
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 863 for ONNX node: 863
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 864 for ONNX tensor: 864
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_753 [DequantizeLinear] outputs: [864 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_754 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_754 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_754 [Constant] outputs: [865 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_755 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_755 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_755 [Constant] outputs: [866 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_756 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 865
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 866
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_756 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [865 -> ()[FLOAT]], [866 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 865 for ONNX node: 865
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 866 for ONNX node: 866
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 867 for ONNX tensor: 867
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_756 [QuantizeLinear] outputs: [867 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_757 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_757 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_757 [Constant] outputs: [868 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_758 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_758 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_758 [Constant] outputs: [869 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_759 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 867
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 868
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 869
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_759 [DequantizeLinear] inputs: [867 -> (128, 8, 1, 1)[FLOAT]], [868 -> ()[FLOAT]], [869 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 868 for ONNX node: 868
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 869 for ONNX node: 869
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 870 for ONNX tensor: 870
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_759 [DequantizeLinear] outputs: [870 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_760 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 864
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 870
[03/01/2023-10:40:48] [V] [TRT] Conv_760 [Conv] inputs: [864 -> (1, 8, 1, 1)[FLOAT]], [870 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_760 for ONNX node: Conv_760
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 871 for ONNX tensor: 871
[03/01/2023-10:40:48] [V] [TRT] Conv_760 [Conv] outputs: [871 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: MaxPool_761 [MaxPool]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 843
[03/01/2023-10:40:48] [V] [TRT] MaxPool_761 [MaxPool] inputs: [843 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: MaxPool_761 for ONNX node: MaxPool_761
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 872 for ONNX tensor: 872
[03/01/2023-10:40:48] [V] [TRT] MaxPool_761 [MaxPool] outputs: [872 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_762 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_762 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_762 [Constant] outputs: [873 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_763 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_763 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_763 [Constant] outputs: [874 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_764 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 872
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 873
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 874
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_764 [QuantizeLinear] inputs: [872 -> (1, 128, 1, 1)[FLOAT]], [873 -> ()[FLOAT]], [874 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 873 for ONNX node: 873
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 874 for ONNX node: 874
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 875 for ONNX tensor: 875
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_764 [QuantizeLinear] outputs: [875 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_765 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_765 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_765 [Constant] outputs: [876 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_766 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_766 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_766 [Constant] outputs: [877 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_767 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 875
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 876
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 877
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_767 [DequantizeLinear] inputs: [875 -> (1, 128, 1, 1)[FLOAT]], [876 -> ()[FLOAT]], [877 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 876 for ONNX node: 876
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 877 for ONNX node: 877
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 878 for ONNX tensor: 878
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_767 [DequantizeLinear] outputs: [878 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_768 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_768 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_768 [Constant] outputs: [879 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_769 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_769 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_769 [Constant] outputs: [880 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_770 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 879
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 880
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_770 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [879 -> ()[FLOAT]], [880 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 879 for ONNX node: 879
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 880 for ONNX node: 880
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 881 for ONNX tensor: 881
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_770 [QuantizeLinear] outputs: [881 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_771 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_771 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_771 [Constant] outputs: [882 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_772 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_772 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_772 [Constant] outputs: [883 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_773 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 881
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 882
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 883
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_773 [DequantizeLinear] inputs: [881 -> (8, 128, 1, 1)[FLOAT]], [882 -> ()[FLOAT]], [883 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 882 for ONNX node: 882
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 883 for ONNX node: 883
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 884 for ONNX tensor: 884
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_773 [DequantizeLinear] outputs: [884 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Conv_774 [Conv]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 878
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 884
[03/01/2023-10:40:48] [V] [TRT] Conv_774 [Conv] inputs: [878 -> (1, 128, 1, 1)[FLOAT]], [884 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Conv_774 for ONNX node: Conv_774
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 885 for ONNX tensor: 885
[03/01/2023-10:40:48] [V] [TRT] Conv_774 [Conv] outputs: [885 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Relu_775 [Relu]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 885
[03/01/2023-10:40:48] [V] [TRT] Relu_775 [Relu] inputs: [885 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: Relu_775 for ONNX node: Relu_775
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 886 for ONNX tensor: 886
[03/01/2023-10:40:48] [V] [TRT] Relu_775 [Relu] outputs: [886 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_776 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_776 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_776 [Constant] outputs: [887 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_777 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_777 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_777 [Constant] outputs: [888 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: QuantizeLinear_778 [QuantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 886
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 887
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 888
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_778 [QuantizeLinear] inputs: [886 -> (1, 8, 1, 1)[FLOAT]], [887 -> ()[FLOAT]], [888 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 887 for ONNX node: 887
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 888 for ONNX node: 888
[03/01/2023-10:40:48] [V] [TRT] Registering tensor: 889 for ONNX tensor: 889
[03/01/2023-10:40:48] [V] [TRT] QuantizeLinear_778 [QuantizeLinear] outputs: [889 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_779 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_779 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_779 [Constant] outputs: [890 -> ()[FLOAT]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: Constant_780 [Constant]
[03/01/2023-10:40:48] [V] [TRT] Constant_780 [Constant] inputs: 
[03/01/2023-10:40:48] [V] [TRT] Constant_780 [Constant] outputs: [891 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Parsing node: DequantizeLinear_781 [DequantizeLinear]
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 889
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 890
[03/01/2023-10:40:48] [V] [TRT] Searching for input: 891
[03/01/2023-10:40:48] [V] [TRT] DequantizeLinear_781 [DequantizeLinear] inputs: [889 -> (1, 8, 1, 1)[FLOAT]], [890 -> ()[FLOAT]], [891 -> ()[INT8]], 
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 890 for ONNX node: 890
[03/01/2023-10:40:48] [V] [TRT] Registering layer: 891 for ONNX node: 891
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 892 for ONNX tensor: 892
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_781 [DequantizeLinear] outputs: [892 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_782 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_782 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_782 [Constant] outputs: [893 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_783 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_783 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_783 [Constant] outputs: [894 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_784 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 893
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 894
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_784 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [893 -> ()[FLOAT]], [894 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 893 for ONNX node: 893
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 894 for ONNX node: 894
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 895 for ONNX tensor: 895
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_784 [QuantizeLinear] outputs: [895 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_785 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_785 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_785 [Constant] outputs: [896 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_786 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_786 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_786 [Constant] outputs: [897 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_787 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 895
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 896
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 897
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_787 [DequantizeLinear] inputs: [895 -> (128, 8, 1, 1)[FLOAT]], [896 -> ()[FLOAT]], [897 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 896 for ONNX node: 896
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 897 for ONNX node: 897
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 898 for ONNX tensor: 898
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_787 [DequantizeLinear] outputs: [898 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_788 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 892
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 898
[03/01/2023-10:40:49] [V] [TRT] Conv_788 [Conv] inputs: [892 -> (1, 8, 1, 1)[FLOAT]], [898 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_788 for ONNX node: Conv_788
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 899 for ONNX tensor: 899
[03/01/2023-10:40:49] [V] [TRT] Conv_788 [Conv] outputs: [899 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Add_789 [Add]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 871
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 899
[03/01/2023-10:40:49] [V] [TRT] Add_789 [Add] inputs: [871 -> (1, 128, 1, 1)[FLOAT]], [899 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Add_789 for ONNX node: Add_789
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 900 for ONNX tensor: 900
[03/01/2023-10:40:49] [V] [TRT] Add_789 [Add] outputs: [900 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Sigmoid_790 [Sigmoid]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 900
[03/01/2023-10:40:49] [V] [TRT] Sigmoid_790 [Sigmoid] inputs: [900 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Sigmoid_790 for ONNX node: Sigmoid_790
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 901 for ONNX tensor: 901
[03/01/2023-10:40:49] [V] [TRT] Sigmoid_790 [Sigmoid] outputs: [901 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Mul_791 [Mul]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 843
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 901
[03/01/2023-10:40:49] [V] [TRT] Mul_791 [Mul] inputs: [843 -> (1, 128, 3, 3)[FLOAT]], [901 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Mul_791 for ONNX node: Mul_791
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 902 for ONNX tensor: 902
[03/01/2023-10:40:49] [V] [TRT] Mul_791 [Mul] outputs: [902 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Concat_792 [Concat]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 753
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 902
[03/01/2023-10:40:49] [V] [TRT] Concat_792 [Concat] inputs: [753 -> (1, 384, 3, 3)[FLOAT]], [902 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Concat_792 for ONNX node: Concat_792
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 903 for ONNX tensor: 903
[03/01/2023-10:40:49] [V] [TRT] Concat_792 [Concat] outputs: [903 -> (1, 512, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_793 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_793 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_793 [Constant] outputs: [904 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_794 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_794 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_794 [Constant] outputs: [905 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_795 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_795 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_795 [Constant] outputs: [906 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_796 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_796 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_796 [Constant] outputs: [907 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Slice_797 [Slice]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: input
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 905
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 906
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 904
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 907
[03/01/2023-10:40:49] [V] [TRT] Slice_797 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [905 -> (1)[INT32]], [906 -> (1)[INT32]], [904 -> (1)[INT32]], [907 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Slice_797 for ONNX node: Slice_797
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 908 for ONNX tensor: 908
[03/01/2023-10:40:49] [V] [TRT] Slice_797 [Slice] outputs: [908 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_798 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_798 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_798 [Constant] outputs: [909 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_799 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_799 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_799 [Constant] outputs: [910 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_800 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_800 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_800 [Constant] outputs: [911 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_801 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_801 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_801 [Constant] outputs: [912 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Slice_802 [Slice]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 908
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 910
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 911
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 909
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 912
[03/01/2023-10:40:49] [V] [TRT] Slice_802 [Slice] inputs: [908 -> (1, 1, 24, 60)[FLOAT]], [910 -> (1)[INT32]], [911 -> (1)[INT32]], [909 -> (1)[INT32]], [912 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Slice_802 for ONNX node: Slice_802
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 913 for ONNX tensor: 913
[03/01/2023-10:40:49] [V] [TRT] Slice_802 [Slice] outputs: [913 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_803 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_803 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_803 [Constant] outputs: [914 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_804 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_804 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_804 [Constant] outputs: [915 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_805 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 913
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 914
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 915
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_805 [QuantizeLinear] inputs: [913 -> (1, 1, 24, 24)[FLOAT]], [914 -> ()[FLOAT]], [915 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 914 for ONNX node: 914
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 915 for ONNX node: 915
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 916 for ONNX tensor: 916
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_805 [QuantizeLinear] outputs: [916 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_806 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_806 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_806 [Constant] outputs: [917 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_807 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_807 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_807 [Constant] outputs: [918 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_808 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 916
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 917
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 918
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_808 [DequantizeLinear] inputs: [916 -> (1, 1, 24, 24)[FLOAT]], [917 -> ()[FLOAT]], [918 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 917 for ONNX node: 917
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 918 for ONNX node: 918
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 919 for ONNX tensor: 919
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_808 [DequantizeLinear] outputs: [919 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_809 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_809 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_809 [Constant] outputs: [920 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_810 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_810 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_810 [Constant] outputs: [921 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_811 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 920
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 921
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_811 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [920 -> ()[FLOAT]], [921 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 920 for ONNX node: 920
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 921 for ONNX node: 921
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 922 for ONNX tensor: 922
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_811 [QuantizeLinear] outputs: [922 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_812 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_812 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_812 [Constant] outputs: [923 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_813 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_813 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_813 [Constant] outputs: [924 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_814 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 922
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 923
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 924
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_814 [DequantizeLinear] inputs: [922 -> (64, 1, 3, 3)[FLOAT]], [923 -> ()[FLOAT]], [924 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 923 for ONNX node: 923
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 924 for ONNX node: 924
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 925 for ONNX tensor: 925
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_814 [DequantizeLinear] outputs: [925 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_815 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 919
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 925
[03/01/2023-10:40:49] [V] [TRT] Conv_815 [Conv] inputs: [919 -> (1, 1, 24, 24)[FLOAT]], [925 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_815 for ONNX node: Conv_815
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 926 for ONNX tensor: 926
[03/01/2023-10:40:49] [V] [TRT] Conv_815 [Conv] outputs: [926 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: BatchNormalization_816 [BatchNormalization]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 926
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_816 [BatchNormalization] inputs: [926 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: BatchNormalization_816 for ONNX node: BatchNormalization_816
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 927 for ONNX tensor: 927
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_816 [BatchNormalization] outputs: [927 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Relu_817 [Relu]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 927
[03/01/2023-10:40:49] [V] [TRT] Relu_817 [Relu] inputs: [927 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Relu_817 for ONNX node: Relu_817
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 928 for ONNX tensor: 928
[03/01/2023-10:40:49] [V] [TRT] Relu_817 [Relu] outputs: [928 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_818 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_818 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_818 [Constant] outputs: [929 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_819 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_819 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_819 [Constant] outputs: [930 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_820 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 928
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 929
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 930
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_820 [QuantizeLinear] inputs: [928 -> (1, 64, 22, 22)[FLOAT]], [929 -> ()[FLOAT]], [930 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 929 for ONNX node: 929
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 930 for ONNX node: 930
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 931 for ONNX tensor: 931
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_820 [QuantizeLinear] outputs: [931 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_821 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_821 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_821 [Constant] outputs: [932 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_822 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_822 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_822 [Constant] outputs: [933 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_823 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 931
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 932
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 933
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_823 [DequantizeLinear] inputs: [931 -> (1, 64, 22, 22)[FLOAT]], [932 -> ()[FLOAT]], [933 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 932 for ONNX node: 932
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 933 for ONNX node: 933
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 934 for ONNX tensor: 934
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_823 [DequantizeLinear] outputs: [934 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_824 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_824 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_824 [Constant] outputs: [935 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_825 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_825 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_825 [Constant] outputs: [936 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_826 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 935
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 936
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_826 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [935 -> ()[FLOAT]], [936 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 935 for ONNX node: 935
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 936 for ONNX node: 936
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 937 for ONNX tensor: 937
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_826 [QuantizeLinear] outputs: [937 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_827 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_827 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_827 [Constant] outputs: [938 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_828 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_828 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_828 [Constant] outputs: [939 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_829 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 937
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 938
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 939
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_829 [DequantizeLinear] inputs: [937 -> (64, 64, 3, 3)[FLOAT]], [938 -> ()[FLOAT]], [939 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 938 for ONNX node: 938
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 939 for ONNX node: 939
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 940 for ONNX tensor: 940
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_829 [DequantizeLinear] outputs: [940 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_830 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 934
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 940
[03/01/2023-10:40:49] [V] [TRT] Conv_830 [Conv] inputs: [934 -> (1, 64, 22, 22)[FLOAT]], [940 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_830 for ONNX node: Conv_830
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 941 for ONNX tensor: 941
[03/01/2023-10:40:49] [V] [TRT] Conv_830 [Conv] outputs: [941 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: BatchNormalization_831 [BatchNormalization]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 941
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_831 [BatchNormalization] inputs: [941 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: BatchNormalization_831 for ONNX node: BatchNormalization_831
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 942 for ONNX tensor: 942
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_831 [BatchNormalization] outputs: [942 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Relu_832 [Relu]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 942
[03/01/2023-10:40:49] [V] [TRT] Relu_832 [Relu] inputs: [942 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Relu_832 for ONNX node: Relu_832
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 943 for ONNX tensor: 943
[03/01/2023-10:40:49] [V] [TRT] Relu_832 [Relu] outputs: [943 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: MaxPool_833 [MaxPool]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 943
[03/01/2023-10:40:49] [V] [TRT] MaxPool_833 [MaxPool] inputs: [943 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: MaxPool_833 for ONNX node: MaxPool_833
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 944 for ONNX tensor: 944
[03/01/2023-10:40:49] [V] [TRT] MaxPool_833 [MaxPool] outputs: [944 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_834 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_834 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_834 [Constant] outputs: [945 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_835 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_835 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_835 [Constant] outputs: [946 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_836 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 944
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 945
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 946
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_836 [QuantizeLinear] inputs: [944 -> (1, 64, 10, 10)[FLOAT]], [945 -> ()[FLOAT]], [946 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 945 for ONNX node: 945
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 946 for ONNX node: 946
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 947 for ONNX tensor: 947
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_836 [QuantizeLinear] outputs: [947 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_837 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_837 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_837 [Constant] outputs: [948 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_838 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_838 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_838 [Constant] outputs: [949 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_839 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 947
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 948
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 949
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_839 [DequantizeLinear] inputs: [947 -> (1, 64, 10, 10)[FLOAT]], [948 -> ()[FLOAT]], [949 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 948 for ONNX node: 948
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 949 for ONNX node: 949
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 950 for ONNX tensor: 950
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_839 [DequantizeLinear] outputs: [950 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_840 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_840 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_840 [Constant] outputs: [951 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_841 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_841 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_841 [Constant] outputs: [952 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_842 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 951
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 952
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_842 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [951 -> ()[FLOAT]], [952 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 951 for ONNX node: 951
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 952 for ONNX node: 952
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 953 for ONNX tensor: 953
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_842 [QuantizeLinear] outputs: [953 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_843 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_843 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_843 [Constant] outputs: [954 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_844 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_844 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_844 [Constant] outputs: [955 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_845 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 953
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 954
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 955
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_845 [DequantizeLinear] inputs: [953 -> (128, 64, 3, 3)[FLOAT]], [954 -> ()[FLOAT]], [955 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 954 for ONNX node: 954
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 955 for ONNX node: 955
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 956 for ONNX tensor: 956
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_845 [DequantizeLinear] outputs: [956 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_846 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 950
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 956
[03/01/2023-10:40:49] [V] [TRT] Conv_846 [Conv] inputs: [950 -> (1, 64, 10, 10)[FLOAT]], [956 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_846 for ONNX node: Conv_846
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 957 for ONNX tensor: 957
[03/01/2023-10:40:49] [V] [TRT] Conv_846 [Conv] outputs: [957 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: BatchNormalization_847 [BatchNormalization]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 957
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_847 [BatchNormalization] inputs: [957 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: BatchNormalization_847 for ONNX node: BatchNormalization_847
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 958 for ONNX tensor: 958
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_847 [BatchNormalization] outputs: [958 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Relu_848 [Relu]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 958
[03/01/2023-10:40:49] [V] [TRT] Relu_848 [Relu] inputs: [958 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Relu_848 for ONNX node: Relu_848
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 959 for ONNX tensor: 959
[03/01/2023-10:40:49] [V] [TRT] Relu_848 [Relu] outputs: [959 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_849 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_849 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_849 [Constant] outputs: [960 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_850 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_850 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_850 [Constant] outputs: [961 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_851 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 959
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 960
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 961
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_851 [QuantizeLinear] inputs: [959 -> (1, 128, 8, 8)[FLOAT]], [960 -> ()[FLOAT]], [961 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 960 for ONNX node: 960
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 961 for ONNX node: 961
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 962 for ONNX tensor: 962
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_851 [QuantizeLinear] outputs: [962 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_852 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_852 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_852 [Constant] outputs: [963 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_853 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_853 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_853 [Constant] outputs: [964 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_854 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 962
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 963
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 964
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_854 [DequantizeLinear] inputs: [962 -> (1, 128, 8, 8)[FLOAT]], [963 -> ()[FLOAT]], [964 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 963 for ONNX node: 963
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 964 for ONNX node: 964
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 965 for ONNX tensor: 965
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_854 [DequantizeLinear] outputs: [965 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_855 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_855 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_855 [Constant] outputs: [966 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_856 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_856 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_856 [Constant] outputs: [967 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_857 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 966
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 967
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_857 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [966 -> ()[FLOAT]], [967 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 966 for ONNX node: 966
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 967 for ONNX node: 967
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 968 for ONNX tensor: 968
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_857 [QuantizeLinear] outputs: [968 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_858 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_858 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_858 [Constant] outputs: [969 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_859 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_859 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_859 [Constant] outputs: [970 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_860 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 968
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 969
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 970
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_860 [DequantizeLinear] inputs: [968 -> (128, 128, 3, 3)[FLOAT]], [969 -> ()[FLOAT]], [970 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 969 for ONNX node: 969
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 970 for ONNX node: 970
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 971 for ONNX tensor: 971
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_860 [DequantizeLinear] outputs: [971 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_861 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 965
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 971
[03/01/2023-10:40:49] [V] [TRT] Conv_861 [Conv] inputs: [965 -> (1, 128, 8, 8)[FLOAT]], [971 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_861 for ONNX node: Conv_861
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 972 for ONNX tensor: 972
[03/01/2023-10:40:49] [V] [TRT] Conv_861 [Conv] outputs: [972 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: BatchNormalization_862 [BatchNormalization]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 972
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_862 [BatchNormalization] inputs: [972 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: BatchNormalization_862 for ONNX node: BatchNormalization_862
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 973 for ONNX tensor: 973
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_862 [BatchNormalization] outputs: [973 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Relu_863 [Relu]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 973
[03/01/2023-10:40:49] [V] [TRT] Relu_863 [Relu] inputs: [973 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Relu_863 for ONNX node: Relu_863
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 974 for ONNX tensor: 974
[03/01/2023-10:40:49] [V] [TRT] Relu_863 [Relu] outputs: [974 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: MaxPool_864 [MaxPool]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 974
[03/01/2023-10:40:49] [V] [TRT] MaxPool_864 [MaxPool] inputs: [974 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: MaxPool_864 for ONNX node: MaxPool_864
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 975 for ONNX tensor: 975
[03/01/2023-10:40:49] [V] [TRT] MaxPool_864 [MaxPool] outputs: [975 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: ReduceMean_865 [ReduceMean]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 975
[03/01/2023-10:40:49] [V] [TRT] ReduceMean_865 [ReduceMean] inputs: [975 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: ReduceMean_865 for ONNX node: ReduceMean_865
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 976 for ONNX tensor: 976
[03/01/2023-10:40:49] [V] [TRT] ReduceMean_865 [ReduceMean] outputs: [976 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: ReduceMax_866 [ReduceMax]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 975
[03/01/2023-10:40:49] [V] [TRT] ReduceMax_866 [ReduceMax] inputs: [975 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: ReduceMax_866 for ONNX node: ReduceMax_866
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 977 for ONNX tensor: 977
[03/01/2023-10:40:49] [V] [TRT] ReduceMax_866 [ReduceMax] outputs: [977 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Concat_867 [Concat]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 976
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 977
[03/01/2023-10:40:49] [V] [TRT] Concat_867 [Concat] inputs: [976 -> (1, 1, 3, 3)[FLOAT]], [977 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Concat_867 for ONNX node: Concat_867
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 978 for ONNX tensor: 978
[03/01/2023-10:40:49] [V] [TRT] Concat_867 [Concat] outputs: [978 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_868 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_868 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_868 [Constant] outputs: [979 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_869 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_869 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_869 [Constant] outputs: [980 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_870 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 978
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 979
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 980
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_870 [QuantizeLinear] inputs: [978 -> (1, 2, 3, 3)[FLOAT]], [979 -> ()[FLOAT]], [980 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 979 for ONNX node: 979
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 980 for ONNX node: 980
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 981 for ONNX tensor: 981
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_870 [QuantizeLinear] outputs: [981 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_871 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_871 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_871 [Constant] outputs: [982 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_872 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_872 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_872 [Constant] outputs: [983 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_873 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 981
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 982
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 983
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_873 [DequantizeLinear] inputs: [981 -> (1, 2, 3, 3)[FLOAT]], [982 -> ()[FLOAT]], [983 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 982 for ONNX node: 982
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 983 for ONNX node: 983
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 984 for ONNX tensor: 984
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_873 [DequantizeLinear] outputs: [984 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_874 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_874 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_874 [Constant] outputs: [985 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_875 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_875 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_875 [Constant] outputs: [986 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_876 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 985
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 986
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_876 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [985 -> ()[FLOAT]], [986 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 985 for ONNX node: 985
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 986 for ONNX node: 986
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 987 for ONNX tensor: 987
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_876 [QuantizeLinear] outputs: [987 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_877 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_877 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_877 [Constant] outputs: [988 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_878 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_878 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_878 [Constant] outputs: [989 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_879 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 987
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 988
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 989
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_879 [DequantizeLinear] inputs: [987 -> (1, 2, 7, 7)[FLOAT]], [988 -> ()[FLOAT]], [989 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 988 for ONNX node: 988
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 989 for ONNX node: 989
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 990 for ONNX tensor: 990
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_879 [DequantizeLinear] outputs: [990 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_880 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 984
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 990
[03/01/2023-10:40:49] [V] [TRT] Conv_880 [Conv] inputs: [984 -> (1, 2, 3, 3)[FLOAT]], [990 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_880 for ONNX node: Conv_880
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 991 for ONNX tensor: 991
[03/01/2023-10:40:49] [V] [TRT] Conv_880 [Conv] outputs: [991 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Sigmoid_881 [Sigmoid]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 991
[03/01/2023-10:40:49] [V] [TRT] Sigmoid_881 [Sigmoid] inputs: [991 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Sigmoid_881 for ONNX node: Sigmoid_881
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 992 for ONNX tensor: 992
[03/01/2023-10:40:49] [V] [TRT] Sigmoid_881 [Sigmoid] outputs: [992 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Mul_882 [Mul]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 975
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 992
[03/01/2023-10:40:49] [V] [TRT] Mul_882 [Mul] inputs: [975 -> (1, 128, 3, 3)[FLOAT]], [992 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Mul_882 for ONNX node: Mul_882
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 993 for ONNX tensor: 993
[03/01/2023-10:40:49] [V] [TRT] Mul_882 [Mul] outputs: [993 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: GlobalAveragePool_883 [GlobalAveragePool]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 993
[03/01/2023-10:40:49] [V] [TRT] GlobalAveragePool_883 [GlobalAveragePool] inputs: [993 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:49] [V] [TRT] Registering layer: GlobalAveragePool_883 for ONNX node: GlobalAveragePool_883
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 994 for ONNX tensor: 994
[03/01/2023-10:40:49] [V] [TRT] GlobalAveragePool_883 [GlobalAveragePool] outputs: [994 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_884 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_884 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_884 [Constant] outputs: [995 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_885 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_885 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_885 [Constant] outputs: [996 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_886 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 994
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 995
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 996
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_886 [QuantizeLinear] inputs: [994 -> (1, 128, 1, 1)[FLOAT]], [995 -> ()[FLOAT]], [996 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 995 for ONNX node: 995
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 996 for ONNX node: 996
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 997 for ONNX tensor: 997
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_886 [QuantizeLinear] outputs: [997 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_887 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_887 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_887 [Constant] outputs: [998 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_888 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_888 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_888 [Constant] outputs: [999 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_889 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 997
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 998
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 999
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_889 [DequantizeLinear] inputs: [997 -> (1, 128, 1, 1)[FLOAT]], [998 -> ()[FLOAT]], [999 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 998 for ONNX node: 998
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 999 for ONNX node: 999
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1000 for ONNX tensor: 1000
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_889 [DequantizeLinear] outputs: [1000 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_890 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_890 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_890 [Constant] outputs: [1001 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_891 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_891 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_891 [Constant] outputs: [1002 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_892 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1001
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1002
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_892 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1001 -> ()[FLOAT]], [1002 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1001 for ONNX node: 1001
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1002 for ONNX node: 1002
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1003 for ONNX tensor: 1003
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_892 [QuantizeLinear] outputs: [1003 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_893 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_893 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_893 [Constant] outputs: [1004 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_894 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_894 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_894 [Constant] outputs: [1005 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_895 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1003
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1004
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1005
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_895 [DequantizeLinear] inputs: [1003 -> (8, 128, 1, 1)[FLOAT]], [1004 -> ()[FLOAT]], [1005 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1004 for ONNX node: 1004
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1005 for ONNX node: 1005
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1006 for ONNX tensor: 1006
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_895 [DequantizeLinear] outputs: [1006 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_896 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1000
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1006
[03/01/2023-10:40:49] [V] [TRT] Conv_896 [Conv] inputs: [1000 -> (1, 128, 1, 1)[FLOAT]], [1006 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_896 for ONNX node: Conv_896
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1007 for ONNX tensor: 1007
[03/01/2023-10:40:49] [V] [TRT] Conv_896 [Conv] outputs: [1007 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Relu_897 [Relu]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1007
[03/01/2023-10:40:49] [V] [TRT] Relu_897 [Relu] inputs: [1007 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Relu_897 for ONNX node: Relu_897
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1008 for ONNX tensor: 1008
[03/01/2023-10:40:49] [V] [TRT] Relu_897 [Relu] outputs: [1008 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_898 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_898 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_898 [Constant] outputs: [1009 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_899 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_899 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_899 [Constant] outputs: [1010 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_900 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1008
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1009
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1010
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_900 [QuantizeLinear] inputs: [1008 -> (1, 8, 1, 1)[FLOAT]], [1009 -> ()[FLOAT]], [1010 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1009 for ONNX node: 1009
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1010 for ONNX node: 1010
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1011 for ONNX tensor: 1011
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_900 [QuantizeLinear] outputs: [1011 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_901 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_901 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_901 [Constant] outputs: [1012 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_902 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_902 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_902 [Constant] outputs: [1013 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_903 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1011
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1012
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1013
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_903 [DequantizeLinear] inputs: [1011 -> (1, 8, 1, 1)[FLOAT]], [1012 -> ()[FLOAT]], [1013 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1012 for ONNX node: 1012
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1013 for ONNX node: 1013
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1014 for ONNX tensor: 1014
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_903 [DequantizeLinear] outputs: [1014 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_904 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_904 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_904 [Constant] outputs: [1015 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_905 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_905 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_905 [Constant] outputs: [1016 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_906 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1015
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1016
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_906 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1015 -> ()[FLOAT]], [1016 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1015 for ONNX node: 1015
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1016 for ONNX node: 1016
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1017 for ONNX tensor: 1017
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_906 [QuantizeLinear] outputs: [1017 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_907 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_907 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_907 [Constant] outputs: [1018 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_908 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_908 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_908 [Constant] outputs: [1019 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_909 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1017
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1018
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1019
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_909 [DequantizeLinear] inputs: [1017 -> (128, 8, 1, 1)[FLOAT]], [1018 -> ()[FLOAT]], [1019 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1018 for ONNX node: 1018
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1019 for ONNX node: 1019
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1020 for ONNX tensor: 1020
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_909 [DequantizeLinear] outputs: [1020 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_910 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1014
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1020
[03/01/2023-10:40:49] [V] [TRT] Conv_910 [Conv] inputs: [1014 -> (1, 8, 1, 1)[FLOAT]], [1020 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_910 for ONNX node: Conv_910
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1021 for ONNX tensor: 1021
[03/01/2023-10:40:49] [V] [TRT] Conv_910 [Conv] outputs: [1021 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: MaxPool_911 [MaxPool]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 993
[03/01/2023-10:40:49] [V] [TRT] MaxPool_911 [MaxPool] inputs: [993 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: MaxPool_911 for ONNX node: MaxPool_911
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1022 for ONNX tensor: 1022
[03/01/2023-10:40:49] [V] [TRT] MaxPool_911 [MaxPool] outputs: [1022 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_912 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_912 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_912 [Constant] outputs: [1023 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_913 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_913 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_913 [Constant] outputs: [1024 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_914 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1022
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1023
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1024
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_914 [QuantizeLinear] inputs: [1022 -> (1, 128, 1, 1)[FLOAT]], [1023 -> ()[FLOAT]], [1024 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1023 for ONNX node: 1023
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1024 for ONNX node: 1024
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1025 for ONNX tensor: 1025
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_914 [QuantizeLinear] outputs: [1025 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_915 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_915 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_915 [Constant] outputs: [1026 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_916 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_916 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_916 [Constant] outputs: [1027 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_917 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1025
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1026
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1027
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_917 [DequantizeLinear] inputs: [1025 -> (1, 128, 1, 1)[FLOAT]], [1026 -> ()[FLOAT]], [1027 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1026 for ONNX node: 1026
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1027 for ONNX node: 1027
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1028 for ONNX tensor: 1028
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_917 [DequantizeLinear] outputs: [1028 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_918 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_918 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_918 [Constant] outputs: [1029 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_919 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_919 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_919 [Constant] outputs: [1030 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_920 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1029
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1030
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_920 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1029 -> ()[FLOAT]], [1030 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1029 for ONNX node: 1029
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1030 for ONNX node: 1030
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1031 for ONNX tensor: 1031
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_920 [QuantizeLinear] outputs: [1031 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_921 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_921 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_921 [Constant] outputs: [1032 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_922 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_922 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_922 [Constant] outputs: [1033 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_923 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1031
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1032
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1033
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_923 [DequantizeLinear] inputs: [1031 -> (8, 128, 1, 1)[FLOAT]], [1032 -> ()[FLOAT]], [1033 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1032 for ONNX node: 1032
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1033 for ONNX node: 1033
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1034 for ONNX tensor: 1034
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_923 [DequantizeLinear] outputs: [1034 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_924 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1028
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1034
[03/01/2023-10:40:49] [V] [TRT] Conv_924 [Conv] inputs: [1028 -> (1, 128, 1, 1)[FLOAT]], [1034 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_924 for ONNX node: Conv_924
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1035 for ONNX tensor: 1035
[03/01/2023-10:40:49] [V] [TRT] Conv_924 [Conv] outputs: [1035 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Relu_925 [Relu]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1035
[03/01/2023-10:40:49] [V] [TRT] Relu_925 [Relu] inputs: [1035 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Relu_925 for ONNX node: Relu_925
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1036 for ONNX tensor: 1036
[03/01/2023-10:40:49] [V] [TRT] Relu_925 [Relu] outputs: [1036 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_926 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_926 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_926 [Constant] outputs: [1037 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_927 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_927 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_927 [Constant] outputs: [1038 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_928 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1036
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1037
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1038
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_928 [QuantizeLinear] inputs: [1036 -> (1, 8, 1, 1)[FLOAT]], [1037 -> ()[FLOAT]], [1038 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1037 for ONNX node: 1037
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1038 for ONNX node: 1038
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1039 for ONNX tensor: 1039
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_928 [QuantizeLinear] outputs: [1039 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_929 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_929 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_929 [Constant] outputs: [1040 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_930 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_930 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_930 [Constant] outputs: [1041 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_931 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1039
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1040
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1041
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_931 [DequantizeLinear] inputs: [1039 -> (1, 8, 1, 1)[FLOAT]], [1040 -> ()[FLOAT]], [1041 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1040 for ONNX node: 1040
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1041 for ONNX node: 1041
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1042 for ONNX tensor: 1042
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_931 [DequantizeLinear] outputs: [1042 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_932 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_932 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_932 [Constant] outputs: [1043 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_933 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_933 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_933 [Constant] outputs: [1044 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_934 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1043
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1044
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_934 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1043 -> ()[FLOAT]], [1044 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1043 for ONNX node: 1043
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1044 for ONNX node: 1044
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1045 for ONNX tensor: 1045
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_934 [QuantizeLinear] outputs: [1045 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_935 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_935 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_935 [Constant] outputs: [1046 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_936 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_936 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_936 [Constant] outputs: [1047 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_937 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1045
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1046
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1047
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_937 [DequantizeLinear] inputs: [1045 -> (128, 8, 1, 1)[FLOAT]], [1046 -> ()[FLOAT]], [1047 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1046 for ONNX node: 1046
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1047 for ONNX node: 1047
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1048 for ONNX tensor: 1048
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_937 [DequantizeLinear] outputs: [1048 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_938 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1042
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1048
[03/01/2023-10:40:49] [V] [TRT] Conv_938 [Conv] inputs: [1042 -> (1, 8, 1, 1)[FLOAT]], [1048 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_938 for ONNX node: Conv_938
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1049 for ONNX tensor: 1049
[03/01/2023-10:40:49] [V] [TRT] Conv_938 [Conv] outputs: [1049 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Add_939 [Add]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1021
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1049
[03/01/2023-10:40:49] [V] [TRT] Add_939 [Add] inputs: [1021 -> (1, 128, 1, 1)[FLOAT]], [1049 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Add_939 for ONNX node: Add_939
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1050 for ONNX tensor: 1050
[03/01/2023-10:40:49] [V] [TRT] Add_939 [Add] outputs: [1050 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Sigmoid_940 [Sigmoid]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1050
[03/01/2023-10:40:49] [V] [TRT] Sigmoid_940 [Sigmoid] inputs: [1050 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Sigmoid_940 for ONNX node: Sigmoid_940
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1051 for ONNX tensor: 1051
[03/01/2023-10:40:49] [V] [TRT] Sigmoid_940 [Sigmoid] outputs: [1051 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Mul_941 [Mul]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 993
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1051
[03/01/2023-10:40:49] [V] [TRT] Mul_941 [Mul] inputs: [993 -> (1, 128, 3, 3)[FLOAT]], [1051 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Mul_941 for ONNX node: Mul_941
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1052 for ONNX tensor: 1052
[03/01/2023-10:40:49] [V] [TRT] Mul_941 [Mul] outputs: [1052 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Concat_942 [Concat]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 903
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1052
[03/01/2023-10:40:49] [V] [TRT] Concat_942 [Concat] inputs: [903 -> (1, 512, 3, 3)[FLOAT]], [1052 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Concat_942 for ONNX node: Concat_942
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1053 for ONNX tensor: 1053
[03/01/2023-10:40:49] [V] [TRT] Concat_942 [Concat] outputs: [1053 -> (1, 640, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_943 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_943 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_943 [Constant] outputs: [1054 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_944 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_944 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_944 [Constant] outputs: [1055 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_945 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_945 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_945 [Constant] outputs: [1056 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_946 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_946 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_946 [Constant] outputs: [1057 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Slice_947 [Slice]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: input
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1055
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1056
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1054
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1057
[03/01/2023-10:40:49] [V] [TRT] Slice_947 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [1055 -> (1)[INT32]], [1056 -> (1)[INT32]], [1054 -> (1)[INT32]], [1057 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Slice_947 for ONNX node: Slice_947
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1058 for ONNX tensor: 1058
[03/01/2023-10:40:49] [V] [TRT] Slice_947 [Slice] outputs: [1058 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_948 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_948 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_948 [Constant] outputs: [1059 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_949 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_949 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_949 [Constant] outputs: [1060 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_950 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_950 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_950 [Constant] outputs: [1061 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_951 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_951 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_951 [Constant] outputs: [1062 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Slice_952 [Slice]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1058
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1060
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1061
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1059
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1062
[03/01/2023-10:40:49] [V] [TRT] Slice_952 [Slice] inputs: [1058 -> (1, 1, 24, 60)[FLOAT]], [1060 -> (1)[INT32]], [1061 -> (1)[INT32]], [1059 -> (1)[INT32]], [1062 -> (1)[INT32]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Slice_952 for ONNX node: Slice_952
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1063 for ONNX tensor: 1063
[03/01/2023-10:40:49] [V] [TRT] Slice_952 [Slice] outputs: [1063 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_953 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_953 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_953 [Constant] outputs: [1064 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_954 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_954 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_954 [Constant] outputs: [1065 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_955 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1063
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1064
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1065
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_955 [QuantizeLinear] inputs: [1063 -> (1, 1, 24, 24)[FLOAT]], [1064 -> ()[FLOAT]], [1065 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1064 for ONNX node: 1064
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1065 for ONNX node: 1065
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1066 for ONNX tensor: 1066
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_955 [QuantizeLinear] outputs: [1066 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_956 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_956 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_956 [Constant] outputs: [1067 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_957 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_957 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_957 [Constant] outputs: [1068 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_958 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1066
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1067
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1068
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_958 [DequantizeLinear] inputs: [1066 -> (1, 1, 24, 24)[FLOAT]], [1067 -> ()[FLOAT]], [1068 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1067 for ONNX node: 1067
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1068 for ONNX node: 1068
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1069 for ONNX tensor: 1069
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_958 [DequantizeLinear] outputs: [1069 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_959 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_959 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_959 [Constant] outputs: [1070 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_960 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_960 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_960 [Constant] outputs: [1071 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_961 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1070
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1071
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_961 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [1070 -> ()[FLOAT]], [1071 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1070 for ONNX node: 1070
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1071 for ONNX node: 1071
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1072 for ONNX tensor: 1072
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_961 [QuantizeLinear] outputs: [1072 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_962 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_962 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_962 [Constant] outputs: [1073 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_963 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_963 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_963 [Constant] outputs: [1074 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_964 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1072
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1073
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1074
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_964 [DequantizeLinear] inputs: [1072 -> (64, 1, 3, 3)[FLOAT]], [1073 -> ()[FLOAT]], [1074 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1073 for ONNX node: 1073
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1074 for ONNX node: 1074
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1075 for ONNX tensor: 1075
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_964 [DequantizeLinear] outputs: [1075 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_965 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1069
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1075
[03/01/2023-10:40:49] [V] [TRT] Conv_965 [Conv] inputs: [1069 -> (1, 1, 24, 24)[FLOAT]], [1075 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_965 for ONNX node: Conv_965
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1076 for ONNX tensor: 1076
[03/01/2023-10:40:49] [V] [TRT] Conv_965 [Conv] outputs: [1076 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: BatchNormalization_966 [BatchNormalization]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1076
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_966 [BatchNormalization] inputs: [1076 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: BatchNormalization_966 for ONNX node: BatchNormalization_966
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1077 for ONNX tensor: 1077
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_966 [BatchNormalization] outputs: [1077 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Relu_967 [Relu]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1077
[03/01/2023-10:40:49] [V] [TRT] Relu_967 [Relu] inputs: [1077 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Relu_967 for ONNX node: Relu_967
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1078 for ONNX tensor: 1078
[03/01/2023-10:40:49] [V] [TRT] Relu_967 [Relu] outputs: [1078 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_968 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_968 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_968 [Constant] outputs: [1079 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_969 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_969 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_969 [Constant] outputs: [1080 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_970 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1078
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1079
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1080
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_970 [QuantizeLinear] inputs: [1078 -> (1, 64, 22, 22)[FLOAT]], [1079 -> ()[FLOAT]], [1080 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1079 for ONNX node: 1079
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1080 for ONNX node: 1080
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1081 for ONNX tensor: 1081
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_970 [QuantizeLinear] outputs: [1081 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_971 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_971 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_971 [Constant] outputs: [1082 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_972 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_972 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_972 [Constant] outputs: [1083 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_973 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1081
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1082
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1083
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_973 [DequantizeLinear] inputs: [1081 -> (1, 64, 22, 22)[FLOAT]], [1082 -> ()[FLOAT]], [1083 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1082 for ONNX node: 1082
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1083 for ONNX node: 1083
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1084 for ONNX tensor: 1084
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_973 [DequantizeLinear] outputs: [1084 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_974 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_974 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_974 [Constant] outputs: [1085 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_975 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_975 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_975 [Constant] outputs: [1086 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_976 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1085
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1086
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_976 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [1085 -> ()[FLOAT]], [1086 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1085 for ONNX node: 1085
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1086 for ONNX node: 1086
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1087 for ONNX tensor: 1087
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_976 [QuantizeLinear] outputs: [1087 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_977 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_977 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_977 [Constant] outputs: [1088 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_978 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_978 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_978 [Constant] outputs: [1089 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_979 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1087
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1088
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1089
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_979 [DequantizeLinear] inputs: [1087 -> (64, 64, 3, 3)[FLOAT]], [1088 -> ()[FLOAT]], [1089 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1088 for ONNX node: 1088
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1089 for ONNX node: 1089
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1090 for ONNX tensor: 1090
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_979 [DequantizeLinear] outputs: [1090 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_980 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1084
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1090
[03/01/2023-10:40:49] [V] [TRT] Conv_980 [Conv] inputs: [1084 -> (1, 64, 22, 22)[FLOAT]], [1090 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_980 for ONNX node: Conv_980
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1091 for ONNX tensor: 1091
[03/01/2023-10:40:49] [V] [TRT] Conv_980 [Conv] outputs: [1091 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: BatchNormalization_981 [BatchNormalization]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1091
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_981 [BatchNormalization] inputs: [1091 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: BatchNormalization_981 for ONNX node: BatchNormalization_981
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1092 for ONNX tensor: 1092
[03/01/2023-10:40:49] [V] [TRT] BatchNormalization_981 [BatchNormalization] outputs: [1092 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Relu_982 [Relu]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1092
[03/01/2023-10:40:49] [V] [TRT] Relu_982 [Relu] inputs: [1092 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Relu_982 for ONNX node: Relu_982
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1093 for ONNX tensor: 1093
[03/01/2023-10:40:49] [V] [TRT] Relu_982 [Relu] outputs: [1093 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: MaxPool_983 [MaxPool]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1093
[03/01/2023-10:40:49] [V] [TRT] MaxPool_983 [MaxPool] inputs: [1093 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: MaxPool_983 for ONNX node: MaxPool_983
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1094 for ONNX tensor: 1094
[03/01/2023-10:40:49] [V] [TRT] MaxPool_983 [MaxPool] outputs: [1094 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_984 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_984 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_984 [Constant] outputs: [1095 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_985 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_985 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_985 [Constant] outputs: [1096 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_986 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1094
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1095
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1096
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_986 [QuantizeLinear] inputs: [1094 -> (1, 64, 10, 10)[FLOAT]], [1095 -> ()[FLOAT]], [1096 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1095 for ONNX node: 1095
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1096 for ONNX node: 1096
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1097 for ONNX tensor: 1097
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_986 [QuantizeLinear] outputs: [1097 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_987 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_987 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_987 [Constant] outputs: [1098 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_988 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_988 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_988 [Constant] outputs: [1099 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_989 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1097
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1098
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1099
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_989 [DequantizeLinear] inputs: [1097 -> (1, 64, 10, 10)[FLOAT]], [1098 -> ()[FLOAT]], [1099 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1098 for ONNX node: 1098
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1099 for ONNX node: 1099
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1100 for ONNX tensor: 1100
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_989 [DequantizeLinear] outputs: [1100 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_990 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_990 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_990 [Constant] outputs: [1101 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_991 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_991 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_991 [Constant] outputs: [1102 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: QuantizeLinear_992 [QuantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1101
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1102
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_992 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [1101 -> ()[FLOAT]], [1102 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1101 for ONNX node: 1101
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1102 for ONNX node: 1102
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1103 for ONNX tensor: 1103
[03/01/2023-10:40:49] [V] [TRT] QuantizeLinear_992 [QuantizeLinear] outputs: [1103 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_993 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_993 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_993 [Constant] outputs: [1104 -> ()[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Constant_994 [Constant]
[03/01/2023-10:40:49] [V] [TRT] Constant_994 [Constant] inputs: 
[03/01/2023-10:40:49] [V] [TRT] Constant_994 [Constant] outputs: [1105 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: DequantizeLinear_995 [DequantizeLinear]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1103
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1104
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1105
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_995 [DequantizeLinear] inputs: [1103 -> (128, 64, 3, 3)[FLOAT]], [1104 -> ()[FLOAT]], [1105 -> ()[INT8]], 
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1104 for ONNX node: 1104
[03/01/2023-10:40:49] [V] [TRT] Registering layer: 1105 for ONNX node: 1105
[03/01/2023-10:40:49] [V] [TRT] Registering tensor: 1106 for ONNX tensor: 1106
[03/01/2023-10:40:49] [V] [TRT] DequantizeLinear_995 [DequantizeLinear] outputs: [1106 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Parsing node: Conv_996 [Conv]
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1100
[03/01/2023-10:40:49] [V] [TRT] Searching for input: 1106
[03/01/2023-10:40:49] [V] [TRT] Conv_996 [Conv] inputs: [1100 -> (1, 64, 10, 10)[FLOAT]], [1106 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:49] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:49] [V] [TRT] Registering layer: Conv_996 for ONNX node: Conv_996
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1107 for ONNX tensor: 1107
[03/01/2023-10:40:50] [V] [TRT] Conv_996 [Conv] outputs: [1107 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: BatchNormalization_997 [BatchNormalization]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1107
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_997 [BatchNormalization] inputs: [1107 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: BatchNormalization_997 for ONNX node: BatchNormalization_997
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1108 for ONNX tensor: 1108
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_997 [BatchNormalization] outputs: [1108 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Relu_998 [Relu]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1108
[03/01/2023-10:40:50] [V] [TRT] Relu_998 [Relu] inputs: [1108 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Relu_998 for ONNX node: Relu_998
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1109 for ONNX tensor: 1109
[03/01/2023-10:40:50] [V] [TRT] Relu_998 [Relu] outputs: [1109 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_999 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_999 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_999 [Constant] outputs: [1110 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1000 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1000 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1000 [Constant] outputs: [1111 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1001 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1109
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1110
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1111
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1001 [QuantizeLinear] inputs: [1109 -> (1, 128, 8, 8)[FLOAT]], [1110 -> ()[FLOAT]], [1111 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1110 for ONNX node: 1110
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1111 for ONNX node: 1111
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1112 for ONNX tensor: 1112
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1001 [QuantizeLinear] outputs: [1112 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1002 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1002 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1002 [Constant] outputs: [1113 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1003 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1003 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1003 [Constant] outputs: [1114 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1004 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1112
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1113
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1114
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1004 [DequantizeLinear] inputs: [1112 -> (1, 128, 8, 8)[FLOAT]], [1113 -> ()[FLOAT]], [1114 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1113 for ONNX node: 1113
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1114 for ONNX node: 1114
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1115 for ONNX tensor: 1115
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1004 [DequantizeLinear] outputs: [1115 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1005 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1005 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1005 [Constant] outputs: [1116 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1006 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1006 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1006 [Constant] outputs: [1117 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1007 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1116
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1117
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1007 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [1116 -> ()[FLOAT]], [1117 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1116 for ONNX node: 1116
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1117 for ONNX node: 1117
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1118 for ONNX tensor: 1118
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1007 [QuantizeLinear] outputs: [1118 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1008 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1008 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1008 [Constant] outputs: [1119 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1009 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1009 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1009 [Constant] outputs: [1120 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1010 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1118
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1119
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1120
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1010 [DequantizeLinear] inputs: [1118 -> (128, 128, 3, 3)[FLOAT]], [1119 -> ()[FLOAT]], [1120 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1119 for ONNX node: 1119
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1120 for ONNX node: 1120
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1121 for ONNX tensor: 1121
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1010 [DequantizeLinear] outputs: [1121 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1011 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1115
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1121
[03/01/2023-10:40:50] [V] [TRT] Conv_1011 [Conv] inputs: [1115 -> (1, 128, 8, 8)[FLOAT]], [1121 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1011 for ONNX node: Conv_1011
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1122 for ONNX tensor: 1122
[03/01/2023-10:40:50] [V] [TRT] Conv_1011 [Conv] outputs: [1122 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: BatchNormalization_1012 [BatchNormalization]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1122
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_1012 [BatchNormalization] inputs: [1122 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: BatchNormalization_1012 for ONNX node: BatchNormalization_1012
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1123 for ONNX tensor: 1123
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_1012 [BatchNormalization] outputs: [1123 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Relu_1013 [Relu]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1123
[03/01/2023-10:40:50] [V] [TRT] Relu_1013 [Relu] inputs: [1123 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Relu_1013 for ONNX node: Relu_1013
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1124 for ONNX tensor: 1124
[03/01/2023-10:40:50] [V] [TRT] Relu_1013 [Relu] outputs: [1124 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: MaxPool_1014 [MaxPool]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1124
[03/01/2023-10:40:50] [V] [TRT] MaxPool_1014 [MaxPool] inputs: [1124 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: MaxPool_1014 for ONNX node: MaxPool_1014
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1125 for ONNX tensor: 1125
[03/01/2023-10:40:50] [V] [TRT] MaxPool_1014 [MaxPool] outputs: [1125 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: ReduceMean_1015 [ReduceMean]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1125
[03/01/2023-10:40:50] [V] [TRT] ReduceMean_1015 [ReduceMean] inputs: [1125 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: ReduceMean_1015 for ONNX node: ReduceMean_1015
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1126 for ONNX tensor: 1126
[03/01/2023-10:40:50] [V] [TRT] ReduceMean_1015 [ReduceMean] outputs: [1126 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: ReduceMax_1016 [ReduceMax]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1125
[03/01/2023-10:40:50] [V] [TRT] ReduceMax_1016 [ReduceMax] inputs: [1125 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: ReduceMax_1016 for ONNX node: ReduceMax_1016
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1127 for ONNX tensor: 1127
[03/01/2023-10:40:50] [V] [TRT] ReduceMax_1016 [ReduceMax] outputs: [1127 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Concat_1017 [Concat]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1126
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1127
[03/01/2023-10:40:50] [V] [TRT] Concat_1017 [Concat] inputs: [1126 -> (1, 1, 3, 3)[FLOAT]], [1127 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Concat_1017 for ONNX node: Concat_1017
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1128 for ONNX tensor: 1128
[03/01/2023-10:40:50] [V] [TRT] Concat_1017 [Concat] outputs: [1128 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1018 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1018 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1018 [Constant] outputs: [1129 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1019 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1019 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1019 [Constant] outputs: [1130 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1020 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1128
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1129
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1130
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1020 [QuantizeLinear] inputs: [1128 -> (1, 2, 3, 3)[FLOAT]], [1129 -> ()[FLOAT]], [1130 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1129 for ONNX node: 1129
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1130 for ONNX node: 1130
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1131 for ONNX tensor: 1131
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1020 [QuantizeLinear] outputs: [1131 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1021 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1021 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1021 [Constant] outputs: [1132 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1022 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1022 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1022 [Constant] outputs: [1133 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1023 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1131
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1132
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1133
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1023 [DequantizeLinear] inputs: [1131 -> (1, 2, 3, 3)[FLOAT]], [1132 -> ()[FLOAT]], [1133 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1132 for ONNX node: 1132
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1133 for ONNX node: 1133
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1134 for ONNX tensor: 1134
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1023 [DequantizeLinear] outputs: [1134 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1024 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1024 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1024 [Constant] outputs: [1135 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1025 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1025 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1025 [Constant] outputs: [1136 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1026 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1135
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1136
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1026 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [1135 -> ()[FLOAT]], [1136 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1135 for ONNX node: 1135
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1136 for ONNX node: 1136
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1137 for ONNX tensor: 1137
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1026 [QuantizeLinear] outputs: [1137 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1027 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1027 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1027 [Constant] outputs: [1138 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1028 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1028 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1028 [Constant] outputs: [1139 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1029 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1137
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1138
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1139
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1029 [DequantizeLinear] inputs: [1137 -> (1, 2, 7, 7)[FLOAT]], [1138 -> ()[FLOAT]], [1139 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1138 for ONNX node: 1138
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1139 for ONNX node: 1139
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1140 for ONNX tensor: 1140
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1029 [DequantizeLinear] outputs: [1140 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1030 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1134
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1140
[03/01/2023-10:40:50] [V] [TRT] Conv_1030 [Conv] inputs: [1134 -> (1, 2, 3, 3)[FLOAT]], [1140 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1030 for ONNX node: Conv_1030
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1141 for ONNX tensor: 1141
[03/01/2023-10:40:50] [V] [TRT] Conv_1030 [Conv] outputs: [1141 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Sigmoid_1031 [Sigmoid]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1141
[03/01/2023-10:40:50] [V] [TRT] Sigmoid_1031 [Sigmoid] inputs: [1141 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Sigmoid_1031 for ONNX node: Sigmoid_1031
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1142 for ONNX tensor: 1142
[03/01/2023-10:40:50] [V] [TRT] Sigmoid_1031 [Sigmoid] outputs: [1142 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Mul_1032 [Mul]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1125
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1142
[03/01/2023-10:40:50] [V] [TRT] Mul_1032 [Mul] inputs: [1125 -> (1, 128, 3, 3)[FLOAT]], [1142 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Mul_1032 for ONNX node: Mul_1032
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1143 for ONNX tensor: 1143
[03/01/2023-10:40:50] [V] [TRT] Mul_1032 [Mul] outputs: [1143 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: GlobalAveragePool_1033 [GlobalAveragePool]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1143
[03/01/2023-10:40:50] [V] [TRT] GlobalAveragePool_1033 [GlobalAveragePool] inputs: [1143 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:50] [V] [TRT] Registering layer: GlobalAveragePool_1033 for ONNX node: GlobalAveragePool_1033
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1144 for ONNX tensor: 1144
[03/01/2023-10:40:50] [V] [TRT] GlobalAveragePool_1033 [GlobalAveragePool] outputs: [1144 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1034 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1034 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1034 [Constant] outputs: [1145 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1035 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1035 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1035 [Constant] outputs: [1146 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1036 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1144
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1145
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1146
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1036 [QuantizeLinear] inputs: [1144 -> (1, 128, 1, 1)[FLOAT]], [1145 -> ()[FLOAT]], [1146 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1145 for ONNX node: 1145
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1146 for ONNX node: 1146
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1147 for ONNX tensor: 1147
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1036 [QuantizeLinear] outputs: [1147 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1037 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1037 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1037 [Constant] outputs: [1148 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1038 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1038 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1038 [Constant] outputs: [1149 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1039 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1147
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1148
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1149
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1039 [DequantizeLinear] inputs: [1147 -> (1, 128, 1, 1)[FLOAT]], [1148 -> ()[FLOAT]], [1149 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1148 for ONNX node: 1148
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1149 for ONNX node: 1149
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1150 for ONNX tensor: 1150
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1039 [DequantizeLinear] outputs: [1150 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1040 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1040 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1040 [Constant] outputs: [1151 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1041 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1041 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1041 [Constant] outputs: [1152 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1042 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1151
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1152
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1042 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1151 -> ()[FLOAT]], [1152 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1151 for ONNX node: 1151
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1152 for ONNX node: 1152
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1153 for ONNX tensor: 1153
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1042 [QuantizeLinear] outputs: [1153 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1043 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1043 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1043 [Constant] outputs: [1154 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1044 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1044 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1044 [Constant] outputs: [1155 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1045 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1153
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1154
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1155
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1045 [DequantizeLinear] inputs: [1153 -> (8, 128, 1, 1)[FLOAT]], [1154 -> ()[FLOAT]], [1155 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1154 for ONNX node: 1154
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1155 for ONNX node: 1155
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1156 for ONNX tensor: 1156
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1045 [DequantizeLinear] outputs: [1156 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1046 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1150
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1156
[03/01/2023-10:40:50] [V] [TRT] Conv_1046 [Conv] inputs: [1150 -> (1, 128, 1, 1)[FLOAT]], [1156 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1046 for ONNX node: Conv_1046
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1157 for ONNX tensor: 1157
[03/01/2023-10:40:50] [V] [TRT] Conv_1046 [Conv] outputs: [1157 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Relu_1047 [Relu]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1157
[03/01/2023-10:40:50] [V] [TRT] Relu_1047 [Relu] inputs: [1157 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Relu_1047 for ONNX node: Relu_1047
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1158 for ONNX tensor: 1158
[03/01/2023-10:40:50] [V] [TRT] Relu_1047 [Relu] outputs: [1158 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1048 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1048 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1048 [Constant] outputs: [1159 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1049 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1049 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1049 [Constant] outputs: [1160 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1050 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1158
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1159
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1160
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1050 [QuantizeLinear] inputs: [1158 -> (1, 8, 1, 1)[FLOAT]], [1159 -> ()[FLOAT]], [1160 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1159 for ONNX node: 1159
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1160 for ONNX node: 1160
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1161 for ONNX tensor: 1161
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1050 [QuantizeLinear] outputs: [1161 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1051 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1051 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1051 [Constant] outputs: [1162 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1052 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1052 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1052 [Constant] outputs: [1163 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1053 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1161
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1162
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1163
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1053 [DequantizeLinear] inputs: [1161 -> (1, 8, 1, 1)[FLOAT]], [1162 -> ()[FLOAT]], [1163 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1162 for ONNX node: 1162
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1163 for ONNX node: 1163
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1164 for ONNX tensor: 1164
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1053 [DequantizeLinear] outputs: [1164 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1054 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1054 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1054 [Constant] outputs: [1165 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1055 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1055 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1055 [Constant] outputs: [1166 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1056 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1165
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1166
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1056 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1165 -> ()[FLOAT]], [1166 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1165 for ONNX node: 1165
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1166 for ONNX node: 1166
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1167 for ONNX tensor: 1167
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1056 [QuantizeLinear] outputs: [1167 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1057 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1057 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1057 [Constant] outputs: [1168 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1058 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1058 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1058 [Constant] outputs: [1169 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1059 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1167
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1168
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1169
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1059 [DequantizeLinear] inputs: [1167 -> (128, 8, 1, 1)[FLOAT]], [1168 -> ()[FLOAT]], [1169 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1168 for ONNX node: 1168
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1169 for ONNX node: 1169
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1170 for ONNX tensor: 1170
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1059 [DequantizeLinear] outputs: [1170 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1060 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1164
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1170
[03/01/2023-10:40:50] [V] [TRT] Conv_1060 [Conv] inputs: [1164 -> (1, 8, 1, 1)[FLOAT]], [1170 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1060 for ONNX node: Conv_1060
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1171 for ONNX tensor: 1171
[03/01/2023-10:40:50] [V] [TRT] Conv_1060 [Conv] outputs: [1171 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: MaxPool_1061 [MaxPool]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1143
[03/01/2023-10:40:50] [V] [TRT] MaxPool_1061 [MaxPool] inputs: [1143 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: MaxPool_1061 for ONNX node: MaxPool_1061
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1172 for ONNX tensor: 1172
[03/01/2023-10:40:50] [V] [TRT] MaxPool_1061 [MaxPool] outputs: [1172 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1062 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1062 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1062 [Constant] outputs: [1173 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1063 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1063 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1063 [Constant] outputs: [1174 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1064 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1172
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1173
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1174
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1064 [QuantizeLinear] inputs: [1172 -> (1, 128, 1, 1)[FLOAT]], [1173 -> ()[FLOAT]], [1174 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1173 for ONNX node: 1173
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1174 for ONNX node: 1174
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1175 for ONNX tensor: 1175
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1064 [QuantizeLinear] outputs: [1175 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1065 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1065 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1065 [Constant] outputs: [1176 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1066 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1066 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1066 [Constant] outputs: [1177 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1067 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1175
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1176
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1177
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1067 [DequantizeLinear] inputs: [1175 -> (1, 128, 1, 1)[FLOAT]], [1176 -> ()[FLOAT]], [1177 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1176 for ONNX node: 1176
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1177 for ONNX node: 1177
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1178 for ONNX tensor: 1178
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1067 [DequantizeLinear] outputs: [1178 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1068 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1068 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1068 [Constant] outputs: [1179 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1069 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1069 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1069 [Constant] outputs: [1180 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1070 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1179
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1180
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1070 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1179 -> ()[FLOAT]], [1180 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1179 for ONNX node: 1179
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1180 for ONNX node: 1180
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1181 for ONNX tensor: 1181
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1070 [QuantizeLinear] outputs: [1181 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1071 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1071 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1071 [Constant] outputs: [1182 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1072 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1072 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1072 [Constant] outputs: [1183 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1073 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1181
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1182
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1183
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1073 [DequantizeLinear] inputs: [1181 -> (8, 128, 1, 1)[FLOAT]], [1182 -> ()[FLOAT]], [1183 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1182 for ONNX node: 1182
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1183 for ONNX node: 1183
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1184 for ONNX tensor: 1184
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1073 [DequantizeLinear] outputs: [1184 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1074 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1178
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1184
[03/01/2023-10:40:50] [V] [TRT] Conv_1074 [Conv] inputs: [1178 -> (1, 128, 1, 1)[FLOAT]], [1184 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1074 for ONNX node: Conv_1074
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1185 for ONNX tensor: 1185
[03/01/2023-10:40:50] [V] [TRT] Conv_1074 [Conv] outputs: [1185 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Relu_1075 [Relu]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1185
[03/01/2023-10:40:50] [V] [TRT] Relu_1075 [Relu] inputs: [1185 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Relu_1075 for ONNX node: Relu_1075
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1186 for ONNX tensor: 1186
[03/01/2023-10:40:50] [V] [TRT] Relu_1075 [Relu] outputs: [1186 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1076 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1076 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1076 [Constant] outputs: [1187 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1077 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1077 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1077 [Constant] outputs: [1188 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1078 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1186
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1187
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1188
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1078 [QuantizeLinear] inputs: [1186 -> (1, 8, 1, 1)[FLOAT]], [1187 -> ()[FLOAT]], [1188 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1187 for ONNX node: 1187
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1188 for ONNX node: 1188
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1189 for ONNX tensor: 1189
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1078 [QuantizeLinear] outputs: [1189 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1079 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1079 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1079 [Constant] outputs: [1190 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1080 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1080 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1080 [Constant] outputs: [1191 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1081 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1189
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1190
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1191
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1081 [DequantizeLinear] inputs: [1189 -> (1, 8, 1, 1)[FLOAT]], [1190 -> ()[FLOAT]], [1191 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1190 for ONNX node: 1190
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1191 for ONNX node: 1191
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1192 for ONNX tensor: 1192
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1081 [DequantizeLinear] outputs: [1192 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1082 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1082 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1082 [Constant] outputs: [1193 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1083 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1083 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1083 [Constant] outputs: [1194 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1084 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1193
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1194
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1084 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1193 -> ()[FLOAT]], [1194 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1193 for ONNX node: 1193
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1194 for ONNX node: 1194
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1195 for ONNX tensor: 1195
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1084 [QuantizeLinear] outputs: [1195 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1085 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1085 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1085 [Constant] outputs: [1196 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1086 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1086 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1086 [Constant] outputs: [1197 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1087 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1195
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1196
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1197
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1087 [DequantizeLinear] inputs: [1195 -> (128, 8, 1, 1)[FLOAT]], [1196 -> ()[FLOAT]], [1197 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1196 for ONNX node: 1196
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1197 for ONNX node: 1197
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1198 for ONNX tensor: 1198
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1087 [DequantizeLinear] outputs: [1198 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1088 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1192
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1198
[03/01/2023-10:40:50] [V] [TRT] Conv_1088 [Conv] inputs: [1192 -> (1, 8, 1, 1)[FLOAT]], [1198 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1088 for ONNX node: Conv_1088
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1199 for ONNX tensor: 1199
[03/01/2023-10:40:50] [V] [TRT] Conv_1088 [Conv] outputs: [1199 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Add_1089 [Add]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1171
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1199
[03/01/2023-10:40:50] [V] [TRT] Add_1089 [Add] inputs: [1171 -> (1, 128, 1, 1)[FLOAT]], [1199 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Add_1089 for ONNX node: Add_1089
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1200 for ONNX tensor: 1200
[03/01/2023-10:40:50] [V] [TRT] Add_1089 [Add] outputs: [1200 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Sigmoid_1090 [Sigmoid]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1200
[03/01/2023-10:40:50] [V] [TRT] Sigmoid_1090 [Sigmoid] inputs: [1200 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Sigmoid_1090 for ONNX node: Sigmoid_1090
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1201 for ONNX tensor: 1201
[03/01/2023-10:40:50] [V] [TRT] Sigmoid_1090 [Sigmoid] outputs: [1201 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Mul_1091 [Mul]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1143
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1201
[03/01/2023-10:40:50] [V] [TRT] Mul_1091 [Mul] inputs: [1143 -> (1, 128, 3, 3)[FLOAT]], [1201 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Mul_1091 for ONNX node: Mul_1091
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1202 for ONNX tensor: 1202
[03/01/2023-10:40:50] [V] [TRT] Mul_1091 [Mul] outputs: [1202 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Concat_1092 [Concat]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1053
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1202
[03/01/2023-10:40:50] [V] [TRT] Concat_1092 [Concat] inputs: [1053 -> (1, 640, 3, 3)[FLOAT]], [1202 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Concat_1092 for ONNX node: Concat_1092
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1203 for ONNX tensor: 1203
[03/01/2023-10:40:50] [V] [TRT] Concat_1092 [Concat] outputs: [1203 -> (1, 768, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1093 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1093 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1093 [Constant] outputs: [1204 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1094 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1094 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1094 [Constant] outputs: [1205 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1095 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1095 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1095 [Constant] outputs: [1206 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1096 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1096 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1096 [Constant] outputs: [1207 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Slice_1097 [Slice]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: input
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1205
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1206
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1204
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1207
[03/01/2023-10:40:50] [V] [TRT] Slice_1097 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [1205 -> (1)[INT32]], [1206 -> (1)[INT32]], [1204 -> (1)[INT32]], [1207 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Slice_1097 for ONNX node: Slice_1097
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1208 for ONNX tensor: 1208
[03/01/2023-10:40:50] [V] [TRT] Slice_1097 [Slice] outputs: [1208 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1098 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1098 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1098 [Constant] outputs: [1209 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1099 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1099 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1099 [Constant] outputs: [1210 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1100 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1100 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1100 [Constant] outputs: [1211 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1101 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1101 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1101 [Constant] outputs: [1212 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Slice_1102 [Slice]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1208
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1210
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1211
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1209
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1212
[03/01/2023-10:40:50] [V] [TRT] Slice_1102 [Slice] inputs: [1208 -> (1, 1, 24, 60)[FLOAT]], [1210 -> (1)[INT32]], [1211 -> (1)[INT32]], [1209 -> (1)[INT32]], [1212 -> (1)[INT32]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Slice_1102 for ONNX node: Slice_1102
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1213 for ONNX tensor: 1213
[03/01/2023-10:40:50] [V] [TRT] Slice_1102 [Slice] outputs: [1213 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1103 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1103 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1103 [Constant] outputs: [1214 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1104 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1104 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1104 [Constant] outputs: [1215 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1105 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1213
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1214
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1215
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1105 [QuantizeLinear] inputs: [1213 -> (1, 1, 24, 24)[FLOAT]], [1214 -> ()[FLOAT]], [1215 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1214 for ONNX node: 1214
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1215 for ONNX node: 1215
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1216 for ONNX tensor: 1216
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1105 [QuantizeLinear] outputs: [1216 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1106 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1106 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1106 [Constant] outputs: [1217 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1107 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1107 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1107 [Constant] outputs: [1218 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1108 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1216
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1217
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1218
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1108 [DequantizeLinear] inputs: [1216 -> (1, 1, 24, 24)[FLOAT]], [1217 -> ()[FLOAT]], [1218 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1217 for ONNX node: 1217
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1218 for ONNX node: 1218
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1219 for ONNX tensor: 1219
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1108 [DequantizeLinear] outputs: [1219 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1109 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1109 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1109 [Constant] outputs: [1220 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1110 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1110 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1110 [Constant] outputs: [1221 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1111 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1220
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1221
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1111 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [1220 -> ()[FLOAT]], [1221 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1220 for ONNX node: 1220
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1221 for ONNX node: 1221
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1222 for ONNX tensor: 1222
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1111 [QuantizeLinear] outputs: [1222 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1112 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1112 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1112 [Constant] outputs: [1223 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1113 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1113 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1113 [Constant] outputs: [1224 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1114 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1222
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1223
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1224
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1114 [DequantizeLinear] inputs: [1222 -> (64, 1, 3, 3)[FLOAT]], [1223 -> ()[FLOAT]], [1224 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1223 for ONNX node: 1223
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1224 for ONNX node: 1224
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1225 for ONNX tensor: 1225
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1114 [DequantizeLinear] outputs: [1225 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1115 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1219
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1225
[03/01/2023-10:40:50] [V] [TRT] Conv_1115 [Conv] inputs: [1219 -> (1, 1, 24, 24)[FLOAT]], [1225 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1115 for ONNX node: Conv_1115
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1226 for ONNX tensor: 1226
[03/01/2023-10:40:50] [V] [TRT] Conv_1115 [Conv] outputs: [1226 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: BatchNormalization_1116 [BatchNormalization]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1226
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_1116 [BatchNormalization] inputs: [1226 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: BatchNormalization_1116 for ONNX node: BatchNormalization_1116
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1227 for ONNX tensor: 1227
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_1116 [BatchNormalization] outputs: [1227 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Relu_1117 [Relu]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1227
[03/01/2023-10:40:50] [V] [TRT] Relu_1117 [Relu] inputs: [1227 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Relu_1117 for ONNX node: Relu_1117
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1228 for ONNX tensor: 1228
[03/01/2023-10:40:50] [V] [TRT] Relu_1117 [Relu] outputs: [1228 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1118 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1118 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1118 [Constant] outputs: [1229 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1119 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1119 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1119 [Constant] outputs: [1230 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1120 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1228
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1229
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1230
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1120 [QuantizeLinear] inputs: [1228 -> (1, 64, 22, 22)[FLOAT]], [1229 -> ()[FLOAT]], [1230 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1229 for ONNX node: 1229
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1230 for ONNX node: 1230
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1231 for ONNX tensor: 1231
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1120 [QuantizeLinear] outputs: [1231 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1121 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1121 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1121 [Constant] outputs: [1232 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1122 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1122 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1122 [Constant] outputs: [1233 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1123 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1231
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1232
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1233
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1123 [DequantizeLinear] inputs: [1231 -> (1, 64, 22, 22)[FLOAT]], [1232 -> ()[FLOAT]], [1233 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1232 for ONNX node: 1232
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1233 for ONNX node: 1233
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1234 for ONNX tensor: 1234
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1123 [DequantizeLinear] outputs: [1234 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1124 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1124 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1124 [Constant] outputs: [1235 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1125 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1125 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1125 [Constant] outputs: [1236 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1126 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1235
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1236
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1126 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [1235 -> ()[FLOAT]], [1236 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1235 for ONNX node: 1235
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1236 for ONNX node: 1236
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1237 for ONNX tensor: 1237
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1126 [QuantizeLinear] outputs: [1237 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1127 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1127 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1127 [Constant] outputs: [1238 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1128 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1128 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1128 [Constant] outputs: [1239 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1129 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1237
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1238
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1239
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1129 [DequantizeLinear] inputs: [1237 -> (64, 64, 3, 3)[FLOAT]], [1238 -> ()[FLOAT]], [1239 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1238 for ONNX node: 1238
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1239 for ONNX node: 1239
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1240 for ONNX tensor: 1240
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1129 [DequantizeLinear] outputs: [1240 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1130 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1234
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1240
[03/01/2023-10:40:50] [V] [TRT] Conv_1130 [Conv] inputs: [1234 -> (1, 64, 22, 22)[FLOAT]], [1240 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1130 for ONNX node: Conv_1130
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1241 for ONNX tensor: 1241
[03/01/2023-10:40:50] [V] [TRT] Conv_1130 [Conv] outputs: [1241 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: BatchNormalization_1131 [BatchNormalization]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1241
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_1131 [BatchNormalization] inputs: [1241 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: BatchNormalization_1131 for ONNX node: BatchNormalization_1131
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1242 for ONNX tensor: 1242
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_1131 [BatchNormalization] outputs: [1242 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Relu_1132 [Relu]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1242
[03/01/2023-10:40:50] [V] [TRT] Relu_1132 [Relu] inputs: [1242 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Relu_1132 for ONNX node: Relu_1132
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1243 for ONNX tensor: 1243
[03/01/2023-10:40:50] [V] [TRT] Relu_1132 [Relu] outputs: [1243 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: MaxPool_1133 [MaxPool]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1243
[03/01/2023-10:40:50] [V] [TRT] MaxPool_1133 [MaxPool] inputs: [1243 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: MaxPool_1133 for ONNX node: MaxPool_1133
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1244 for ONNX tensor: 1244
[03/01/2023-10:40:50] [V] [TRT] MaxPool_1133 [MaxPool] outputs: [1244 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1134 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1134 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1134 [Constant] outputs: [1245 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1135 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1135 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1135 [Constant] outputs: [1246 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1136 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1244
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1245
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1246
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1136 [QuantizeLinear] inputs: [1244 -> (1, 64, 10, 10)[FLOAT]], [1245 -> ()[FLOAT]], [1246 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1245 for ONNX node: 1245
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1246 for ONNX node: 1246
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1247 for ONNX tensor: 1247
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1136 [QuantizeLinear] outputs: [1247 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1137 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1137 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1137 [Constant] outputs: [1248 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1138 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1138 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1138 [Constant] outputs: [1249 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1139 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1247
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1248
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1249
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1139 [DequantizeLinear] inputs: [1247 -> (1, 64, 10, 10)[FLOAT]], [1248 -> ()[FLOAT]], [1249 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1248 for ONNX node: 1248
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1249 for ONNX node: 1249
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1250 for ONNX tensor: 1250
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1139 [DequantizeLinear] outputs: [1250 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1140 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1140 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1140 [Constant] outputs: [1251 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1141 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1141 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1141 [Constant] outputs: [1252 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1142 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1251
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1252
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1142 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [1251 -> ()[FLOAT]], [1252 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1251 for ONNX node: 1251
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1252 for ONNX node: 1252
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1253 for ONNX tensor: 1253
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1142 [QuantizeLinear] outputs: [1253 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1143 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1143 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1143 [Constant] outputs: [1254 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1144 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1144 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1144 [Constant] outputs: [1255 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1145 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1253
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1254
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1255
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1145 [DequantizeLinear] inputs: [1253 -> (128, 64, 3, 3)[FLOAT]], [1254 -> ()[FLOAT]], [1255 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1254 for ONNX node: 1254
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1255 for ONNX node: 1255
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1256 for ONNX tensor: 1256
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1145 [DequantizeLinear] outputs: [1256 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1146 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1250
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1256
[03/01/2023-10:40:50] [V] [TRT] Conv_1146 [Conv] inputs: [1250 -> (1, 64, 10, 10)[FLOAT]], [1256 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1146 for ONNX node: Conv_1146
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1257 for ONNX tensor: 1257
[03/01/2023-10:40:50] [V] [TRT] Conv_1146 [Conv] outputs: [1257 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: BatchNormalization_1147 [BatchNormalization]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1257
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_1147 [BatchNormalization] inputs: [1257 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: BatchNormalization_1147 for ONNX node: BatchNormalization_1147
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1258 for ONNX tensor: 1258
[03/01/2023-10:40:50] [V] [TRT] BatchNormalization_1147 [BatchNormalization] outputs: [1258 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Relu_1148 [Relu]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1258
[03/01/2023-10:40:50] [V] [TRT] Relu_1148 [Relu] inputs: [1258 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Relu_1148 for ONNX node: Relu_1148
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1259 for ONNX tensor: 1259
[03/01/2023-10:40:50] [V] [TRT] Relu_1148 [Relu] outputs: [1259 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1149 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1149 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1149 [Constant] outputs: [1260 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1150 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1150 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1150 [Constant] outputs: [1261 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1151 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1259
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1260
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1261
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1151 [QuantizeLinear] inputs: [1259 -> (1, 128, 8, 8)[FLOAT]], [1260 -> ()[FLOAT]], [1261 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1260 for ONNX node: 1260
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1261 for ONNX node: 1261
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1262 for ONNX tensor: 1262
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1151 [QuantizeLinear] outputs: [1262 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1152 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1152 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1152 [Constant] outputs: [1263 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1153 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1153 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1153 [Constant] outputs: [1264 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1154 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1262
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1263
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1264
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1154 [DequantizeLinear] inputs: [1262 -> (1, 128, 8, 8)[FLOAT]], [1263 -> ()[FLOAT]], [1264 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1263 for ONNX node: 1263
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1264 for ONNX node: 1264
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1265 for ONNX tensor: 1265
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1154 [DequantizeLinear] outputs: [1265 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1155 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1155 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1155 [Constant] outputs: [1266 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1156 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1156 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1156 [Constant] outputs: [1267 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: QuantizeLinear_1157 [QuantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1266
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1267
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1157 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [1266 -> ()[FLOAT]], [1267 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1266 for ONNX node: 1266
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1267 for ONNX node: 1267
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1268 for ONNX tensor: 1268
[03/01/2023-10:40:50] [V] [TRT] QuantizeLinear_1157 [QuantizeLinear] outputs: [1268 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1158 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1158 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1158 [Constant] outputs: [1269 -> ()[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Constant_1159 [Constant]
[03/01/2023-10:40:50] [V] [TRT] Constant_1159 [Constant] inputs: 
[03/01/2023-10:40:50] [V] [TRT] Constant_1159 [Constant] outputs: [1270 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: DequantizeLinear_1160 [DequantizeLinear]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1268
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1269
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1270
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1160 [DequantizeLinear] inputs: [1268 -> (128, 128, 3, 3)[FLOAT]], [1269 -> ()[FLOAT]], [1270 -> ()[INT8]], 
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1269 for ONNX node: 1269
[03/01/2023-10:40:50] [V] [TRT] Registering layer: 1270 for ONNX node: 1270
[03/01/2023-10:40:50] [V] [TRT] Registering tensor: 1271 for ONNX tensor: 1271
[03/01/2023-10:40:50] [V] [TRT] DequantizeLinear_1160 [DequantizeLinear] outputs: [1271 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Parsing node: Conv_1161 [Conv]
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1265
[03/01/2023-10:40:50] [V] [TRT] Searching for input: 1271
[03/01/2023-10:40:50] [V] [TRT] Conv_1161 [Conv] inputs: [1265 -> (1, 128, 8, 8)[FLOAT]], [1271 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:50] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:50] [V] [TRT] Registering layer: Conv_1161 for ONNX node: Conv_1161
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1272 for ONNX tensor: 1272
[03/01/2023-10:40:51] [V] [TRT] Conv_1161 [Conv] outputs: [1272 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: BatchNormalization_1162 [BatchNormalization]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1272
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1162 [BatchNormalization] inputs: [1272 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: BatchNormalization_1162 for ONNX node: BatchNormalization_1162
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1273 for ONNX tensor: 1273
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1162 [BatchNormalization] outputs: [1273 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Relu_1163 [Relu]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1273
[03/01/2023-10:40:51] [V] [TRT] Relu_1163 [Relu] inputs: [1273 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Relu_1163 for ONNX node: Relu_1163
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1274 for ONNX tensor: 1274
[03/01/2023-10:40:51] [V] [TRT] Relu_1163 [Relu] outputs: [1274 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: MaxPool_1164 [MaxPool]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1274
[03/01/2023-10:40:51] [V] [TRT] MaxPool_1164 [MaxPool] inputs: [1274 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: MaxPool_1164 for ONNX node: MaxPool_1164
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1275 for ONNX tensor: 1275
[03/01/2023-10:40:51] [V] [TRT] MaxPool_1164 [MaxPool] outputs: [1275 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: ReduceMean_1165 [ReduceMean]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1275
[03/01/2023-10:40:51] [V] [TRT] ReduceMean_1165 [ReduceMean] inputs: [1275 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: ReduceMean_1165 for ONNX node: ReduceMean_1165
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1276 for ONNX tensor: 1276
[03/01/2023-10:40:51] [V] [TRT] ReduceMean_1165 [ReduceMean] outputs: [1276 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: ReduceMax_1166 [ReduceMax]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1275
[03/01/2023-10:40:51] [V] [TRT] ReduceMax_1166 [ReduceMax] inputs: [1275 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: ReduceMax_1166 for ONNX node: ReduceMax_1166
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1277 for ONNX tensor: 1277
[03/01/2023-10:40:51] [V] [TRT] ReduceMax_1166 [ReduceMax] outputs: [1277 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Concat_1167 [Concat]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1276
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1277
[03/01/2023-10:40:51] [V] [TRT] Concat_1167 [Concat] inputs: [1276 -> (1, 1, 3, 3)[FLOAT]], [1277 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Concat_1167 for ONNX node: Concat_1167
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1278 for ONNX tensor: 1278
[03/01/2023-10:40:51] [V] [TRT] Concat_1167 [Concat] outputs: [1278 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1168 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1168 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1168 [Constant] outputs: [1279 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1169 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1169 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1169 [Constant] outputs: [1280 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1170 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1278
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1279
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1280
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1170 [QuantizeLinear] inputs: [1278 -> (1, 2, 3, 3)[FLOAT]], [1279 -> ()[FLOAT]], [1280 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1279 for ONNX node: 1279
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1280 for ONNX node: 1280
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1281 for ONNX tensor: 1281
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1170 [QuantizeLinear] outputs: [1281 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1171 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1171 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1171 [Constant] outputs: [1282 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1172 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1172 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1172 [Constant] outputs: [1283 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1173 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1281
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1282
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1283
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1173 [DequantizeLinear] inputs: [1281 -> (1, 2, 3, 3)[FLOAT]], [1282 -> ()[FLOAT]], [1283 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1282 for ONNX node: 1282
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1283 for ONNX node: 1283
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1284 for ONNX tensor: 1284
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1173 [DequantizeLinear] outputs: [1284 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1174 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1174 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1174 [Constant] outputs: [1285 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1175 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1175 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1175 [Constant] outputs: [1286 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1176 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1285
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1286
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1176 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [1285 -> ()[FLOAT]], [1286 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1285 for ONNX node: 1285
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1286 for ONNX node: 1286
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1287 for ONNX tensor: 1287
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1176 [QuantizeLinear] outputs: [1287 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1177 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1177 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1177 [Constant] outputs: [1288 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1178 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1178 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1178 [Constant] outputs: [1289 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1179 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1287
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1288
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1289
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1179 [DequantizeLinear] inputs: [1287 -> (1, 2, 7, 7)[FLOAT]], [1288 -> ()[FLOAT]], [1289 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1288 for ONNX node: 1288
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1289 for ONNX node: 1289
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1290 for ONNX tensor: 1290
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1179 [DequantizeLinear] outputs: [1290 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Conv_1180 [Conv]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1284
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1290
[03/01/2023-10:40:51] [V] [TRT] Conv_1180 [Conv] inputs: [1284 -> (1, 2, 3, 3)[FLOAT]], [1290 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Conv_1180 for ONNX node: Conv_1180
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1291 for ONNX tensor: 1291
[03/01/2023-10:40:51] [V] [TRT] Conv_1180 [Conv] outputs: [1291 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Sigmoid_1181 [Sigmoid]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1291
[03/01/2023-10:40:51] [V] [TRT] Sigmoid_1181 [Sigmoid] inputs: [1291 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Sigmoid_1181 for ONNX node: Sigmoid_1181
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1292 for ONNX tensor: 1292
[03/01/2023-10:40:51] [V] [TRT] Sigmoid_1181 [Sigmoid] outputs: [1292 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Mul_1182 [Mul]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1275
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1292
[03/01/2023-10:40:51] [V] [TRT] Mul_1182 [Mul] inputs: [1275 -> (1, 128, 3, 3)[FLOAT]], [1292 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Mul_1182 for ONNX node: Mul_1182
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1293 for ONNX tensor: 1293
[03/01/2023-10:40:51] [V] [TRT] Mul_1182 [Mul] outputs: [1293 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: GlobalAveragePool_1183 [GlobalAveragePool]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1293
[03/01/2023-10:40:51] [V] [TRT] GlobalAveragePool_1183 [GlobalAveragePool] inputs: [1293 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:51] [V] [TRT] Registering layer: GlobalAveragePool_1183 for ONNX node: GlobalAveragePool_1183
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1294 for ONNX tensor: 1294
[03/01/2023-10:40:51] [V] [TRT] GlobalAveragePool_1183 [GlobalAveragePool] outputs: [1294 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1184 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1184 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1184 [Constant] outputs: [1295 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1185 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1185 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1185 [Constant] outputs: [1296 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1186 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1294
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1295
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1296
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1186 [QuantizeLinear] inputs: [1294 -> (1, 128, 1, 1)[FLOAT]], [1295 -> ()[FLOAT]], [1296 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1295 for ONNX node: 1295
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1296 for ONNX node: 1296
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1297 for ONNX tensor: 1297
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1186 [QuantizeLinear] outputs: [1297 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1187 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1187 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1187 [Constant] outputs: [1298 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1188 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1188 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1188 [Constant] outputs: [1299 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1189 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1297
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1298
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1299
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1189 [DequantizeLinear] inputs: [1297 -> (1, 128, 1, 1)[FLOAT]], [1298 -> ()[FLOAT]], [1299 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1298 for ONNX node: 1298
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1299 for ONNX node: 1299
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1300 for ONNX tensor: 1300
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1189 [DequantizeLinear] outputs: [1300 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1190 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1190 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1190 [Constant] outputs: [1301 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1191 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1191 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1191 [Constant] outputs: [1302 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1192 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1301
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1302
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1192 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1301 -> ()[FLOAT]], [1302 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1301 for ONNX node: 1301
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1302 for ONNX node: 1302
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1303 for ONNX tensor: 1303
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1192 [QuantizeLinear] outputs: [1303 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1193 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1193 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1193 [Constant] outputs: [1304 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1194 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1194 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1194 [Constant] outputs: [1305 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1195 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1303
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1304
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1305
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1195 [DequantizeLinear] inputs: [1303 -> (8, 128, 1, 1)[FLOAT]], [1304 -> ()[FLOAT]], [1305 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1304 for ONNX node: 1304
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1305 for ONNX node: 1305
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1306 for ONNX tensor: 1306
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1195 [DequantizeLinear] outputs: [1306 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Conv_1196 [Conv]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1300
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1306
[03/01/2023-10:40:51] [V] [TRT] Conv_1196 [Conv] inputs: [1300 -> (1, 128, 1, 1)[FLOAT]], [1306 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Conv_1196 for ONNX node: Conv_1196
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1307 for ONNX tensor: 1307
[03/01/2023-10:40:51] [V] [TRT] Conv_1196 [Conv] outputs: [1307 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Relu_1197 [Relu]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1307
[03/01/2023-10:40:51] [V] [TRT] Relu_1197 [Relu] inputs: [1307 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Relu_1197 for ONNX node: Relu_1197
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1308 for ONNX tensor: 1308
[03/01/2023-10:40:51] [V] [TRT] Relu_1197 [Relu] outputs: [1308 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1198 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1198 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1198 [Constant] outputs: [1309 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1199 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1199 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1199 [Constant] outputs: [1310 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1200 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1308
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1309
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1310
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1200 [QuantizeLinear] inputs: [1308 -> (1, 8, 1, 1)[FLOAT]], [1309 -> ()[FLOAT]], [1310 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1309 for ONNX node: 1309
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1310 for ONNX node: 1310
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1311 for ONNX tensor: 1311
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1200 [QuantizeLinear] outputs: [1311 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1201 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1201 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1201 [Constant] outputs: [1312 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1202 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1202 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1202 [Constant] outputs: [1313 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1203 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1311
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1312
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1313
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1203 [DequantizeLinear] inputs: [1311 -> (1, 8, 1, 1)[FLOAT]], [1312 -> ()[FLOAT]], [1313 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1312 for ONNX node: 1312
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1313 for ONNX node: 1313
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1314 for ONNX tensor: 1314
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1203 [DequantizeLinear] outputs: [1314 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1204 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1204 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1204 [Constant] outputs: [1315 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1205 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1205 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1205 [Constant] outputs: [1316 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1206 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1315
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1316
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1206 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1315 -> ()[FLOAT]], [1316 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1315 for ONNX node: 1315
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1316 for ONNX node: 1316
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1317 for ONNX tensor: 1317
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1206 [QuantizeLinear] outputs: [1317 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1207 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1207 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1207 [Constant] outputs: [1318 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1208 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1208 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1208 [Constant] outputs: [1319 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1209 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1317
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1318
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1319
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1209 [DequantizeLinear] inputs: [1317 -> (128, 8, 1, 1)[FLOAT]], [1318 -> ()[FLOAT]], [1319 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1318 for ONNX node: 1318
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1319 for ONNX node: 1319
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1320 for ONNX tensor: 1320
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1209 [DequantizeLinear] outputs: [1320 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Conv_1210 [Conv]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1314
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1320
[03/01/2023-10:40:51] [V] [TRT] Conv_1210 [Conv] inputs: [1314 -> (1, 8, 1, 1)[FLOAT]], [1320 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Conv_1210 for ONNX node: Conv_1210
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1321 for ONNX tensor: 1321
[03/01/2023-10:40:51] [V] [TRT] Conv_1210 [Conv] outputs: [1321 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: MaxPool_1211 [MaxPool]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1293
[03/01/2023-10:40:51] [V] [TRT] MaxPool_1211 [MaxPool] inputs: [1293 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: MaxPool_1211 for ONNX node: MaxPool_1211
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1322 for ONNX tensor: 1322
[03/01/2023-10:40:51] [V] [TRT] MaxPool_1211 [MaxPool] outputs: [1322 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1212 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1212 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1212 [Constant] outputs: [1323 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1213 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1213 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1213 [Constant] outputs: [1324 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1214 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1322
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1323
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1324
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1214 [QuantizeLinear] inputs: [1322 -> (1, 128, 1, 1)[FLOAT]], [1323 -> ()[FLOAT]], [1324 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1323 for ONNX node: 1323
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1324 for ONNX node: 1324
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1325 for ONNX tensor: 1325
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1214 [QuantizeLinear] outputs: [1325 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1215 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1215 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1215 [Constant] outputs: [1326 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1216 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1216 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1216 [Constant] outputs: [1327 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1217 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1325
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1326
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1327
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1217 [DequantizeLinear] inputs: [1325 -> (1, 128, 1, 1)[FLOAT]], [1326 -> ()[FLOAT]], [1327 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1326 for ONNX node: 1326
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1327 for ONNX node: 1327
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1328 for ONNX tensor: 1328
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1217 [DequantizeLinear] outputs: [1328 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1218 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1218 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1218 [Constant] outputs: [1329 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1219 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1219 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1219 [Constant] outputs: [1330 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1220 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1329
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1330
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1220 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1329 -> ()[FLOAT]], [1330 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1329 for ONNX node: 1329
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1330 for ONNX node: 1330
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1331 for ONNX tensor: 1331
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1220 [QuantizeLinear] outputs: [1331 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1221 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1221 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1221 [Constant] outputs: [1332 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1222 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1222 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1222 [Constant] outputs: [1333 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1223 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1331
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1332
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1333
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1223 [DequantizeLinear] inputs: [1331 -> (8, 128, 1, 1)[FLOAT]], [1332 -> ()[FLOAT]], [1333 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1332 for ONNX node: 1332
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1333 for ONNX node: 1333
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1334 for ONNX tensor: 1334
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1223 [DequantizeLinear] outputs: [1334 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Conv_1224 [Conv]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1328
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1334
[03/01/2023-10:40:51] [V] [TRT] Conv_1224 [Conv] inputs: [1328 -> (1, 128, 1, 1)[FLOAT]], [1334 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Conv_1224 for ONNX node: Conv_1224
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1335 for ONNX tensor: 1335
[03/01/2023-10:40:51] [V] [TRT] Conv_1224 [Conv] outputs: [1335 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Relu_1225 [Relu]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1335
[03/01/2023-10:40:51] [V] [TRT] Relu_1225 [Relu] inputs: [1335 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Relu_1225 for ONNX node: Relu_1225
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1336 for ONNX tensor: 1336
[03/01/2023-10:40:51] [V] [TRT] Relu_1225 [Relu] outputs: [1336 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1226 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1226 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1226 [Constant] outputs: [1337 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1227 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1227 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1227 [Constant] outputs: [1338 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1228 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1336
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1337
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1338
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1228 [QuantizeLinear] inputs: [1336 -> (1, 8, 1, 1)[FLOAT]], [1337 -> ()[FLOAT]], [1338 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1337 for ONNX node: 1337
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1338 for ONNX node: 1338
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1339 for ONNX tensor: 1339
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1228 [QuantizeLinear] outputs: [1339 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1229 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1229 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1229 [Constant] outputs: [1340 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1230 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1230 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1230 [Constant] outputs: [1341 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1231 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1339
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1340
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1341
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1231 [DequantizeLinear] inputs: [1339 -> (1, 8, 1, 1)[FLOAT]], [1340 -> ()[FLOAT]], [1341 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1340 for ONNX node: 1340
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1341 for ONNX node: 1341
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1342 for ONNX tensor: 1342
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1231 [DequantizeLinear] outputs: [1342 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1232 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1232 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1232 [Constant] outputs: [1343 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1233 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1233 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1233 [Constant] outputs: [1344 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1234 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1343
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1344
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1234 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1343 -> ()[FLOAT]], [1344 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1343 for ONNX node: 1343
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1344 for ONNX node: 1344
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1345 for ONNX tensor: 1345
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1234 [QuantizeLinear] outputs: [1345 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1235 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1235 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1235 [Constant] outputs: [1346 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1236 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1236 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1236 [Constant] outputs: [1347 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1237 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1345
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1346
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1347
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1237 [DequantizeLinear] inputs: [1345 -> (128, 8, 1, 1)[FLOAT]], [1346 -> ()[FLOAT]], [1347 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1346 for ONNX node: 1346
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1347 for ONNX node: 1347
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1348 for ONNX tensor: 1348
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1237 [DequantizeLinear] outputs: [1348 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Conv_1238 [Conv]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1342
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1348
[03/01/2023-10:40:51] [V] [TRT] Conv_1238 [Conv] inputs: [1342 -> (1, 8, 1, 1)[FLOAT]], [1348 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Conv_1238 for ONNX node: Conv_1238
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1349 for ONNX tensor: 1349
[03/01/2023-10:40:51] [V] [TRT] Conv_1238 [Conv] outputs: [1349 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Add_1239 [Add]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1321
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1349
[03/01/2023-10:40:51] [V] [TRT] Add_1239 [Add] inputs: [1321 -> (1, 128, 1, 1)[FLOAT]], [1349 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Add_1239 for ONNX node: Add_1239
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1350 for ONNX tensor: 1350
[03/01/2023-10:40:51] [V] [TRT] Add_1239 [Add] outputs: [1350 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Sigmoid_1240 [Sigmoid]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1350
[03/01/2023-10:40:51] [V] [TRT] Sigmoid_1240 [Sigmoid] inputs: [1350 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Sigmoid_1240 for ONNX node: Sigmoid_1240
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1351 for ONNX tensor: 1351
[03/01/2023-10:40:51] [V] [TRT] Sigmoid_1240 [Sigmoid] outputs: [1351 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Mul_1241 [Mul]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1293
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1351
[03/01/2023-10:40:51] [V] [TRT] Mul_1241 [Mul] inputs: [1293 -> (1, 128, 3, 3)[FLOAT]], [1351 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Mul_1241 for ONNX node: Mul_1241
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1352 for ONNX tensor: 1352
[03/01/2023-10:40:51] [V] [TRT] Mul_1241 [Mul] outputs: [1352 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Concat_1242 [Concat]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1203
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1352
[03/01/2023-10:40:51] [V] [TRT] Concat_1242 [Concat] inputs: [1203 -> (1, 768, 3, 3)[FLOAT]], [1352 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Concat_1242 for ONNX node: Concat_1242
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1353 for ONNX tensor: 1353
[03/01/2023-10:40:51] [V] [TRT] Concat_1242 [Concat] outputs: [1353 -> (1, 896, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1243 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1243 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1243 [Constant] outputs: [1354 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1244 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1244 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1244 [Constant] outputs: [1355 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1245 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1245 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1245 [Constant] outputs: [1356 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1246 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1246 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1246 [Constant] outputs: [1357 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Slice_1247 [Slice]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: input
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1355
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1356
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1354
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1357
[03/01/2023-10:40:51] [V] [TRT] Slice_1247 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [1355 -> (1)[INT32]], [1356 -> (1)[INT32]], [1354 -> (1)[INT32]], [1357 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Slice_1247 for ONNX node: Slice_1247
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1358 for ONNX tensor: 1358
[03/01/2023-10:40:51] [V] [TRT] Slice_1247 [Slice] outputs: [1358 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1248 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1248 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1248 [Constant] outputs: [1359 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1249 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1249 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1249 [Constant] outputs: [1360 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1250 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1250 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1250 [Constant] outputs: [1361 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1251 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1251 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1251 [Constant] outputs: [1362 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Slice_1252 [Slice]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1358
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1360
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1361
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1359
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1362
[03/01/2023-10:40:51] [V] [TRT] Slice_1252 [Slice] inputs: [1358 -> (1, 1, 24, 60)[FLOAT]], [1360 -> (1)[INT32]], [1361 -> (1)[INT32]], [1359 -> (1)[INT32]], [1362 -> (1)[INT32]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Slice_1252 for ONNX node: Slice_1252
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1363 for ONNX tensor: 1363
[03/01/2023-10:40:51] [V] [TRT] Slice_1252 [Slice] outputs: [1363 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1253 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1253 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1253 [Constant] outputs: [1364 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1254 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1254 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1254 [Constant] outputs: [1365 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1255 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1363
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1364
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1365
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1255 [QuantizeLinear] inputs: [1363 -> (1, 1, 24, 24)[FLOAT]], [1364 -> ()[FLOAT]], [1365 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1364 for ONNX node: 1364
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1365 for ONNX node: 1365
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1366 for ONNX tensor: 1366
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1255 [QuantizeLinear] outputs: [1366 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1256 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1256 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1256 [Constant] outputs: [1367 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1257 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1257 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1257 [Constant] outputs: [1368 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1258 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1366
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1367
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1368
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1258 [DequantizeLinear] inputs: [1366 -> (1, 1, 24, 24)[FLOAT]], [1367 -> ()[FLOAT]], [1368 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1367 for ONNX node: 1367
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1368 for ONNX node: 1368
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1369 for ONNX tensor: 1369
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1258 [DequantizeLinear] outputs: [1369 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1259 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1259 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1259 [Constant] outputs: [1370 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1260 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1260 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1260 [Constant] outputs: [1371 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1261 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1370
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1371
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1261 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [1370 -> ()[FLOAT]], [1371 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1370 for ONNX node: 1370
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1371 for ONNX node: 1371
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1372 for ONNX tensor: 1372
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1261 [QuantizeLinear] outputs: [1372 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1262 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1262 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1262 [Constant] outputs: [1373 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1263 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1263 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1263 [Constant] outputs: [1374 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1264 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1372
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1373
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1374
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1264 [DequantizeLinear] inputs: [1372 -> (64, 1, 3, 3)[FLOAT]], [1373 -> ()[FLOAT]], [1374 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1373 for ONNX node: 1373
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1374 for ONNX node: 1374
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1375 for ONNX tensor: 1375
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1264 [DequantizeLinear] outputs: [1375 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Conv_1265 [Conv]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1369
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1375
[03/01/2023-10:40:51] [V] [TRT] Conv_1265 [Conv] inputs: [1369 -> (1, 1, 24, 24)[FLOAT]], [1375 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Conv_1265 for ONNX node: Conv_1265
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1376 for ONNX tensor: 1376
[03/01/2023-10:40:51] [V] [TRT] Conv_1265 [Conv] outputs: [1376 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: BatchNormalization_1266 [BatchNormalization]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1376
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1266 [BatchNormalization] inputs: [1376 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: BatchNormalization_1266 for ONNX node: BatchNormalization_1266
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1377 for ONNX tensor: 1377
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1266 [BatchNormalization] outputs: [1377 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Relu_1267 [Relu]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1377
[03/01/2023-10:40:51] [V] [TRT] Relu_1267 [Relu] inputs: [1377 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Relu_1267 for ONNX node: Relu_1267
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1378 for ONNX tensor: 1378
[03/01/2023-10:40:51] [V] [TRT] Relu_1267 [Relu] outputs: [1378 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1268 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1268 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1268 [Constant] outputs: [1379 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1269 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1269 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1269 [Constant] outputs: [1380 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1270 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1378
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1379
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1380
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1270 [QuantizeLinear] inputs: [1378 -> (1, 64, 22, 22)[FLOAT]], [1379 -> ()[FLOAT]], [1380 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1379 for ONNX node: 1379
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1380 for ONNX node: 1380
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1381 for ONNX tensor: 1381
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1270 [QuantizeLinear] outputs: [1381 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1271 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1271 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1271 [Constant] outputs: [1382 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1272 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1272 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1272 [Constant] outputs: [1383 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1273 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1381
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1382
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1383
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1273 [DequantizeLinear] inputs: [1381 -> (1, 64, 22, 22)[FLOAT]], [1382 -> ()[FLOAT]], [1383 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1382 for ONNX node: 1382
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1383 for ONNX node: 1383
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1384 for ONNX tensor: 1384
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1273 [DequantizeLinear] outputs: [1384 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1274 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1274 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1274 [Constant] outputs: [1385 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1275 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1275 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1275 [Constant] outputs: [1386 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1276 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1385
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1386
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1276 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [1385 -> ()[FLOAT]], [1386 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1385 for ONNX node: 1385
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1386 for ONNX node: 1386
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1387 for ONNX tensor: 1387
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1276 [QuantizeLinear] outputs: [1387 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1277 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1277 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1277 [Constant] outputs: [1388 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1278 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1278 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1278 [Constant] outputs: [1389 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1279 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1387
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1388
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1389
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1279 [DequantizeLinear] inputs: [1387 -> (64, 64, 3, 3)[FLOAT]], [1388 -> ()[FLOAT]], [1389 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1388 for ONNX node: 1388
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1389 for ONNX node: 1389
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1390 for ONNX tensor: 1390
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1279 [DequantizeLinear] outputs: [1390 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Conv_1280 [Conv]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1384
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1390
[03/01/2023-10:40:51] [V] [TRT] Conv_1280 [Conv] inputs: [1384 -> (1, 64, 22, 22)[FLOAT]], [1390 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Conv_1280 for ONNX node: Conv_1280
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1391 for ONNX tensor: 1391
[03/01/2023-10:40:51] [V] [TRT] Conv_1280 [Conv] outputs: [1391 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: BatchNormalization_1281 [BatchNormalization]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1391
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1281 [BatchNormalization] inputs: [1391 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: BatchNormalization_1281 for ONNX node: BatchNormalization_1281
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1392 for ONNX tensor: 1392
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1281 [BatchNormalization] outputs: [1392 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Relu_1282 [Relu]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1392
[03/01/2023-10:40:51] [V] [TRT] Relu_1282 [Relu] inputs: [1392 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Relu_1282 for ONNX node: Relu_1282
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1393 for ONNX tensor: 1393
[03/01/2023-10:40:51] [V] [TRT] Relu_1282 [Relu] outputs: [1393 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: MaxPool_1283 [MaxPool]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1393
[03/01/2023-10:40:51] [V] [TRT] MaxPool_1283 [MaxPool] inputs: [1393 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: MaxPool_1283 for ONNX node: MaxPool_1283
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1394 for ONNX tensor: 1394
[03/01/2023-10:40:51] [V] [TRT] MaxPool_1283 [MaxPool] outputs: [1394 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1284 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1284 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1284 [Constant] outputs: [1395 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1285 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1285 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1285 [Constant] outputs: [1396 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1286 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1394
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1395
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1396
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1286 [QuantizeLinear] inputs: [1394 -> (1, 64, 10, 10)[FLOAT]], [1395 -> ()[FLOAT]], [1396 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1395 for ONNX node: 1395
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1396 for ONNX node: 1396
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1397 for ONNX tensor: 1397
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1286 [QuantizeLinear] outputs: [1397 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1287 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1287 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1287 [Constant] outputs: [1398 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1288 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1288 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1288 [Constant] outputs: [1399 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1289 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1397
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1398
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1399
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1289 [DequantizeLinear] inputs: [1397 -> (1, 64, 10, 10)[FLOAT]], [1398 -> ()[FLOAT]], [1399 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1398 for ONNX node: 1398
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1399 for ONNX node: 1399
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1400 for ONNX tensor: 1400
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1289 [DequantizeLinear] outputs: [1400 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1290 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1290 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1290 [Constant] outputs: [1401 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1291 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1291 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1291 [Constant] outputs: [1402 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1292 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1401
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1402
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1292 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [1401 -> ()[FLOAT]], [1402 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1401 for ONNX node: 1401
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1402 for ONNX node: 1402
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1403 for ONNX tensor: 1403
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1292 [QuantizeLinear] outputs: [1403 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1293 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1293 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1293 [Constant] outputs: [1404 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1294 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1294 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1294 [Constant] outputs: [1405 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1295 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1403
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1404
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1405
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1295 [DequantizeLinear] inputs: [1403 -> (128, 64, 3, 3)[FLOAT]], [1404 -> ()[FLOAT]], [1405 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1404 for ONNX node: 1404
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1405 for ONNX node: 1405
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1406 for ONNX tensor: 1406
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1295 [DequantizeLinear] outputs: [1406 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Conv_1296 [Conv]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1400
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1406
[03/01/2023-10:40:51] [V] [TRT] Conv_1296 [Conv] inputs: [1400 -> (1, 64, 10, 10)[FLOAT]], [1406 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Conv_1296 for ONNX node: Conv_1296
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1407 for ONNX tensor: 1407
[03/01/2023-10:40:51] [V] [TRT] Conv_1296 [Conv] outputs: [1407 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: BatchNormalization_1297 [BatchNormalization]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1407
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1297 [BatchNormalization] inputs: [1407 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: BatchNormalization_1297 for ONNX node: BatchNormalization_1297
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1408 for ONNX tensor: 1408
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1297 [BatchNormalization] outputs: [1408 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Relu_1298 [Relu]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1408
[03/01/2023-10:40:51] [V] [TRT] Relu_1298 [Relu] inputs: [1408 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Relu_1298 for ONNX node: Relu_1298
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1409 for ONNX tensor: 1409
[03/01/2023-10:40:51] [V] [TRT] Relu_1298 [Relu] outputs: [1409 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1299 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1299 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1299 [Constant] outputs: [1410 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1300 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1300 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1300 [Constant] outputs: [1411 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1301 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1409
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1410
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1411
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1301 [QuantizeLinear] inputs: [1409 -> (1, 128, 8, 8)[FLOAT]], [1410 -> ()[FLOAT]], [1411 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1410 for ONNX node: 1410
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1411 for ONNX node: 1411
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1412 for ONNX tensor: 1412
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1301 [QuantizeLinear] outputs: [1412 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1302 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1302 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1302 [Constant] outputs: [1413 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1303 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1303 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1303 [Constant] outputs: [1414 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1304 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1412
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1413
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1414
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1304 [DequantizeLinear] inputs: [1412 -> (1, 128, 8, 8)[FLOAT]], [1413 -> ()[FLOAT]], [1414 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1413 for ONNX node: 1413
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1414 for ONNX node: 1414
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1415 for ONNX tensor: 1415
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1304 [DequantizeLinear] outputs: [1415 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1305 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1305 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1305 [Constant] outputs: [1416 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1306 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1306 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1306 [Constant] outputs: [1417 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: QuantizeLinear_1307 [QuantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1416
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1417
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1307 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [1416 -> ()[FLOAT]], [1417 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1416 for ONNX node: 1416
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1417 for ONNX node: 1417
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1418 for ONNX tensor: 1418
[03/01/2023-10:40:51] [V] [TRT] QuantizeLinear_1307 [QuantizeLinear] outputs: [1418 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1308 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1308 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1308 [Constant] outputs: [1419 -> ()[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Constant_1309 [Constant]
[03/01/2023-10:40:51] [V] [TRT] Constant_1309 [Constant] inputs: 
[03/01/2023-10:40:51] [V] [TRT] Constant_1309 [Constant] outputs: [1420 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: DequantizeLinear_1310 [DequantizeLinear]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1418
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1419
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1420
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1310 [DequantizeLinear] inputs: [1418 -> (128, 128, 3, 3)[FLOAT]], [1419 -> ()[FLOAT]], [1420 -> ()[INT8]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1419 for ONNX node: 1419
[03/01/2023-10:40:51] [V] [TRT] Registering layer: 1420 for ONNX node: 1420
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1421 for ONNX tensor: 1421
[03/01/2023-10:40:51] [V] [TRT] DequantizeLinear_1310 [DequantizeLinear] outputs: [1421 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Conv_1311 [Conv]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1415
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1421
[03/01/2023-10:40:51] [V] [TRT] Conv_1311 [Conv] inputs: [1415 -> (1, 128, 8, 8)[FLOAT]], [1421 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Conv_1311 for ONNX node: Conv_1311
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1422 for ONNX tensor: 1422
[03/01/2023-10:40:51] [V] [TRT] Conv_1311 [Conv] outputs: [1422 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: BatchNormalization_1312 [BatchNormalization]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1422
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:51] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1312 [BatchNormalization] inputs: [1422 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: BatchNormalization_1312 for ONNX node: BatchNormalization_1312
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1423 for ONNX tensor: 1423
[03/01/2023-10:40:51] [V] [TRT] BatchNormalization_1312 [BatchNormalization] outputs: [1423 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: Relu_1313 [Relu]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1423
[03/01/2023-10:40:51] [V] [TRT] Relu_1313 [Relu] inputs: [1423 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: Relu_1313 for ONNX node: Relu_1313
[03/01/2023-10:40:51] [V] [TRT] Registering tensor: 1424 for ONNX tensor: 1424
[03/01/2023-10:40:51] [V] [TRT] Relu_1313 [Relu] outputs: [1424 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Parsing node: MaxPool_1314 [MaxPool]
[03/01/2023-10:40:51] [V] [TRT] Searching for input: 1424
[03/01/2023-10:40:51] [V] [TRT] MaxPool_1314 [MaxPool] inputs: [1424 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:51] [V] [TRT] Registering layer: MaxPool_1314 for ONNX node: MaxPool_1314
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1425 for ONNX tensor: 1425
[03/01/2023-10:40:52] [V] [TRT] MaxPool_1314 [MaxPool] outputs: [1425 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: ReduceMean_1315 [ReduceMean]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1425
[03/01/2023-10:40:52] [V] [TRT] ReduceMean_1315 [ReduceMean] inputs: [1425 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: ReduceMean_1315 for ONNX node: ReduceMean_1315
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1426 for ONNX tensor: 1426
[03/01/2023-10:40:52] [V] [TRT] ReduceMean_1315 [ReduceMean] outputs: [1426 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: ReduceMax_1316 [ReduceMax]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1425
[03/01/2023-10:40:52] [V] [TRT] ReduceMax_1316 [ReduceMax] inputs: [1425 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: ReduceMax_1316 for ONNX node: ReduceMax_1316
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1427 for ONNX tensor: 1427
[03/01/2023-10:40:52] [V] [TRT] ReduceMax_1316 [ReduceMax] outputs: [1427 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Concat_1317 [Concat]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1426
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1427
[03/01/2023-10:40:52] [V] [TRT] Concat_1317 [Concat] inputs: [1426 -> (1, 1, 3, 3)[FLOAT]], [1427 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Concat_1317 for ONNX node: Concat_1317
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1428 for ONNX tensor: 1428
[03/01/2023-10:40:52] [V] [TRT] Concat_1317 [Concat] outputs: [1428 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1318 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1318 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1318 [Constant] outputs: [1429 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1319 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1319 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1319 [Constant] outputs: [1430 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1320 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1428
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1429
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1430
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1320 [QuantizeLinear] inputs: [1428 -> (1, 2, 3, 3)[FLOAT]], [1429 -> ()[FLOAT]], [1430 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1429 for ONNX node: 1429
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1430 for ONNX node: 1430
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1431 for ONNX tensor: 1431
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1320 [QuantizeLinear] outputs: [1431 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1321 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1321 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1321 [Constant] outputs: [1432 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1322 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1322 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1322 [Constant] outputs: [1433 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1323 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1431
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1432
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1433
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1323 [DequantizeLinear] inputs: [1431 -> (1, 2, 3, 3)[FLOAT]], [1432 -> ()[FLOAT]], [1433 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1432 for ONNX node: 1432
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1433 for ONNX node: 1433
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1434 for ONNX tensor: 1434
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1323 [DequantizeLinear] outputs: [1434 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1324 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1324 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1324 [Constant] outputs: [1435 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1325 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1325 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1325 [Constant] outputs: [1436 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1326 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1435
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1436
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1326 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [1435 -> ()[FLOAT]], [1436 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1435 for ONNX node: 1435
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1436 for ONNX node: 1436
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1437 for ONNX tensor: 1437
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1326 [QuantizeLinear] outputs: [1437 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1327 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1327 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1327 [Constant] outputs: [1438 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1328 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1328 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1328 [Constant] outputs: [1439 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1329 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1437
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1438
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1439
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1329 [DequantizeLinear] inputs: [1437 -> (1, 2, 7, 7)[FLOAT]], [1438 -> ()[FLOAT]], [1439 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1438 for ONNX node: 1438
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1439 for ONNX node: 1439
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1440 for ONNX tensor: 1440
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1329 [DequantizeLinear] outputs: [1440 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Conv_1330 [Conv]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1434
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1440
[03/01/2023-10:40:52] [V] [TRT] Conv_1330 [Conv] inputs: [1434 -> (1, 2, 3, 3)[FLOAT]], [1440 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Conv_1330 for ONNX node: Conv_1330
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1441 for ONNX tensor: 1441
[03/01/2023-10:40:52] [V] [TRT] Conv_1330 [Conv] outputs: [1441 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Sigmoid_1331 [Sigmoid]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1441
[03/01/2023-10:40:52] [V] [TRT] Sigmoid_1331 [Sigmoid] inputs: [1441 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Sigmoid_1331 for ONNX node: Sigmoid_1331
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1442 for ONNX tensor: 1442
[03/01/2023-10:40:52] [V] [TRT] Sigmoid_1331 [Sigmoid] outputs: [1442 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Mul_1332 [Mul]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1425
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1442
[03/01/2023-10:40:52] [V] [TRT] Mul_1332 [Mul] inputs: [1425 -> (1, 128, 3, 3)[FLOAT]], [1442 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Mul_1332 for ONNX node: Mul_1332
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1443 for ONNX tensor: 1443
[03/01/2023-10:40:52] [V] [TRT] Mul_1332 [Mul] outputs: [1443 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: GlobalAveragePool_1333 [GlobalAveragePool]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1443
[03/01/2023-10:40:52] [V] [TRT] GlobalAveragePool_1333 [GlobalAveragePool] inputs: [1443 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:52] [V] [TRT] Registering layer: GlobalAveragePool_1333 for ONNX node: GlobalAveragePool_1333
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1444 for ONNX tensor: 1444
[03/01/2023-10:40:52] [V] [TRT] GlobalAveragePool_1333 [GlobalAveragePool] outputs: [1444 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1334 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1334 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1334 [Constant] outputs: [1445 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1335 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1335 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1335 [Constant] outputs: [1446 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1336 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1444
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1445
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1446
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1336 [QuantizeLinear] inputs: [1444 -> (1, 128, 1, 1)[FLOAT]], [1445 -> ()[FLOAT]], [1446 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1445 for ONNX node: 1445
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1446 for ONNX node: 1446
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1447 for ONNX tensor: 1447
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1336 [QuantizeLinear] outputs: [1447 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1337 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1337 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1337 [Constant] outputs: [1448 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1338 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1338 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1338 [Constant] outputs: [1449 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1339 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1447
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1448
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1449
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1339 [DequantizeLinear] inputs: [1447 -> (1, 128, 1, 1)[FLOAT]], [1448 -> ()[FLOAT]], [1449 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1448 for ONNX node: 1448
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1449 for ONNX node: 1449
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1450 for ONNX tensor: 1450
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1339 [DequantizeLinear] outputs: [1450 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1340 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1340 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1340 [Constant] outputs: [1451 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1341 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1341 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1341 [Constant] outputs: [1452 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1342 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1451
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1452
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1342 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1451 -> ()[FLOAT]], [1452 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1451 for ONNX node: 1451
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1452 for ONNX node: 1452
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1453 for ONNX tensor: 1453
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1342 [QuantizeLinear] outputs: [1453 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1343 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1343 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1343 [Constant] outputs: [1454 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1344 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1344 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1344 [Constant] outputs: [1455 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1345 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1453
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1454
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1455
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1345 [DequantizeLinear] inputs: [1453 -> (8, 128, 1, 1)[FLOAT]], [1454 -> ()[FLOAT]], [1455 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1454 for ONNX node: 1454
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1455 for ONNX node: 1455
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1456 for ONNX tensor: 1456
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1345 [DequantizeLinear] outputs: [1456 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Conv_1346 [Conv]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1450
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1456
[03/01/2023-10:40:52] [V] [TRT] Conv_1346 [Conv] inputs: [1450 -> (1, 128, 1, 1)[FLOAT]], [1456 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Conv_1346 for ONNX node: Conv_1346
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1457 for ONNX tensor: 1457
[03/01/2023-10:40:52] [V] [TRT] Conv_1346 [Conv] outputs: [1457 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Relu_1347 [Relu]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1457
[03/01/2023-10:40:52] [V] [TRT] Relu_1347 [Relu] inputs: [1457 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Relu_1347 for ONNX node: Relu_1347
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1458 for ONNX tensor: 1458
[03/01/2023-10:40:52] [V] [TRT] Relu_1347 [Relu] outputs: [1458 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1348 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1348 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1348 [Constant] outputs: [1459 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1349 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1349 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1349 [Constant] outputs: [1460 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1350 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1458
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1459
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1460
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1350 [QuantizeLinear] inputs: [1458 -> (1, 8, 1, 1)[FLOAT]], [1459 -> ()[FLOAT]], [1460 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1459 for ONNX node: 1459
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1460 for ONNX node: 1460
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1461 for ONNX tensor: 1461
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1350 [QuantizeLinear] outputs: [1461 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1351 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1351 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1351 [Constant] outputs: [1462 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1352 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1352 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1352 [Constant] outputs: [1463 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1353 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1461
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1462
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1463
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1353 [DequantizeLinear] inputs: [1461 -> (1, 8, 1, 1)[FLOAT]], [1462 -> ()[FLOAT]], [1463 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1462 for ONNX node: 1462
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1463 for ONNX node: 1463
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1464 for ONNX tensor: 1464
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1353 [DequantizeLinear] outputs: [1464 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1354 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1354 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1354 [Constant] outputs: [1465 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1355 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1355 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1355 [Constant] outputs: [1466 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1356 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1465
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1466
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1356 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1465 -> ()[FLOAT]], [1466 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1465 for ONNX node: 1465
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1466 for ONNX node: 1466
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1467 for ONNX tensor: 1467
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1356 [QuantizeLinear] outputs: [1467 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1357 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1357 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1357 [Constant] outputs: [1468 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1358 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1358 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1358 [Constant] outputs: [1469 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1359 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1467
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1468
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1469
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1359 [DequantizeLinear] inputs: [1467 -> (128, 8, 1, 1)[FLOAT]], [1468 -> ()[FLOAT]], [1469 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1468 for ONNX node: 1468
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1469 for ONNX node: 1469
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1470 for ONNX tensor: 1470
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1359 [DequantizeLinear] outputs: [1470 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Conv_1360 [Conv]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1464
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1470
[03/01/2023-10:40:52] [V] [TRT] Conv_1360 [Conv] inputs: [1464 -> (1, 8, 1, 1)[FLOAT]], [1470 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Conv_1360 for ONNX node: Conv_1360
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1471 for ONNX tensor: 1471
[03/01/2023-10:40:52] [V] [TRT] Conv_1360 [Conv] outputs: [1471 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: MaxPool_1361 [MaxPool]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1443
[03/01/2023-10:40:52] [V] [TRT] MaxPool_1361 [MaxPool] inputs: [1443 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: MaxPool_1361 for ONNX node: MaxPool_1361
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1472 for ONNX tensor: 1472
[03/01/2023-10:40:52] [V] [TRT] MaxPool_1361 [MaxPool] outputs: [1472 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1362 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1362 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1362 [Constant] outputs: [1473 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1363 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1363 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1363 [Constant] outputs: [1474 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1364 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1472
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1473
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1474
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1364 [QuantizeLinear] inputs: [1472 -> (1, 128, 1, 1)[FLOAT]], [1473 -> ()[FLOAT]], [1474 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1473 for ONNX node: 1473
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1474 for ONNX node: 1474
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1475 for ONNX tensor: 1475
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1364 [QuantizeLinear] outputs: [1475 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1365 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1365 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1365 [Constant] outputs: [1476 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1366 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1366 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1366 [Constant] outputs: [1477 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1367 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1475
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1476
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1477
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1367 [DequantizeLinear] inputs: [1475 -> (1, 128, 1, 1)[FLOAT]], [1476 -> ()[FLOAT]], [1477 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1476 for ONNX node: 1476
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1477 for ONNX node: 1477
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1478 for ONNX tensor: 1478
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1367 [DequantizeLinear] outputs: [1478 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1368 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1368 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1368 [Constant] outputs: [1479 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1369 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1369 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1369 [Constant] outputs: [1480 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1370 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1479
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1480
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1370 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1479 -> ()[FLOAT]], [1480 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1479 for ONNX node: 1479
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1480 for ONNX node: 1480
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1481 for ONNX tensor: 1481
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1370 [QuantizeLinear] outputs: [1481 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1371 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1371 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1371 [Constant] outputs: [1482 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1372 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1372 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1372 [Constant] outputs: [1483 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1373 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1481
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1482
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1483
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1373 [DequantizeLinear] inputs: [1481 -> (8, 128, 1, 1)[FLOAT]], [1482 -> ()[FLOAT]], [1483 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1482 for ONNX node: 1482
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1483 for ONNX node: 1483
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1484 for ONNX tensor: 1484
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1373 [DequantizeLinear] outputs: [1484 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Conv_1374 [Conv]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1478
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1484
[03/01/2023-10:40:52] [V] [TRT] Conv_1374 [Conv] inputs: [1478 -> (1, 128, 1, 1)[FLOAT]], [1484 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Conv_1374 for ONNX node: Conv_1374
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1485 for ONNX tensor: 1485
[03/01/2023-10:40:52] [V] [TRT] Conv_1374 [Conv] outputs: [1485 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Relu_1375 [Relu]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1485
[03/01/2023-10:40:52] [V] [TRT] Relu_1375 [Relu] inputs: [1485 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Relu_1375 for ONNX node: Relu_1375
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1486 for ONNX tensor: 1486
[03/01/2023-10:40:52] [V] [TRT] Relu_1375 [Relu] outputs: [1486 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1376 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1376 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1376 [Constant] outputs: [1487 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1377 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1377 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1377 [Constant] outputs: [1488 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1378 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1486
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1487
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1488
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1378 [QuantizeLinear] inputs: [1486 -> (1, 8, 1, 1)[FLOAT]], [1487 -> ()[FLOAT]], [1488 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1487 for ONNX node: 1487
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1488 for ONNX node: 1488
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1489 for ONNX tensor: 1489
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1378 [QuantizeLinear] outputs: [1489 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1379 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1379 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1379 [Constant] outputs: [1490 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1380 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1380 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1380 [Constant] outputs: [1491 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1381 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1489
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1490
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1491
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1381 [DequantizeLinear] inputs: [1489 -> (1, 8, 1, 1)[FLOAT]], [1490 -> ()[FLOAT]], [1491 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1490 for ONNX node: 1490
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1491 for ONNX node: 1491
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1492 for ONNX tensor: 1492
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1381 [DequantizeLinear] outputs: [1492 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1382 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1382 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1382 [Constant] outputs: [1493 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1383 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1383 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1383 [Constant] outputs: [1494 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1384 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1493
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1494
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1384 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1493 -> ()[FLOAT]], [1494 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1493 for ONNX node: 1493
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1494 for ONNX node: 1494
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1495 for ONNX tensor: 1495
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1384 [QuantizeLinear] outputs: [1495 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1385 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1385 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1385 [Constant] outputs: [1496 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1386 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1386 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1386 [Constant] outputs: [1497 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1387 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1495
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1496
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1497
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1387 [DequantizeLinear] inputs: [1495 -> (128, 8, 1, 1)[FLOAT]], [1496 -> ()[FLOAT]], [1497 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1496 for ONNX node: 1496
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1497 for ONNX node: 1497
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1498 for ONNX tensor: 1498
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1387 [DequantizeLinear] outputs: [1498 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Conv_1388 [Conv]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1492
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1498
[03/01/2023-10:40:52] [V] [TRT] Conv_1388 [Conv] inputs: [1492 -> (1, 8, 1, 1)[FLOAT]], [1498 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Conv_1388 for ONNX node: Conv_1388
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1499 for ONNX tensor: 1499
[03/01/2023-10:40:52] [V] [TRT] Conv_1388 [Conv] outputs: [1499 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Add_1389 [Add]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1471
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1499
[03/01/2023-10:40:52] [V] [TRT] Add_1389 [Add] inputs: [1471 -> (1, 128, 1, 1)[FLOAT]], [1499 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Add_1389 for ONNX node: Add_1389
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1500 for ONNX tensor: 1500
[03/01/2023-10:40:52] [V] [TRT] Add_1389 [Add] outputs: [1500 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Sigmoid_1390 [Sigmoid]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1500
[03/01/2023-10:40:52] [V] [TRT] Sigmoid_1390 [Sigmoid] inputs: [1500 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Sigmoid_1390 for ONNX node: Sigmoid_1390
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1501 for ONNX tensor: 1501
[03/01/2023-10:40:52] [V] [TRT] Sigmoid_1390 [Sigmoid] outputs: [1501 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Mul_1391 [Mul]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1443
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1501
[03/01/2023-10:40:52] [V] [TRT] Mul_1391 [Mul] inputs: [1443 -> (1, 128, 3, 3)[FLOAT]], [1501 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Mul_1391 for ONNX node: Mul_1391
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1502 for ONNX tensor: 1502
[03/01/2023-10:40:52] [V] [TRT] Mul_1391 [Mul] outputs: [1502 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Concat_1392 [Concat]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1353
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1502
[03/01/2023-10:40:52] [V] [TRT] Concat_1392 [Concat] inputs: [1353 -> (1, 896, 3, 3)[FLOAT]], [1502 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Concat_1392 for ONNX node: Concat_1392
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1503 for ONNX tensor: 1503
[03/01/2023-10:40:52] [V] [TRT] Concat_1392 [Concat] outputs: [1503 -> (1, 1024, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1393 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1393 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1393 [Constant] outputs: [1504 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1394 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1394 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1394 [Constant] outputs: [1505 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1395 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1395 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1395 [Constant] outputs: [1506 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1396 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1396 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1396 [Constant] outputs: [1507 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Slice_1397 [Slice]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: input
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1505
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1506
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1504
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1507
[03/01/2023-10:40:52] [V] [TRT] Slice_1397 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [1505 -> (1)[INT32]], [1506 -> (1)[INT32]], [1504 -> (1)[INT32]], [1507 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Slice_1397 for ONNX node: Slice_1397
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1508 for ONNX tensor: 1508
[03/01/2023-10:40:52] [V] [TRT] Slice_1397 [Slice] outputs: [1508 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1398 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1398 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1398 [Constant] outputs: [1509 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1399 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1399 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1399 [Constant] outputs: [1510 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1400 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1400 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1400 [Constant] outputs: [1511 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1401 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1401 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1401 [Constant] outputs: [1512 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Slice_1402 [Slice]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1508
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1510
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1511
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1509
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1512
[03/01/2023-10:40:52] [V] [TRT] Slice_1402 [Slice] inputs: [1508 -> (1, 1, 24, 60)[FLOAT]], [1510 -> (1)[INT32]], [1511 -> (1)[INT32]], [1509 -> (1)[INT32]], [1512 -> (1)[INT32]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Slice_1402 for ONNX node: Slice_1402
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1513 for ONNX tensor: 1513
[03/01/2023-10:40:52] [V] [TRT] Slice_1402 [Slice] outputs: [1513 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1403 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1403 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1403 [Constant] outputs: [1514 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1404 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1404 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1404 [Constant] outputs: [1515 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1405 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1513
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1514
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1515
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1405 [QuantizeLinear] inputs: [1513 -> (1, 1, 24, 24)[FLOAT]], [1514 -> ()[FLOAT]], [1515 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1514 for ONNX node: 1514
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1515 for ONNX node: 1515
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1516 for ONNX tensor: 1516
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1405 [QuantizeLinear] outputs: [1516 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1406 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1406 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1406 [Constant] outputs: [1517 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1407 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1407 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1407 [Constant] outputs: [1518 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1408 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1516
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1517
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1518
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1408 [DequantizeLinear] inputs: [1516 -> (1, 1, 24, 24)[FLOAT]], [1517 -> ()[FLOAT]], [1518 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1517 for ONNX node: 1517
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1518 for ONNX node: 1518
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1519 for ONNX tensor: 1519
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1408 [DequantizeLinear] outputs: [1519 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1409 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1409 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1409 [Constant] outputs: [1520 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1410 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1410 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1410 [Constant] outputs: [1521 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1411 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1520
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1521
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1411 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [1520 -> ()[FLOAT]], [1521 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1520 for ONNX node: 1520
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1521 for ONNX node: 1521
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1522 for ONNX tensor: 1522
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1411 [QuantizeLinear] outputs: [1522 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1412 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1412 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1412 [Constant] outputs: [1523 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1413 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1413 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1413 [Constant] outputs: [1524 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1414 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1522
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1523
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1524
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1414 [DequantizeLinear] inputs: [1522 -> (64, 1, 3, 3)[FLOAT]], [1523 -> ()[FLOAT]], [1524 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1523 for ONNX node: 1523
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1524 for ONNX node: 1524
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1525 for ONNX tensor: 1525
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1414 [DequantizeLinear] outputs: [1525 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Conv_1415 [Conv]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1519
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1525
[03/01/2023-10:40:52] [V] [TRT] Conv_1415 [Conv] inputs: [1519 -> (1, 1, 24, 24)[FLOAT]], [1525 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Conv_1415 for ONNX node: Conv_1415
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1526 for ONNX tensor: 1526
[03/01/2023-10:40:52] [V] [TRT] Conv_1415 [Conv] outputs: [1526 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: BatchNormalization_1416 [BatchNormalization]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1526
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:52] [V] [TRT] BatchNormalization_1416 [BatchNormalization] inputs: [1526 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: BatchNormalization_1416 for ONNX node: BatchNormalization_1416
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1527 for ONNX tensor: 1527
[03/01/2023-10:40:52] [V] [TRT] BatchNormalization_1416 [BatchNormalization] outputs: [1527 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Relu_1417 [Relu]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1527
[03/01/2023-10:40:52] [V] [TRT] Relu_1417 [Relu] inputs: [1527 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Relu_1417 for ONNX node: Relu_1417
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1528 for ONNX tensor: 1528
[03/01/2023-10:40:52] [V] [TRT] Relu_1417 [Relu] outputs: [1528 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1418 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1418 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1418 [Constant] outputs: [1529 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1419 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1419 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1419 [Constant] outputs: [1530 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1420 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1528
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1529
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1530
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1420 [QuantizeLinear] inputs: [1528 -> (1, 64, 22, 22)[FLOAT]], [1529 -> ()[FLOAT]], [1530 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1529 for ONNX node: 1529
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1530 for ONNX node: 1530
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1531 for ONNX tensor: 1531
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1420 [QuantizeLinear] outputs: [1531 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1421 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1421 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1421 [Constant] outputs: [1532 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1422 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1422 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1422 [Constant] outputs: [1533 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1423 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1531
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1532
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1533
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1423 [DequantizeLinear] inputs: [1531 -> (1, 64, 22, 22)[FLOAT]], [1532 -> ()[FLOAT]], [1533 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1532 for ONNX node: 1532
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1533 for ONNX node: 1533
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1534 for ONNX tensor: 1534
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1423 [DequantizeLinear] outputs: [1534 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1424 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1424 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1424 [Constant] outputs: [1535 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1425 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1425 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1425 [Constant] outputs: [1536 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1426 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1535
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1536
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1426 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [1535 -> ()[FLOAT]], [1536 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1535 for ONNX node: 1535
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1536 for ONNX node: 1536
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1537 for ONNX tensor: 1537
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1426 [QuantizeLinear] outputs: [1537 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1427 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1427 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1427 [Constant] outputs: [1538 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1428 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1428 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1428 [Constant] outputs: [1539 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1429 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1537
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1538
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1539
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1429 [DequantizeLinear] inputs: [1537 -> (64, 64, 3, 3)[FLOAT]], [1538 -> ()[FLOAT]], [1539 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1538 for ONNX node: 1538
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1539 for ONNX node: 1539
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1540 for ONNX tensor: 1540
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1429 [DequantizeLinear] outputs: [1540 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Conv_1430 [Conv]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1534
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1540
[03/01/2023-10:40:52] [V] [TRT] Conv_1430 [Conv] inputs: [1534 -> (1, 64, 22, 22)[FLOAT]], [1540 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Conv_1430 for ONNX node: Conv_1430
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1541 for ONNX tensor: 1541
[03/01/2023-10:40:52] [V] [TRT] Conv_1430 [Conv] outputs: [1541 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: BatchNormalization_1431 [BatchNormalization]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1541
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:52] [V] [TRT] BatchNormalization_1431 [BatchNormalization] inputs: [1541 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: BatchNormalization_1431 for ONNX node: BatchNormalization_1431
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1542 for ONNX tensor: 1542
[03/01/2023-10:40:52] [V] [TRT] BatchNormalization_1431 [BatchNormalization] outputs: [1542 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Relu_1432 [Relu]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1542
[03/01/2023-10:40:52] [V] [TRT] Relu_1432 [Relu] inputs: [1542 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Relu_1432 for ONNX node: Relu_1432
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1543 for ONNX tensor: 1543
[03/01/2023-10:40:52] [V] [TRT] Relu_1432 [Relu] outputs: [1543 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: MaxPool_1433 [MaxPool]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1543
[03/01/2023-10:40:52] [V] [TRT] MaxPool_1433 [MaxPool] inputs: [1543 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: MaxPool_1433 for ONNX node: MaxPool_1433
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1544 for ONNX tensor: 1544
[03/01/2023-10:40:52] [V] [TRT] MaxPool_1433 [MaxPool] outputs: [1544 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1434 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1434 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1434 [Constant] outputs: [1545 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1435 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1435 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1435 [Constant] outputs: [1546 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1436 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1544
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1545
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1546
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1436 [QuantizeLinear] inputs: [1544 -> (1, 64, 10, 10)[FLOAT]], [1545 -> ()[FLOAT]], [1546 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1545 for ONNX node: 1545
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1546 for ONNX node: 1546
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1547 for ONNX tensor: 1547
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1436 [QuantizeLinear] outputs: [1547 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1437 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1437 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1437 [Constant] outputs: [1548 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1438 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1438 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1438 [Constant] outputs: [1549 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1439 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1547
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1548
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1549
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1439 [DequantizeLinear] inputs: [1547 -> (1, 64, 10, 10)[FLOAT]], [1548 -> ()[FLOAT]], [1549 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1548 for ONNX node: 1548
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1549 for ONNX node: 1549
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1550 for ONNX tensor: 1550
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1439 [DequantizeLinear] outputs: [1550 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1440 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1440 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1440 [Constant] outputs: [1551 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1441 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1441 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1441 [Constant] outputs: [1552 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1442 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1551
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1552
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1442 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [1551 -> ()[FLOAT]], [1552 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1551 for ONNX node: 1551
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1552 for ONNX node: 1552
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1553 for ONNX tensor: 1553
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1442 [QuantizeLinear] outputs: [1553 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1443 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1443 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1443 [Constant] outputs: [1554 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1444 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1444 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1444 [Constant] outputs: [1555 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1445 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1553
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1554
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1555
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1445 [DequantizeLinear] inputs: [1553 -> (128, 64, 3, 3)[FLOAT]], [1554 -> ()[FLOAT]], [1555 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1554 for ONNX node: 1554
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1555 for ONNX node: 1555
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1556 for ONNX tensor: 1556
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1445 [DequantizeLinear] outputs: [1556 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Conv_1446 [Conv]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1550
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1556
[03/01/2023-10:40:52] [V] [TRT] Conv_1446 [Conv] inputs: [1550 -> (1, 64, 10, 10)[FLOAT]], [1556 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Conv_1446 for ONNX node: Conv_1446
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1557 for ONNX tensor: 1557
[03/01/2023-10:40:52] [V] [TRT] Conv_1446 [Conv] outputs: [1557 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: BatchNormalization_1447 [BatchNormalization]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1557
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:52] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:52] [V] [TRT] BatchNormalization_1447 [BatchNormalization] inputs: [1557 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: BatchNormalization_1447 for ONNX node: BatchNormalization_1447
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1558 for ONNX tensor: 1558
[03/01/2023-10:40:52] [V] [TRT] BatchNormalization_1447 [BatchNormalization] outputs: [1558 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Relu_1448 [Relu]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1558
[03/01/2023-10:40:52] [V] [TRT] Relu_1448 [Relu] inputs: [1558 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: Relu_1448 for ONNX node: Relu_1448
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1559 for ONNX tensor: 1559
[03/01/2023-10:40:52] [V] [TRT] Relu_1448 [Relu] outputs: [1559 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1449 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1449 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1449 [Constant] outputs: [1560 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1450 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1450 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1450 [Constant] outputs: [1561 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: QuantizeLinear_1451 [QuantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1559
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1560
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1561
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1451 [QuantizeLinear] inputs: [1559 -> (1, 128, 8, 8)[FLOAT]], [1560 -> ()[FLOAT]], [1561 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1560 for ONNX node: 1560
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1561 for ONNX node: 1561
[03/01/2023-10:40:52] [V] [TRT] Registering tensor: 1562 for ONNX tensor: 1562
[03/01/2023-10:40:52] [V] [TRT] QuantizeLinear_1451 [QuantizeLinear] outputs: [1562 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1452 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1452 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1452 [Constant] outputs: [1563 -> ()[FLOAT]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: Constant_1453 [Constant]
[03/01/2023-10:40:52] [V] [TRT] Constant_1453 [Constant] inputs: 
[03/01/2023-10:40:52] [V] [TRT] Constant_1453 [Constant] outputs: [1564 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Parsing node: DequantizeLinear_1454 [DequantizeLinear]
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1562
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1563
[03/01/2023-10:40:52] [V] [TRT] Searching for input: 1564
[03/01/2023-10:40:52] [V] [TRT] DequantizeLinear_1454 [DequantizeLinear] inputs: [1562 -> (1, 128, 8, 8)[FLOAT]], [1563 -> ()[FLOAT]], [1564 -> ()[INT8]], 
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1563 for ONNX node: 1563
[03/01/2023-10:40:52] [V] [TRT] Registering layer: 1564 for ONNX node: 1564
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1565 for ONNX tensor: 1565
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1454 [DequantizeLinear] outputs: [1565 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1455 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1455 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1455 [Constant] outputs: [1566 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1456 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1456 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1456 [Constant] outputs: [1567 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1457 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1566
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1567
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1457 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [1566 -> ()[FLOAT]], [1567 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1566 for ONNX node: 1566
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1567 for ONNX node: 1567
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1568 for ONNX tensor: 1568
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1457 [QuantizeLinear] outputs: [1568 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1458 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1458 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1458 [Constant] outputs: [1569 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1459 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1459 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1459 [Constant] outputs: [1570 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1460 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1568
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1569
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1570
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1460 [DequantizeLinear] inputs: [1568 -> (128, 128, 3, 3)[FLOAT]], [1569 -> ()[FLOAT]], [1570 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1569 for ONNX node: 1569
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1570 for ONNX node: 1570
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1571 for ONNX tensor: 1571
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1460 [DequantizeLinear] outputs: [1571 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Conv_1461 [Conv]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1565
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1571
[03/01/2023-10:40:53] [V] [TRT] Conv_1461 [Conv] inputs: [1565 -> (1, 128, 8, 8)[FLOAT]], [1571 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Conv_1461 for ONNX node: Conv_1461
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1572 for ONNX tensor: 1572
[03/01/2023-10:40:53] [V] [TRT] Conv_1461 [Conv] outputs: [1572 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: BatchNormalization_1462 [BatchNormalization]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1572
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:53] [V] [TRT] BatchNormalization_1462 [BatchNormalization] inputs: [1572 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: BatchNormalization_1462 for ONNX node: BatchNormalization_1462
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1573 for ONNX tensor: 1573
[03/01/2023-10:40:53] [V] [TRT] BatchNormalization_1462 [BatchNormalization] outputs: [1573 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Relu_1463 [Relu]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1573
[03/01/2023-10:40:53] [V] [TRT] Relu_1463 [Relu] inputs: [1573 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Relu_1463 for ONNX node: Relu_1463
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1574 for ONNX tensor: 1574
[03/01/2023-10:40:53] [V] [TRT] Relu_1463 [Relu] outputs: [1574 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: MaxPool_1464 [MaxPool]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1574
[03/01/2023-10:40:53] [V] [TRT] MaxPool_1464 [MaxPool] inputs: [1574 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: MaxPool_1464 for ONNX node: MaxPool_1464
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1575 for ONNX tensor: 1575
[03/01/2023-10:40:53] [V] [TRT] MaxPool_1464 [MaxPool] outputs: [1575 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: ReduceMean_1465 [ReduceMean]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1575
[03/01/2023-10:40:53] [V] [TRT] ReduceMean_1465 [ReduceMean] inputs: [1575 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: ReduceMean_1465 for ONNX node: ReduceMean_1465
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1576 for ONNX tensor: 1576
[03/01/2023-10:40:53] [V] [TRT] ReduceMean_1465 [ReduceMean] outputs: [1576 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: ReduceMax_1466 [ReduceMax]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1575
[03/01/2023-10:40:53] [V] [TRT] ReduceMax_1466 [ReduceMax] inputs: [1575 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: ReduceMax_1466 for ONNX node: ReduceMax_1466
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1577 for ONNX tensor: 1577
[03/01/2023-10:40:53] [V] [TRT] ReduceMax_1466 [ReduceMax] outputs: [1577 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Concat_1467 [Concat]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1576
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1577
[03/01/2023-10:40:53] [V] [TRT] Concat_1467 [Concat] inputs: [1576 -> (1, 1, 3, 3)[FLOAT]], [1577 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Concat_1467 for ONNX node: Concat_1467
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1578 for ONNX tensor: 1578
[03/01/2023-10:40:53] [V] [TRT] Concat_1467 [Concat] outputs: [1578 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1468 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1468 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1468 [Constant] outputs: [1579 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1469 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1469 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1469 [Constant] outputs: [1580 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1470 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1578
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1579
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1580
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1470 [QuantizeLinear] inputs: [1578 -> (1, 2, 3, 3)[FLOAT]], [1579 -> ()[FLOAT]], [1580 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1579 for ONNX node: 1579
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1580 for ONNX node: 1580
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1581 for ONNX tensor: 1581
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1470 [QuantizeLinear] outputs: [1581 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1471 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1471 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1471 [Constant] outputs: [1582 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1472 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1472 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1472 [Constant] outputs: [1583 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1473 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1581
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1582
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1583
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1473 [DequantizeLinear] inputs: [1581 -> (1, 2, 3, 3)[FLOAT]], [1582 -> ()[FLOAT]], [1583 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1582 for ONNX node: 1582
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1583 for ONNX node: 1583
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1584 for ONNX tensor: 1584
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1473 [DequantizeLinear] outputs: [1584 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1474 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1474 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1474 [Constant] outputs: [1585 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1475 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1475 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1475 [Constant] outputs: [1586 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1476 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1585
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1586
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1476 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [1585 -> ()[FLOAT]], [1586 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1585 for ONNX node: 1585
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1586 for ONNX node: 1586
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1587 for ONNX tensor: 1587
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1476 [QuantizeLinear] outputs: [1587 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1477 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1477 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1477 [Constant] outputs: [1588 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1478 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1478 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1478 [Constant] outputs: [1589 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1479 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1587
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1588
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1589
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1479 [DequantizeLinear] inputs: [1587 -> (1, 2, 7, 7)[FLOAT]], [1588 -> ()[FLOAT]], [1589 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1588 for ONNX node: 1588
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1589 for ONNX node: 1589
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1590 for ONNX tensor: 1590
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1479 [DequantizeLinear] outputs: [1590 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Conv_1480 [Conv]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1584
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1590
[03/01/2023-10:40:53] [V] [TRT] Conv_1480 [Conv] inputs: [1584 -> (1, 2, 3, 3)[FLOAT]], [1590 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Conv_1480 for ONNX node: Conv_1480
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1591 for ONNX tensor: 1591
[03/01/2023-10:40:53] [V] [TRT] Conv_1480 [Conv] outputs: [1591 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Sigmoid_1481 [Sigmoid]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1591
[03/01/2023-10:40:53] [V] [TRT] Sigmoid_1481 [Sigmoid] inputs: [1591 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Sigmoid_1481 for ONNX node: Sigmoid_1481
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1592 for ONNX tensor: 1592
[03/01/2023-10:40:53] [V] [TRT] Sigmoid_1481 [Sigmoid] outputs: [1592 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Mul_1482 [Mul]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1575
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1592
[03/01/2023-10:40:53] [V] [TRT] Mul_1482 [Mul] inputs: [1575 -> (1, 128, 3, 3)[FLOAT]], [1592 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Mul_1482 for ONNX node: Mul_1482
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1593 for ONNX tensor: 1593
[03/01/2023-10:40:53] [V] [TRT] Mul_1482 [Mul] outputs: [1593 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: GlobalAveragePool_1483 [GlobalAveragePool]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1593
[03/01/2023-10:40:53] [V] [TRT] GlobalAveragePool_1483 [GlobalAveragePool] inputs: [1593 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:53] [V] [TRT] Registering layer: GlobalAveragePool_1483 for ONNX node: GlobalAveragePool_1483
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1594 for ONNX tensor: 1594
[03/01/2023-10:40:53] [V] [TRT] GlobalAveragePool_1483 [GlobalAveragePool] outputs: [1594 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1484 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1484 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1484 [Constant] outputs: [1595 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1485 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1485 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1485 [Constant] outputs: [1596 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1486 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1594
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1595
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1596
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1486 [QuantizeLinear] inputs: [1594 -> (1, 128, 1, 1)[FLOAT]], [1595 -> ()[FLOAT]], [1596 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1595 for ONNX node: 1595
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1596 for ONNX node: 1596
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1597 for ONNX tensor: 1597
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1486 [QuantizeLinear] outputs: [1597 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1487 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1487 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1487 [Constant] outputs: [1598 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1488 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1488 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1488 [Constant] outputs: [1599 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1489 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1597
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1598
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1599
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1489 [DequantizeLinear] inputs: [1597 -> (1, 128, 1, 1)[FLOAT]], [1598 -> ()[FLOAT]], [1599 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1598 for ONNX node: 1598
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1599 for ONNX node: 1599
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1600 for ONNX tensor: 1600
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1489 [DequantizeLinear] outputs: [1600 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1490 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1490 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1490 [Constant] outputs: [1601 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1491 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1491 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1491 [Constant] outputs: [1602 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1492 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1601
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1602
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1492 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1601 -> ()[FLOAT]], [1602 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1601 for ONNX node: 1601
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1602 for ONNX node: 1602
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1603 for ONNX tensor: 1603
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1492 [QuantizeLinear] outputs: [1603 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1493 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1493 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1493 [Constant] outputs: [1604 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1494 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1494 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1494 [Constant] outputs: [1605 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1495 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1603
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1604
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1605
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1495 [DequantizeLinear] inputs: [1603 -> (8, 128, 1, 1)[FLOAT]], [1604 -> ()[FLOAT]], [1605 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1604 for ONNX node: 1604
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1605 for ONNX node: 1605
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1606 for ONNX tensor: 1606
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1495 [DequantizeLinear] outputs: [1606 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Conv_1496 [Conv]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1600
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1606
[03/01/2023-10:40:53] [V] [TRT] Conv_1496 [Conv] inputs: [1600 -> (1, 128, 1, 1)[FLOAT]], [1606 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Conv_1496 for ONNX node: Conv_1496
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1607 for ONNX tensor: 1607
[03/01/2023-10:40:53] [V] [TRT] Conv_1496 [Conv] outputs: [1607 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Relu_1497 [Relu]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1607
[03/01/2023-10:40:53] [V] [TRT] Relu_1497 [Relu] inputs: [1607 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Relu_1497 for ONNX node: Relu_1497
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1608 for ONNX tensor: 1608
[03/01/2023-10:40:53] [V] [TRT] Relu_1497 [Relu] outputs: [1608 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1498 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1498 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1498 [Constant] outputs: [1609 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1499 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1499 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1499 [Constant] outputs: [1610 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1500 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1608
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1609
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1610
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1500 [QuantizeLinear] inputs: [1608 -> (1, 8, 1, 1)[FLOAT]], [1609 -> ()[FLOAT]], [1610 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1609 for ONNX node: 1609
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1610 for ONNX node: 1610
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1611 for ONNX tensor: 1611
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1500 [QuantizeLinear] outputs: [1611 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1501 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1501 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1501 [Constant] outputs: [1612 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1502 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1502 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1502 [Constant] outputs: [1613 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1503 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1611
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1612
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1613
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1503 [DequantizeLinear] inputs: [1611 -> (1, 8, 1, 1)[FLOAT]], [1612 -> ()[FLOAT]], [1613 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1612 for ONNX node: 1612
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1613 for ONNX node: 1613
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1614 for ONNX tensor: 1614
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1503 [DequantizeLinear] outputs: [1614 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1504 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1504 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1504 [Constant] outputs: [1615 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1505 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1505 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1505 [Constant] outputs: [1616 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1506 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1615
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1616
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1506 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1615 -> ()[FLOAT]], [1616 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1615 for ONNX node: 1615
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1616 for ONNX node: 1616
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1617 for ONNX tensor: 1617
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1506 [QuantizeLinear] outputs: [1617 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1507 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1507 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1507 [Constant] outputs: [1618 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1508 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1508 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1508 [Constant] outputs: [1619 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1509 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1617
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1618
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1619
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1509 [DequantizeLinear] inputs: [1617 -> (128, 8, 1, 1)[FLOAT]], [1618 -> ()[FLOAT]], [1619 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1618 for ONNX node: 1618
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1619 for ONNX node: 1619
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1620 for ONNX tensor: 1620
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1509 [DequantizeLinear] outputs: [1620 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Conv_1510 [Conv]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1614
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1620
[03/01/2023-10:40:53] [V] [TRT] Conv_1510 [Conv] inputs: [1614 -> (1, 8, 1, 1)[FLOAT]], [1620 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Conv_1510 for ONNX node: Conv_1510
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1621 for ONNX tensor: 1621
[03/01/2023-10:40:53] [V] [TRT] Conv_1510 [Conv] outputs: [1621 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: MaxPool_1511 [MaxPool]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1593
[03/01/2023-10:40:53] [V] [TRT] MaxPool_1511 [MaxPool] inputs: [1593 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: MaxPool_1511 for ONNX node: MaxPool_1511
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1622 for ONNX tensor: 1622
[03/01/2023-10:40:53] [V] [TRT] MaxPool_1511 [MaxPool] outputs: [1622 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1512 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1512 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1512 [Constant] outputs: [1623 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1513 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1513 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1513 [Constant] outputs: [1624 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1514 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1622
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1623
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1624
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1514 [QuantizeLinear] inputs: [1622 -> (1, 128, 1, 1)[FLOAT]], [1623 -> ()[FLOAT]], [1624 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1623 for ONNX node: 1623
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1624 for ONNX node: 1624
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1625 for ONNX tensor: 1625
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1514 [QuantizeLinear] outputs: [1625 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1515 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1515 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1515 [Constant] outputs: [1626 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1516 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1516 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1516 [Constant] outputs: [1627 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1517 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1625
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1626
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1627
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1517 [DequantizeLinear] inputs: [1625 -> (1, 128, 1, 1)[FLOAT]], [1626 -> ()[FLOAT]], [1627 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1626 for ONNX node: 1626
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1627 for ONNX node: 1627
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1628 for ONNX tensor: 1628
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1517 [DequantizeLinear] outputs: [1628 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1518 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1518 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1518 [Constant] outputs: [1629 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1519 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1519 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1519 [Constant] outputs: [1630 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1520 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1629
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1630
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1520 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1629 -> ()[FLOAT]], [1630 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1629 for ONNX node: 1629
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1630 for ONNX node: 1630
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1631 for ONNX tensor: 1631
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1520 [QuantizeLinear] outputs: [1631 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1521 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1521 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1521 [Constant] outputs: [1632 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1522 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1522 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1522 [Constant] outputs: [1633 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1523 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1631
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1632
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1633
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1523 [DequantizeLinear] inputs: [1631 -> (8, 128, 1, 1)[FLOAT]], [1632 -> ()[FLOAT]], [1633 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1632 for ONNX node: 1632
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1633 for ONNX node: 1633
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1634 for ONNX tensor: 1634
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1523 [DequantizeLinear] outputs: [1634 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Conv_1524 [Conv]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1628
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1634
[03/01/2023-10:40:53] [V] [TRT] Conv_1524 [Conv] inputs: [1628 -> (1, 128, 1, 1)[FLOAT]], [1634 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Conv_1524 for ONNX node: Conv_1524
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1635 for ONNX tensor: 1635
[03/01/2023-10:40:53] [V] [TRT] Conv_1524 [Conv] outputs: [1635 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Relu_1525 [Relu]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1635
[03/01/2023-10:40:53] [V] [TRT] Relu_1525 [Relu] inputs: [1635 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Relu_1525 for ONNX node: Relu_1525
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1636 for ONNX tensor: 1636
[03/01/2023-10:40:53] [V] [TRT] Relu_1525 [Relu] outputs: [1636 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1526 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1526 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1526 [Constant] outputs: [1637 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1527 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1527 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1527 [Constant] outputs: [1638 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1528 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1636
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1637
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1638
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1528 [QuantizeLinear] inputs: [1636 -> (1, 8, 1, 1)[FLOAT]], [1637 -> ()[FLOAT]], [1638 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1637 for ONNX node: 1637
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1638 for ONNX node: 1638
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1639 for ONNX tensor: 1639
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1528 [QuantizeLinear] outputs: [1639 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1529 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1529 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1529 [Constant] outputs: [1640 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1530 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1530 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1530 [Constant] outputs: [1641 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1531 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1639
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1640
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1641
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1531 [DequantizeLinear] inputs: [1639 -> (1, 8, 1, 1)[FLOAT]], [1640 -> ()[FLOAT]], [1641 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1640 for ONNX node: 1640
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1641 for ONNX node: 1641
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1642 for ONNX tensor: 1642
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1531 [DequantizeLinear] outputs: [1642 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1532 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1532 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1532 [Constant] outputs: [1643 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1533 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1533 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1533 [Constant] outputs: [1644 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1534 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1643
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1644
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1534 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1643 -> ()[FLOAT]], [1644 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1643 for ONNX node: 1643
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1644 for ONNX node: 1644
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1645 for ONNX tensor: 1645
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1534 [QuantizeLinear] outputs: [1645 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1535 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1535 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1535 [Constant] outputs: [1646 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1536 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1536 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1536 [Constant] outputs: [1647 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1537 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1645
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1646
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1647
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1537 [DequantizeLinear] inputs: [1645 -> (128, 8, 1, 1)[FLOAT]], [1646 -> ()[FLOAT]], [1647 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1646 for ONNX node: 1646
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1647 for ONNX node: 1647
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1648 for ONNX tensor: 1648
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1537 [DequantizeLinear] outputs: [1648 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Conv_1538 [Conv]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1642
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1648
[03/01/2023-10:40:53] [V] [TRT] Conv_1538 [Conv] inputs: [1642 -> (1, 8, 1, 1)[FLOAT]], [1648 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Conv_1538 for ONNX node: Conv_1538
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1649 for ONNX tensor: 1649
[03/01/2023-10:40:53] [V] [TRT] Conv_1538 [Conv] outputs: [1649 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Add_1539 [Add]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1621
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1649
[03/01/2023-10:40:53] [V] [TRT] Add_1539 [Add] inputs: [1621 -> (1, 128, 1, 1)[FLOAT]], [1649 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Add_1539 for ONNX node: Add_1539
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1650 for ONNX tensor: 1650
[03/01/2023-10:40:53] [V] [TRT] Add_1539 [Add] outputs: [1650 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Sigmoid_1540 [Sigmoid]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1650
[03/01/2023-10:40:53] [V] [TRT] Sigmoid_1540 [Sigmoid] inputs: [1650 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Sigmoid_1540 for ONNX node: Sigmoid_1540
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1651 for ONNX tensor: 1651
[03/01/2023-10:40:53] [V] [TRT] Sigmoid_1540 [Sigmoid] outputs: [1651 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Mul_1541 [Mul]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1593
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1651
[03/01/2023-10:40:53] [V] [TRT] Mul_1541 [Mul] inputs: [1593 -> (1, 128, 3, 3)[FLOAT]], [1651 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Mul_1541 for ONNX node: Mul_1541
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1652 for ONNX tensor: 1652
[03/01/2023-10:40:53] [V] [TRT] Mul_1541 [Mul] outputs: [1652 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Concat_1542 [Concat]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1503
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1652
[03/01/2023-10:40:53] [V] [TRT] Concat_1542 [Concat] inputs: [1503 -> (1, 1024, 3, 3)[FLOAT]], [1652 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Concat_1542 for ONNX node: Concat_1542
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1653 for ONNX tensor: 1653
[03/01/2023-10:40:53] [V] [TRT] Concat_1542 [Concat] outputs: [1653 -> (1, 1152, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1543 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1543 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1543 [Constant] outputs: [1654 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1544 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1544 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1544 [Constant] outputs: [1655 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1545 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1545 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1545 [Constant] outputs: [1656 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1546 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1546 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1546 [Constant] outputs: [1657 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Slice_1547 [Slice]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: input
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1655
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1656
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1654
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1657
[03/01/2023-10:40:53] [V] [TRT] Slice_1547 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [1655 -> (1)[INT32]], [1656 -> (1)[INT32]], [1654 -> (1)[INT32]], [1657 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Slice_1547 for ONNX node: Slice_1547
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1658 for ONNX tensor: 1658
[03/01/2023-10:40:53] [V] [TRT] Slice_1547 [Slice] outputs: [1658 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1548 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1548 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1548 [Constant] outputs: [1659 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1549 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1549 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1549 [Constant] outputs: [1660 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1550 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1550 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1550 [Constant] outputs: [1661 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1551 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1551 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1551 [Constant] outputs: [1662 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Slice_1552 [Slice]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1658
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1660
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1661
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1659
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1662
[03/01/2023-10:40:53] [V] [TRT] Slice_1552 [Slice] inputs: [1658 -> (1, 1, 24, 60)[FLOAT]], [1660 -> (1)[INT32]], [1661 -> (1)[INT32]], [1659 -> (1)[INT32]], [1662 -> (1)[INT32]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Slice_1552 for ONNX node: Slice_1552
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1663 for ONNX tensor: 1663
[03/01/2023-10:40:53] [V] [TRT] Slice_1552 [Slice] outputs: [1663 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1553 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1553 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1553 [Constant] outputs: [1664 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1554 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1554 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1554 [Constant] outputs: [1665 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1555 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1663
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1664
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1665
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1555 [QuantizeLinear] inputs: [1663 -> (1, 1, 24, 24)[FLOAT]], [1664 -> ()[FLOAT]], [1665 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1664 for ONNX node: 1664
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1665 for ONNX node: 1665
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1666 for ONNX tensor: 1666
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1555 [QuantizeLinear] outputs: [1666 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1556 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1556 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1556 [Constant] outputs: [1667 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1557 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1557 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1557 [Constant] outputs: [1668 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1558 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1666
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1667
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1668
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1558 [DequantizeLinear] inputs: [1666 -> (1, 1, 24, 24)[FLOAT]], [1667 -> ()[FLOAT]], [1668 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1667 for ONNX node: 1667
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1668 for ONNX node: 1668
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1669 for ONNX tensor: 1669
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1558 [DequantizeLinear] outputs: [1669 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1559 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1559 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1559 [Constant] outputs: [1670 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1560 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1560 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1560 [Constant] outputs: [1671 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1561 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1670
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1671
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1561 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [1670 -> ()[FLOAT]], [1671 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1670 for ONNX node: 1670
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1671 for ONNX node: 1671
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1672 for ONNX tensor: 1672
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1561 [QuantizeLinear] outputs: [1672 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1562 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1562 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1562 [Constant] outputs: [1673 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1563 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1563 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1563 [Constant] outputs: [1674 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1564 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1672
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1673
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1674
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1564 [DequantizeLinear] inputs: [1672 -> (64, 1, 3, 3)[FLOAT]], [1673 -> ()[FLOAT]], [1674 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1673 for ONNX node: 1673
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1674 for ONNX node: 1674
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1675 for ONNX tensor: 1675
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1564 [DequantizeLinear] outputs: [1675 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Conv_1565 [Conv]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1669
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1675
[03/01/2023-10:40:53] [V] [TRT] Conv_1565 [Conv] inputs: [1669 -> (1, 1, 24, 24)[FLOAT]], [1675 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Conv_1565 for ONNX node: Conv_1565
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1676 for ONNX tensor: 1676
[03/01/2023-10:40:53] [V] [TRT] Conv_1565 [Conv] outputs: [1676 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: BatchNormalization_1566 [BatchNormalization]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1676
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:53] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:53] [V] [TRT] BatchNormalization_1566 [BatchNormalization] inputs: [1676 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: BatchNormalization_1566 for ONNX node: BatchNormalization_1566
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1677 for ONNX tensor: 1677
[03/01/2023-10:40:53] [V] [TRT] BatchNormalization_1566 [BatchNormalization] outputs: [1677 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Relu_1567 [Relu]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1677
[03/01/2023-10:40:53] [V] [TRT] Relu_1567 [Relu] inputs: [1677 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: Relu_1567 for ONNX node: Relu_1567
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1678 for ONNX tensor: 1678
[03/01/2023-10:40:53] [V] [TRT] Relu_1567 [Relu] outputs: [1678 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1568 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1568 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1568 [Constant] outputs: [1679 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1569 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1569 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1569 [Constant] outputs: [1680 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: QuantizeLinear_1570 [QuantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1678
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1679
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1680
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1570 [QuantizeLinear] inputs: [1678 -> (1, 64, 22, 22)[FLOAT]], [1679 -> ()[FLOAT]], [1680 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1679 for ONNX node: 1679
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1680 for ONNX node: 1680
[03/01/2023-10:40:53] [V] [TRT] Registering tensor: 1681 for ONNX tensor: 1681
[03/01/2023-10:40:53] [V] [TRT] QuantizeLinear_1570 [QuantizeLinear] outputs: [1681 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1571 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1571 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1571 [Constant] outputs: [1682 -> ()[FLOAT]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: Constant_1572 [Constant]
[03/01/2023-10:40:53] [V] [TRT] Constant_1572 [Constant] inputs: 
[03/01/2023-10:40:53] [V] [TRT] Constant_1572 [Constant] outputs: [1683 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Parsing node: DequantizeLinear_1573 [DequantizeLinear]
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1681
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1682
[03/01/2023-10:40:53] [V] [TRT] Searching for input: 1683
[03/01/2023-10:40:53] [V] [TRT] DequantizeLinear_1573 [DequantizeLinear] inputs: [1681 -> (1, 64, 22, 22)[FLOAT]], [1682 -> ()[FLOAT]], [1683 -> ()[INT8]], 
[03/01/2023-10:40:53] [V] [TRT] Registering layer: 1682 for ONNX node: 1682
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1683 for ONNX node: 1683
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1684 for ONNX tensor: 1684
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1573 [DequantizeLinear] outputs: [1684 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1574 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1574 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1574 [Constant] outputs: [1685 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1575 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1575 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1575 [Constant] outputs: [1686 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1576 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1685
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1686
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1576 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [1685 -> ()[FLOAT]], [1686 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1685 for ONNX node: 1685
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1686 for ONNX node: 1686
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1687 for ONNX tensor: 1687
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1576 [QuantizeLinear] outputs: [1687 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1577 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1577 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1577 [Constant] outputs: [1688 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1578 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1578 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1578 [Constant] outputs: [1689 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1579 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1687
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1688
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1689
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1579 [DequantizeLinear] inputs: [1687 -> (64, 64, 3, 3)[FLOAT]], [1688 -> ()[FLOAT]], [1689 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1688 for ONNX node: 1688
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1689 for ONNX node: 1689
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1690 for ONNX tensor: 1690
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1579 [DequantizeLinear] outputs: [1690 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Conv_1580 [Conv]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1684
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1690
[03/01/2023-10:40:54] [V] [TRT] Conv_1580 [Conv] inputs: [1684 -> (1, 64, 22, 22)[FLOAT]], [1690 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Conv_1580 for ONNX node: Conv_1580
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1691 for ONNX tensor: 1691
[03/01/2023-10:40:54] [V] [TRT] Conv_1580 [Conv] outputs: [1691 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: BatchNormalization_1581 [BatchNormalization]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1691
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:54] [V] [TRT] BatchNormalization_1581 [BatchNormalization] inputs: [1691 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: BatchNormalization_1581 for ONNX node: BatchNormalization_1581
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1692 for ONNX tensor: 1692
[03/01/2023-10:40:54] [V] [TRT] BatchNormalization_1581 [BatchNormalization] outputs: [1692 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Relu_1582 [Relu]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1692
[03/01/2023-10:40:54] [V] [TRT] Relu_1582 [Relu] inputs: [1692 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Relu_1582 for ONNX node: Relu_1582
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1693 for ONNX tensor: 1693
[03/01/2023-10:40:54] [V] [TRT] Relu_1582 [Relu] outputs: [1693 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: MaxPool_1583 [MaxPool]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1693
[03/01/2023-10:40:54] [V] [TRT] MaxPool_1583 [MaxPool] inputs: [1693 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: MaxPool_1583 for ONNX node: MaxPool_1583
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1694 for ONNX tensor: 1694
[03/01/2023-10:40:54] [V] [TRT] MaxPool_1583 [MaxPool] outputs: [1694 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1584 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1584 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1584 [Constant] outputs: [1695 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1585 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1585 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1585 [Constant] outputs: [1696 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1586 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1694
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1695
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1696
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1586 [QuantizeLinear] inputs: [1694 -> (1, 64, 10, 10)[FLOAT]], [1695 -> ()[FLOAT]], [1696 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1695 for ONNX node: 1695
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1696 for ONNX node: 1696
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1697 for ONNX tensor: 1697
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1586 [QuantizeLinear] outputs: [1697 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1587 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1587 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1587 [Constant] outputs: [1698 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1588 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1588 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1588 [Constant] outputs: [1699 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1589 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1697
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1698
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1699
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1589 [DequantizeLinear] inputs: [1697 -> (1, 64, 10, 10)[FLOAT]], [1698 -> ()[FLOAT]], [1699 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1698 for ONNX node: 1698
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1699 for ONNX node: 1699
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1700 for ONNX tensor: 1700
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1589 [DequantizeLinear] outputs: [1700 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1590 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1590 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1590 [Constant] outputs: [1701 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1591 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1591 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1591 [Constant] outputs: [1702 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1592 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1701
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1702
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1592 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [1701 -> ()[FLOAT]], [1702 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1701 for ONNX node: 1701
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1702 for ONNX node: 1702
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1703 for ONNX tensor: 1703
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1592 [QuantizeLinear] outputs: [1703 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1593 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1593 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1593 [Constant] outputs: [1704 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1594 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1594 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1594 [Constant] outputs: [1705 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1595 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1703
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1704
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1705
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1595 [DequantizeLinear] inputs: [1703 -> (128, 64, 3, 3)[FLOAT]], [1704 -> ()[FLOAT]], [1705 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1704 for ONNX node: 1704
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1705 for ONNX node: 1705
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1706 for ONNX tensor: 1706
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1595 [DequantizeLinear] outputs: [1706 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Conv_1596 [Conv]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1700
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1706
[03/01/2023-10:40:54] [V] [TRT] Conv_1596 [Conv] inputs: [1700 -> (1, 64, 10, 10)[FLOAT]], [1706 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Conv_1596 for ONNX node: Conv_1596
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1707 for ONNX tensor: 1707
[03/01/2023-10:40:54] [V] [TRT] Conv_1596 [Conv] outputs: [1707 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: BatchNormalization_1597 [BatchNormalization]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1707
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:54] [V] [TRT] BatchNormalization_1597 [BatchNormalization] inputs: [1707 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: BatchNormalization_1597 for ONNX node: BatchNormalization_1597
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1708 for ONNX tensor: 1708
[03/01/2023-10:40:54] [V] [TRT] BatchNormalization_1597 [BatchNormalization] outputs: [1708 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Relu_1598 [Relu]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1708
[03/01/2023-10:40:54] [V] [TRT] Relu_1598 [Relu] inputs: [1708 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Relu_1598 for ONNX node: Relu_1598
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1709 for ONNX tensor: 1709
[03/01/2023-10:40:54] [V] [TRT] Relu_1598 [Relu] outputs: [1709 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1599 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1599 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1599 [Constant] outputs: [1710 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1600 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1600 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1600 [Constant] outputs: [1711 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1601 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1709
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1710
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1711
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1601 [QuantizeLinear] inputs: [1709 -> (1, 128, 8, 8)[FLOAT]], [1710 -> ()[FLOAT]], [1711 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1710 for ONNX node: 1710
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1711 for ONNX node: 1711
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1712 for ONNX tensor: 1712
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1601 [QuantizeLinear] outputs: [1712 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1602 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1602 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1602 [Constant] outputs: [1713 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1603 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1603 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1603 [Constant] outputs: [1714 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1604 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1712
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1713
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1714
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1604 [DequantizeLinear] inputs: [1712 -> (1, 128, 8, 8)[FLOAT]], [1713 -> ()[FLOAT]], [1714 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1713 for ONNX node: 1713
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1714 for ONNX node: 1714
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1715 for ONNX tensor: 1715
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1604 [DequantizeLinear] outputs: [1715 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1605 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1605 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1605 [Constant] outputs: [1716 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1606 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1606 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1606 [Constant] outputs: [1717 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1607 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1716
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1717
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1607 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [1716 -> ()[FLOAT]], [1717 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1716 for ONNX node: 1716
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1717 for ONNX node: 1717
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1718 for ONNX tensor: 1718
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1607 [QuantizeLinear] outputs: [1718 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1608 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1608 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1608 [Constant] outputs: [1719 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1609 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1609 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1609 [Constant] outputs: [1720 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1610 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1718
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1719
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1720
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1610 [DequantizeLinear] inputs: [1718 -> (128, 128, 3, 3)[FLOAT]], [1719 -> ()[FLOAT]], [1720 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1719 for ONNX node: 1719
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1720 for ONNX node: 1720
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1721 for ONNX tensor: 1721
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1610 [DequantizeLinear] outputs: [1721 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Conv_1611 [Conv]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1715
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1721
[03/01/2023-10:40:54] [V] [TRT] Conv_1611 [Conv] inputs: [1715 -> (1, 128, 8, 8)[FLOAT]], [1721 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Conv_1611 for ONNX node: Conv_1611
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1722 for ONNX tensor: 1722
[03/01/2023-10:40:54] [V] [TRT] Conv_1611 [Conv] outputs: [1722 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: BatchNormalization_1612 [BatchNormalization]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1722
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:54] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:54] [V] [TRT] BatchNormalization_1612 [BatchNormalization] inputs: [1722 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: BatchNormalization_1612 for ONNX node: BatchNormalization_1612
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1723 for ONNX tensor: 1723
[03/01/2023-10:40:54] [V] [TRT] BatchNormalization_1612 [BatchNormalization] outputs: [1723 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Relu_1613 [Relu]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1723
[03/01/2023-10:40:54] [V] [TRT] Relu_1613 [Relu] inputs: [1723 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Relu_1613 for ONNX node: Relu_1613
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1724 for ONNX tensor: 1724
[03/01/2023-10:40:54] [V] [TRT] Relu_1613 [Relu] outputs: [1724 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: MaxPool_1614 [MaxPool]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1724
[03/01/2023-10:40:54] [V] [TRT] MaxPool_1614 [MaxPool] inputs: [1724 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: MaxPool_1614 for ONNX node: MaxPool_1614
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1725 for ONNX tensor: 1725
[03/01/2023-10:40:54] [V] [TRT] MaxPool_1614 [MaxPool] outputs: [1725 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: ReduceMean_1615 [ReduceMean]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1725
[03/01/2023-10:40:54] [V] [TRT] ReduceMean_1615 [ReduceMean] inputs: [1725 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: ReduceMean_1615 for ONNX node: ReduceMean_1615
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1726 for ONNX tensor: 1726
[03/01/2023-10:40:54] [V] [TRT] ReduceMean_1615 [ReduceMean] outputs: [1726 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: ReduceMax_1616 [ReduceMax]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1725
[03/01/2023-10:40:54] [V] [TRT] ReduceMax_1616 [ReduceMax] inputs: [1725 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: ReduceMax_1616 for ONNX node: ReduceMax_1616
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1727 for ONNX tensor: 1727
[03/01/2023-10:40:54] [V] [TRT] ReduceMax_1616 [ReduceMax] outputs: [1727 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Concat_1617 [Concat]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1726
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1727
[03/01/2023-10:40:54] [V] [TRT] Concat_1617 [Concat] inputs: [1726 -> (1, 1, 3, 3)[FLOAT]], [1727 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Concat_1617 for ONNX node: Concat_1617
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1728 for ONNX tensor: 1728
[03/01/2023-10:40:54] [V] [TRT] Concat_1617 [Concat] outputs: [1728 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1618 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1618 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1618 [Constant] outputs: [1729 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1619 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1619 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1619 [Constant] outputs: [1730 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1620 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1728
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1729
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1730
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1620 [QuantizeLinear] inputs: [1728 -> (1, 2, 3, 3)[FLOAT]], [1729 -> ()[FLOAT]], [1730 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1729 for ONNX node: 1729
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1730 for ONNX node: 1730
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1731 for ONNX tensor: 1731
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1620 [QuantizeLinear] outputs: [1731 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1621 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1621 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1621 [Constant] outputs: [1732 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1622 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1622 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1622 [Constant] outputs: [1733 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1623 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1731
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1732
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1733
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1623 [DequantizeLinear] inputs: [1731 -> (1, 2, 3, 3)[FLOAT]], [1732 -> ()[FLOAT]], [1733 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1732 for ONNX node: 1732
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1733 for ONNX node: 1733
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1734 for ONNX tensor: 1734
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1623 [DequantizeLinear] outputs: [1734 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1624 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1624 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1624 [Constant] outputs: [1735 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1625 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1625 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1625 [Constant] outputs: [1736 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1626 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1735
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1736
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1626 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [1735 -> ()[FLOAT]], [1736 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1735 for ONNX node: 1735
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1736 for ONNX node: 1736
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1737 for ONNX tensor: 1737
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1626 [QuantizeLinear] outputs: [1737 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1627 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1627 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1627 [Constant] outputs: [1738 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1628 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1628 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1628 [Constant] outputs: [1739 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1629 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1737
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1738
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1739
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1629 [DequantizeLinear] inputs: [1737 -> (1, 2, 7, 7)[FLOAT]], [1738 -> ()[FLOAT]], [1739 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1738 for ONNX node: 1738
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1739 for ONNX node: 1739
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1740 for ONNX tensor: 1740
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1629 [DequantizeLinear] outputs: [1740 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Conv_1630 [Conv]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1734
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1740
[03/01/2023-10:40:54] [V] [TRT] Conv_1630 [Conv] inputs: [1734 -> (1, 2, 3, 3)[FLOAT]], [1740 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Conv_1630 for ONNX node: Conv_1630
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1741 for ONNX tensor: 1741
[03/01/2023-10:40:54] [V] [TRT] Conv_1630 [Conv] outputs: [1741 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Sigmoid_1631 [Sigmoid]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1741
[03/01/2023-10:40:54] [V] [TRT] Sigmoid_1631 [Sigmoid] inputs: [1741 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Sigmoid_1631 for ONNX node: Sigmoid_1631
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1742 for ONNX tensor: 1742
[03/01/2023-10:40:54] [V] [TRT] Sigmoid_1631 [Sigmoid] outputs: [1742 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Mul_1632 [Mul]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1725
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1742
[03/01/2023-10:40:54] [V] [TRT] Mul_1632 [Mul] inputs: [1725 -> (1, 128, 3, 3)[FLOAT]], [1742 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Mul_1632 for ONNX node: Mul_1632
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1743 for ONNX tensor: 1743
[03/01/2023-10:40:54] [V] [TRT] Mul_1632 [Mul] outputs: [1743 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: GlobalAveragePool_1633 [GlobalAveragePool]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1743
[03/01/2023-10:40:54] [V] [TRT] GlobalAveragePool_1633 [GlobalAveragePool] inputs: [1743 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:54] [V] [TRT] Registering layer: GlobalAveragePool_1633 for ONNX node: GlobalAveragePool_1633
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1744 for ONNX tensor: 1744
[03/01/2023-10:40:54] [V] [TRT] GlobalAveragePool_1633 [GlobalAveragePool] outputs: [1744 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1634 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1634 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1634 [Constant] outputs: [1745 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1635 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1635 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1635 [Constant] outputs: [1746 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1636 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1744
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1745
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1746
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1636 [QuantizeLinear] inputs: [1744 -> (1, 128, 1, 1)[FLOAT]], [1745 -> ()[FLOAT]], [1746 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1745 for ONNX node: 1745
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1746 for ONNX node: 1746
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1747 for ONNX tensor: 1747
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1636 [QuantizeLinear] outputs: [1747 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1637 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1637 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1637 [Constant] outputs: [1748 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1638 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1638 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1638 [Constant] outputs: [1749 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1639 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1747
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1748
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1749
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1639 [DequantizeLinear] inputs: [1747 -> (1, 128, 1, 1)[FLOAT]], [1748 -> ()[FLOAT]], [1749 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1748 for ONNX node: 1748
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1749 for ONNX node: 1749
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1750 for ONNX tensor: 1750
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1639 [DequantizeLinear] outputs: [1750 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1640 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1640 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1640 [Constant] outputs: [1751 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1641 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1641 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1641 [Constant] outputs: [1752 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1642 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1751
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1752
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1642 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1751 -> ()[FLOAT]], [1752 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1751 for ONNX node: 1751
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1752 for ONNX node: 1752
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1753 for ONNX tensor: 1753
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1642 [QuantizeLinear] outputs: [1753 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1643 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1643 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1643 [Constant] outputs: [1754 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1644 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1644 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1644 [Constant] outputs: [1755 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1645 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1753
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1754
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1755
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1645 [DequantizeLinear] inputs: [1753 -> (8, 128, 1, 1)[FLOAT]], [1754 -> ()[FLOAT]], [1755 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1754 for ONNX node: 1754
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1755 for ONNX node: 1755
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1756 for ONNX tensor: 1756
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1645 [DequantizeLinear] outputs: [1756 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Conv_1646 [Conv]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1750
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1756
[03/01/2023-10:40:54] [V] [TRT] Conv_1646 [Conv] inputs: [1750 -> (1, 128, 1, 1)[FLOAT]], [1756 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Conv_1646 for ONNX node: Conv_1646
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1757 for ONNX tensor: 1757
[03/01/2023-10:40:54] [V] [TRT] Conv_1646 [Conv] outputs: [1757 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Relu_1647 [Relu]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1757
[03/01/2023-10:40:54] [V] [TRT] Relu_1647 [Relu] inputs: [1757 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Relu_1647 for ONNX node: Relu_1647
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1758 for ONNX tensor: 1758
[03/01/2023-10:40:54] [V] [TRT] Relu_1647 [Relu] outputs: [1758 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1648 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1648 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1648 [Constant] outputs: [1759 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1649 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1649 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1649 [Constant] outputs: [1760 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1650 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1758
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1759
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1760
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1650 [QuantizeLinear] inputs: [1758 -> (1, 8, 1, 1)[FLOAT]], [1759 -> ()[FLOAT]], [1760 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1759 for ONNX node: 1759
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1760 for ONNX node: 1760
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1761 for ONNX tensor: 1761
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1650 [QuantizeLinear] outputs: [1761 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1651 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1651 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1651 [Constant] outputs: [1762 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1652 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1652 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1652 [Constant] outputs: [1763 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1653 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1761
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1762
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1763
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1653 [DequantizeLinear] inputs: [1761 -> (1, 8, 1, 1)[FLOAT]], [1762 -> ()[FLOAT]], [1763 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1762 for ONNX node: 1762
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1763 for ONNX node: 1763
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1764 for ONNX tensor: 1764
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1653 [DequantizeLinear] outputs: [1764 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1654 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1654 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1654 [Constant] outputs: [1765 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1655 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1655 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1655 [Constant] outputs: [1766 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1656 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1765
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1766
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1656 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1765 -> ()[FLOAT]], [1766 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1765 for ONNX node: 1765
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1766 for ONNX node: 1766
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1767 for ONNX tensor: 1767
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1656 [QuantizeLinear] outputs: [1767 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1657 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1657 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1657 [Constant] outputs: [1768 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1658 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1658 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1658 [Constant] outputs: [1769 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1659 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1767
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1768
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1769
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1659 [DequantizeLinear] inputs: [1767 -> (128, 8, 1, 1)[FLOAT]], [1768 -> ()[FLOAT]], [1769 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1768 for ONNX node: 1768
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1769 for ONNX node: 1769
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1770 for ONNX tensor: 1770
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1659 [DequantizeLinear] outputs: [1770 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Conv_1660 [Conv]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1764
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1770
[03/01/2023-10:40:54] [V] [TRT] Conv_1660 [Conv] inputs: [1764 -> (1, 8, 1, 1)[FLOAT]], [1770 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:54] [V] [TRT] Registering layer: Conv_1660 for ONNX node: Conv_1660
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1771 for ONNX tensor: 1771
[03/01/2023-10:40:54] [V] [TRT] Conv_1660 [Conv] outputs: [1771 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: MaxPool_1661 [MaxPool]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1743
[03/01/2023-10:40:54] [V] [TRT] MaxPool_1661 [MaxPool] inputs: [1743 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: MaxPool_1661 for ONNX node: MaxPool_1661
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1772 for ONNX tensor: 1772
[03/01/2023-10:40:54] [V] [TRT] MaxPool_1661 [MaxPool] outputs: [1772 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1662 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1662 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1662 [Constant] outputs: [1773 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1663 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1663 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1663 [Constant] outputs: [1774 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: QuantizeLinear_1664 [QuantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1772
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1773
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1774
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1664 [QuantizeLinear] inputs: [1772 -> (1, 128, 1, 1)[FLOAT]], [1773 -> ()[FLOAT]], [1774 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1773 for ONNX node: 1773
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1774 for ONNX node: 1774
[03/01/2023-10:40:54] [V] [TRT] Registering tensor: 1775 for ONNX tensor: 1775
[03/01/2023-10:40:54] [V] [TRT] QuantizeLinear_1664 [QuantizeLinear] outputs: [1775 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1665 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1665 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1665 [Constant] outputs: [1776 -> ()[FLOAT]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: Constant_1666 [Constant]
[03/01/2023-10:40:54] [V] [TRT] Constant_1666 [Constant] inputs: 
[03/01/2023-10:40:54] [V] [TRT] Constant_1666 [Constant] outputs: [1777 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Parsing node: DequantizeLinear_1667 [DequantizeLinear]
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1775
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1776
[03/01/2023-10:40:54] [V] [TRT] Searching for input: 1777
[03/01/2023-10:40:54] [V] [TRT] DequantizeLinear_1667 [DequantizeLinear] inputs: [1775 -> (1, 128, 1, 1)[FLOAT]], [1776 -> ()[FLOAT]], [1777 -> ()[INT8]], 
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1776 for ONNX node: 1776
[03/01/2023-10:40:54] [V] [TRT] Registering layer: 1777 for ONNX node: 1777
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1778 for ONNX tensor: 1778
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1667 [DequantizeLinear] outputs: [1778 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1668 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1668 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1668 [Constant] outputs: [1779 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1669 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1669 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1669 [Constant] outputs: [1780 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1670 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1779
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1780
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1670 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1779 -> ()[FLOAT]], [1780 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1779 for ONNX node: 1779
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1780 for ONNX node: 1780
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1781 for ONNX tensor: 1781
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1670 [QuantizeLinear] outputs: [1781 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1671 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1671 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1671 [Constant] outputs: [1782 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1672 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1672 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1672 [Constant] outputs: [1783 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1673 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1781
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1782
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1783
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1673 [DequantizeLinear] inputs: [1781 -> (8, 128, 1, 1)[FLOAT]], [1782 -> ()[FLOAT]], [1783 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1782 for ONNX node: 1782
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1783 for ONNX node: 1783
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1784 for ONNX tensor: 1784
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1673 [DequantizeLinear] outputs: [1784 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Conv_1674 [Conv]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1778
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1784
[03/01/2023-10:40:55] [V] [TRT] Conv_1674 [Conv] inputs: [1778 -> (1, 128, 1, 1)[FLOAT]], [1784 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Conv_1674 for ONNX node: Conv_1674
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1785 for ONNX tensor: 1785
[03/01/2023-10:40:55] [V] [TRT] Conv_1674 [Conv] outputs: [1785 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Relu_1675 [Relu]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1785
[03/01/2023-10:40:55] [V] [TRT] Relu_1675 [Relu] inputs: [1785 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Relu_1675 for ONNX node: Relu_1675
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1786 for ONNX tensor: 1786
[03/01/2023-10:40:55] [V] [TRT] Relu_1675 [Relu] outputs: [1786 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1676 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1676 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1676 [Constant] outputs: [1787 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1677 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1677 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1677 [Constant] outputs: [1788 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1678 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1786
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1787
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1788
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1678 [QuantizeLinear] inputs: [1786 -> (1, 8, 1, 1)[FLOAT]], [1787 -> ()[FLOAT]], [1788 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1787 for ONNX node: 1787
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1788 for ONNX node: 1788
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1789 for ONNX tensor: 1789
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1678 [QuantizeLinear] outputs: [1789 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1679 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1679 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1679 [Constant] outputs: [1790 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1680 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1680 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1680 [Constant] outputs: [1791 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1681 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1789
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1790
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1791
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1681 [DequantizeLinear] inputs: [1789 -> (1, 8, 1, 1)[FLOAT]], [1790 -> ()[FLOAT]], [1791 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1790 for ONNX node: 1790
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1791 for ONNX node: 1791
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1792 for ONNX tensor: 1792
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1681 [DequantizeLinear] outputs: [1792 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1682 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1682 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1682 [Constant] outputs: [1793 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1683 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1683 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1683 [Constant] outputs: [1794 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1684 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1793
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1794
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1684 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1793 -> ()[FLOAT]], [1794 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1793 for ONNX node: 1793
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1794 for ONNX node: 1794
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1795 for ONNX tensor: 1795
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1684 [QuantizeLinear] outputs: [1795 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1685 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1685 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1685 [Constant] outputs: [1796 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1686 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1686 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1686 [Constant] outputs: [1797 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1687 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1795
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1796
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1797
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1687 [DequantizeLinear] inputs: [1795 -> (128, 8, 1, 1)[FLOAT]], [1796 -> ()[FLOAT]], [1797 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1796 for ONNX node: 1796
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1797 for ONNX node: 1797
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1798 for ONNX tensor: 1798
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1687 [DequantizeLinear] outputs: [1798 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Conv_1688 [Conv]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1792
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1798
[03/01/2023-10:40:55] [V] [TRT] Conv_1688 [Conv] inputs: [1792 -> (1, 8, 1, 1)[FLOAT]], [1798 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Conv_1688 for ONNX node: Conv_1688
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1799 for ONNX tensor: 1799
[03/01/2023-10:40:55] [V] [TRT] Conv_1688 [Conv] outputs: [1799 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Add_1689 [Add]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1771
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1799
[03/01/2023-10:40:55] [V] [TRT] Add_1689 [Add] inputs: [1771 -> (1, 128, 1, 1)[FLOAT]], [1799 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Add_1689 for ONNX node: Add_1689
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1800 for ONNX tensor: 1800
[03/01/2023-10:40:55] [V] [TRT] Add_1689 [Add] outputs: [1800 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Sigmoid_1690 [Sigmoid]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1800
[03/01/2023-10:40:55] [V] [TRT] Sigmoid_1690 [Sigmoid] inputs: [1800 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Sigmoid_1690 for ONNX node: Sigmoid_1690
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1801 for ONNX tensor: 1801
[03/01/2023-10:40:55] [V] [TRT] Sigmoid_1690 [Sigmoid] outputs: [1801 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Mul_1691 [Mul]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1743
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1801
[03/01/2023-10:40:55] [V] [TRT] Mul_1691 [Mul] inputs: [1743 -> (1, 128, 3, 3)[FLOAT]], [1801 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Mul_1691 for ONNX node: Mul_1691
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1802 for ONNX tensor: 1802
[03/01/2023-10:40:55] [V] [TRT] Mul_1691 [Mul] outputs: [1802 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Concat_1692 [Concat]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1653
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1802
[03/01/2023-10:40:55] [V] [TRT] Concat_1692 [Concat] inputs: [1653 -> (1, 1152, 3, 3)[FLOAT]], [1802 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Concat_1692 for ONNX node: Concat_1692
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1803 for ONNX tensor: 1803
[03/01/2023-10:40:55] [V] [TRT] Concat_1692 [Concat] outputs: [1803 -> (1, 1280, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1693 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1693 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1693 [Constant] outputs: [1804 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1694 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1694 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1694 [Constant] outputs: [1805 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1695 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1695 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1695 [Constant] outputs: [1806 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1696 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1696 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1696 [Constant] outputs: [1807 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Slice_1697 [Slice]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: input
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1805
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1806
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1804
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1807
[03/01/2023-10:40:55] [V] [TRT] Slice_1697 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [1805 -> (1)[INT32]], [1806 -> (1)[INT32]], [1804 -> (1)[INT32]], [1807 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Slice_1697 for ONNX node: Slice_1697
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1808 for ONNX tensor: 1808
[03/01/2023-10:40:55] [V] [TRT] Slice_1697 [Slice] outputs: [1808 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1698 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1698 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1698 [Constant] outputs: [1809 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1699 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1699 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1699 [Constant] outputs: [1810 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1700 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1700 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1700 [Constant] outputs: [1811 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1701 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1701 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1701 [Constant] outputs: [1812 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Slice_1702 [Slice]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1808
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1810
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1811
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1809
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1812
[03/01/2023-10:40:55] [V] [TRT] Slice_1702 [Slice] inputs: [1808 -> (1, 1, 24, 60)[FLOAT]], [1810 -> (1)[INT32]], [1811 -> (1)[INT32]], [1809 -> (1)[INT32]], [1812 -> (1)[INT32]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Slice_1702 for ONNX node: Slice_1702
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1813 for ONNX tensor: 1813
[03/01/2023-10:40:55] [V] [TRT] Slice_1702 [Slice] outputs: [1813 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1703 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1703 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1703 [Constant] outputs: [1814 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1704 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1704 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1704 [Constant] outputs: [1815 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1705 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1813
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1814
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1815
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1705 [QuantizeLinear] inputs: [1813 -> (1, 1, 24, 24)[FLOAT]], [1814 -> ()[FLOAT]], [1815 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1814 for ONNX node: 1814
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1815 for ONNX node: 1815
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1816 for ONNX tensor: 1816
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1705 [QuantizeLinear] outputs: [1816 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1706 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1706 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1706 [Constant] outputs: [1817 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1707 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1707 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1707 [Constant] outputs: [1818 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1708 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1816
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1817
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1818
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1708 [DequantizeLinear] inputs: [1816 -> (1, 1, 24, 24)[FLOAT]], [1817 -> ()[FLOAT]], [1818 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1817 for ONNX node: 1817
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1818 for ONNX node: 1818
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1819 for ONNX tensor: 1819
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1708 [DequantizeLinear] outputs: [1819 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1709 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1709 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1709 [Constant] outputs: [1820 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1710 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1710 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1710 [Constant] outputs: [1821 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1711 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1820
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1821
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1711 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [1820 -> ()[FLOAT]], [1821 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1820 for ONNX node: 1820
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1821 for ONNX node: 1821
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1822 for ONNX tensor: 1822
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1711 [QuantizeLinear] outputs: [1822 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1712 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1712 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1712 [Constant] outputs: [1823 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1713 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1713 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1713 [Constant] outputs: [1824 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1714 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1822
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1823
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1824
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1714 [DequantizeLinear] inputs: [1822 -> (64, 1, 3, 3)[FLOAT]], [1823 -> ()[FLOAT]], [1824 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1823 for ONNX node: 1823
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1824 for ONNX node: 1824
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1825 for ONNX tensor: 1825
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1714 [DequantizeLinear] outputs: [1825 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Conv_1715 [Conv]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1819
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1825
[03/01/2023-10:40:55] [V] [TRT] Conv_1715 [Conv] inputs: [1819 -> (1, 1, 24, 24)[FLOAT]], [1825 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Conv_1715 for ONNX node: Conv_1715
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1826 for ONNX tensor: 1826
[03/01/2023-10:40:55] [V] [TRT] Conv_1715 [Conv] outputs: [1826 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: BatchNormalization_1716 [BatchNormalization]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1826
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:55] [V] [TRT] BatchNormalization_1716 [BatchNormalization] inputs: [1826 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: BatchNormalization_1716 for ONNX node: BatchNormalization_1716
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1827 for ONNX tensor: 1827
[03/01/2023-10:40:55] [V] [TRT] BatchNormalization_1716 [BatchNormalization] outputs: [1827 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Relu_1717 [Relu]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1827
[03/01/2023-10:40:55] [V] [TRT] Relu_1717 [Relu] inputs: [1827 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Relu_1717 for ONNX node: Relu_1717
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1828 for ONNX tensor: 1828
[03/01/2023-10:40:55] [V] [TRT] Relu_1717 [Relu] outputs: [1828 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1718 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1718 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1718 [Constant] outputs: [1829 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1719 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1719 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1719 [Constant] outputs: [1830 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1720 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1828
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1829
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1830
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1720 [QuantizeLinear] inputs: [1828 -> (1, 64, 22, 22)[FLOAT]], [1829 -> ()[FLOAT]], [1830 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1829 for ONNX node: 1829
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1830 for ONNX node: 1830
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1831 for ONNX tensor: 1831
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1720 [QuantizeLinear] outputs: [1831 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1721 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1721 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1721 [Constant] outputs: [1832 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1722 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1722 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1722 [Constant] outputs: [1833 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1723 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1831
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1832
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1833
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1723 [DequantizeLinear] inputs: [1831 -> (1, 64, 22, 22)[FLOAT]], [1832 -> ()[FLOAT]], [1833 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1832 for ONNX node: 1832
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1833 for ONNX node: 1833
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1834 for ONNX tensor: 1834
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1723 [DequantizeLinear] outputs: [1834 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1724 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1724 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1724 [Constant] outputs: [1835 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1725 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1725 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1725 [Constant] outputs: [1836 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1726 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1835
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1836
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1726 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [1835 -> ()[FLOAT]], [1836 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1835 for ONNX node: 1835
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1836 for ONNX node: 1836
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1837 for ONNX tensor: 1837
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1726 [QuantizeLinear] outputs: [1837 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1727 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1727 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1727 [Constant] outputs: [1838 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1728 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1728 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1728 [Constant] outputs: [1839 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1729 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1837
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1838
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1839
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1729 [DequantizeLinear] inputs: [1837 -> (64, 64, 3, 3)[FLOAT]], [1838 -> ()[FLOAT]], [1839 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1838 for ONNX node: 1838
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1839 for ONNX node: 1839
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1840 for ONNX tensor: 1840
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1729 [DequantizeLinear] outputs: [1840 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Conv_1730 [Conv]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1834
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1840
[03/01/2023-10:40:55] [V] [TRT] Conv_1730 [Conv] inputs: [1834 -> (1, 64, 22, 22)[FLOAT]], [1840 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Conv_1730 for ONNX node: Conv_1730
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1841 for ONNX tensor: 1841
[03/01/2023-10:40:55] [V] [TRT] Conv_1730 [Conv] outputs: [1841 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: BatchNormalization_1731 [BatchNormalization]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1841
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:55] [V] [TRT] BatchNormalization_1731 [BatchNormalization] inputs: [1841 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: BatchNormalization_1731 for ONNX node: BatchNormalization_1731
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1842 for ONNX tensor: 1842
[03/01/2023-10:40:55] [V] [TRT] BatchNormalization_1731 [BatchNormalization] outputs: [1842 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Relu_1732 [Relu]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1842
[03/01/2023-10:40:55] [V] [TRT] Relu_1732 [Relu] inputs: [1842 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Relu_1732 for ONNX node: Relu_1732
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1843 for ONNX tensor: 1843
[03/01/2023-10:40:55] [V] [TRT] Relu_1732 [Relu] outputs: [1843 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: MaxPool_1733 [MaxPool]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1843
[03/01/2023-10:40:55] [V] [TRT] MaxPool_1733 [MaxPool] inputs: [1843 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: MaxPool_1733 for ONNX node: MaxPool_1733
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1844 for ONNX tensor: 1844
[03/01/2023-10:40:55] [V] [TRT] MaxPool_1733 [MaxPool] outputs: [1844 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1734 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1734 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1734 [Constant] outputs: [1845 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1735 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1735 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1735 [Constant] outputs: [1846 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1736 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1844
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1845
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1846
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1736 [QuantizeLinear] inputs: [1844 -> (1, 64, 10, 10)[FLOAT]], [1845 -> ()[FLOAT]], [1846 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1845 for ONNX node: 1845
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1846 for ONNX node: 1846
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1847 for ONNX tensor: 1847
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1736 [QuantizeLinear] outputs: [1847 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1737 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1737 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1737 [Constant] outputs: [1848 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1738 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1738 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1738 [Constant] outputs: [1849 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1739 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1847
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1848
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1849
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1739 [DequantizeLinear] inputs: [1847 -> (1, 64, 10, 10)[FLOAT]], [1848 -> ()[FLOAT]], [1849 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1848 for ONNX node: 1848
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1849 for ONNX node: 1849
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1850 for ONNX tensor: 1850
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1739 [DequantizeLinear] outputs: [1850 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1740 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1740 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1740 [Constant] outputs: [1851 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1741 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1741 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1741 [Constant] outputs: [1852 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1742 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1851
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1852
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1742 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [1851 -> ()[FLOAT]], [1852 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1851 for ONNX node: 1851
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1852 for ONNX node: 1852
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1853 for ONNX tensor: 1853
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1742 [QuantizeLinear] outputs: [1853 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1743 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1743 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1743 [Constant] outputs: [1854 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1744 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1744 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1744 [Constant] outputs: [1855 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1745 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1853
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1854
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1855
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1745 [DequantizeLinear] inputs: [1853 -> (128, 64, 3, 3)[FLOAT]], [1854 -> ()[FLOAT]], [1855 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1854 for ONNX node: 1854
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1855 for ONNX node: 1855
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1856 for ONNX tensor: 1856
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1745 [DequantizeLinear] outputs: [1856 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Conv_1746 [Conv]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1850
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1856
[03/01/2023-10:40:55] [V] [TRT] Conv_1746 [Conv] inputs: [1850 -> (1, 64, 10, 10)[FLOAT]], [1856 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Conv_1746 for ONNX node: Conv_1746
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1857 for ONNX tensor: 1857
[03/01/2023-10:40:55] [V] [TRT] Conv_1746 [Conv] outputs: [1857 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: BatchNormalization_1747 [BatchNormalization]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1857
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:55] [V] [TRT] BatchNormalization_1747 [BatchNormalization] inputs: [1857 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: BatchNormalization_1747 for ONNX node: BatchNormalization_1747
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1858 for ONNX tensor: 1858
[03/01/2023-10:40:55] [V] [TRT] BatchNormalization_1747 [BatchNormalization] outputs: [1858 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Relu_1748 [Relu]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1858
[03/01/2023-10:40:55] [V] [TRT] Relu_1748 [Relu] inputs: [1858 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Relu_1748 for ONNX node: Relu_1748
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1859 for ONNX tensor: 1859
[03/01/2023-10:40:55] [V] [TRT] Relu_1748 [Relu] outputs: [1859 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1749 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1749 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1749 [Constant] outputs: [1860 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1750 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1750 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1750 [Constant] outputs: [1861 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1751 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1859
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1860
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1861
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1751 [QuantizeLinear] inputs: [1859 -> (1, 128, 8, 8)[FLOAT]], [1860 -> ()[FLOAT]], [1861 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1860 for ONNX node: 1860
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1861 for ONNX node: 1861
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1862 for ONNX tensor: 1862
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1751 [QuantizeLinear] outputs: [1862 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1752 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1752 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1752 [Constant] outputs: [1863 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1753 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1753 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1753 [Constant] outputs: [1864 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1754 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1862
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1863
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1864
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1754 [DequantizeLinear] inputs: [1862 -> (1, 128, 8, 8)[FLOAT]], [1863 -> ()[FLOAT]], [1864 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1863 for ONNX node: 1863
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1864 for ONNX node: 1864
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1865 for ONNX tensor: 1865
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1754 [DequantizeLinear] outputs: [1865 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1755 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1755 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1755 [Constant] outputs: [1866 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1756 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1756 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1756 [Constant] outputs: [1867 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1757 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1866
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1867
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1757 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [1866 -> ()[FLOAT]], [1867 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1866 for ONNX node: 1866
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1867 for ONNX node: 1867
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1868 for ONNX tensor: 1868
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1757 [QuantizeLinear] outputs: [1868 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1758 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1758 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1758 [Constant] outputs: [1869 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1759 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1759 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1759 [Constant] outputs: [1870 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1760 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1868
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1869
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1870
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1760 [DequantizeLinear] inputs: [1868 -> (128, 128, 3, 3)[FLOAT]], [1869 -> ()[FLOAT]], [1870 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1869 for ONNX node: 1869
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1870 for ONNX node: 1870
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1871 for ONNX tensor: 1871
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1760 [DequantizeLinear] outputs: [1871 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Conv_1761 [Conv]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1865
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1871
[03/01/2023-10:40:55] [V] [TRT] Conv_1761 [Conv] inputs: [1865 -> (1, 128, 8, 8)[FLOAT]], [1871 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Conv_1761 for ONNX node: Conv_1761
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1872 for ONNX tensor: 1872
[03/01/2023-10:40:55] [V] [TRT] Conv_1761 [Conv] outputs: [1872 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: BatchNormalization_1762 [BatchNormalization]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1872
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:55] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:55] [V] [TRT] BatchNormalization_1762 [BatchNormalization] inputs: [1872 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: BatchNormalization_1762 for ONNX node: BatchNormalization_1762
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1873 for ONNX tensor: 1873
[03/01/2023-10:40:55] [V] [TRT] BatchNormalization_1762 [BatchNormalization] outputs: [1873 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Relu_1763 [Relu]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1873
[03/01/2023-10:40:55] [V] [TRT] Relu_1763 [Relu] inputs: [1873 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Relu_1763 for ONNX node: Relu_1763
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1874 for ONNX tensor: 1874
[03/01/2023-10:40:55] [V] [TRT] Relu_1763 [Relu] outputs: [1874 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: MaxPool_1764 [MaxPool]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1874
[03/01/2023-10:40:55] [V] [TRT] MaxPool_1764 [MaxPool] inputs: [1874 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: MaxPool_1764 for ONNX node: MaxPool_1764
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1875 for ONNX tensor: 1875
[03/01/2023-10:40:55] [V] [TRT] MaxPool_1764 [MaxPool] outputs: [1875 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: ReduceMean_1765 [ReduceMean]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1875
[03/01/2023-10:40:55] [V] [TRT] ReduceMean_1765 [ReduceMean] inputs: [1875 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: ReduceMean_1765 for ONNX node: ReduceMean_1765
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1876 for ONNX tensor: 1876
[03/01/2023-10:40:55] [V] [TRT] ReduceMean_1765 [ReduceMean] outputs: [1876 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: ReduceMax_1766 [ReduceMax]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1875
[03/01/2023-10:40:55] [V] [TRT] ReduceMax_1766 [ReduceMax] inputs: [1875 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: ReduceMax_1766 for ONNX node: ReduceMax_1766
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1877 for ONNX tensor: 1877
[03/01/2023-10:40:55] [V] [TRT] ReduceMax_1766 [ReduceMax] outputs: [1877 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Concat_1767 [Concat]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1876
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1877
[03/01/2023-10:40:55] [V] [TRT] Concat_1767 [Concat] inputs: [1876 -> (1, 1, 3, 3)[FLOAT]], [1877 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: Concat_1767 for ONNX node: Concat_1767
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1878 for ONNX tensor: 1878
[03/01/2023-10:40:55] [V] [TRT] Concat_1767 [Concat] outputs: [1878 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1768 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1768 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1768 [Constant] outputs: [1879 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1769 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1769 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1769 [Constant] outputs: [1880 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: QuantizeLinear_1770 [QuantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1878
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1879
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1880
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1770 [QuantizeLinear] inputs: [1878 -> (1, 2, 3, 3)[FLOAT]], [1879 -> ()[FLOAT]], [1880 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1879 for ONNX node: 1879
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1880 for ONNX node: 1880
[03/01/2023-10:40:55] [V] [TRT] Registering tensor: 1881 for ONNX tensor: 1881
[03/01/2023-10:40:55] [V] [TRT] QuantizeLinear_1770 [QuantizeLinear] outputs: [1881 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1771 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1771 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1771 [Constant] outputs: [1882 -> ()[FLOAT]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: Constant_1772 [Constant]
[03/01/2023-10:40:55] [V] [TRT] Constant_1772 [Constant] inputs: 
[03/01/2023-10:40:55] [V] [TRT] Constant_1772 [Constant] outputs: [1883 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Parsing node: DequantizeLinear_1773 [DequantizeLinear]
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1881
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1882
[03/01/2023-10:40:55] [V] [TRT] Searching for input: 1883
[03/01/2023-10:40:55] [V] [TRT] DequantizeLinear_1773 [DequantizeLinear] inputs: [1881 -> (1, 2, 3, 3)[FLOAT]], [1882 -> ()[FLOAT]], [1883 -> ()[INT8]], 
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1882 for ONNX node: 1882
[03/01/2023-10:40:55] [V] [TRT] Registering layer: 1883 for ONNX node: 1883
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1884 for ONNX tensor: 1884
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1773 [DequantizeLinear] outputs: [1884 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1774 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1774 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1774 [Constant] outputs: [1885 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1775 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1775 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1775 [Constant] outputs: [1886 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1776 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1885
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1886
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1776 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [1885 -> ()[FLOAT]], [1886 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1885 for ONNX node: 1885
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1886 for ONNX node: 1886
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1887 for ONNX tensor: 1887
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1776 [QuantizeLinear] outputs: [1887 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1777 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1777 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1777 [Constant] outputs: [1888 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1778 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1778 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1778 [Constant] outputs: [1889 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1779 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1887
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1888
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1889
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1779 [DequantizeLinear] inputs: [1887 -> (1, 2, 7, 7)[FLOAT]], [1888 -> ()[FLOAT]], [1889 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1888 for ONNX node: 1888
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1889 for ONNX node: 1889
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1890 for ONNX tensor: 1890
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1779 [DequantizeLinear] outputs: [1890 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Conv_1780 [Conv]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1884
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1890
[03/01/2023-10:40:56] [V] [TRT] Conv_1780 [Conv] inputs: [1884 -> (1, 2, 3, 3)[FLOAT]], [1890 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Conv_1780 for ONNX node: Conv_1780
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1891 for ONNX tensor: 1891
[03/01/2023-10:40:56] [V] [TRT] Conv_1780 [Conv] outputs: [1891 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Sigmoid_1781 [Sigmoid]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1891
[03/01/2023-10:40:56] [V] [TRT] Sigmoid_1781 [Sigmoid] inputs: [1891 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Sigmoid_1781 for ONNX node: Sigmoid_1781
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1892 for ONNX tensor: 1892
[03/01/2023-10:40:56] [V] [TRT] Sigmoid_1781 [Sigmoid] outputs: [1892 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Mul_1782 [Mul]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1875
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1892
[03/01/2023-10:40:56] [V] [TRT] Mul_1782 [Mul] inputs: [1875 -> (1, 128, 3, 3)[FLOAT]], [1892 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Mul_1782 for ONNX node: Mul_1782
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1893 for ONNX tensor: 1893
[03/01/2023-10:40:56] [V] [TRT] Mul_1782 [Mul] outputs: [1893 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: GlobalAveragePool_1783 [GlobalAveragePool]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1893
[03/01/2023-10:40:56] [V] [TRT] GlobalAveragePool_1783 [GlobalAveragePool] inputs: [1893 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:56] [V] [TRT] Registering layer: GlobalAveragePool_1783 for ONNX node: GlobalAveragePool_1783
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1894 for ONNX tensor: 1894
[03/01/2023-10:40:56] [V] [TRT] GlobalAveragePool_1783 [GlobalAveragePool] outputs: [1894 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1784 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1784 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1784 [Constant] outputs: [1895 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1785 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1785 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1785 [Constant] outputs: [1896 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1786 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1894
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1895
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1896
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1786 [QuantizeLinear] inputs: [1894 -> (1, 128, 1, 1)[FLOAT]], [1895 -> ()[FLOAT]], [1896 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1895 for ONNX node: 1895
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1896 for ONNX node: 1896
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1897 for ONNX tensor: 1897
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1786 [QuantizeLinear] outputs: [1897 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1787 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1787 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1787 [Constant] outputs: [1898 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1788 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1788 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1788 [Constant] outputs: [1899 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1789 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1897
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1898
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1899
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1789 [DequantizeLinear] inputs: [1897 -> (1, 128, 1, 1)[FLOAT]], [1898 -> ()[FLOAT]], [1899 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1898 for ONNX node: 1898
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1899 for ONNX node: 1899
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1900 for ONNX tensor: 1900
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1789 [DequantizeLinear] outputs: [1900 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1790 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1790 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1790 [Constant] outputs: [1901 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1791 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1791 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1791 [Constant] outputs: [1902 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1792 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1901
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1902
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1792 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1901 -> ()[FLOAT]], [1902 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1901 for ONNX node: 1901
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1902 for ONNX node: 1902
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1903 for ONNX tensor: 1903
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1792 [QuantizeLinear] outputs: [1903 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1793 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1793 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1793 [Constant] outputs: [1904 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1794 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1794 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1794 [Constant] outputs: [1905 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1795 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1903
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1904
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1905
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1795 [DequantizeLinear] inputs: [1903 -> (8, 128, 1, 1)[FLOAT]], [1904 -> ()[FLOAT]], [1905 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1904 for ONNX node: 1904
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1905 for ONNX node: 1905
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1906 for ONNX tensor: 1906
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1795 [DequantizeLinear] outputs: [1906 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Conv_1796 [Conv]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1900
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1906
[03/01/2023-10:40:56] [V] [TRT] Conv_1796 [Conv] inputs: [1900 -> (1, 128, 1, 1)[FLOAT]], [1906 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Conv_1796 for ONNX node: Conv_1796
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1907 for ONNX tensor: 1907
[03/01/2023-10:40:56] [V] [TRT] Conv_1796 [Conv] outputs: [1907 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Relu_1797 [Relu]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1907
[03/01/2023-10:40:56] [V] [TRT] Relu_1797 [Relu] inputs: [1907 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Relu_1797 for ONNX node: Relu_1797
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1908 for ONNX tensor: 1908
[03/01/2023-10:40:56] [V] [TRT] Relu_1797 [Relu] outputs: [1908 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1798 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1798 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1798 [Constant] outputs: [1909 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1799 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1799 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1799 [Constant] outputs: [1910 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1800 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1908
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1909
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1910
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1800 [QuantizeLinear] inputs: [1908 -> (1, 8, 1, 1)[FLOAT]], [1909 -> ()[FLOAT]], [1910 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1909 for ONNX node: 1909
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1910 for ONNX node: 1910
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1911 for ONNX tensor: 1911
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1800 [QuantizeLinear] outputs: [1911 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1801 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1801 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1801 [Constant] outputs: [1912 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1802 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1802 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1802 [Constant] outputs: [1913 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1803 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1911
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1912
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1913
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1803 [DequantizeLinear] inputs: [1911 -> (1, 8, 1, 1)[FLOAT]], [1912 -> ()[FLOAT]], [1913 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1912 for ONNX node: 1912
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1913 for ONNX node: 1913
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1914 for ONNX tensor: 1914
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1803 [DequantizeLinear] outputs: [1914 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1804 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1804 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1804 [Constant] outputs: [1915 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1805 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1805 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1805 [Constant] outputs: [1916 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1806 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1915
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1916
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1806 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1915 -> ()[FLOAT]], [1916 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1915 for ONNX node: 1915
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1916 for ONNX node: 1916
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1917 for ONNX tensor: 1917
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1806 [QuantizeLinear] outputs: [1917 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1807 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1807 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1807 [Constant] outputs: [1918 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1808 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1808 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1808 [Constant] outputs: [1919 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1809 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1917
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1918
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1919
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1809 [DequantizeLinear] inputs: [1917 -> (128, 8, 1, 1)[FLOAT]], [1918 -> ()[FLOAT]], [1919 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1918 for ONNX node: 1918
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1919 for ONNX node: 1919
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1920 for ONNX tensor: 1920
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1809 [DequantizeLinear] outputs: [1920 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Conv_1810 [Conv]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1914
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1920
[03/01/2023-10:40:56] [V] [TRT] Conv_1810 [Conv] inputs: [1914 -> (1, 8, 1, 1)[FLOAT]], [1920 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Conv_1810 for ONNX node: Conv_1810
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1921 for ONNX tensor: 1921
[03/01/2023-10:40:56] [V] [TRT] Conv_1810 [Conv] outputs: [1921 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: MaxPool_1811 [MaxPool]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1893
[03/01/2023-10:40:56] [V] [TRT] MaxPool_1811 [MaxPool] inputs: [1893 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: MaxPool_1811 for ONNX node: MaxPool_1811
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1922 for ONNX tensor: 1922
[03/01/2023-10:40:56] [V] [TRT] MaxPool_1811 [MaxPool] outputs: [1922 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1812 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1812 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1812 [Constant] outputs: [1923 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1813 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1813 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1813 [Constant] outputs: [1924 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1814 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1922
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1923
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1924
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1814 [QuantizeLinear] inputs: [1922 -> (1, 128, 1, 1)[FLOAT]], [1923 -> ()[FLOAT]], [1924 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1923 for ONNX node: 1923
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1924 for ONNX node: 1924
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1925 for ONNX tensor: 1925
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1814 [QuantizeLinear] outputs: [1925 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1815 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1815 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1815 [Constant] outputs: [1926 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1816 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1816 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1816 [Constant] outputs: [1927 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1817 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1925
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1926
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1927
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1817 [DequantizeLinear] inputs: [1925 -> (1, 128, 1, 1)[FLOAT]], [1926 -> ()[FLOAT]], [1927 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1926 for ONNX node: 1926
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1927 for ONNX node: 1927
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1928 for ONNX tensor: 1928
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1817 [DequantizeLinear] outputs: [1928 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1818 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1818 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1818 [Constant] outputs: [1929 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1819 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1819 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1819 [Constant] outputs: [1930 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1820 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1929
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1930
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1820 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [1929 -> ()[FLOAT]], [1930 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1929 for ONNX node: 1929
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1930 for ONNX node: 1930
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1931 for ONNX tensor: 1931
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1820 [QuantizeLinear] outputs: [1931 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1821 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1821 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1821 [Constant] outputs: [1932 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1822 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1822 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1822 [Constant] outputs: [1933 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1823 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1931
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1932
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1933
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1823 [DequantizeLinear] inputs: [1931 -> (8, 128, 1, 1)[FLOAT]], [1932 -> ()[FLOAT]], [1933 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1932 for ONNX node: 1932
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1933 for ONNX node: 1933
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1934 for ONNX tensor: 1934
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1823 [DequantizeLinear] outputs: [1934 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Conv_1824 [Conv]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1928
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1934
[03/01/2023-10:40:56] [V] [TRT] Conv_1824 [Conv] inputs: [1928 -> (1, 128, 1, 1)[FLOAT]], [1934 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Conv_1824 for ONNX node: Conv_1824
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1935 for ONNX tensor: 1935
[03/01/2023-10:40:56] [V] [TRT] Conv_1824 [Conv] outputs: [1935 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Relu_1825 [Relu]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1935
[03/01/2023-10:40:56] [V] [TRT] Relu_1825 [Relu] inputs: [1935 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Relu_1825 for ONNX node: Relu_1825
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1936 for ONNX tensor: 1936
[03/01/2023-10:40:56] [V] [TRT] Relu_1825 [Relu] outputs: [1936 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1826 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1826 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1826 [Constant] outputs: [1937 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1827 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1827 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1827 [Constant] outputs: [1938 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1828 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1936
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1937
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1938
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1828 [QuantizeLinear] inputs: [1936 -> (1, 8, 1, 1)[FLOAT]], [1937 -> ()[FLOAT]], [1938 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1937 for ONNX node: 1937
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1938 for ONNX node: 1938
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1939 for ONNX tensor: 1939
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1828 [QuantizeLinear] outputs: [1939 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1829 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1829 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1829 [Constant] outputs: [1940 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1830 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1830 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1830 [Constant] outputs: [1941 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1831 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1939
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1940
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1941
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1831 [DequantizeLinear] inputs: [1939 -> (1, 8, 1, 1)[FLOAT]], [1940 -> ()[FLOAT]], [1941 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1940 for ONNX node: 1940
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1941 for ONNX node: 1941
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1942 for ONNX tensor: 1942
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1831 [DequantizeLinear] outputs: [1942 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1832 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1832 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1832 [Constant] outputs: [1943 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1833 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1833 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1833 [Constant] outputs: [1944 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1834 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1943
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1944
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1834 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [1943 -> ()[FLOAT]], [1944 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1943 for ONNX node: 1943
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1944 for ONNX node: 1944
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1945 for ONNX tensor: 1945
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1834 [QuantizeLinear] outputs: [1945 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1835 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1835 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1835 [Constant] outputs: [1946 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1836 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1836 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1836 [Constant] outputs: [1947 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1837 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1945
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1946
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1947
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1837 [DequantizeLinear] inputs: [1945 -> (128, 8, 1, 1)[FLOAT]], [1946 -> ()[FLOAT]], [1947 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1946 for ONNX node: 1946
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1947 for ONNX node: 1947
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1948 for ONNX tensor: 1948
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1837 [DequantizeLinear] outputs: [1948 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Conv_1838 [Conv]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1942
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1948
[03/01/2023-10:40:56] [V] [TRT] Conv_1838 [Conv] inputs: [1942 -> (1, 8, 1, 1)[FLOAT]], [1948 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Conv_1838 for ONNX node: Conv_1838
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1949 for ONNX tensor: 1949
[03/01/2023-10:40:56] [V] [TRT] Conv_1838 [Conv] outputs: [1949 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Add_1839 [Add]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1921
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1949
[03/01/2023-10:40:56] [V] [TRT] Add_1839 [Add] inputs: [1921 -> (1, 128, 1, 1)[FLOAT]], [1949 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Add_1839 for ONNX node: Add_1839
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1950 for ONNX tensor: 1950
[03/01/2023-10:40:56] [V] [TRT] Add_1839 [Add] outputs: [1950 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Sigmoid_1840 [Sigmoid]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1950
[03/01/2023-10:40:56] [V] [TRT] Sigmoid_1840 [Sigmoid] inputs: [1950 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Sigmoid_1840 for ONNX node: Sigmoid_1840
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1951 for ONNX tensor: 1951
[03/01/2023-10:40:56] [V] [TRT] Sigmoid_1840 [Sigmoid] outputs: [1951 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Mul_1841 [Mul]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1893
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1951
[03/01/2023-10:40:56] [V] [TRT] Mul_1841 [Mul] inputs: [1893 -> (1, 128, 3, 3)[FLOAT]], [1951 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Mul_1841 for ONNX node: Mul_1841
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1952 for ONNX tensor: 1952
[03/01/2023-10:40:56] [V] [TRT] Mul_1841 [Mul] outputs: [1952 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Concat_1842 [Concat]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1803
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1952
[03/01/2023-10:40:56] [V] [TRT] Concat_1842 [Concat] inputs: [1803 -> (1, 1280, 3, 3)[FLOAT]], [1952 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Concat_1842 for ONNX node: Concat_1842
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1953 for ONNX tensor: 1953
[03/01/2023-10:40:56] [V] [TRT] Concat_1842 [Concat] outputs: [1953 -> (1, 1408, 3, 3)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1843 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1843 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1843 [Constant] outputs: [1954 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1844 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1844 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1844 [Constant] outputs: [1955 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1845 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1845 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1845 [Constant] outputs: [1956 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1846 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1846 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1846 [Constant] outputs: [1957 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Slice_1847 [Slice]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: input
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1955
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1956
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1954
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1957
[03/01/2023-10:40:56] [V] [TRT] Slice_1847 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [1955 -> (1)[INT32]], [1956 -> (1)[INT32]], [1954 -> (1)[INT32]], [1957 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Slice_1847 for ONNX node: Slice_1847
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1958 for ONNX tensor: 1958
[03/01/2023-10:40:56] [V] [TRT] Slice_1847 [Slice] outputs: [1958 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1848 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1848 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1848 [Constant] outputs: [1959 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1849 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1849 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1849 [Constant] outputs: [1960 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1850 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1850 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1850 [Constant] outputs: [1961 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1851 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1851 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1851 [Constant] outputs: [1962 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Slice_1852 [Slice]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1958
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1960
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1961
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1959
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1962
[03/01/2023-10:40:56] [V] [TRT] Slice_1852 [Slice] inputs: [1958 -> (1, 1, 24, 60)[FLOAT]], [1960 -> (1)[INT32]], [1961 -> (1)[INT32]], [1959 -> (1)[INT32]], [1962 -> (1)[INT32]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: Slice_1852 for ONNX node: Slice_1852
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1963 for ONNX tensor: 1963
[03/01/2023-10:40:56] [V] [TRT] Slice_1852 [Slice] outputs: [1963 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1853 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1853 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1853 [Constant] outputs: [1964 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1854 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1854 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1854 [Constant] outputs: [1965 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1855 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1963
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1964
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1965
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1855 [QuantizeLinear] inputs: [1963 -> (1, 1, 24, 24)[FLOAT]], [1964 -> ()[FLOAT]], [1965 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1964 for ONNX node: 1964
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1965 for ONNX node: 1965
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1966 for ONNX tensor: 1966
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1855 [QuantizeLinear] outputs: [1966 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1856 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1856 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1856 [Constant] outputs: [1967 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1857 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1857 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1857 [Constant] outputs: [1968 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: DequantizeLinear_1858 [DequantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1966
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1967
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1968
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1858 [DequantizeLinear] inputs: [1966 -> (1, 1, 24, 24)[FLOAT]], [1967 -> ()[FLOAT]], [1968 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1967 for ONNX node: 1967
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1968 for ONNX node: 1968
[03/01/2023-10:40:56] [V] [TRT] Registering tensor: 1969 for ONNX tensor: 1969
[03/01/2023-10:40:56] [V] [TRT] DequantizeLinear_1858 [DequantizeLinear] outputs: [1969 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1859 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1859 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1859 [Constant] outputs: [1970 -> ()[FLOAT]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: Constant_1860 [Constant]
[03/01/2023-10:40:56] [V] [TRT] Constant_1860 [Constant] inputs: 
[03/01/2023-10:40:56] [V] [TRT] Constant_1860 [Constant] outputs: [1971 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Parsing node: QuantizeLinear_1861 [QuantizeLinear]
[03/01/2023-10:40:56] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1970
[03/01/2023-10:40:56] [V] [TRT] Searching for input: 1971
[03/01/2023-10:40:56] [V] [TRT] QuantizeLinear_1861 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [1970 -> ()[FLOAT]], [1971 -> ()[INT8]], 
[03/01/2023-10:40:56] [V] [TRT] Registering layer: 1970 for ONNX node: 1970
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1971 for ONNX node: 1971
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1972 for ONNX tensor: 1972
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1861 [QuantizeLinear] outputs: [1972 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1862 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1862 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1862 [Constant] outputs: [1973 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1863 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1863 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1863 [Constant] outputs: [1974 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1864 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1972
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1973
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1974
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1864 [DequantizeLinear] inputs: [1972 -> (64, 1, 3, 3)[FLOAT]], [1973 -> ()[FLOAT]], [1974 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1973 for ONNX node: 1973
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1974 for ONNX node: 1974
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1975 for ONNX tensor: 1975
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1864 [DequantizeLinear] outputs: [1975 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Conv_1865 [Conv]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1969
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1975
[03/01/2023-10:40:57] [V] [TRT] Conv_1865 [Conv] inputs: [1969 -> (1, 1, 24, 24)[FLOAT]], [1975 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Conv_1865 for ONNX node: Conv_1865
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1976 for ONNX tensor: 1976
[03/01/2023-10:40:57] [V] [TRT] Conv_1865 [Conv] outputs: [1976 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: BatchNormalization_1866 [BatchNormalization]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1976
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:57] [V] [TRT] BatchNormalization_1866 [BatchNormalization] inputs: [1976 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: BatchNormalization_1866 for ONNX node: BatchNormalization_1866
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1977 for ONNX tensor: 1977
[03/01/2023-10:40:57] [V] [TRT] BatchNormalization_1866 [BatchNormalization] outputs: [1977 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Relu_1867 [Relu]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1977
[03/01/2023-10:40:57] [V] [TRT] Relu_1867 [Relu] inputs: [1977 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Relu_1867 for ONNX node: Relu_1867
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1978 for ONNX tensor: 1978
[03/01/2023-10:40:57] [V] [TRT] Relu_1867 [Relu] outputs: [1978 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1868 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1868 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1868 [Constant] outputs: [1979 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1869 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1869 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1869 [Constant] outputs: [1980 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1870 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1978
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1979
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1980
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1870 [QuantizeLinear] inputs: [1978 -> (1, 64, 22, 22)[FLOAT]], [1979 -> ()[FLOAT]], [1980 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1979 for ONNX node: 1979
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1980 for ONNX node: 1980
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1981 for ONNX tensor: 1981
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1870 [QuantizeLinear] outputs: [1981 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1871 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1871 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1871 [Constant] outputs: [1982 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1872 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1872 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1872 [Constant] outputs: [1983 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1873 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1981
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1982
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1983
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1873 [DequantizeLinear] inputs: [1981 -> (1, 64, 22, 22)[FLOAT]], [1982 -> ()[FLOAT]], [1983 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1982 for ONNX node: 1982
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1983 for ONNX node: 1983
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1984 for ONNX tensor: 1984
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1873 [DequantizeLinear] outputs: [1984 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1874 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1874 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1874 [Constant] outputs: [1985 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1875 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1875 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1875 [Constant] outputs: [1986 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1876 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1985
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1986
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1876 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [1985 -> ()[FLOAT]], [1986 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1985 for ONNX node: 1985
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1986 for ONNX node: 1986
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1987 for ONNX tensor: 1987
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1876 [QuantizeLinear] outputs: [1987 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1877 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1877 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1877 [Constant] outputs: [1988 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1878 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1878 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1878 [Constant] outputs: [1989 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1879 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1987
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1988
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1989
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1879 [DequantizeLinear] inputs: [1987 -> (64, 64, 3, 3)[FLOAT]], [1988 -> ()[FLOAT]], [1989 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1988 for ONNX node: 1988
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1989 for ONNX node: 1989
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1990 for ONNX tensor: 1990
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1879 [DequantizeLinear] outputs: [1990 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Conv_1880 [Conv]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1984
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1990
[03/01/2023-10:40:57] [V] [TRT] Conv_1880 [Conv] inputs: [1984 -> (1, 64, 22, 22)[FLOAT]], [1990 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Conv_1880 for ONNX node: Conv_1880
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1991 for ONNX tensor: 1991
[03/01/2023-10:40:57] [V] [TRT] Conv_1880 [Conv] outputs: [1991 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: BatchNormalization_1881 [BatchNormalization]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1991
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:57] [V] [TRT] BatchNormalization_1881 [BatchNormalization] inputs: [1991 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: BatchNormalization_1881 for ONNX node: BatchNormalization_1881
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1992 for ONNX tensor: 1992
[03/01/2023-10:40:57] [V] [TRT] BatchNormalization_1881 [BatchNormalization] outputs: [1992 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Relu_1882 [Relu]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1992
[03/01/2023-10:40:57] [V] [TRT] Relu_1882 [Relu] inputs: [1992 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Relu_1882 for ONNX node: Relu_1882
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1993 for ONNX tensor: 1993
[03/01/2023-10:40:57] [V] [TRT] Relu_1882 [Relu] outputs: [1993 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: MaxPool_1883 [MaxPool]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1993
[03/01/2023-10:40:57] [V] [TRT] MaxPool_1883 [MaxPool] inputs: [1993 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: MaxPool_1883 for ONNX node: MaxPool_1883
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1994 for ONNX tensor: 1994
[03/01/2023-10:40:57] [V] [TRT] MaxPool_1883 [MaxPool] outputs: [1994 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1884 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1884 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1884 [Constant] outputs: [1995 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1885 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1885 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1885 [Constant] outputs: [1996 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1886 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1994
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1995
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1996
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1886 [QuantizeLinear] inputs: [1994 -> (1, 64, 10, 10)[FLOAT]], [1995 -> ()[FLOAT]], [1996 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1995 for ONNX node: 1995
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1996 for ONNX node: 1996
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 1997 for ONNX tensor: 1997
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1886 [QuantizeLinear] outputs: [1997 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1887 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1887 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1887 [Constant] outputs: [1998 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1888 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1888 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1888 [Constant] outputs: [1999 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1889 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1997
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1998
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 1999
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1889 [DequantizeLinear] inputs: [1997 -> (1, 64, 10, 10)[FLOAT]], [1998 -> ()[FLOAT]], [1999 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1998 for ONNX node: 1998
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 1999 for ONNX node: 1999
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2000 for ONNX tensor: 2000
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1889 [DequantizeLinear] outputs: [2000 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1890 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1890 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1890 [Constant] outputs: [2001 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1891 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1891 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1891 [Constant] outputs: [2002 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1892 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2001
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2002
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1892 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [2001 -> ()[FLOAT]], [2002 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2001 for ONNX node: 2001
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2002 for ONNX node: 2002
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2003 for ONNX tensor: 2003
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1892 [QuantizeLinear] outputs: [2003 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1893 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1893 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1893 [Constant] outputs: [2004 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1894 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1894 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1894 [Constant] outputs: [2005 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1895 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2003
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2004
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2005
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1895 [DequantizeLinear] inputs: [2003 -> (128, 64, 3, 3)[FLOAT]], [2004 -> ()[FLOAT]], [2005 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2004 for ONNX node: 2004
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2005 for ONNX node: 2005
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2006 for ONNX tensor: 2006
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1895 [DequantizeLinear] outputs: [2006 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Conv_1896 [Conv]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2000
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2006
[03/01/2023-10:40:57] [V] [TRT] Conv_1896 [Conv] inputs: [2000 -> (1, 64, 10, 10)[FLOAT]], [2006 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Conv_1896 for ONNX node: Conv_1896
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2007 for ONNX tensor: 2007
[03/01/2023-10:40:57] [V] [TRT] Conv_1896 [Conv] outputs: [2007 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: BatchNormalization_1897 [BatchNormalization]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2007
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:57] [V] [TRT] BatchNormalization_1897 [BatchNormalization] inputs: [2007 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: BatchNormalization_1897 for ONNX node: BatchNormalization_1897
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2008 for ONNX tensor: 2008
[03/01/2023-10:40:57] [V] [TRT] BatchNormalization_1897 [BatchNormalization] outputs: [2008 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Relu_1898 [Relu]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2008
[03/01/2023-10:40:57] [V] [TRT] Relu_1898 [Relu] inputs: [2008 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Relu_1898 for ONNX node: Relu_1898
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2009 for ONNX tensor: 2009
[03/01/2023-10:40:57] [V] [TRT] Relu_1898 [Relu] outputs: [2009 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1899 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1899 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1899 [Constant] outputs: [2010 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1900 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1900 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1900 [Constant] outputs: [2011 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1901 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2009
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2010
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2011
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1901 [QuantizeLinear] inputs: [2009 -> (1, 128, 8, 8)[FLOAT]], [2010 -> ()[FLOAT]], [2011 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2010 for ONNX node: 2010
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2011 for ONNX node: 2011
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2012 for ONNX tensor: 2012
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1901 [QuantizeLinear] outputs: [2012 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1902 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1902 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1902 [Constant] outputs: [2013 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1903 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1903 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1903 [Constant] outputs: [2014 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1904 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2012
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2013
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2014
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1904 [DequantizeLinear] inputs: [2012 -> (1, 128, 8, 8)[FLOAT]], [2013 -> ()[FLOAT]], [2014 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2013 for ONNX node: 2013
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2014 for ONNX node: 2014
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2015 for ONNX tensor: 2015
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1904 [DequantizeLinear] outputs: [2015 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1905 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1905 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1905 [Constant] outputs: [2016 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1906 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1906 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1906 [Constant] outputs: [2017 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1907 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2016
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2017
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1907 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [2016 -> ()[FLOAT]], [2017 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2016 for ONNX node: 2016
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2017 for ONNX node: 2017
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2018 for ONNX tensor: 2018
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1907 [QuantizeLinear] outputs: [2018 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1908 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1908 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1908 [Constant] outputs: [2019 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1909 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1909 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1909 [Constant] outputs: [2020 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1910 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2018
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2019
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2020
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1910 [DequantizeLinear] inputs: [2018 -> (128, 128, 3, 3)[FLOAT]], [2019 -> ()[FLOAT]], [2020 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2019 for ONNX node: 2019
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2020 for ONNX node: 2020
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2021 for ONNX tensor: 2021
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1910 [DequantizeLinear] outputs: [2021 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Conv_1911 [Conv]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2015
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2021
[03/01/2023-10:40:57] [V] [TRT] Conv_1911 [Conv] inputs: [2015 -> (1, 128, 8, 8)[FLOAT]], [2021 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Conv_1911 for ONNX node: Conv_1911
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2022 for ONNX tensor: 2022
[03/01/2023-10:40:57] [V] [TRT] Conv_1911 [Conv] outputs: [2022 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: BatchNormalization_1912 [BatchNormalization]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2022
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:57] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:57] [V] [TRT] BatchNormalization_1912 [BatchNormalization] inputs: [2022 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: BatchNormalization_1912 for ONNX node: BatchNormalization_1912
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2023 for ONNX tensor: 2023
[03/01/2023-10:40:57] [V] [TRT] BatchNormalization_1912 [BatchNormalization] outputs: [2023 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Relu_1913 [Relu]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2023
[03/01/2023-10:40:57] [V] [TRT] Relu_1913 [Relu] inputs: [2023 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Relu_1913 for ONNX node: Relu_1913
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2024 for ONNX tensor: 2024
[03/01/2023-10:40:57] [V] [TRT] Relu_1913 [Relu] outputs: [2024 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: MaxPool_1914 [MaxPool]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2024
[03/01/2023-10:40:57] [V] [TRT] MaxPool_1914 [MaxPool] inputs: [2024 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: MaxPool_1914 for ONNX node: MaxPool_1914
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2025 for ONNX tensor: 2025
[03/01/2023-10:40:57] [V] [TRT] MaxPool_1914 [MaxPool] outputs: [2025 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: ReduceMean_1915 [ReduceMean]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2025
[03/01/2023-10:40:57] [V] [TRT] ReduceMean_1915 [ReduceMean] inputs: [2025 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: ReduceMean_1915 for ONNX node: ReduceMean_1915
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2026 for ONNX tensor: 2026
[03/01/2023-10:40:57] [V] [TRT] ReduceMean_1915 [ReduceMean] outputs: [2026 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: ReduceMax_1916 [ReduceMax]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2025
[03/01/2023-10:40:57] [V] [TRT] ReduceMax_1916 [ReduceMax] inputs: [2025 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: ReduceMax_1916 for ONNX node: ReduceMax_1916
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2027 for ONNX tensor: 2027
[03/01/2023-10:40:57] [V] [TRT] ReduceMax_1916 [ReduceMax] outputs: [2027 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Concat_1917 [Concat]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2026
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2027
[03/01/2023-10:40:57] [V] [TRT] Concat_1917 [Concat] inputs: [2026 -> (1, 1, 3, 3)[FLOAT]], [2027 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Concat_1917 for ONNX node: Concat_1917
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2028 for ONNX tensor: 2028
[03/01/2023-10:40:57] [V] [TRT] Concat_1917 [Concat] outputs: [2028 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1918 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1918 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1918 [Constant] outputs: [2029 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1919 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1919 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1919 [Constant] outputs: [2030 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1920 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2028
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2029
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2030
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1920 [QuantizeLinear] inputs: [2028 -> (1, 2, 3, 3)[FLOAT]], [2029 -> ()[FLOAT]], [2030 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2029 for ONNX node: 2029
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2030 for ONNX node: 2030
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2031 for ONNX tensor: 2031
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1920 [QuantizeLinear] outputs: [2031 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1921 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1921 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1921 [Constant] outputs: [2032 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1922 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1922 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1922 [Constant] outputs: [2033 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1923 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2031
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2032
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2033
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1923 [DequantizeLinear] inputs: [2031 -> (1, 2, 3, 3)[FLOAT]], [2032 -> ()[FLOAT]], [2033 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2032 for ONNX node: 2032
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2033 for ONNX node: 2033
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2034 for ONNX tensor: 2034
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1923 [DequantizeLinear] outputs: [2034 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1924 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1924 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1924 [Constant] outputs: [2035 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1925 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1925 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1925 [Constant] outputs: [2036 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1926 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2035
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2036
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1926 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [2035 -> ()[FLOAT]], [2036 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2035 for ONNX node: 2035
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2036 for ONNX node: 2036
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2037 for ONNX tensor: 2037
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1926 [QuantizeLinear] outputs: [2037 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1927 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1927 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1927 [Constant] outputs: [2038 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1928 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1928 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1928 [Constant] outputs: [2039 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1929 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2037
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2038
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2039
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1929 [DequantizeLinear] inputs: [2037 -> (1, 2, 7, 7)[FLOAT]], [2038 -> ()[FLOAT]], [2039 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2038 for ONNX node: 2038
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2039 for ONNX node: 2039
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2040 for ONNX tensor: 2040
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1929 [DequantizeLinear] outputs: [2040 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Conv_1930 [Conv]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2034
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2040
[03/01/2023-10:40:57] [V] [TRT] Conv_1930 [Conv] inputs: [2034 -> (1, 2, 3, 3)[FLOAT]], [2040 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Conv_1930 for ONNX node: Conv_1930
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2041 for ONNX tensor: 2041
[03/01/2023-10:40:57] [V] [TRT] Conv_1930 [Conv] outputs: [2041 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Sigmoid_1931 [Sigmoid]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2041
[03/01/2023-10:40:57] [V] [TRT] Sigmoid_1931 [Sigmoid] inputs: [2041 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Sigmoid_1931 for ONNX node: Sigmoid_1931
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2042 for ONNX tensor: 2042
[03/01/2023-10:40:57] [V] [TRT] Sigmoid_1931 [Sigmoid] outputs: [2042 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Mul_1932 [Mul]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2025
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2042
[03/01/2023-10:40:57] [V] [TRT] Mul_1932 [Mul] inputs: [2025 -> (1, 128, 3, 3)[FLOAT]], [2042 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Mul_1932 for ONNX node: Mul_1932
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2043 for ONNX tensor: 2043
[03/01/2023-10:40:57] [V] [TRT] Mul_1932 [Mul] outputs: [2043 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: GlobalAveragePool_1933 [GlobalAveragePool]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2043
[03/01/2023-10:40:57] [V] [TRT] GlobalAveragePool_1933 [GlobalAveragePool] inputs: [2043 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:57] [V] [TRT] Registering layer: GlobalAveragePool_1933 for ONNX node: GlobalAveragePool_1933
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2044 for ONNX tensor: 2044
[03/01/2023-10:40:57] [V] [TRT] GlobalAveragePool_1933 [GlobalAveragePool] outputs: [2044 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1934 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1934 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1934 [Constant] outputs: [2045 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1935 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1935 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1935 [Constant] outputs: [2046 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1936 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2044
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2045
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2046
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1936 [QuantizeLinear] inputs: [2044 -> (1, 128, 1, 1)[FLOAT]], [2045 -> ()[FLOAT]], [2046 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2045 for ONNX node: 2045
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2046 for ONNX node: 2046
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2047 for ONNX tensor: 2047
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1936 [QuantizeLinear] outputs: [2047 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1937 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1937 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1937 [Constant] outputs: [2048 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1938 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1938 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1938 [Constant] outputs: [2049 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1939 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2047
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2048
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2049
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1939 [DequantizeLinear] inputs: [2047 -> (1, 128, 1, 1)[FLOAT]], [2048 -> ()[FLOAT]], [2049 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2048 for ONNX node: 2048
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2049 for ONNX node: 2049
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2050 for ONNX tensor: 2050
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1939 [DequantizeLinear] outputs: [2050 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1940 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1940 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1940 [Constant] outputs: [2051 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1941 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1941 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1941 [Constant] outputs: [2052 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1942 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2051
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2052
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1942 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2051 -> ()[FLOAT]], [2052 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2051 for ONNX node: 2051
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2052 for ONNX node: 2052
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2053 for ONNX tensor: 2053
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1942 [QuantizeLinear] outputs: [2053 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1943 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1943 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1943 [Constant] outputs: [2054 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1944 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1944 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1944 [Constant] outputs: [2055 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: DequantizeLinear_1945 [DequantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2053
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2054
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2055
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1945 [DequantizeLinear] inputs: [2053 -> (8, 128, 1, 1)[FLOAT]], [2054 -> ()[FLOAT]], [2055 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2054 for ONNX node: 2054
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2055 for ONNX node: 2055
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2056 for ONNX tensor: 2056
[03/01/2023-10:40:57] [V] [TRT] DequantizeLinear_1945 [DequantizeLinear] outputs: [2056 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Conv_1946 [Conv]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2050
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2056
[03/01/2023-10:40:57] [V] [TRT] Conv_1946 [Conv] inputs: [2050 -> (1, 128, 1, 1)[FLOAT]], [2056 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Conv_1946 for ONNX node: Conv_1946
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2057 for ONNX tensor: 2057
[03/01/2023-10:40:57] [V] [TRT] Conv_1946 [Conv] outputs: [2057 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Relu_1947 [Relu]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2057
[03/01/2023-10:40:57] [V] [TRT] Relu_1947 [Relu] inputs: [2057 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: Relu_1947 for ONNX node: Relu_1947
[03/01/2023-10:40:57] [V] [TRT] Registering tensor: 2058 for ONNX tensor: 2058
[03/01/2023-10:40:57] [V] [TRT] Relu_1947 [Relu] outputs: [2058 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1948 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1948 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1948 [Constant] outputs: [2059 -> ()[FLOAT]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: Constant_1949 [Constant]
[03/01/2023-10:40:57] [V] [TRT] Constant_1949 [Constant] inputs: 
[03/01/2023-10:40:57] [V] [TRT] Constant_1949 [Constant] outputs: [2060 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Parsing node: QuantizeLinear_1950 [QuantizeLinear]
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2058
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2059
[03/01/2023-10:40:57] [V] [TRT] Searching for input: 2060
[03/01/2023-10:40:57] [V] [TRT] QuantizeLinear_1950 [QuantizeLinear] inputs: [2058 -> (1, 8, 1, 1)[FLOAT]], [2059 -> ()[FLOAT]], [2060 -> ()[INT8]], 
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2059 for ONNX node: 2059
[03/01/2023-10:40:57] [V] [TRT] Registering layer: 2060 for ONNX node: 2060
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2061 for ONNX tensor: 2061
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1950 [QuantizeLinear] outputs: [2061 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1951 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1951 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1951 [Constant] outputs: [2062 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1952 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1952 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1952 [Constant] outputs: [2063 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_1953 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2061
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2062
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2063
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1953 [DequantizeLinear] inputs: [2061 -> (1, 8, 1, 1)[FLOAT]], [2062 -> ()[FLOAT]], [2063 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2062 for ONNX node: 2062
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2063 for ONNX node: 2063
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2064 for ONNX tensor: 2064
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1953 [DequantizeLinear] outputs: [2064 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1954 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1954 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1954 [Constant] outputs: [2065 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1955 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1955 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1955 [Constant] outputs: [2066 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_1956 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2065
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2066
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1956 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2065 -> ()[FLOAT]], [2066 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2065 for ONNX node: 2065
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2066 for ONNX node: 2066
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2067 for ONNX tensor: 2067
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1956 [QuantizeLinear] outputs: [2067 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1957 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1957 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1957 [Constant] outputs: [2068 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1958 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1958 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1958 [Constant] outputs: [2069 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_1959 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2067
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2068
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2069
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1959 [DequantizeLinear] inputs: [2067 -> (128, 8, 1, 1)[FLOAT]], [2068 -> ()[FLOAT]], [2069 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2068 for ONNX node: 2068
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2069 for ONNX node: 2069
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2070 for ONNX tensor: 2070
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1959 [DequantizeLinear] outputs: [2070 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Conv_1960 [Conv]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2064
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2070
[03/01/2023-10:40:58] [V] [TRT] Conv_1960 [Conv] inputs: [2064 -> (1, 8, 1, 1)[FLOAT]], [2070 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Conv_1960 for ONNX node: Conv_1960
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2071 for ONNX tensor: 2071
[03/01/2023-10:40:58] [V] [TRT] Conv_1960 [Conv] outputs: [2071 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: MaxPool_1961 [MaxPool]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2043
[03/01/2023-10:40:58] [V] [TRT] MaxPool_1961 [MaxPool] inputs: [2043 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: MaxPool_1961 for ONNX node: MaxPool_1961
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2072 for ONNX tensor: 2072
[03/01/2023-10:40:58] [V] [TRT] MaxPool_1961 [MaxPool] outputs: [2072 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1962 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1962 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1962 [Constant] outputs: [2073 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1963 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1963 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1963 [Constant] outputs: [2074 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_1964 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2072
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2073
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2074
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1964 [QuantizeLinear] inputs: [2072 -> (1, 128, 1, 1)[FLOAT]], [2073 -> ()[FLOAT]], [2074 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2073 for ONNX node: 2073
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2074 for ONNX node: 2074
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2075 for ONNX tensor: 2075
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1964 [QuantizeLinear] outputs: [2075 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1965 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1965 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1965 [Constant] outputs: [2076 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1966 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1966 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1966 [Constant] outputs: [2077 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_1967 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2075
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2076
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2077
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1967 [DequantizeLinear] inputs: [2075 -> (1, 128, 1, 1)[FLOAT]], [2076 -> ()[FLOAT]], [2077 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2076 for ONNX node: 2076
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2077 for ONNX node: 2077
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2078 for ONNX tensor: 2078
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1967 [DequantizeLinear] outputs: [2078 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1968 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1968 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1968 [Constant] outputs: [2079 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1969 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1969 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1969 [Constant] outputs: [2080 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_1970 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2079
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2080
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1970 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2079 -> ()[FLOAT]], [2080 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2079 for ONNX node: 2079
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2080 for ONNX node: 2080
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2081 for ONNX tensor: 2081
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1970 [QuantizeLinear] outputs: [2081 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1971 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1971 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1971 [Constant] outputs: [2082 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1972 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1972 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1972 [Constant] outputs: [2083 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_1973 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2081
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2082
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2083
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1973 [DequantizeLinear] inputs: [2081 -> (8, 128, 1, 1)[FLOAT]], [2082 -> ()[FLOAT]], [2083 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2082 for ONNX node: 2082
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2083 for ONNX node: 2083
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2084 for ONNX tensor: 2084
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1973 [DequantizeLinear] outputs: [2084 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Conv_1974 [Conv]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2078
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2084
[03/01/2023-10:40:58] [V] [TRT] Conv_1974 [Conv] inputs: [2078 -> (1, 128, 1, 1)[FLOAT]], [2084 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Conv_1974 for ONNX node: Conv_1974
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2085 for ONNX tensor: 2085
[03/01/2023-10:40:58] [V] [TRT] Conv_1974 [Conv] outputs: [2085 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Relu_1975 [Relu]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2085
[03/01/2023-10:40:58] [V] [TRT] Relu_1975 [Relu] inputs: [2085 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Relu_1975 for ONNX node: Relu_1975
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2086 for ONNX tensor: 2086
[03/01/2023-10:40:58] [V] [TRT] Relu_1975 [Relu] outputs: [2086 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1976 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1976 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1976 [Constant] outputs: [2087 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1977 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1977 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1977 [Constant] outputs: [2088 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_1978 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2086
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2087
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2088
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1978 [QuantizeLinear] inputs: [2086 -> (1, 8, 1, 1)[FLOAT]], [2087 -> ()[FLOAT]], [2088 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2087 for ONNX node: 2087
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2088 for ONNX node: 2088
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2089 for ONNX tensor: 2089
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1978 [QuantizeLinear] outputs: [2089 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1979 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1979 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1979 [Constant] outputs: [2090 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1980 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1980 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1980 [Constant] outputs: [2091 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_1981 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2089
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2090
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2091
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1981 [DequantizeLinear] inputs: [2089 -> (1, 8, 1, 1)[FLOAT]], [2090 -> ()[FLOAT]], [2091 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2090 for ONNX node: 2090
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2091 for ONNX node: 2091
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2092 for ONNX tensor: 2092
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1981 [DequantizeLinear] outputs: [2092 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1982 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1982 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1982 [Constant] outputs: [2093 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1983 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1983 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1983 [Constant] outputs: [2094 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_1984 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2093
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2094
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1984 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2093 -> ()[FLOAT]], [2094 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2093 for ONNX node: 2093
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2094 for ONNX node: 2094
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2095 for ONNX tensor: 2095
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_1984 [QuantizeLinear] outputs: [2095 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1985 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1985 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1985 [Constant] outputs: [2096 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1986 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1986 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1986 [Constant] outputs: [2097 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_1987 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2095
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2096
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2097
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1987 [DequantizeLinear] inputs: [2095 -> (128, 8, 1, 1)[FLOAT]], [2096 -> ()[FLOAT]], [2097 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2096 for ONNX node: 2096
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2097 for ONNX node: 2097
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2098 for ONNX tensor: 2098
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_1987 [DequantizeLinear] outputs: [2098 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Conv_1988 [Conv]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2092
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2098
[03/01/2023-10:40:58] [V] [TRT] Conv_1988 [Conv] inputs: [2092 -> (1, 8, 1, 1)[FLOAT]], [2098 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Conv_1988 for ONNX node: Conv_1988
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2099 for ONNX tensor: 2099
[03/01/2023-10:40:58] [V] [TRT] Conv_1988 [Conv] outputs: [2099 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Add_1989 [Add]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2071
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2099
[03/01/2023-10:40:58] [V] [TRT] Add_1989 [Add] inputs: [2071 -> (1, 128, 1, 1)[FLOAT]], [2099 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Add_1989 for ONNX node: Add_1989
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2100 for ONNX tensor: 2100
[03/01/2023-10:40:58] [V] [TRT] Add_1989 [Add] outputs: [2100 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Sigmoid_1990 [Sigmoid]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2100
[03/01/2023-10:40:58] [V] [TRT] Sigmoid_1990 [Sigmoid] inputs: [2100 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Sigmoid_1990 for ONNX node: Sigmoid_1990
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2101 for ONNX tensor: 2101
[03/01/2023-10:40:58] [V] [TRT] Sigmoid_1990 [Sigmoid] outputs: [2101 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Mul_1991 [Mul]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2043
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2101
[03/01/2023-10:40:58] [V] [TRT] Mul_1991 [Mul] inputs: [2043 -> (1, 128, 3, 3)[FLOAT]], [2101 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Mul_1991 for ONNX node: Mul_1991
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2102 for ONNX tensor: 2102
[03/01/2023-10:40:58] [V] [TRT] Mul_1991 [Mul] outputs: [2102 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Concat_1992 [Concat]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 1953
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2102
[03/01/2023-10:40:58] [V] [TRT] Concat_1992 [Concat] inputs: [1953 -> (1, 1408, 3, 3)[FLOAT]], [2102 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Concat_1992 for ONNX node: Concat_1992
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2103 for ONNX tensor: 2103
[03/01/2023-10:40:58] [V] [TRT] Concat_1992 [Concat] outputs: [2103 -> (1, 1536, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1993 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1993 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1993 [Constant] outputs: [2104 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1994 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1994 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1994 [Constant] outputs: [2105 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1995 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1995 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1995 [Constant] outputs: [2106 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1996 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1996 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1996 [Constant] outputs: [2107 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Slice_1997 [Slice]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: input
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2105
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2106
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2104
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2107
[03/01/2023-10:40:58] [V] [TRT] Slice_1997 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [2105 -> (1)[INT32]], [2106 -> (1)[INT32]], [2104 -> (1)[INT32]], [2107 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Slice_1997 for ONNX node: Slice_1997
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2108 for ONNX tensor: 2108
[03/01/2023-10:40:58] [V] [TRT] Slice_1997 [Slice] outputs: [2108 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1998 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1998 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1998 [Constant] outputs: [2109 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_1999 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_1999 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_1999 [Constant] outputs: [2110 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2000 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2000 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2000 [Constant] outputs: [2111 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2001 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2001 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2001 [Constant] outputs: [2112 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Slice_2002 [Slice]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2108
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2110
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2111
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2109
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2112
[03/01/2023-10:40:58] [V] [TRT] Slice_2002 [Slice] inputs: [2108 -> (1, 1, 24, 60)[FLOAT]], [2110 -> (1)[INT32]], [2111 -> (1)[INT32]], [2109 -> (1)[INT32]], [2112 -> (1)[INT32]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Slice_2002 for ONNX node: Slice_2002
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2113 for ONNX tensor: 2113
[03/01/2023-10:40:58] [V] [TRT] Slice_2002 [Slice] outputs: [2113 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2003 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2003 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2003 [Constant] outputs: [2114 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2004 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2004 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2004 [Constant] outputs: [2115 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_2005 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2113
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2114
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2115
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2005 [QuantizeLinear] inputs: [2113 -> (1, 1, 24, 24)[FLOAT]], [2114 -> ()[FLOAT]], [2115 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2114 for ONNX node: 2114
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2115 for ONNX node: 2115
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2116 for ONNX tensor: 2116
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2005 [QuantizeLinear] outputs: [2116 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2006 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2006 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2006 [Constant] outputs: [2117 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2007 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2007 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2007 [Constant] outputs: [2118 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_2008 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2116
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2117
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2118
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2008 [DequantizeLinear] inputs: [2116 -> (1, 1, 24, 24)[FLOAT]], [2117 -> ()[FLOAT]], [2118 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2117 for ONNX node: 2117
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2118 for ONNX node: 2118
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2119 for ONNX tensor: 2119
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2008 [DequantizeLinear] outputs: [2119 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2009 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2009 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2009 [Constant] outputs: [2120 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2010 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2010 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2010 [Constant] outputs: [2121 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_2011 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2120
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2121
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2011 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [2120 -> ()[FLOAT]], [2121 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2120 for ONNX node: 2120
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2121 for ONNX node: 2121
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2122 for ONNX tensor: 2122
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2011 [QuantizeLinear] outputs: [2122 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2012 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2012 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2012 [Constant] outputs: [2123 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2013 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2013 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2013 [Constant] outputs: [2124 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_2014 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2122
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2123
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2124
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2014 [DequantizeLinear] inputs: [2122 -> (64, 1, 3, 3)[FLOAT]], [2123 -> ()[FLOAT]], [2124 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2123 for ONNX node: 2123
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2124 for ONNX node: 2124
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2125 for ONNX tensor: 2125
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2014 [DequantizeLinear] outputs: [2125 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Conv_2015 [Conv]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2119
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2125
[03/01/2023-10:40:58] [V] [TRT] Conv_2015 [Conv] inputs: [2119 -> (1, 1, 24, 24)[FLOAT]], [2125 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Conv_2015 for ONNX node: Conv_2015
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2126 for ONNX tensor: 2126
[03/01/2023-10:40:58] [V] [TRT] Conv_2015 [Conv] outputs: [2126 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: BatchNormalization_2016 [BatchNormalization]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2126
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:40:58] [V] [TRT] BatchNormalization_2016 [BatchNormalization] inputs: [2126 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: BatchNormalization_2016 for ONNX node: BatchNormalization_2016
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2127 for ONNX tensor: 2127
[03/01/2023-10:40:58] [V] [TRT] BatchNormalization_2016 [BatchNormalization] outputs: [2127 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Relu_2017 [Relu]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2127
[03/01/2023-10:40:58] [V] [TRT] Relu_2017 [Relu] inputs: [2127 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Relu_2017 for ONNX node: Relu_2017
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2128 for ONNX tensor: 2128
[03/01/2023-10:40:58] [V] [TRT] Relu_2017 [Relu] outputs: [2128 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2018 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2018 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2018 [Constant] outputs: [2129 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2019 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2019 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2019 [Constant] outputs: [2130 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_2020 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2128
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2129
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2130
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2020 [QuantizeLinear] inputs: [2128 -> (1, 64, 22, 22)[FLOAT]], [2129 -> ()[FLOAT]], [2130 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2129 for ONNX node: 2129
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2130 for ONNX node: 2130
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2131 for ONNX tensor: 2131
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2020 [QuantizeLinear] outputs: [2131 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2021 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2021 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2021 [Constant] outputs: [2132 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2022 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2022 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2022 [Constant] outputs: [2133 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_2023 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2131
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2132
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2133
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2023 [DequantizeLinear] inputs: [2131 -> (1, 64, 22, 22)[FLOAT]], [2132 -> ()[FLOAT]], [2133 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2132 for ONNX node: 2132
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2133 for ONNX node: 2133
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2134 for ONNX tensor: 2134
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2023 [DequantizeLinear] outputs: [2134 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2024 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2024 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2024 [Constant] outputs: [2135 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2025 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2025 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2025 [Constant] outputs: [2136 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_2026 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2135
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2136
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2026 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [2135 -> ()[FLOAT]], [2136 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2135 for ONNX node: 2135
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2136 for ONNX node: 2136
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2137 for ONNX tensor: 2137
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2026 [QuantizeLinear] outputs: [2137 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2027 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2027 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2027 [Constant] outputs: [2138 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2028 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2028 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2028 [Constant] outputs: [2139 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_2029 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2137
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2138
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2139
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2029 [DequantizeLinear] inputs: [2137 -> (64, 64, 3, 3)[FLOAT]], [2138 -> ()[FLOAT]], [2139 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2138 for ONNX node: 2138
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2139 for ONNX node: 2139
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2140 for ONNX tensor: 2140
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2029 [DequantizeLinear] outputs: [2140 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Conv_2030 [Conv]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2134
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2140
[03/01/2023-10:40:58] [V] [TRT] Conv_2030 [Conv] inputs: [2134 -> (1, 64, 22, 22)[FLOAT]], [2140 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Conv_2030 for ONNX node: Conv_2030
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2141 for ONNX tensor: 2141
[03/01/2023-10:40:58] [V] [TRT] Conv_2030 [Conv] outputs: [2141 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: BatchNormalization_2031 [BatchNormalization]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2141
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:40:58] [V] [TRT] BatchNormalization_2031 [BatchNormalization] inputs: [2141 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: BatchNormalization_2031 for ONNX node: BatchNormalization_2031
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2142 for ONNX tensor: 2142
[03/01/2023-10:40:58] [V] [TRT] BatchNormalization_2031 [BatchNormalization] outputs: [2142 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Relu_2032 [Relu]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2142
[03/01/2023-10:40:58] [V] [TRT] Relu_2032 [Relu] inputs: [2142 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: Relu_2032 for ONNX node: Relu_2032
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2143 for ONNX tensor: 2143
[03/01/2023-10:40:58] [V] [TRT] Relu_2032 [Relu] outputs: [2143 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: MaxPool_2033 [MaxPool]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2143
[03/01/2023-10:40:58] [V] [TRT] MaxPool_2033 [MaxPool] inputs: [2143 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: MaxPool_2033 for ONNX node: MaxPool_2033
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2144 for ONNX tensor: 2144
[03/01/2023-10:40:58] [V] [TRT] MaxPool_2033 [MaxPool] outputs: [2144 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2034 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2034 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2034 [Constant] outputs: [2145 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2035 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2035 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2035 [Constant] outputs: [2146 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_2036 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2144
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2145
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2146
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2036 [QuantizeLinear] inputs: [2144 -> (1, 64, 10, 10)[FLOAT]], [2145 -> ()[FLOAT]], [2146 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2145 for ONNX node: 2145
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2146 for ONNX node: 2146
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2147 for ONNX tensor: 2147
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2036 [QuantizeLinear] outputs: [2147 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2037 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2037 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2037 [Constant] outputs: [2148 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2038 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2038 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2038 [Constant] outputs: [2149 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: DequantizeLinear_2039 [DequantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2147
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2148
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2149
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2039 [DequantizeLinear] inputs: [2147 -> (1, 64, 10, 10)[FLOAT]], [2148 -> ()[FLOAT]], [2149 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2148 for ONNX node: 2148
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2149 for ONNX node: 2149
[03/01/2023-10:40:58] [V] [TRT] Registering tensor: 2150 for ONNX tensor: 2150
[03/01/2023-10:40:58] [V] [TRT] DequantizeLinear_2039 [DequantizeLinear] outputs: [2150 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2040 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2040 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2040 [Constant] outputs: [2151 -> ()[FLOAT]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: Constant_2041 [Constant]
[03/01/2023-10:40:58] [V] [TRT] Constant_2041 [Constant] inputs: 
[03/01/2023-10:40:58] [V] [TRT] Constant_2041 [Constant] outputs: [2152 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Parsing node: QuantizeLinear_2042 [QuantizeLinear]
[03/01/2023-10:40:58] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2151
[03/01/2023-10:40:58] [V] [TRT] Searching for input: 2152
[03/01/2023-10:40:58] [V] [TRT] QuantizeLinear_2042 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [2151 -> ()[FLOAT]], [2152 -> ()[INT8]], 
[03/01/2023-10:40:58] [V] [TRT] Registering layer: 2151 for ONNX node: 2151
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2152 for ONNX node: 2152
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2153 for ONNX tensor: 2153
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2042 [QuantizeLinear] outputs: [2153 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2043 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2043 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2043 [Constant] outputs: [2154 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2044 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2044 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2044 [Constant] outputs: [2155 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2045 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2153
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2154
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2155
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2045 [DequantizeLinear] inputs: [2153 -> (128, 64, 3, 3)[FLOAT]], [2154 -> ()[FLOAT]], [2155 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2154 for ONNX node: 2154
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2155 for ONNX node: 2155
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2156 for ONNX tensor: 2156
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2045 [DequantizeLinear] outputs: [2156 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Conv_2046 [Conv]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2150
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2156
[03/01/2023-10:40:59] [V] [TRT] Conv_2046 [Conv] inputs: [2150 -> (1, 64, 10, 10)[FLOAT]], [2156 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Conv_2046 for ONNX node: Conv_2046
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2157 for ONNX tensor: 2157
[03/01/2023-10:40:59] [V] [TRT] Conv_2046 [Conv] outputs: [2157 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: BatchNormalization_2047 [BatchNormalization]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2157
[03/01/2023-10:40:59] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:40:59] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:40:59] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:40:59] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:40:59] [V] [TRT] BatchNormalization_2047 [BatchNormalization] inputs: [2157 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: BatchNormalization_2047 for ONNX node: BatchNormalization_2047
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2158 for ONNX tensor: 2158
[03/01/2023-10:40:59] [V] [TRT] BatchNormalization_2047 [BatchNormalization] outputs: [2158 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Relu_2048 [Relu]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2158
[03/01/2023-10:40:59] [V] [TRT] Relu_2048 [Relu] inputs: [2158 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Relu_2048 for ONNX node: Relu_2048
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2159 for ONNX tensor: 2159
[03/01/2023-10:40:59] [V] [TRT] Relu_2048 [Relu] outputs: [2159 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2049 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2049 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2049 [Constant] outputs: [2160 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2050 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2050 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2050 [Constant] outputs: [2161 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2051 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2159
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2160
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2161
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2051 [QuantizeLinear] inputs: [2159 -> (1, 128, 8, 8)[FLOAT]], [2160 -> ()[FLOAT]], [2161 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2160 for ONNX node: 2160
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2161 for ONNX node: 2161
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2162 for ONNX tensor: 2162
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2051 [QuantizeLinear] outputs: [2162 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2052 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2052 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2052 [Constant] outputs: [2163 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2053 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2053 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2053 [Constant] outputs: [2164 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2054 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2162
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2163
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2164
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2054 [DequantizeLinear] inputs: [2162 -> (1, 128, 8, 8)[FLOAT]], [2163 -> ()[FLOAT]], [2164 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2163 for ONNX node: 2163
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2164 for ONNX node: 2164
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2165 for ONNX tensor: 2165
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2054 [DequantizeLinear] outputs: [2165 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2055 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2055 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2055 [Constant] outputs: [2166 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2056 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2056 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2056 [Constant] outputs: [2167 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2057 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2166
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2167
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2057 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [2166 -> ()[FLOAT]], [2167 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2166 for ONNX node: 2166
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2167 for ONNX node: 2167
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2168 for ONNX tensor: 2168
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2057 [QuantizeLinear] outputs: [2168 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2058 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2058 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2058 [Constant] outputs: [2169 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2059 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2059 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2059 [Constant] outputs: [2170 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2060 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2168
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2169
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2170
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2060 [DequantizeLinear] inputs: [2168 -> (128, 128, 3, 3)[FLOAT]], [2169 -> ()[FLOAT]], [2170 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2169 for ONNX node: 2169
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2170 for ONNX node: 2170
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2171 for ONNX tensor: 2171
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2060 [DequantizeLinear] outputs: [2171 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Conv_2061 [Conv]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2165
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2171
[03/01/2023-10:40:59] [V] [TRT] Conv_2061 [Conv] inputs: [2165 -> (1, 128, 8, 8)[FLOAT]], [2171 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Conv_2061 for ONNX node: Conv_2061
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2172 for ONNX tensor: 2172
[03/01/2023-10:40:59] [V] [TRT] Conv_2061 [Conv] outputs: [2172 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: BatchNormalization_2062 [BatchNormalization]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2172
[03/01/2023-10:40:59] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:40:59] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:40:59] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:40:59] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:40:59] [V] [TRT] BatchNormalization_2062 [BatchNormalization] inputs: [2172 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: BatchNormalization_2062 for ONNX node: BatchNormalization_2062
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2173 for ONNX tensor: 2173
[03/01/2023-10:40:59] [V] [TRT] BatchNormalization_2062 [BatchNormalization] outputs: [2173 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Relu_2063 [Relu]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2173
[03/01/2023-10:40:59] [V] [TRT] Relu_2063 [Relu] inputs: [2173 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Relu_2063 for ONNX node: Relu_2063
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2174 for ONNX tensor: 2174
[03/01/2023-10:40:59] [V] [TRT] Relu_2063 [Relu] outputs: [2174 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: MaxPool_2064 [MaxPool]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2174
[03/01/2023-10:40:59] [V] [TRT] MaxPool_2064 [MaxPool] inputs: [2174 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: MaxPool_2064 for ONNX node: MaxPool_2064
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2175 for ONNX tensor: 2175
[03/01/2023-10:40:59] [V] [TRT] MaxPool_2064 [MaxPool] outputs: [2175 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: ReduceMean_2065 [ReduceMean]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2175
[03/01/2023-10:40:59] [V] [TRT] ReduceMean_2065 [ReduceMean] inputs: [2175 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: ReduceMean_2065 for ONNX node: ReduceMean_2065
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2176 for ONNX tensor: 2176
[03/01/2023-10:40:59] [V] [TRT] ReduceMean_2065 [ReduceMean] outputs: [2176 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: ReduceMax_2066 [ReduceMax]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2175
[03/01/2023-10:40:59] [V] [TRT] ReduceMax_2066 [ReduceMax] inputs: [2175 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: ReduceMax_2066 for ONNX node: ReduceMax_2066
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2177 for ONNX tensor: 2177
[03/01/2023-10:40:59] [V] [TRT] ReduceMax_2066 [ReduceMax] outputs: [2177 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Concat_2067 [Concat]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2176
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2177
[03/01/2023-10:40:59] [V] [TRT] Concat_2067 [Concat] inputs: [2176 -> (1, 1, 3, 3)[FLOAT]], [2177 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Concat_2067 for ONNX node: Concat_2067
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2178 for ONNX tensor: 2178
[03/01/2023-10:40:59] [V] [TRT] Concat_2067 [Concat] outputs: [2178 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2068 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2068 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2068 [Constant] outputs: [2179 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2069 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2069 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2069 [Constant] outputs: [2180 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2070 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2178
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2179
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2180
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2070 [QuantizeLinear] inputs: [2178 -> (1, 2, 3, 3)[FLOAT]], [2179 -> ()[FLOAT]], [2180 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2179 for ONNX node: 2179
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2180 for ONNX node: 2180
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2181 for ONNX tensor: 2181
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2070 [QuantizeLinear] outputs: [2181 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2071 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2071 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2071 [Constant] outputs: [2182 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2072 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2072 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2072 [Constant] outputs: [2183 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2073 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2181
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2182
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2183
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2073 [DequantizeLinear] inputs: [2181 -> (1, 2, 3, 3)[FLOAT]], [2182 -> ()[FLOAT]], [2183 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2182 for ONNX node: 2182
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2183 for ONNX node: 2183
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2184 for ONNX tensor: 2184
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2073 [DequantizeLinear] outputs: [2184 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2074 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2074 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2074 [Constant] outputs: [2185 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2075 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2075 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2075 [Constant] outputs: [2186 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2076 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2185
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2186
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2076 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [2185 -> ()[FLOAT]], [2186 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2185 for ONNX node: 2185
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2186 for ONNX node: 2186
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2187 for ONNX tensor: 2187
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2076 [QuantizeLinear] outputs: [2187 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2077 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2077 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2077 [Constant] outputs: [2188 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2078 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2078 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2078 [Constant] outputs: [2189 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2079 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2187
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2188
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2189
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2079 [DequantizeLinear] inputs: [2187 -> (1, 2, 7, 7)[FLOAT]], [2188 -> ()[FLOAT]], [2189 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2188 for ONNX node: 2188
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2189 for ONNX node: 2189
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2190 for ONNX tensor: 2190
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2079 [DequantizeLinear] outputs: [2190 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Conv_2080 [Conv]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2184
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2190
[03/01/2023-10:40:59] [V] [TRT] Conv_2080 [Conv] inputs: [2184 -> (1, 2, 3, 3)[FLOAT]], [2190 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Conv_2080 for ONNX node: Conv_2080
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2191 for ONNX tensor: 2191
[03/01/2023-10:40:59] [V] [TRT] Conv_2080 [Conv] outputs: [2191 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Sigmoid_2081 [Sigmoid]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2191
[03/01/2023-10:40:59] [V] [TRT] Sigmoid_2081 [Sigmoid] inputs: [2191 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Sigmoid_2081 for ONNX node: Sigmoid_2081
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2192 for ONNX tensor: 2192
[03/01/2023-10:40:59] [V] [TRT] Sigmoid_2081 [Sigmoid] outputs: [2192 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Mul_2082 [Mul]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2175
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2192
[03/01/2023-10:40:59] [V] [TRT] Mul_2082 [Mul] inputs: [2175 -> (1, 128, 3, 3)[FLOAT]], [2192 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Mul_2082 for ONNX node: Mul_2082
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2193 for ONNX tensor: 2193
[03/01/2023-10:40:59] [V] [TRT] Mul_2082 [Mul] outputs: [2193 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: GlobalAveragePool_2083 [GlobalAveragePool]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2193
[03/01/2023-10:40:59] [V] [TRT] GlobalAveragePool_2083 [GlobalAveragePool] inputs: [2193 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:40:59] [V] [TRT] Registering layer: GlobalAveragePool_2083 for ONNX node: GlobalAveragePool_2083
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2194 for ONNX tensor: 2194
[03/01/2023-10:40:59] [V] [TRT] GlobalAveragePool_2083 [GlobalAveragePool] outputs: [2194 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2084 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2084 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2084 [Constant] outputs: [2195 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2085 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2085 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2085 [Constant] outputs: [2196 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2086 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2194
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2195
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2196
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2086 [QuantizeLinear] inputs: [2194 -> (1, 128, 1, 1)[FLOAT]], [2195 -> ()[FLOAT]], [2196 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2195 for ONNX node: 2195
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2196 for ONNX node: 2196
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2197 for ONNX tensor: 2197
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2086 [QuantizeLinear] outputs: [2197 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2087 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2087 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2087 [Constant] outputs: [2198 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2088 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2088 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2088 [Constant] outputs: [2199 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2089 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2197
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2198
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2199
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2089 [DequantizeLinear] inputs: [2197 -> (1, 128, 1, 1)[FLOAT]], [2198 -> ()[FLOAT]], [2199 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2198 for ONNX node: 2198
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2199 for ONNX node: 2199
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2200 for ONNX tensor: 2200
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2089 [DequantizeLinear] outputs: [2200 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2090 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2090 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2090 [Constant] outputs: [2201 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2091 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2091 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2091 [Constant] outputs: [2202 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2092 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2201
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2202
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2092 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2201 -> ()[FLOAT]], [2202 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2201 for ONNX node: 2201
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2202 for ONNX node: 2202
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2203 for ONNX tensor: 2203
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2092 [QuantizeLinear] outputs: [2203 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2093 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2093 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2093 [Constant] outputs: [2204 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2094 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2094 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2094 [Constant] outputs: [2205 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2095 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2203
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2204
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2205
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2095 [DequantizeLinear] inputs: [2203 -> (8, 128, 1, 1)[FLOAT]], [2204 -> ()[FLOAT]], [2205 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2204 for ONNX node: 2204
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2205 for ONNX node: 2205
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2206 for ONNX tensor: 2206
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2095 [DequantizeLinear] outputs: [2206 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Conv_2096 [Conv]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2200
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2206
[03/01/2023-10:40:59] [V] [TRT] Conv_2096 [Conv] inputs: [2200 -> (1, 128, 1, 1)[FLOAT]], [2206 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Conv_2096 for ONNX node: Conv_2096
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2207 for ONNX tensor: 2207
[03/01/2023-10:40:59] [V] [TRT] Conv_2096 [Conv] outputs: [2207 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Relu_2097 [Relu]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2207
[03/01/2023-10:40:59] [V] [TRT] Relu_2097 [Relu] inputs: [2207 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Relu_2097 for ONNX node: Relu_2097
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2208 for ONNX tensor: 2208
[03/01/2023-10:40:59] [V] [TRT] Relu_2097 [Relu] outputs: [2208 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2098 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2098 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2098 [Constant] outputs: [2209 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2099 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2099 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2099 [Constant] outputs: [2210 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2100 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2208
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2209
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2210
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2100 [QuantizeLinear] inputs: [2208 -> (1, 8, 1, 1)[FLOAT]], [2209 -> ()[FLOAT]], [2210 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2209 for ONNX node: 2209
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2210 for ONNX node: 2210
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2211 for ONNX tensor: 2211
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2100 [QuantizeLinear] outputs: [2211 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2101 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2101 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2101 [Constant] outputs: [2212 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2102 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2102 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2102 [Constant] outputs: [2213 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2103 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2211
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2212
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2213
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2103 [DequantizeLinear] inputs: [2211 -> (1, 8, 1, 1)[FLOAT]], [2212 -> ()[FLOAT]], [2213 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2212 for ONNX node: 2212
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2213 for ONNX node: 2213
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2214 for ONNX tensor: 2214
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2103 [DequantizeLinear] outputs: [2214 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2104 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2104 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2104 [Constant] outputs: [2215 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2105 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2105 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2105 [Constant] outputs: [2216 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2106 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2215
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2216
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2106 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2215 -> ()[FLOAT]], [2216 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2215 for ONNX node: 2215
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2216 for ONNX node: 2216
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2217 for ONNX tensor: 2217
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2106 [QuantizeLinear] outputs: [2217 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2107 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2107 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2107 [Constant] outputs: [2218 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2108 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2108 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2108 [Constant] outputs: [2219 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2109 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2217
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2218
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2219
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2109 [DequantizeLinear] inputs: [2217 -> (128, 8, 1, 1)[FLOAT]], [2218 -> ()[FLOAT]], [2219 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2218 for ONNX node: 2218
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2219 for ONNX node: 2219
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2220 for ONNX tensor: 2220
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2109 [DequantizeLinear] outputs: [2220 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Conv_2110 [Conv]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2214
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2220
[03/01/2023-10:40:59] [V] [TRT] Conv_2110 [Conv] inputs: [2214 -> (1, 8, 1, 1)[FLOAT]], [2220 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:40:59] [V] [TRT] Registering layer: Conv_2110 for ONNX node: Conv_2110
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2221 for ONNX tensor: 2221
[03/01/2023-10:40:59] [V] [TRT] Conv_2110 [Conv] outputs: [2221 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: MaxPool_2111 [MaxPool]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2193
[03/01/2023-10:40:59] [V] [TRT] MaxPool_2111 [MaxPool] inputs: [2193 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: MaxPool_2111 for ONNX node: MaxPool_2111
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2222 for ONNX tensor: 2222
[03/01/2023-10:40:59] [V] [TRT] MaxPool_2111 [MaxPool] outputs: [2222 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2112 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2112 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2112 [Constant] outputs: [2223 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2113 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2113 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2113 [Constant] outputs: [2224 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2114 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2222
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2223
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2224
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2114 [QuantizeLinear] inputs: [2222 -> (1, 128, 1, 1)[FLOAT]], [2223 -> ()[FLOAT]], [2224 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2223 for ONNX node: 2223
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2224 for ONNX node: 2224
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2225 for ONNX tensor: 2225
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2114 [QuantizeLinear] outputs: [2225 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2115 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2115 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2115 [Constant] outputs: [2226 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2116 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2116 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2116 [Constant] outputs: [2227 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: DequantizeLinear_2117 [DequantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2225
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2226
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2227
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2117 [DequantizeLinear] inputs: [2225 -> (1, 128, 1, 1)[FLOAT]], [2226 -> ()[FLOAT]], [2227 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2226 for ONNX node: 2226
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2227 for ONNX node: 2227
[03/01/2023-10:40:59] [V] [TRT] Registering tensor: 2228 for ONNX tensor: 2228
[03/01/2023-10:40:59] [V] [TRT] DequantizeLinear_2117 [DequantizeLinear] outputs: [2228 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2118 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2118 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2118 [Constant] outputs: [2229 -> ()[FLOAT]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: Constant_2119 [Constant]
[03/01/2023-10:40:59] [V] [TRT] Constant_2119 [Constant] inputs: 
[03/01/2023-10:40:59] [V] [TRT] Constant_2119 [Constant] outputs: [2230 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Parsing node: QuantizeLinear_2120 [QuantizeLinear]
[03/01/2023-10:40:59] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2229
[03/01/2023-10:40:59] [V] [TRT] Searching for input: 2230
[03/01/2023-10:40:59] [V] [TRT] QuantizeLinear_2120 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2229 -> ()[FLOAT]], [2230 -> ()[INT8]], 
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2229 for ONNX node: 2229
[03/01/2023-10:40:59] [V] [TRT] Registering layer: 2230 for ONNX node: 2230
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2231 for ONNX tensor: 2231
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2120 [QuantizeLinear] outputs: [2231 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2121 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2121 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2121 [Constant] outputs: [2232 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2122 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2122 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2122 [Constant] outputs: [2233 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: DequantizeLinear_2123 [DequantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2231
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2232
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2233
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2123 [DequantizeLinear] inputs: [2231 -> (8, 128, 1, 1)[FLOAT]], [2232 -> ()[FLOAT]], [2233 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2232 for ONNX node: 2232
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2233 for ONNX node: 2233
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2234 for ONNX tensor: 2234
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2123 [DequantizeLinear] outputs: [2234 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Conv_2124 [Conv]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2228
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2234
[03/01/2023-10:41:00] [V] [TRT] Conv_2124 [Conv] inputs: [2228 -> (1, 128, 1, 1)[FLOAT]], [2234 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Conv_2124 for ONNX node: Conv_2124
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2235 for ONNX tensor: 2235
[03/01/2023-10:41:00] [V] [TRT] Conv_2124 [Conv] outputs: [2235 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Relu_2125 [Relu]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2235
[03/01/2023-10:41:00] [V] [TRT] Relu_2125 [Relu] inputs: [2235 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Relu_2125 for ONNX node: Relu_2125
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2236 for ONNX tensor: 2236
[03/01/2023-10:41:00] [V] [TRT] Relu_2125 [Relu] outputs: [2236 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2126 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2126 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2126 [Constant] outputs: [2237 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2127 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2127 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2127 [Constant] outputs: [2238 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: QuantizeLinear_2128 [QuantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2236
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2237
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2238
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2128 [QuantizeLinear] inputs: [2236 -> (1, 8, 1, 1)[FLOAT]], [2237 -> ()[FLOAT]], [2238 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2237 for ONNX node: 2237
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2238 for ONNX node: 2238
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2239 for ONNX tensor: 2239
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2128 [QuantizeLinear] outputs: [2239 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2129 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2129 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2129 [Constant] outputs: [2240 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2130 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2130 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2130 [Constant] outputs: [2241 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: DequantizeLinear_2131 [DequantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2239
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2240
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2241
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2131 [DequantizeLinear] inputs: [2239 -> (1, 8, 1, 1)[FLOAT]], [2240 -> ()[FLOAT]], [2241 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2240 for ONNX node: 2240
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2241 for ONNX node: 2241
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2242 for ONNX tensor: 2242
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2131 [DequantizeLinear] outputs: [2242 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2132 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2132 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2132 [Constant] outputs: [2243 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2133 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2133 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2133 [Constant] outputs: [2244 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: QuantizeLinear_2134 [QuantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2243
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2244
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2134 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2243 -> ()[FLOAT]], [2244 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2243 for ONNX node: 2243
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2244 for ONNX node: 2244
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2245 for ONNX tensor: 2245
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2134 [QuantizeLinear] outputs: [2245 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2135 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2135 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2135 [Constant] outputs: [2246 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2136 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2136 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2136 [Constant] outputs: [2247 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: DequantizeLinear_2137 [DequantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2245
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2246
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2247
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2137 [DequantizeLinear] inputs: [2245 -> (128, 8, 1, 1)[FLOAT]], [2246 -> ()[FLOAT]], [2247 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2246 for ONNX node: 2246
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2247 for ONNX node: 2247
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2248 for ONNX tensor: 2248
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2137 [DequantizeLinear] outputs: [2248 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Conv_2138 [Conv]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2242
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2248
[03/01/2023-10:41:00] [V] [TRT] Conv_2138 [Conv] inputs: [2242 -> (1, 8, 1, 1)[FLOAT]], [2248 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Conv_2138 for ONNX node: Conv_2138
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2249 for ONNX tensor: 2249
[03/01/2023-10:41:00] [V] [TRT] Conv_2138 [Conv] outputs: [2249 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Add_2139 [Add]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2221
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2249
[03/01/2023-10:41:00] [V] [TRT] Add_2139 [Add] inputs: [2221 -> (1, 128, 1, 1)[FLOAT]], [2249 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Add_2139 for ONNX node: Add_2139
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2250 for ONNX tensor: 2250
[03/01/2023-10:41:00] [V] [TRT] Add_2139 [Add] outputs: [2250 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Sigmoid_2140 [Sigmoid]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2250
[03/01/2023-10:41:00] [V] [TRT] Sigmoid_2140 [Sigmoid] inputs: [2250 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Sigmoid_2140 for ONNX node: Sigmoid_2140
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2251 for ONNX tensor: 2251
[03/01/2023-10:41:00] [V] [TRT] Sigmoid_2140 [Sigmoid] outputs: [2251 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Mul_2141 [Mul]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2193
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2251
[03/01/2023-10:41:00] [V] [TRT] Mul_2141 [Mul] inputs: [2193 -> (1, 128, 3, 3)[FLOAT]], [2251 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Mul_2141 for ONNX node: Mul_2141
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2252 for ONNX tensor: 2252
[03/01/2023-10:41:00] [V] [TRT] Mul_2141 [Mul] outputs: [2252 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Concat_2142 [Concat]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2103
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2252
[03/01/2023-10:41:00] [V] [TRT] Concat_2142 [Concat] inputs: [2103 -> (1, 1536, 3, 3)[FLOAT]], [2252 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Concat_2142 for ONNX node: Concat_2142
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2253 for ONNX tensor: 2253
[03/01/2023-10:41:00] [V] [TRT] Concat_2142 [Concat] outputs: [2253 -> (1, 1664, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2143 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2143 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2143 [Constant] outputs: [2254 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2144 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2144 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2144 [Constant] outputs: [2255 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2145 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2145 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2145 [Constant] outputs: [2256 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2146 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2146 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2146 [Constant] outputs: [2257 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Slice_2147 [Slice]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: input
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2255
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2256
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2254
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2257
[03/01/2023-10:41:00] [V] [TRT] Slice_2147 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [2255 -> (1)[INT32]], [2256 -> (1)[INT32]], [2254 -> (1)[INT32]], [2257 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Slice_2147 for ONNX node: Slice_2147
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2258 for ONNX tensor: 2258
[03/01/2023-10:41:00] [V] [TRT] Slice_2147 [Slice] outputs: [2258 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2148 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2148 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2148 [Constant] outputs: [2259 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2149 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2149 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2149 [Constant] outputs: [2260 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2150 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2150 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2150 [Constant] outputs: [2261 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2151 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2151 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2151 [Constant] outputs: [2262 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Slice_2152 [Slice]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2258
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2260
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2261
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2259
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2262
[03/01/2023-10:41:00] [V] [TRT] Slice_2152 [Slice] inputs: [2258 -> (1, 1, 24, 60)[FLOAT]], [2260 -> (1)[INT32]], [2261 -> (1)[INT32]], [2259 -> (1)[INT32]], [2262 -> (1)[INT32]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Slice_2152 for ONNX node: Slice_2152
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2263 for ONNX tensor: 2263
[03/01/2023-10:41:00] [V] [TRT] Slice_2152 [Slice] outputs: [2263 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2153 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2153 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2153 [Constant] outputs: [2264 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2154 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2154 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2154 [Constant] outputs: [2265 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: QuantizeLinear_2155 [QuantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2263
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2264
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2265
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2155 [QuantizeLinear] inputs: [2263 -> (1, 1, 24, 24)[FLOAT]], [2264 -> ()[FLOAT]], [2265 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2264 for ONNX node: 2264
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2265 for ONNX node: 2265
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2266 for ONNX tensor: 2266
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2155 [QuantizeLinear] outputs: [2266 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2156 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2156 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2156 [Constant] outputs: [2267 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2157 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2157 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2157 [Constant] outputs: [2268 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: DequantizeLinear_2158 [DequantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2266
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2267
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2268
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2158 [DequantizeLinear] inputs: [2266 -> (1, 1, 24, 24)[FLOAT]], [2267 -> ()[FLOAT]], [2268 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2267 for ONNX node: 2267
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2268 for ONNX node: 2268
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2269 for ONNX tensor: 2269
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2158 [DequantizeLinear] outputs: [2269 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2159 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2159 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2159 [Constant] outputs: [2270 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2160 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2160 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2160 [Constant] outputs: [2271 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: QuantizeLinear_2161 [QuantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2270
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2271
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2161 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [2270 -> ()[FLOAT]], [2271 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2270 for ONNX node: 2270
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2271 for ONNX node: 2271
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2272 for ONNX tensor: 2272
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2161 [QuantizeLinear] outputs: [2272 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2162 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2162 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2162 [Constant] outputs: [2273 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2163 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2163 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2163 [Constant] outputs: [2274 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: DequantizeLinear_2164 [DequantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2272
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2273
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2274
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2164 [DequantizeLinear] inputs: [2272 -> (64, 1, 3, 3)[FLOAT]], [2273 -> ()[FLOAT]], [2274 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2273 for ONNX node: 2273
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2274 for ONNX node: 2274
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2275 for ONNX tensor: 2275
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2164 [DequantizeLinear] outputs: [2275 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Conv_2165 [Conv]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2269
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2275
[03/01/2023-10:41:00] [V] [TRT] Conv_2165 [Conv] inputs: [2269 -> (1, 1, 24, 24)[FLOAT]], [2275 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Conv_2165 for ONNX node: Conv_2165
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2276 for ONNX tensor: 2276
[03/01/2023-10:41:00] [V] [TRT] Conv_2165 [Conv] outputs: [2276 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: BatchNormalization_2166 [BatchNormalization]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2276
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:41:00] [V] [TRT] BatchNormalization_2166 [BatchNormalization] inputs: [2276 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: BatchNormalization_2166 for ONNX node: BatchNormalization_2166
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2277 for ONNX tensor: 2277
[03/01/2023-10:41:00] [V] [TRT] BatchNormalization_2166 [BatchNormalization] outputs: [2277 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Relu_2167 [Relu]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2277
[03/01/2023-10:41:00] [V] [TRT] Relu_2167 [Relu] inputs: [2277 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Relu_2167 for ONNX node: Relu_2167
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2278 for ONNX tensor: 2278
[03/01/2023-10:41:00] [V] [TRT] Relu_2167 [Relu] outputs: [2278 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2168 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2168 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2168 [Constant] outputs: [2279 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2169 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2169 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2169 [Constant] outputs: [2280 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: QuantizeLinear_2170 [QuantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2278
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2279
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2280
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2170 [QuantizeLinear] inputs: [2278 -> (1, 64, 22, 22)[FLOAT]], [2279 -> ()[FLOAT]], [2280 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2279 for ONNX node: 2279
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2280 for ONNX node: 2280
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2281 for ONNX tensor: 2281
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2170 [QuantizeLinear] outputs: [2281 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2171 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2171 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2171 [Constant] outputs: [2282 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2172 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2172 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2172 [Constant] outputs: [2283 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: DequantizeLinear_2173 [DequantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2281
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2282
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2283
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2173 [DequantizeLinear] inputs: [2281 -> (1, 64, 22, 22)[FLOAT]], [2282 -> ()[FLOAT]], [2283 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2282 for ONNX node: 2282
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2283 for ONNX node: 2283
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2284 for ONNX tensor: 2284
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2173 [DequantizeLinear] outputs: [2284 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2174 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2174 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2174 [Constant] outputs: [2285 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2175 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2175 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2175 [Constant] outputs: [2286 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: QuantizeLinear_2176 [QuantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2285
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2286
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2176 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [2285 -> ()[FLOAT]], [2286 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2285 for ONNX node: 2285
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2286 for ONNX node: 2286
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2287 for ONNX tensor: 2287
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2176 [QuantizeLinear] outputs: [2287 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2177 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2177 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2177 [Constant] outputs: [2288 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2178 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2178 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2178 [Constant] outputs: [2289 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: DequantizeLinear_2179 [DequantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2287
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2288
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2289
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2179 [DequantizeLinear] inputs: [2287 -> (64, 64, 3, 3)[FLOAT]], [2288 -> ()[FLOAT]], [2289 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2288 for ONNX node: 2288
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2289 for ONNX node: 2289
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2290 for ONNX tensor: 2290
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2179 [DequantizeLinear] outputs: [2290 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Conv_2180 [Conv]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2284
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2290
[03/01/2023-10:41:00] [V] [TRT] Conv_2180 [Conv] inputs: [2284 -> (1, 64, 22, 22)[FLOAT]], [2290 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Conv_2180 for ONNX node: Conv_2180
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2291 for ONNX tensor: 2291
[03/01/2023-10:41:00] [V] [TRT] Conv_2180 [Conv] outputs: [2291 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: BatchNormalization_2181 [BatchNormalization]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2291
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:41:00] [V] [TRT] BatchNormalization_2181 [BatchNormalization] inputs: [2291 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: BatchNormalization_2181 for ONNX node: BatchNormalization_2181
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2292 for ONNX tensor: 2292
[03/01/2023-10:41:00] [V] [TRT] BatchNormalization_2181 [BatchNormalization] outputs: [2292 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Relu_2182 [Relu]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2292
[03/01/2023-10:41:00] [V] [TRT] Relu_2182 [Relu] inputs: [2292 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Relu_2182 for ONNX node: Relu_2182
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2293 for ONNX tensor: 2293
[03/01/2023-10:41:00] [V] [TRT] Relu_2182 [Relu] outputs: [2293 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: MaxPool_2183 [MaxPool]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2293
[03/01/2023-10:41:00] [V] [TRT] MaxPool_2183 [MaxPool] inputs: [2293 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: MaxPool_2183 for ONNX node: MaxPool_2183
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2294 for ONNX tensor: 2294
[03/01/2023-10:41:00] [V] [TRT] MaxPool_2183 [MaxPool] outputs: [2294 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2184 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2184 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2184 [Constant] outputs: [2295 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2185 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2185 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2185 [Constant] outputs: [2296 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: QuantizeLinear_2186 [QuantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2294
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2295
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2296
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2186 [QuantizeLinear] inputs: [2294 -> (1, 64, 10, 10)[FLOAT]], [2295 -> ()[FLOAT]], [2296 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2295 for ONNX node: 2295
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2296 for ONNX node: 2296
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2297 for ONNX tensor: 2297
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2186 [QuantizeLinear] outputs: [2297 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2187 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2187 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2187 [Constant] outputs: [2298 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2188 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2188 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2188 [Constant] outputs: [2299 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: DequantizeLinear_2189 [DequantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2297
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2298
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2299
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2189 [DequantizeLinear] inputs: [2297 -> (1, 64, 10, 10)[FLOAT]], [2298 -> ()[FLOAT]], [2299 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2298 for ONNX node: 2298
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2299 for ONNX node: 2299
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2300 for ONNX tensor: 2300
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2189 [DequantizeLinear] outputs: [2300 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2190 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2190 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2190 [Constant] outputs: [2301 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2191 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2191 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2191 [Constant] outputs: [2302 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: QuantizeLinear_2192 [QuantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2301
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2302
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2192 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [2301 -> ()[FLOAT]], [2302 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2301 for ONNX node: 2301
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2302 for ONNX node: 2302
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2303 for ONNX tensor: 2303
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2192 [QuantizeLinear] outputs: [2303 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2193 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2193 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2193 [Constant] outputs: [2304 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2194 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2194 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2194 [Constant] outputs: [2305 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: DequantizeLinear_2195 [DequantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2303
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2304
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2305
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2195 [DequantizeLinear] inputs: [2303 -> (128, 64, 3, 3)[FLOAT]], [2304 -> ()[FLOAT]], [2305 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2304 for ONNX node: 2304
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2305 for ONNX node: 2305
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2306 for ONNX tensor: 2306
[03/01/2023-10:41:00] [V] [TRT] DequantizeLinear_2195 [DequantizeLinear] outputs: [2306 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Conv_2196 [Conv]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2300
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2306
[03/01/2023-10:41:00] [V] [TRT] Conv_2196 [Conv] inputs: [2300 -> (1, 64, 10, 10)[FLOAT]], [2306 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Conv_2196 for ONNX node: Conv_2196
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2307 for ONNX tensor: 2307
[03/01/2023-10:41:00] [V] [TRT] Conv_2196 [Conv] outputs: [2307 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: BatchNormalization_2197 [BatchNormalization]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2307
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:41:00] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:41:00] [V] [TRT] BatchNormalization_2197 [BatchNormalization] inputs: [2307 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: BatchNormalization_2197 for ONNX node: BatchNormalization_2197
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2308 for ONNX tensor: 2308
[03/01/2023-10:41:00] [V] [TRT] BatchNormalization_2197 [BatchNormalization] outputs: [2308 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Relu_2198 [Relu]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2308
[03/01/2023-10:41:00] [V] [TRT] Relu_2198 [Relu] inputs: [2308 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: Relu_2198 for ONNX node: Relu_2198
[03/01/2023-10:41:00] [V] [TRT] Registering tensor: 2309 for ONNX tensor: 2309
[03/01/2023-10:41:00] [V] [TRT] Relu_2198 [Relu] outputs: [2309 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2199 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2199 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2199 [Constant] outputs: [2310 -> ()[FLOAT]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: Constant_2200 [Constant]
[03/01/2023-10:41:00] [V] [TRT] Constant_2200 [Constant] inputs: 
[03/01/2023-10:41:00] [V] [TRT] Constant_2200 [Constant] outputs: [2311 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Parsing node: QuantizeLinear_2201 [QuantizeLinear]
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2309
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2310
[03/01/2023-10:41:00] [V] [TRT] Searching for input: 2311
[03/01/2023-10:41:00] [V] [TRT] QuantizeLinear_2201 [QuantizeLinear] inputs: [2309 -> (1, 128, 8, 8)[FLOAT]], [2310 -> ()[FLOAT]], [2311 -> ()[INT8]], 
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2310 for ONNX node: 2310
[03/01/2023-10:41:00] [V] [TRT] Registering layer: 2311 for ONNX node: 2311
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2312 for ONNX tensor: 2312
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2201 [QuantizeLinear] outputs: [2312 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2202 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2202 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2202 [Constant] outputs: [2313 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2203 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2203 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2203 [Constant] outputs: [2314 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2204 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2312
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2313
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2314
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2204 [DequantizeLinear] inputs: [2312 -> (1, 128, 8, 8)[FLOAT]], [2313 -> ()[FLOAT]], [2314 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2313 for ONNX node: 2313
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2314 for ONNX node: 2314
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2315 for ONNX tensor: 2315
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2204 [DequantizeLinear] outputs: [2315 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2205 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2205 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2205 [Constant] outputs: [2316 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2206 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2206 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2206 [Constant] outputs: [2317 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: QuantizeLinear_2207 [QuantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2316
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2317
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2207 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [2316 -> ()[FLOAT]], [2317 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2316 for ONNX node: 2316
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2317 for ONNX node: 2317
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2318 for ONNX tensor: 2318
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2207 [QuantizeLinear] outputs: [2318 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2208 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2208 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2208 [Constant] outputs: [2319 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2209 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2209 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2209 [Constant] outputs: [2320 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2210 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2318
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2319
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2320
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2210 [DequantizeLinear] inputs: [2318 -> (128, 128, 3, 3)[FLOAT]], [2319 -> ()[FLOAT]], [2320 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2319 for ONNX node: 2319
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2320 for ONNX node: 2320
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2321 for ONNX tensor: 2321
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2210 [DequantizeLinear] outputs: [2321 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Conv_2211 [Conv]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2315
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2321
[03/01/2023-10:41:01] [V] [TRT] Conv_2211 [Conv] inputs: [2315 -> (1, 128, 8, 8)[FLOAT]], [2321 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:01] [V] [TRT] Registering layer: Conv_2211 for ONNX node: Conv_2211
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2322 for ONNX tensor: 2322
[03/01/2023-10:41:01] [V] [TRT] Conv_2211 [Conv] outputs: [2322 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: BatchNormalization_2212 [BatchNormalization]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2322
[03/01/2023-10:41:01] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:41:01] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:41:01] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:41:01] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:41:01] [V] [TRT] BatchNormalization_2212 [BatchNormalization] inputs: [2322 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: BatchNormalization_2212 for ONNX node: BatchNormalization_2212
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2323 for ONNX tensor: 2323
[03/01/2023-10:41:01] [V] [TRT] BatchNormalization_2212 [BatchNormalization] outputs: [2323 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Relu_2213 [Relu]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2323
[03/01/2023-10:41:01] [V] [TRT] Relu_2213 [Relu] inputs: [2323 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: Relu_2213 for ONNX node: Relu_2213
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2324 for ONNX tensor: 2324
[03/01/2023-10:41:01] [V] [TRT] Relu_2213 [Relu] outputs: [2324 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: MaxPool_2214 [MaxPool]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2324
[03/01/2023-10:41:01] [V] [TRT] MaxPool_2214 [MaxPool] inputs: [2324 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: MaxPool_2214 for ONNX node: MaxPool_2214
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2325 for ONNX tensor: 2325
[03/01/2023-10:41:01] [V] [TRT] MaxPool_2214 [MaxPool] outputs: [2325 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: ReduceMean_2215 [ReduceMean]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2325
[03/01/2023-10:41:01] [V] [TRT] ReduceMean_2215 [ReduceMean] inputs: [2325 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: ReduceMean_2215 for ONNX node: ReduceMean_2215
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2326 for ONNX tensor: 2326
[03/01/2023-10:41:01] [V] [TRT] ReduceMean_2215 [ReduceMean] outputs: [2326 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: ReduceMax_2216 [ReduceMax]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2325
[03/01/2023-10:41:01] [V] [TRT] ReduceMax_2216 [ReduceMax] inputs: [2325 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: ReduceMax_2216 for ONNX node: ReduceMax_2216
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2327 for ONNX tensor: 2327
[03/01/2023-10:41:01] [V] [TRT] ReduceMax_2216 [ReduceMax] outputs: [2327 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Concat_2217 [Concat]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2326
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2327
[03/01/2023-10:41:01] [V] [TRT] Concat_2217 [Concat] inputs: [2326 -> (1, 1, 3, 3)[FLOAT]], [2327 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: Concat_2217 for ONNX node: Concat_2217
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2328 for ONNX tensor: 2328
[03/01/2023-10:41:01] [V] [TRT] Concat_2217 [Concat] outputs: [2328 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2218 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2218 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2218 [Constant] outputs: [2329 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2219 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2219 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2219 [Constant] outputs: [2330 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: QuantizeLinear_2220 [QuantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2328
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2329
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2330
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2220 [QuantizeLinear] inputs: [2328 -> (1, 2, 3, 3)[FLOAT]], [2329 -> ()[FLOAT]], [2330 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2329 for ONNX node: 2329
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2330 for ONNX node: 2330
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2331 for ONNX tensor: 2331
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2220 [QuantizeLinear] outputs: [2331 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2221 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2221 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2221 [Constant] outputs: [2332 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2222 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2222 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2222 [Constant] outputs: [2333 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2223 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2331
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2332
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2333
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2223 [DequantizeLinear] inputs: [2331 -> (1, 2, 3, 3)[FLOAT]], [2332 -> ()[FLOAT]], [2333 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2332 for ONNX node: 2332
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2333 for ONNX node: 2333
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2334 for ONNX tensor: 2334
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2223 [DequantizeLinear] outputs: [2334 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2224 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2224 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2224 [Constant] outputs: [2335 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2225 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2225 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2225 [Constant] outputs: [2336 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: QuantizeLinear_2226 [QuantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2335
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2336
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2226 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [2335 -> ()[FLOAT]], [2336 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2335 for ONNX node: 2335
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2336 for ONNX node: 2336
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2337 for ONNX tensor: 2337
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2226 [QuantizeLinear] outputs: [2337 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2227 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2227 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2227 [Constant] outputs: [2338 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2228 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2228 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2228 [Constant] outputs: [2339 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2229 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2337
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2338
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2339
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2229 [DequantizeLinear] inputs: [2337 -> (1, 2, 7, 7)[FLOAT]], [2338 -> ()[FLOAT]], [2339 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2338 for ONNX node: 2338
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2339 for ONNX node: 2339
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2340 for ONNX tensor: 2340
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2229 [DequantizeLinear] outputs: [2340 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Conv_2230 [Conv]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2334
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2340
[03/01/2023-10:41:01] [V] [TRT] Conv_2230 [Conv] inputs: [2334 -> (1, 2, 3, 3)[FLOAT]], [2340 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:01] [V] [TRT] Registering layer: Conv_2230 for ONNX node: Conv_2230
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2341 for ONNX tensor: 2341
[03/01/2023-10:41:01] [V] [TRT] Conv_2230 [Conv] outputs: [2341 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Sigmoid_2231 [Sigmoid]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2341
[03/01/2023-10:41:01] [V] [TRT] Sigmoid_2231 [Sigmoid] inputs: [2341 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: Sigmoid_2231 for ONNX node: Sigmoid_2231
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2342 for ONNX tensor: 2342
[03/01/2023-10:41:01] [V] [TRT] Sigmoid_2231 [Sigmoid] outputs: [2342 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Mul_2232 [Mul]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2325
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2342
[03/01/2023-10:41:01] [V] [TRT] Mul_2232 [Mul] inputs: [2325 -> (1, 128, 3, 3)[FLOAT]], [2342 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: Mul_2232 for ONNX node: Mul_2232
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2343 for ONNX tensor: 2343
[03/01/2023-10:41:01] [V] [TRT] Mul_2232 [Mul] outputs: [2343 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: GlobalAveragePool_2233 [GlobalAveragePool]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2343
[03/01/2023-10:41:01] [V] [TRT] GlobalAveragePool_2233 [GlobalAveragePool] inputs: [2343 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:41:01] [V] [TRT] Registering layer: GlobalAveragePool_2233 for ONNX node: GlobalAveragePool_2233
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2344 for ONNX tensor: 2344
[03/01/2023-10:41:01] [V] [TRT] GlobalAveragePool_2233 [GlobalAveragePool] outputs: [2344 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2234 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2234 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2234 [Constant] outputs: [2345 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2235 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2235 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2235 [Constant] outputs: [2346 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: QuantizeLinear_2236 [QuantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2344
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2345
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2346
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2236 [QuantizeLinear] inputs: [2344 -> (1, 128, 1, 1)[FLOAT]], [2345 -> ()[FLOAT]], [2346 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2345 for ONNX node: 2345
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2346 for ONNX node: 2346
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2347 for ONNX tensor: 2347
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2236 [QuantizeLinear] outputs: [2347 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2237 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2237 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2237 [Constant] outputs: [2348 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2238 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2238 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2238 [Constant] outputs: [2349 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2239 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2347
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2348
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2349
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2239 [DequantizeLinear] inputs: [2347 -> (1, 128, 1, 1)[FLOAT]], [2348 -> ()[FLOAT]], [2349 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2348 for ONNX node: 2348
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2349 for ONNX node: 2349
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2350 for ONNX tensor: 2350
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2239 [DequantizeLinear] outputs: [2350 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2240 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2240 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2240 [Constant] outputs: [2351 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2241 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2241 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2241 [Constant] outputs: [2352 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: QuantizeLinear_2242 [QuantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2351
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2352
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2242 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2351 -> ()[FLOAT]], [2352 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2351 for ONNX node: 2351
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2352 for ONNX node: 2352
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2353 for ONNX tensor: 2353
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2242 [QuantizeLinear] outputs: [2353 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2243 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2243 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2243 [Constant] outputs: [2354 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2244 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2244 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2244 [Constant] outputs: [2355 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2245 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2353
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2354
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2355
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2245 [DequantizeLinear] inputs: [2353 -> (8, 128, 1, 1)[FLOAT]], [2354 -> ()[FLOAT]], [2355 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2354 for ONNX node: 2354
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2355 for ONNX node: 2355
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2356 for ONNX tensor: 2356
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2245 [DequantizeLinear] outputs: [2356 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Conv_2246 [Conv]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2350
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2356
[03/01/2023-10:41:01] [V] [TRT] Conv_2246 [Conv] inputs: [2350 -> (1, 128, 1, 1)[FLOAT]], [2356 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:01] [V] [TRT] Registering layer: Conv_2246 for ONNX node: Conv_2246
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2357 for ONNX tensor: 2357
[03/01/2023-10:41:01] [V] [TRT] Conv_2246 [Conv] outputs: [2357 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Relu_2247 [Relu]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2357
[03/01/2023-10:41:01] [V] [TRT] Relu_2247 [Relu] inputs: [2357 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: Relu_2247 for ONNX node: Relu_2247
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2358 for ONNX tensor: 2358
[03/01/2023-10:41:01] [V] [TRT] Relu_2247 [Relu] outputs: [2358 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2248 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2248 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2248 [Constant] outputs: [2359 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2249 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2249 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2249 [Constant] outputs: [2360 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: QuantizeLinear_2250 [QuantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2358
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2359
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2360
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2250 [QuantizeLinear] inputs: [2358 -> (1, 8, 1, 1)[FLOAT]], [2359 -> ()[FLOAT]], [2360 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2359 for ONNX node: 2359
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2360 for ONNX node: 2360
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2361 for ONNX tensor: 2361
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2250 [QuantizeLinear] outputs: [2361 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2251 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2251 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2251 [Constant] outputs: [2362 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2252 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2252 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2252 [Constant] outputs: [2363 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2253 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2361
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2362
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2363
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2253 [DequantizeLinear] inputs: [2361 -> (1, 8, 1, 1)[FLOAT]], [2362 -> ()[FLOAT]], [2363 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2362 for ONNX node: 2362
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2363 for ONNX node: 2363
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2364 for ONNX tensor: 2364
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2253 [DequantizeLinear] outputs: [2364 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2254 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2254 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2254 [Constant] outputs: [2365 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2255 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2255 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2255 [Constant] outputs: [2366 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: QuantizeLinear_2256 [QuantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2365
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2366
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2256 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2365 -> ()[FLOAT]], [2366 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2365 for ONNX node: 2365
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2366 for ONNX node: 2366
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2367 for ONNX tensor: 2367
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2256 [QuantizeLinear] outputs: [2367 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2257 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2257 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2257 [Constant] outputs: [2368 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2258 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2258 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2258 [Constant] outputs: [2369 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2259 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2367
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2368
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2369
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2259 [DequantizeLinear] inputs: [2367 -> (128, 8, 1, 1)[FLOAT]], [2368 -> ()[FLOAT]], [2369 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2368 for ONNX node: 2368
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2369 for ONNX node: 2369
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2370 for ONNX tensor: 2370
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2259 [DequantizeLinear] outputs: [2370 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Conv_2260 [Conv]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2364
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2370
[03/01/2023-10:41:01] [V] [TRT] Conv_2260 [Conv] inputs: [2364 -> (1, 8, 1, 1)[FLOAT]], [2370 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:01] [V] [TRT] Registering layer: Conv_2260 for ONNX node: Conv_2260
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2371 for ONNX tensor: 2371
[03/01/2023-10:41:01] [V] [TRT] Conv_2260 [Conv] outputs: [2371 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: MaxPool_2261 [MaxPool]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2343
[03/01/2023-10:41:01] [V] [TRT] MaxPool_2261 [MaxPool] inputs: [2343 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: MaxPool_2261 for ONNX node: MaxPool_2261
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2372 for ONNX tensor: 2372
[03/01/2023-10:41:01] [V] [TRT] MaxPool_2261 [MaxPool] outputs: [2372 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2262 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2262 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2262 [Constant] outputs: [2373 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2263 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2263 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2263 [Constant] outputs: [2374 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: QuantizeLinear_2264 [QuantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2372
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2373
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2374
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2264 [QuantizeLinear] inputs: [2372 -> (1, 128, 1, 1)[FLOAT]], [2373 -> ()[FLOAT]], [2374 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2373 for ONNX node: 2373
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2374 for ONNX node: 2374
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2375 for ONNX tensor: 2375
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2264 [QuantizeLinear] outputs: [2375 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2265 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2265 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2265 [Constant] outputs: [2376 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2266 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2266 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2266 [Constant] outputs: [2377 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2267 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2375
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2376
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2377
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2267 [DequantizeLinear] inputs: [2375 -> (1, 128, 1, 1)[FLOAT]], [2376 -> ()[FLOAT]], [2377 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2376 for ONNX node: 2376
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2377 for ONNX node: 2377
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2378 for ONNX tensor: 2378
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2267 [DequantizeLinear] outputs: [2378 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2268 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2268 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2268 [Constant] outputs: [2379 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2269 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2269 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2269 [Constant] outputs: [2380 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: QuantizeLinear_2270 [QuantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2379
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2380
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2270 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2379 -> ()[FLOAT]], [2380 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2379 for ONNX node: 2379
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2380 for ONNX node: 2380
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2381 for ONNX tensor: 2381
[03/01/2023-10:41:01] [V] [TRT] QuantizeLinear_2270 [QuantizeLinear] outputs: [2381 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2271 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2271 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2271 [Constant] outputs: [2382 -> ()[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Constant_2272 [Constant]
[03/01/2023-10:41:01] [V] [TRT] Constant_2272 [Constant] inputs: 
[03/01/2023-10:41:01] [V] [TRT] Constant_2272 [Constant] outputs: [2383 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: DequantizeLinear_2273 [DequantizeLinear]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2381
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2382
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2383
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2273 [DequantizeLinear] inputs: [2381 -> (8, 128, 1, 1)[FLOAT]], [2382 -> ()[FLOAT]], [2383 -> ()[INT8]], 
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2382 for ONNX node: 2382
[03/01/2023-10:41:01] [V] [TRT] Registering layer: 2383 for ONNX node: 2383
[03/01/2023-10:41:01] [V] [TRT] Registering tensor: 2384 for ONNX tensor: 2384
[03/01/2023-10:41:01] [V] [TRT] DequantizeLinear_2273 [DequantizeLinear] outputs: [2384 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:01] [V] [TRT] Parsing node: Conv_2274 [Conv]
[03/01/2023-10:41:01] [V] [TRT] Searching for input: 2378
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2384
[03/01/2023-10:41:02] [V] [TRT] Conv_2274 [Conv] inputs: [2378 -> (1, 128, 1, 1)[FLOAT]], [2384 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Conv_2274 for ONNX node: Conv_2274
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2385 for ONNX tensor: 2385
[03/01/2023-10:41:02] [V] [TRT] Conv_2274 [Conv] outputs: [2385 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Relu_2275 [Relu]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2385
[03/01/2023-10:41:02] [V] [TRT] Relu_2275 [Relu] inputs: [2385 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Relu_2275 for ONNX node: Relu_2275
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2386 for ONNX tensor: 2386
[03/01/2023-10:41:02] [V] [TRT] Relu_2275 [Relu] outputs: [2386 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2276 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2276 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2276 [Constant] outputs: [2387 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2277 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2277 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2277 [Constant] outputs: [2388 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: QuantizeLinear_2278 [QuantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2386
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2387
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2388
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2278 [QuantizeLinear] inputs: [2386 -> (1, 8, 1, 1)[FLOAT]], [2387 -> ()[FLOAT]], [2388 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2387 for ONNX node: 2387
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2388 for ONNX node: 2388
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2389 for ONNX tensor: 2389
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2278 [QuantizeLinear] outputs: [2389 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2279 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2279 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2279 [Constant] outputs: [2390 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2280 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2280 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2280 [Constant] outputs: [2391 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: DequantizeLinear_2281 [DequantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2389
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2390
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2391
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2281 [DequantizeLinear] inputs: [2389 -> (1, 8, 1, 1)[FLOAT]], [2390 -> ()[FLOAT]], [2391 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2390 for ONNX node: 2390
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2391 for ONNX node: 2391
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2392 for ONNX tensor: 2392
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2281 [DequantizeLinear] outputs: [2392 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2282 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2282 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2282 [Constant] outputs: [2393 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2283 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2283 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2283 [Constant] outputs: [2394 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: QuantizeLinear_2284 [QuantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2393
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2394
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2284 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2393 -> ()[FLOAT]], [2394 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2393 for ONNX node: 2393
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2394 for ONNX node: 2394
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2395 for ONNX tensor: 2395
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2284 [QuantizeLinear] outputs: [2395 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2285 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2285 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2285 [Constant] outputs: [2396 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2286 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2286 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2286 [Constant] outputs: [2397 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: DequantizeLinear_2287 [DequantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2395
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2396
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2397
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2287 [DequantizeLinear] inputs: [2395 -> (128, 8, 1, 1)[FLOAT]], [2396 -> ()[FLOAT]], [2397 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2396 for ONNX node: 2396
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2397 for ONNX node: 2397
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2398 for ONNX tensor: 2398
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2287 [DequantizeLinear] outputs: [2398 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Conv_2288 [Conv]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2392
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2398
[03/01/2023-10:41:02] [V] [TRT] Conv_2288 [Conv] inputs: [2392 -> (1, 8, 1, 1)[FLOAT]], [2398 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Conv_2288 for ONNX node: Conv_2288
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2399 for ONNX tensor: 2399
[03/01/2023-10:41:02] [V] [TRT] Conv_2288 [Conv] outputs: [2399 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Add_2289 [Add]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2371
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2399
[03/01/2023-10:41:02] [V] [TRT] Add_2289 [Add] inputs: [2371 -> (1, 128, 1, 1)[FLOAT]], [2399 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Add_2289 for ONNX node: Add_2289
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2400 for ONNX tensor: 2400
[03/01/2023-10:41:02] [V] [TRT] Add_2289 [Add] outputs: [2400 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Sigmoid_2290 [Sigmoid]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2400
[03/01/2023-10:41:02] [V] [TRT] Sigmoid_2290 [Sigmoid] inputs: [2400 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Sigmoid_2290 for ONNX node: Sigmoid_2290
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2401 for ONNX tensor: 2401
[03/01/2023-10:41:02] [V] [TRT] Sigmoid_2290 [Sigmoid] outputs: [2401 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Mul_2291 [Mul]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2343
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2401
[03/01/2023-10:41:02] [V] [TRT] Mul_2291 [Mul] inputs: [2343 -> (1, 128, 3, 3)[FLOAT]], [2401 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Mul_2291 for ONNX node: Mul_2291
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2402 for ONNX tensor: 2402
[03/01/2023-10:41:02] [V] [TRT] Mul_2291 [Mul] outputs: [2402 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Concat_2292 [Concat]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2253
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2402
[03/01/2023-10:41:02] [V] [TRT] Concat_2292 [Concat] inputs: [2253 -> (1, 1664, 3, 3)[FLOAT]], [2402 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Concat_2292 for ONNX node: Concat_2292
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2403 for ONNX tensor: 2403
[03/01/2023-10:41:02] [V] [TRT] Concat_2292 [Concat] outputs: [2403 -> (1, 1792, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2293 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2293 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2293 [Constant] outputs: [2404 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2294 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2294 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2294 [Constant] outputs: [2405 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2295 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2295 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2295 [Constant] outputs: [2406 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2296 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2296 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2296 [Constant] outputs: [2407 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Slice_2297 [Slice]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: input
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2405
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2406
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2404
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2407
[03/01/2023-10:41:02] [V] [TRT] Slice_2297 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [2405 -> (1)[INT32]], [2406 -> (1)[INT32]], [2404 -> (1)[INT32]], [2407 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Slice_2297 for ONNX node: Slice_2297
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2408 for ONNX tensor: 2408
[03/01/2023-10:41:02] [V] [TRT] Slice_2297 [Slice] outputs: [2408 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2298 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2298 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2298 [Constant] outputs: [2409 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2299 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2299 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2299 [Constant] outputs: [2410 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2300 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2300 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2300 [Constant] outputs: [2411 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2301 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2301 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2301 [Constant] outputs: [2412 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Slice_2302 [Slice]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2408
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2410
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2411
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2409
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2412
[03/01/2023-10:41:02] [V] [TRT] Slice_2302 [Slice] inputs: [2408 -> (1, 1, 24, 60)[FLOAT]], [2410 -> (1)[INT32]], [2411 -> (1)[INT32]], [2409 -> (1)[INT32]], [2412 -> (1)[INT32]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Slice_2302 for ONNX node: Slice_2302
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2413 for ONNX tensor: 2413
[03/01/2023-10:41:02] [V] [TRT] Slice_2302 [Slice] outputs: [2413 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2303 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2303 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2303 [Constant] outputs: [2414 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2304 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2304 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2304 [Constant] outputs: [2415 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: QuantizeLinear_2305 [QuantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2413
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2414
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2415
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2305 [QuantizeLinear] inputs: [2413 -> (1, 1, 24, 24)[FLOAT]], [2414 -> ()[FLOAT]], [2415 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2414 for ONNX node: 2414
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2415 for ONNX node: 2415
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2416 for ONNX tensor: 2416
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2305 [QuantizeLinear] outputs: [2416 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2306 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2306 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2306 [Constant] outputs: [2417 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2307 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2307 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2307 [Constant] outputs: [2418 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: DequantizeLinear_2308 [DequantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2416
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2417
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2418
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2308 [DequantizeLinear] inputs: [2416 -> (1, 1, 24, 24)[FLOAT]], [2417 -> ()[FLOAT]], [2418 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2417 for ONNX node: 2417
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2418 for ONNX node: 2418
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2419 for ONNX tensor: 2419
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2308 [DequantizeLinear] outputs: [2419 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2309 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2309 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2309 [Constant] outputs: [2420 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2310 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2310 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2310 [Constant] outputs: [2421 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: QuantizeLinear_2311 [QuantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2420
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2421
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2311 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [2420 -> ()[FLOAT]], [2421 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2420 for ONNX node: 2420
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2421 for ONNX node: 2421
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2422 for ONNX tensor: 2422
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2311 [QuantizeLinear] outputs: [2422 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2312 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2312 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2312 [Constant] outputs: [2423 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2313 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2313 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2313 [Constant] outputs: [2424 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: DequantizeLinear_2314 [DequantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2422
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2423
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2424
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2314 [DequantizeLinear] inputs: [2422 -> (64, 1, 3, 3)[FLOAT]], [2423 -> ()[FLOAT]], [2424 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2423 for ONNX node: 2423
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2424 for ONNX node: 2424
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2425 for ONNX tensor: 2425
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2314 [DequantizeLinear] outputs: [2425 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Conv_2315 [Conv]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2419
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2425
[03/01/2023-10:41:02] [V] [TRT] Conv_2315 [Conv] inputs: [2419 -> (1, 1, 24, 24)[FLOAT]], [2425 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Conv_2315 for ONNX node: Conv_2315
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2426 for ONNX tensor: 2426
[03/01/2023-10:41:02] [V] [TRT] Conv_2315 [Conv] outputs: [2426 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: BatchNormalization_2316 [BatchNormalization]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2426
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:41:02] [V] [TRT] BatchNormalization_2316 [BatchNormalization] inputs: [2426 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: BatchNormalization_2316 for ONNX node: BatchNormalization_2316
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2427 for ONNX tensor: 2427
[03/01/2023-10:41:02] [V] [TRT] BatchNormalization_2316 [BatchNormalization] outputs: [2427 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Relu_2317 [Relu]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2427
[03/01/2023-10:41:02] [V] [TRT] Relu_2317 [Relu] inputs: [2427 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Relu_2317 for ONNX node: Relu_2317
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2428 for ONNX tensor: 2428
[03/01/2023-10:41:02] [V] [TRT] Relu_2317 [Relu] outputs: [2428 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2318 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2318 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2318 [Constant] outputs: [2429 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2319 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2319 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2319 [Constant] outputs: [2430 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: QuantizeLinear_2320 [QuantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2428
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2429
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2430
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2320 [QuantizeLinear] inputs: [2428 -> (1, 64, 22, 22)[FLOAT]], [2429 -> ()[FLOAT]], [2430 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2429 for ONNX node: 2429
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2430 for ONNX node: 2430
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2431 for ONNX tensor: 2431
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2320 [QuantizeLinear] outputs: [2431 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2321 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2321 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2321 [Constant] outputs: [2432 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2322 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2322 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2322 [Constant] outputs: [2433 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: DequantizeLinear_2323 [DequantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2431
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2432
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2433
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2323 [DequantizeLinear] inputs: [2431 -> (1, 64, 22, 22)[FLOAT]], [2432 -> ()[FLOAT]], [2433 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2432 for ONNX node: 2432
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2433 for ONNX node: 2433
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2434 for ONNX tensor: 2434
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2323 [DequantizeLinear] outputs: [2434 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2324 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2324 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2324 [Constant] outputs: [2435 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2325 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2325 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2325 [Constant] outputs: [2436 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: QuantizeLinear_2326 [QuantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2435
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2436
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2326 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [2435 -> ()[FLOAT]], [2436 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2435 for ONNX node: 2435
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2436 for ONNX node: 2436
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2437 for ONNX tensor: 2437
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2326 [QuantizeLinear] outputs: [2437 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2327 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2327 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2327 [Constant] outputs: [2438 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2328 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2328 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2328 [Constant] outputs: [2439 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: DequantizeLinear_2329 [DequantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2437
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2438
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2439
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2329 [DequantizeLinear] inputs: [2437 -> (64, 64, 3, 3)[FLOAT]], [2438 -> ()[FLOAT]], [2439 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2438 for ONNX node: 2438
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2439 for ONNX node: 2439
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2440 for ONNX tensor: 2440
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2329 [DequantizeLinear] outputs: [2440 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Conv_2330 [Conv]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2434
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2440
[03/01/2023-10:41:02] [V] [TRT] Conv_2330 [Conv] inputs: [2434 -> (1, 64, 22, 22)[FLOAT]], [2440 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Conv_2330 for ONNX node: Conv_2330
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2441 for ONNX tensor: 2441
[03/01/2023-10:41:02] [V] [TRT] Conv_2330 [Conv] outputs: [2441 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: BatchNormalization_2331 [BatchNormalization]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2441
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:41:02] [V] [TRT] BatchNormalization_2331 [BatchNormalization] inputs: [2441 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: BatchNormalization_2331 for ONNX node: BatchNormalization_2331
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2442 for ONNX tensor: 2442
[03/01/2023-10:41:02] [V] [TRT] BatchNormalization_2331 [BatchNormalization] outputs: [2442 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Relu_2332 [Relu]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2442
[03/01/2023-10:41:02] [V] [TRT] Relu_2332 [Relu] inputs: [2442 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Relu_2332 for ONNX node: Relu_2332
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2443 for ONNX tensor: 2443
[03/01/2023-10:41:02] [V] [TRT] Relu_2332 [Relu] outputs: [2443 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: MaxPool_2333 [MaxPool]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2443
[03/01/2023-10:41:02] [V] [TRT] MaxPool_2333 [MaxPool] inputs: [2443 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: MaxPool_2333 for ONNX node: MaxPool_2333
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2444 for ONNX tensor: 2444
[03/01/2023-10:41:02] [V] [TRT] MaxPool_2333 [MaxPool] outputs: [2444 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2334 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2334 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2334 [Constant] outputs: [2445 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2335 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2335 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2335 [Constant] outputs: [2446 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: QuantizeLinear_2336 [QuantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2444
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2445
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2446
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2336 [QuantizeLinear] inputs: [2444 -> (1, 64, 10, 10)[FLOAT]], [2445 -> ()[FLOAT]], [2446 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2445 for ONNX node: 2445
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2446 for ONNX node: 2446
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2447 for ONNX tensor: 2447
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2336 [QuantizeLinear] outputs: [2447 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2337 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2337 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2337 [Constant] outputs: [2448 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2338 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2338 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2338 [Constant] outputs: [2449 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: DequantizeLinear_2339 [DequantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2447
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2448
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2449
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2339 [DequantizeLinear] inputs: [2447 -> (1, 64, 10, 10)[FLOAT]], [2448 -> ()[FLOAT]], [2449 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2448 for ONNX node: 2448
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2449 for ONNX node: 2449
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2450 for ONNX tensor: 2450
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2339 [DequantizeLinear] outputs: [2450 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2340 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2340 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2340 [Constant] outputs: [2451 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2341 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2341 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2341 [Constant] outputs: [2452 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: QuantizeLinear_2342 [QuantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2451
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2452
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2342 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [2451 -> ()[FLOAT]], [2452 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2451 for ONNX node: 2451
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2452 for ONNX node: 2452
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2453 for ONNX tensor: 2453
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2342 [QuantizeLinear] outputs: [2453 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2343 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2343 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2343 [Constant] outputs: [2454 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2344 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2344 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2344 [Constant] outputs: [2455 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: DequantizeLinear_2345 [DequantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2453
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2454
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2455
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2345 [DequantizeLinear] inputs: [2453 -> (128, 64, 3, 3)[FLOAT]], [2454 -> ()[FLOAT]], [2455 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2454 for ONNX node: 2454
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2455 for ONNX node: 2455
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2456 for ONNX tensor: 2456
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2345 [DequantizeLinear] outputs: [2456 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Conv_2346 [Conv]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2450
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2456
[03/01/2023-10:41:02] [V] [TRT] Conv_2346 [Conv] inputs: [2450 -> (1, 64, 10, 10)[FLOAT]], [2456 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Conv_2346 for ONNX node: Conv_2346
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2457 for ONNX tensor: 2457
[03/01/2023-10:41:02] [V] [TRT] Conv_2346 [Conv] outputs: [2457 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: BatchNormalization_2347 [BatchNormalization]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2457
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:41:02] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:41:02] [V] [TRT] BatchNormalization_2347 [BatchNormalization] inputs: [2457 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: BatchNormalization_2347 for ONNX node: BatchNormalization_2347
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2458 for ONNX tensor: 2458
[03/01/2023-10:41:02] [V] [TRT] BatchNormalization_2347 [BatchNormalization] outputs: [2458 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Relu_2348 [Relu]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2458
[03/01/2023-10:41:02] [V] [TRT] Relu_2348 [Relu] inputs: [2458 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: Relu_2348 for ONNX node: Relu_2348
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2459 for ONNX tensor: 2459
[03/01/2023-10:41:02] [V] [TRT] Relu_2348 [Relu] outputs: [2459 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2349 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2349 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2349 [Constant] outputs: [2460 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2350 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2350 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2350 [Constant] outputs: [2461 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: QuantizeLinear_2351 [QuantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2459
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2460
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2461
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2351 [QuantizeLinear] inputs: [2459 -> (1, 128, 8, 8)[FLOAT]], [2460 -> ()[FLOAT]], [2461 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2460 for ONNX node: 2460
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2461 for ONNX node: 2461
[03/01/2023-10:41:02] [V] [TRT] Registering tensor: 2462 for ONNX tensor: 2462
[03/01/2023-10:41:02] [V] [TRT] QuantizeLinear_2351 [QuantizeLinear] outputs: [2462 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2352 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2352 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2352 [Constant] outputs: [2463 -> ()[FLOAT]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: Constant_2353 [Constant]
[03/01/2023-10:41:02] [V] [TRT] Constant_2353 [Constant] inputs: 
[03/01/2023-10:41:02] [V] [TRT] Constant_2353 [Constant] outputs: [2464 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Parsing node: DequantizeLinear_2354 [DequantizeLinear]
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2462
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2463
[03/01/2023-10:41:02] [V] [TRT] Searching for input: 2464
[03/01/2023-10:41:02] [V] [TRT] DequantizeLinear_2354 [DequantizeLinear] inputs: [2462 -> (1, 128, 8, 8)[FLOAT]], [2463 -> ()[FLOAT]], [2464 -> ()[INT8]], 
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2463 for ONNX node: 2463
[03/01/2023-10:41:02] [V] [TRT] Registering layer: 2464 for ONNX node: 2464
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2465 for ONNX tensor: 2465
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2354 [DequantizeLinear] outputs: [2465 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2355 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2355 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2355 [Constant] outputs: [2466 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2356 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2356 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2356 [Constant] outputs: [2467 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: QuantizeLinear_2357 [QuantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2466
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2467
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2357 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [2466 -> ()[FLOAT]], [2467 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2466 for ONNX node: 2466
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2467 for ONNX node: 2467
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2468 for ONNX tensor: 2468
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2357 [QuantizeLinear] outputs: [2468 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2358 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2358 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2358 [Constant] outputs: [2469 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2359 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2359 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2359 [Constant] outputs: [2470 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: DequantizeLinear_2360 [DequantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2468
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2469
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2470
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2360 [DequantizeLinear] inputs: [2468 -> (128, 128, 3, 3)[FLOAT]], [2469 -> ()[FLOAT]], [2470 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2469 for ONNX node: 2469
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2470 for ONNX node: 2470
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2471 for ONNX tensor: 2471
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2360 [DequantizeLinear] outputs: [2471 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Conv_2361 [Conv]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2465
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2471
[03/01/2023-10:41:03] [V] [TRT] Conv_2361 [Conv] inputs: [2465 -> (1, 128, 8, 8)[FLOAT]], [2471 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:03] [V] [TRT] Registering layer: Conv_2361 for ONNX node: Conv_2361
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2472 for ONNX tensor: 2472
[03/01/2023-10:41:03] [V] [TRT] Conv_2361 [Conv] outputs: [2472 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: BatchNormalization_2362 [BatchNormalization]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2472
[03/01/2023-10:41:03] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:41:03] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:41:03] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:41:03] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:41:03] [V] [TRT] BatchNormalization_2362 [BatchNormalization] inputs: [2472 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: BatchNormalization_2362 for ONNX node: BatchNormalization_2362
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2473 for ONNX tensor: 2473
[03/01/2023-10:41:03] [V] [TRT] BatchNormalization_2362 [BatchNormalization] outputs: [2473 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Relu_2363 [Relu]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2473
[03/01/2023-10:41:03] [V] [TRT] Relu_2363 [Relu] inputs: [2473 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: Relu_2363 for ONNX node: Relu_2363
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2474 for ONNX tensor: 2474
[03/01/2023-10:41:03] [V] [TRT] Relu_2363 [Relu] outputs: [2474 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: MaxPool_2364 [MaxPool]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2474
[03/01/2023-10:41:03] [V] [TRT] MaxPool_2364 [MaxPool] inputs: [2474 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: MaxPool_2364 for ONNX node: MaxPool_2364
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2475 for ONNX tensor: 2475
[03/01/2023-10:41:03] [V] [TRT] MaxPool_2364 [MaxPool] outputs: [2475 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: ReduceMean_2365 [ReduceMean]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2475
[03/01/2023-10:41:03] [V] [TRT] ReduceMean_2365 [ReduceMean] inputs: [2475 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: ReduceMean_2365 for ONNX node: ReduceMean_2365
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2476 for ONNX tensor: 2476
[03/01/2023-10:41:03] [V] [TRT] ReduceMean_2365 [ReduceMean] outputs: [2476 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: ReduceMax_2366 [ReduceMax]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2475
[03/01/2023-10:41:03] [V] [TRT] ReduceMax_2366 [ReduceMax] inputs: [2475 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: ReduceMax_2366 for ONNX node: ReduceMax_2366
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2477 for ONNX tensor: 2477
[03/01/2023-10:41:03] [V] [TRT] ReduceMax_2366 [ReduceMax] outputs: [2477 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Concat_2367 [Concat]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2476
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2477
[03/01/2023-10:41:03] [V] [TRT] Concat_2367 [Concat] inputs: [2476 -> (1, 1, 3, 3)[FLOAT]], [2477 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: Concat_2367 for ONNX node: Concat_2367
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2478 for ONNX tensor: 2478
[03/01/2023-10:41:03] [V] [TRT] Concat_2367 [Concat] outputs: [2478 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2368 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2368 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2368 [Constant] outputs: [2479 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2369 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2369 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2369 [Constant] outputs: [2480 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: QuantizeLinear_2370 [QuantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2478
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2479
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2480
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2370 [QuantizeLinear] inputs: [2478 -> (1, 2, 3, 3)[FLOAT]], [2479 -> ()[FLOAT]], [2480 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2479 for ONNX node: 2479
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2480 for ONNX node: 2480
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2481 for ONNX tensor: 2481
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2370 [QuantizeLinear] outputs: [2481 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2371 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2371 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2371 [Constant] outputs: [2482 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2372 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2372 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2372 [Constant] outputs: [2483 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: DequantizeLinear_2373 [DequantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2481
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2482
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2483
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2373 [DequantizeLinear] inputs: [2481 -> (1, 2, 3, 3)[FLOAT]], [2482 -> ()[FLOAT]], [2483 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2482 for ONNX node: 2482
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2483 for ONNX node: 2483
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2484 for ONNX tensor: 2484
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2373 [DequantizeLinear] outputs: [2484 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2374 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2374 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2374 [Constant] outputs: [2485 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2375 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2375 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2375 [Constant] outputs: [2486 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: QuantizeLinear_2376 [QuantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2485
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2486
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2376 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [2485 -> ()[FLOAT]], [2486 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2485 for ONNX node: 2485
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2486 for ONNX node: 2486
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2487 for ONNX tensor: 2487
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2376 [QuantizeLinear] outputs: [2487 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2377 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2377 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2377 [Constant] outputs: [2488 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2378 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2378 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2378 [Constant] outputs: [2489 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: DequantizeLinear_2379 [DequantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2487
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2488
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2489
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2379 [DequantizeLinear] inputs: [2487 -> (1, 2, 7, 7)[FLOAT]], [2488 -> ()[FLOAT]], [2489 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2488 for ONNX node: 2488
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2489 for ONNX node: 2489
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2490 for ONNX tensor: 2490
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2379 [DequantizeLinear] outputs: [2490 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Conv_2380 [Conv]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2484
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2490
[03/01/2023-10:41:03] [V] [TRT] Conv_2380 [Conv] inputs: [2484 -> (1, 2, 3, 3)[FLOAT]], [2490 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:03] [V] [TRT] Registering layer: Conv_2380 for ONNX node: Conv_2380
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2491 for ONNX tensor: 2491
[03/01/2023-10:41:03] [V] [TRT] Conv_2380 [Conv] outputs: [2491 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Sigmoid_2381 [Sigmoid]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2491
[03/01/2023-10:41:03] [V] [TRT] Sigmoid_2381 [Sigmoid] inputs: [2491 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: Sigmoid_2381 for ONNX node: Sigmoid_2381
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2492 for ONNX tensor: 2492
[03/01/2023-10:41:03] [V] [TRT] Sigmoid_2381 [Sigmoid] outputs: [2492 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Mul_2382 [Mul]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2475
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2492
[03/01/2023-10:41:03] [V] [TRT] Mul_2382 [Mul] inputs: [2475 -> (1, 128, 3, 3)[FLOAT]], [2492 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: Mul_2382 for ONNX node: Mul_2382
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2493 for ONNX tensor: 2493
[03/01/2023-10:41:03] [V] [TRT] Mul_2382 [Mul] outputs: [2493 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: GlobalAveragePool_2383 [GlobalAveragePool]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2493
[03/01/2023-10:41:03] [V] [TRT] GlobalAveragePool_2383 [GlobalAveragePool] inputs: [2493 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:41:03] [V] [TRT] Registering layer: GlobalAveragePool_2383 for ONNX node: GlobalAveragePool_2383
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2494 for ONNX tensor: 2494
[03/01/2023-10:41:03] [V] [TRT] GlobalAveragePool_2383 [GlobalAveragePool] outputs: [2494 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2384 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2384 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2384 [Constant] outputs: [2495 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2385 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2385 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2385 [Constant] outputs: [2496 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: QuantizeLinear_2386 [QuantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2494
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2495
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2496
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2386 [QuantizeLinear] inputs: [2494 -> (1, 128, 1, 1)[FLOAT]], [2495 -> ()[FLOAT]], [2496 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2495 for ONNX node: 2495
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2496 for ONNX node: 2496
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2497 for ONNX tensor: 2497
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2386 [QuantizeLinear] outputs: [2497 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2387 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2387 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2387 [Constant] outputs: [2498 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2388 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2388 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2388 [Constant] outputs: [2499 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: DequantizeLinear_2389 [DequantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2497
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2498
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2499
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2389 [DequantizeLinear] inputs: [2497 -> (1, 128, 1, 1)[FLOAT]], [2498 -> ()[FLOAT]], [2499 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2498 for ONNX node: 2498
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2499 for ONNX node: 2499
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2500 for ONNX tensor: 2500
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2389 [DequantizeLinear] outputs: [2500 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2390 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2390 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2390 [Constant] outputs: [2501 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2391 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2391 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2391 [Constant] outputs: [2502 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: QuantizeLinear_2392 [QuantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2501
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2502
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2392 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2501 -> ()[FLOAT]], [2502 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2501 for ONNX node: 2501
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2502 for ONNX node: 2502
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2503 for ONNX tensor: 2503
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2392 [QuantizeLinear] outputs: [2503 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2393 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2393 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2393 [Constant] outputs: [2504 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2394 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2394 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2394 [Constant] outputs: [2505 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: DequantizeLinear_2395 [DequantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2503
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2504
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2505
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2395 [DequantizeLinear] inputs: [2503 -> (8, 128, 1, 1)[FLOAT]], [2504 -> ()[FLOAT]], [2505 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2504 for ONNX node: 2504
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2505 for ONNX node: 2505
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2506 for ONNX tensor: 2506
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2395 [DequantizeLinear] outputs: [2506 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Conv_2396 [Conv]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2500
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2506
[03/01/2023-10:41:03] [V] [TRT] Conv_2396 [Conv] inputs: [2500 -> (1, 128, 1, 1)[FLOAT]], [2506 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:03] [V] [TRT] Registering layer: Conv_2396 for ONNX node: Conv_2396
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2507 for ONNX tensor: 2507
[03/01/2023-10:41:03] [V] [TRT] Conv_2396 [Conv] outputs: [2507 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Relu_2397 [Relu]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2507
[03/01/2023-10:41:03] [V] [TRT] Relu_2397 [Relu] inputs: [2507 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: Relu_2397 for ONNX node: Relu_2397
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2508 for ONNX tensor: 2508
[03/01/2023-10:41:03] [V] [TRT] Relu_2397 [Relu] outputs: [2508 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2398 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2398 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2398 [Constant] outputs: [2509 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2399 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2399 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2399 [Constant] outputs: [2510 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: QuantizeLinear_2400 [QuantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2508
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2509
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2510
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2400 [QuantizeLinear] inputs: [2508 -> (1, 8, 1, 1)[FLOAT]], [2509 -> ()[FLOAT]], [2510 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2509 for ONNX node: 2509
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2510 for ONNX node: 2510
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2511 for ONNX tensor: 2511
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2400 [QuantizeLinear] outputs: [2511 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2401 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2401 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2401 [Constant] outputs: [2512 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2402 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2402 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2402 [Constant] outputs: [2513 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: DequantizeLinear_2403 [DequantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2511
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2512
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2513
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2403 [DequantizeLinear] inputs: [2511 -> (1, 8, 1, 1)[FLOAT]], [2512 -> ()[FLOAT]], [2513 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2512 for ONNX node: 2512
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2513 for ONNX node: 2513
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2514 for ONNX tensor: 2514
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2403 [DequantizeLinear] outputs: [2514 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2404 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2404 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2404 [Constant] outputs: [2515 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2405 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2405 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2405 [Constant] outputs: [2516 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: QuantizeLinear_2406 [QuantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2515
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2516
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2406 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2515 -> ()[FLOAT]], [2516 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2515 for ONNX node: 2515
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2516 for ONNX node: 2516
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2517 for ONNX tensor: 2517
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2406 [QuantizeLinear] outputs: [2517 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2407 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2407 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2407 [Constant] outputs: [2518 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2408 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2408 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2408 [Constant] outputs: [2519 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: DequantizeLinear_2409 [DequantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2517
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2518
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2519
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2409 [DequantizeLinear] inputs: [2517 -> (128, 8, 1, 1)[FLOAT]], [2518 -> ()[FLOAT]], [2519 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2518 for ONNX node: 2518
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2519 for ONNX node: 2519
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2520 for ONNX tensor: 2520
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2409 [DequantizeLinear] outputs: [2520 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Conv_2410 [Conv]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2514
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2520
[03/01/2023-10:41:03] [V] [TRT] Conv_2410 [Conv] inputs: [2514 -> (1, 8, 1, 1)[FLOAT]], [2520 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:03] [V] [TRT] Registering layer: Conv_2410 for ONNX node: Conv_2410
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2521 for ONNX tensor: 2521
[03/01/2023-10:41:03] [V] [TRT] Conv_2410 [Conv] outputs: [2521 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: MaxPool_2411 [MaxPool]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2493
[03/01/2023-10:41:03] [V] [TRT] MaxPool_2411 [MaxPool] inputs: [2493 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: MaxPool_2411 for ONNX node: MaxPool_2411
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2522 for ONNX tensor: 2522
[03/01/2023-10:41:03] [V] [TRT] MaxPool_2411 [MaxPool] outputs: [2522 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2412 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2412 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2412 [Constant] outputs: [2523 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2413 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2413 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2413 [Constant] outputs: [2524 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: QuantizeLinear_2414 [QuantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2522
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2523
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2524
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2414 [QuantizeLinear] inputs: [2522 -> (1, 128, 1, 1)[FLOAT]], [2523 -> ()[FLOAT]], [2524 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2523 for ONNX node: 2523
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2524 for ONNX node: 2524
[03/01/2023-10:41:03] [V] [TRT] Registering tensor: 2525 for ONNX tensor: 2525
[03/01/2023-10:41:03] [V] [TRT] QuantizeLinear_2414 [QuantizeLinear] outputs: [2525 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2415 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2415 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2415 [Constant] outputs: [2526 -> ()[FLOAT]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: Constant_2416 [Constant]
[03/01/2023-10:41:03] [V] [TRT] Constant_2416 [Constant] inputs: 
[03/01/2023-10:41:03] [V] [TRT] Constant_2416 [Constant] outputs: [2527 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Parsing node: DequantizeLinear_2417 [DequantizeLinear]
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2525
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2526
[03/01/2023-10:41:03] [V] [TRT] Searching for input: 2527
[03/01/2023-10:41:03] [V] [TRT] DequantizeLinear_2417 [DequantizeLinear] inputs: [2525 -> (1, 128, 1, 1)[FLOAT]], [2526 -> ()[FLOAT]], [2527 -> ()[INT8]], 
[03/01/2023-10:41:03] [V] [TRT] Registering layer: 2526 for ONNX node: 2526
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2527 for ONNX node: 2527
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2528 for ONNX tensor: 2528
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2417 [DequantizeLinear] outputs: [2528 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2418 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2418 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2418 [Constant] outputs: [2529 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2419 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2419 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2419 [Constant] outputs: [2530 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: QuantizeLinear_2420 [QuantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2529
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2530
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2420 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2529 -> ()[FLOAT]], [2530 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2529 for ONNX node: 2529
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2530 for ONNX node: 2530
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2531 for ONNX tensor: 2531
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2420 [QuantizeLinear] outputs: [2531 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2421 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2421 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2421 [Constant] outputs: [2532 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2422 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2422 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2422 [Constant] outputs: [2533 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: DequantizeLinear_2423 [DequantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2531
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2532
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2533
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2423 [DequantizeLinear] inputs: [2531 -> (8, 128, 1, 1)[FLOAT]], [2532 -> ()[FLOAT]], [2533 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2532 for ONNX node: 2532
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2533 for ONNX node: 2533
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2534 for ONNX tensor: 2534
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2423 [DequantizeLinear] outputs: [2534 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Conv_2424 [Conv]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2528
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2534
[03/01/2023-10:41:04] [V] [TRT] Conv_2424 [Conv] inputs: [2528 -> (1, 128, 1, 1)[FLOAT]], [2534 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Conv_2424 for ONNX node: Conv_2424
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2535 for ONNX tensor: 2535
[03/01/2023-10:41:04] [V] [TRT] Conv_2424 [Conv] outputs: [2535 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Relu_2425 [Relu]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2535
[03/01/2023-10:41:04] [V] [TRT] Relu_2425 [Relu] inputs: [2535 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Relu_2425 for ONNX node: Relu_2425
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2536 for ONNX tensor: 2536
[03/01/2023-10:41:04] [V] [TRT] Relu_2425 [Relu] outputs: [2536 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2426 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2426 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2426 [Constant] outputs: [2537 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2427 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2427 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2427 [Constant] outputs: [2538 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: QuantizeLinear_2428 [QuantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2536
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2537
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2538
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2428 [QuantizeLinear] inputs: [2536 -> (1, 8, 1, 1)[FLOAT]], [2537 -> ()[FLOAT]], [2538 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2537 for ONNX node: 2537
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2538 for ONNX node: 2538
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2539 for ONNX tensor: 2539
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2428 [QuantizeLinear] outputs: [2539 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2429 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2429 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2429 [Constant] outputs: [2540 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2430 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2430 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2430 [Constant] outputs: [2541 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: DequantizeLinear_2431 [DequantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2539
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2540
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2541
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2431 [DequantizeLinear] inputs: [2539 -> (1, 8, 1, 1)[FLOAT]], [2540 -> ()[FLOAT]], [2541 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2540 for ONNX node: 2540
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2541 for ONNX node: 2541
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2542 for ONNX tensor: 2542
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2431 [DequantizeLinear] outputs: [2542 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2432 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2432 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2432 [Constant] outputs: [2543 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2433 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2433 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2433 [Constant] outputs: [2544 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: QuantizeLinear_2434 [QuantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2543
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2544
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2434 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2543 -> ()[FLOAT]], [2544 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2543 for ONNX node: 2543
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2544 for ONNX node: 2544
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2545 for ONNX tensor: 2545
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2434 [QuantizeLinear] outputs: [2545 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2435 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2435 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2435 [Constant] outputs: [2546 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2436 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2436 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2436 [Constant] outputs: [2547 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: DequantizeLinear_2437 [DequantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2545
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2546
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2547
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2437 [DequantizeLinear] inputs: [2545 -> (128, 8, 1, 1)[FLOAT]], [2546 -> ()[FLOAT]], [2547 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2546 for ONNX node: 2546
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2547 for ONNX node: 2547
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2548 for ONNX tensor: 2548
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2437 [DequantizeLinear] outputs: [2548 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Conv_2438 [Conv]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2542
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2548
[03/01/2023-10:41:04] [V] [TRT] Conv_2438 [Conv] inputs: [2542 -> (1, 8, 1, 1)[FLOAT]], [2548 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Conv_2438 for ONNX node: Conv_2438
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2549 for ONNX tensor: 2549
[03/01/2023-10:41:04] [V] [TRT] Conv_2438 [Conv] outputs: [2549 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Add_2439 [Add]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2521
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2549
[03/01/2023-10:41:04] [V] [TRT] Add_2439 [Add] inputs: [2521 -> (1, 128, 1, 1)[FLOAT]], [2549 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Add_2439 for ONNX node: Add_2439
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2550 for ONNX tensor: 2550
[03/01/2023-10:41:04] [V] [TRT] Add_2439 [Add] outputs: [2550 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Sigmoid_2440 [Sigmoid]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2550
[03/01/2023-10:41:04] [V] [TRT] Sigmoid_2440 [Sigmoid] inputs: [2550 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Sigmoid_2440 for ONNX node: Sigmoid_2440
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2551 for ONNX tensor: 2551
[03/01/2023-10:41:04] [V] [TRT] Sigmoid_2440 [Sigmoid] outputs: [2551 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Mul_2441 [Mul]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2493
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2551
[03/01/2023-10:41:04] [V] [TRT] Mul_2441 [Mul] inputs: [2493 -> (1, 128, 3, 3)[FLOAT]], [2551 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Mul_2441 for ONNX node: Mul_2441
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2552 for ONNX tensor: 2552
[03/01/2023-10:41:04] [V] [TRT] Mul_2441 [Mul] outputs: [2552 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Concat_2442 [Concat]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2403
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2552
[03/01/2023-10:41:04] [V] [TRT] Concat_2442 [Concat] inputs: [2403 -> (1, 1792, 3, 3)[FLOAT]], [2552 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Concat_2442 for ONNX node: Concat_2442
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2553 for ONNX tensor: 2553
[03/01/2023-10:41:04] [V] [TRT] Concat_2442 [Concat] outputs: [2553 -> (1, 1920, 3, 3)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2443 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2443 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2443 [Constant] outputs: [2554 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2444 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2444 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2444 [Constant] outputs: [2555 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2445 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2445 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2445 [Constant] outputs: [2556 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2446 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2446 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2446 [Constant] outputs: [2557 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Slice_2447 [Slice]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: input
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2555
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2556
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2554
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2557
[03/01/2023-10:41:04] [V] [TRT] Slice_2447 [Slice] inputs: [input -> (1, 1, 60, 60)[FLOAT]], [2555 -> (1)[INT32]], [2556 -> (1)[INT32]], [2554 -> (1)[INT32]], [2557 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Slice_2447 for ONNX node: Slice_2447
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2558 for ONNX tensor: 2558
[03/01/2023-10:41:04] [V] [TRT] Slice_2447 [Slice] outputs: [2558 -> (1, 1, 24, 60)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2448 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2448 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2448 [Constant] outputs: [2559 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2449 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2449 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2449 [Constant] outputs: [2560 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2450 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2450 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2450 [Constant] outputs: [2561 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2451 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2451 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2451 [Constant] outputs: [2562 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Slice_2452 [Slice]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2558
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2560
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2561
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2559
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2562
[03/01/2023-10:41:04] [V] [TRT] Slice_2452 [Slice] inputs: [2558 -> (1, 1, 24, 60)[FLOAT]], [2560 -> (1)[INT32]], [2561 -> (1)[INT32]], [2559 -> (1)[INT32]], [2562 -> (1)[INT32]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Slice_2452 for ONNX node: Slice_2452
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2563 for ONNX tensor: 2563
[03/01/2023-10:41:04] [V] [TRT] Slice_2452 [Slice] outputs: [2563 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2453 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2453 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2453 [Constant] outputs: [2564 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2454 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2454 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2454 [Constant] outputs: [2565 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: QuantizeLinear_2455 [QuantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2563
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2564
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2565
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2455 [QuantizeLinear] inputs: [2563 -> (1, 1, 24, 24)[FLOAT]], [2564 -> ()[FLOAT]], [2565 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2564 for ONNX node: 2564
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2565 for ONNX node: 2565
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2566 for ONNX tensor: 2566
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2455 [QuantizeLinear] outputs: [2566 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2456 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2456 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2456 [Constant] outputs: [2567 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2457 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2457 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2457 [Constant] outputs: [2568 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: DequantizeLinear_2458 [DequantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2566
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2567
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2568
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2458 [DequantizeLinear] inputs: [2566 -> (1, 1, 24, 24)[FLOAT]], [2567 -> ()[FLOAT]], [2568 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2567 for ONNX node: 2567
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2568 for ONNX node: 2568
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2569 for ONNX tensor: 2569
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2458 [DequantizeLinear] outputs: [2569 -> (1, 1, 24, 24)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2459 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2459 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2459 [Constant] outputs: [2570 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2460 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2460 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2460 [Constant] outputs: [2571 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: QuantizeLinear_2461 [QuantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.0.weight
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2570
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2571
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2461 [QuantizeLinear] inputs: [conv4.0.weight -> (64, 1, 3, 3)[FLOAT]], [2570 -> ()[FLOAT]], [2571 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2570 for ONNX node: 2570
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2571 for ONNX node: 2571
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2572 for ONNX tensor: 2572
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2461 [QuantizeLinear] outputs: [2572 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2462 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2462 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2462 [Constant] outputs: [2573 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2463 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2463 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2463 [Constant] outputs: [2574 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: DequantizeLinear_2464 [DequantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2572
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2573
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2574
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2464 [DequantizeLinear] inputs: [2572 -> (64, 1, 3, 3)[FLOAT]], [2573 -> ()[FLOAT]], [2574 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2573 for ONNX node: 2573
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2574 for ONNX node: 2574
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2575 for ONNX tensor: 2575
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2464 [DequantizeLinear] outputs: [2575 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Conv_2465 [Conv]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2569
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2575
[03/01/2023-10:41:04] [V] [TRT] Conv_2465 [Conv] inputs: [2569 -> (1, 1, 24, 24)[FLOAT]], [2575 -> (64, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Conv_2465 for ONNX node: Conv_2465
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2576 for ONNX tensor: 2576
[03/01/2023-10:41:04] [V] [TRT] Conv_2465 [Conv] outputs: [2576 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: BatchNormalization_2466 [BatchNormalization]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2576
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.1.weight
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.1.bias
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.1.running_mean
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.1.running_var
[03/01/2023-10:41:04] [V] [TRT] BatchNormalization_2466 [BatchNormalization] inputs: [2576 -> (1, 64, 22, 22)[FLOAT]], [conv4.1.weight -> (64)[FLOAT]], [conv4.1.bias -> (64)[FLOAT]], [conv4.1.running_mean -> (64)[FLOAT]], [conv4.1.running_var -> (64)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: BatchNormalization_2466 for ONNX node: BatchNormalization_2466
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2577 for ONNX tensor: 2577
[03/01/2023-10:41:04] [V] [TRT] BatchNormalization_2466 [BatchNormalization] outputs: [2577 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Relu_2467 [Relu]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2577
[03/01/2023-10:41:04] [V] [TRT] Relu_2467 [Relu] inputs: [2577 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Relu_2467 for ONNX node: Relu_2467
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2578 for ONNX tensor: 2578
[03/01/2023-10:41:04] [V] [TRT] Relu_2467 [Relu] outputs: [2578 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2468 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2468 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2468 [Constant] outputs: [2579 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2469 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2469 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2469 [Constant] outputs: [2580 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: QuantizeLinear_2470 [QuantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2578
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2579
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2580
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2470 [QuantizeLinear] inputs: [2578 -> (1, 64, 22, 22)[FLOAT]], [2579 -> ()[FLOAT]], [2580 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2579 for ONNX node: 2579
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2580 for ONNX node: 2580
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2581 for ONNX tensor: 2581
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2470 [QuantizeLinear] outputs: [2581 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2471 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2471 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2471 [Constant] outputs: [2582 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2472 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2472 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2472 [Constant] outputs: [2583 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: DequantizeLinear_2473 [DequantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2581
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2582
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2583
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2473 [DequantizeLinear] inputs: [2581 -> (1, 64, 22, 22)[FLOAT]], [2582 -> ()[FLOAT]], [2583 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2582 for ONNX node: 2582
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2583 for ONNX node: 2583
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2584 for ONNX tensor: 2584
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2473 [DequantizeLinear] outputs: [2584 -> (1, 64, 22, 22)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2474 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2474 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2474 [Constant] outputs: [2585 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2475 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2475 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2475 [Constant] outputs: [2586 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: QuantizeLinear_2476 [QuantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.3.weight
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2585
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2586
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2476 [QuantizeLinear] inputs: [conv4.3.weight -> (64, 64, 3, 3)[FLOAT]], [2585 -> ()[FLOAT]], [2586 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2585 for ONNX node: 2585
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2586 for ONNX node: 2586
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2587 for ONNX tensor: 2587
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2476 [QuantizeLinear] outputs: [2587 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2477 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2477 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2477 [Constant] outputs: [2588 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2478 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2478 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2478 [Constant] outputs: [2589 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: DequantizeLinear_2479 [DequantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2587
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2588
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2589
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2479 [DequantizeLinear] inputs: [2587 -> (64, 64, 3, 3)[FLOAT]], [2588 -> ()[FLOAT]], [2589 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2588 for ONNX node: 2588
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2589 for ONNX node: 2589
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2590 for ONNX tensor: 2590
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2479 [DequantizeLinear] outputs: [2590 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Conv_2480 [Conv]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2584
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2590
[03/01/2023-10:41:04] [V] [TRT] Conv_2480 [Conv] inputs: [2584 -> (1, 64, 22, 22)[FLOAT]], [2590 -> (64, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Conv_2480 for ONNX node: Conv_2480
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2591 for ONNX tensor: 2591
[03/01/2023-10:41:04] [V] [TRT] Conv_2480 [Conv] outputs: [2591 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: BatchNormalization_2481 [BatchNormalization]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2591
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.4.weight
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.4.bias
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.4.running_mean
[03/01/2023-10:41:04] [V] [TRT] Searching for input: conv4.4.running_var
[03/01/2023-10:41:04] [V] [TRT] BatchNormalization_2481 [BatchNormalization] inputs: [2591 -> (1, 64, 20, 20)[FLOAT]], [conv4.4.weight -> (64)[FLOAT]], [conv4.4.bias -> (64)[FLOAT]], [conv4.4.running_mean -> (64)[FLOAT]], [conv4.4.running_var -> (64)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: BatchNormalization_2481 for ONNX node: BatchNormalization_2481
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2592 for ONNX tensor: 2592
[03/01/2023-10:41:04] [V] [TRT] BatchNormalization_2481 [BatchNormalization] outputs: [2592 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Relu_2482 [Relu]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2592
[03/01/2023-10:41:04] [V] [TRT] Relu_2482 [Relu] inputs: [2592 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: Relu_2482 for ONNX node: Relu_2482
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2593 for ONNX tensor: 2593
[03/01/2023-10:41:04] [V] [TRT] Relu_2482 [Relu] outputs: [2593 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: MaxPool_2483 [MaxPool]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2593
[03/01/2023-10:41:04] [V] [TRT] MaxPool_2483 [MaxPool] inputs: [2593 -> (1, 64, 20, 20)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: MaxPool_2483 for ONNX node: MaxPool_2483
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2594 for ONNX tensor: 2594
[03/01/2023-10:41:04] [V] [TRT] MaxPool_2483 [MaxPool] outputs: [2594 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2484 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2484 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2484 [Constant] outputs: [2595 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2485 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2485 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2485 [Constant] outputs: [2596 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: QuantizeLinear_2486 [QuantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2594
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2595
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2596
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2486 [QuantizeLinear] inputs: [2594 -> (1, 64, 10, 10)[FLOAT]], [2595 -> ()[FLOAT]], [2596 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2595 for ONNX node: 2595
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2596 for ONNX node: 2596
[03/01/2023-10:41:04] [V] [TRT] Registering tensor: 2597 for ONNX tensor: 2597
[03/01/2023-10:41:04] [V] [TRT] QuantizeLinear_2486 [QuantizeLinear] outputs: [2597 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2487 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2487 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2487 [Constant] outputs: [2598 -> ()[FLOAT]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: Constant_2488 [Constant]
[03/01/2023-10:41:04] [V] [TRT] Constant_2488 [Constant] inputs: 
[03/01/2023-10:41:04] [V] [TRT] Constant_2488 [Constant] outputs: [2599 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Parsing node: DequantizeLinear_2489 [DequantizeLinear]
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2597
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2598
[03/01/2023-10:41:04] [V] [TRT] Searching for input: 2599
[03/01/2023-10:41:04] [V] [TRT] DequantizeLinear_2489 [DequantizeLinear] inputs: [2597 -> (1, 64, 10, 10)[FLOAT]], [2598 -> ()[FLOAT]], [2599 -> ()[INT8]], 
[03/01/2023-10:41:04] [V] [TRT] Registering layer: 2598 for ONNX node: 2598
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2599 for ONNX node: 2599
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2600 for ONNX tensor: 2600
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2489 [DequantizeLinear] outputs: [2600 -> (1, 64, 10, 10)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2490 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2490 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2490 [Constant] outputs: [2601 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2491 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2491 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2491 [Constant] outputs: [2602 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: QuantizeLinear_2492 [QuantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.0.weight
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2601
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2602
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2492 [QuantizeLinear] inputs: [conv5.0.weight -> (128, 64, 3, 3)[FLOAT]], [2601 -> ()[FLOAT]], [2602 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2601 for ONNX node: 2601
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2602 for ONNX node: 2602
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2603 for ONNX tensor: 2603
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2492 [QuantizeLinear] outputs: [2603 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2493 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2493 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2493 [Constant] outputs: [2604 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2494 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2494 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2494 [Constant] outputs: [2605 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: DequantizeLinear_2495 [DequantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2603
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2604
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2605
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2495 [DequantizeLinear] inputs: [2603 -> (128, 64, 3, 3)[FLOAT]], [2604 -> ()[FLOAT]], [2605 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2604 for ONNX node: 2604
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2605 for ONNX node: 2605
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2606 for ONNX tensor: 2606
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2495 [DequantizeLinear] outputs: [2606 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Conv_2496 [Conv]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2600
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2606
[03/01/2023-10:41:05] [V] [TRT] Conv_2496 [Conv] inputs: [2600 -> (1, 64, 10, 10)[FLOAT]], [2606 -> (128, 64, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Conv_2496 for ONNX node: Conv_2496
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2607 for ONNX tensor: 2607
[03/01/2023-10:41:05] [V] [TRT] Conv_2496 [Conv] outputs: [2607 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: BatchNormalization_2497 [BatchNormalization]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2607
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.1.weight
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.1.bias
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.1.running_mean
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.1.running_var
[03/01/2023-10:41:05] [V] [TRT] BatchNormalization_2497 [BatchNormalization] inputs: [2607 -> (1, 128, 8, 8)[FLOAT]], [conv5.1.weight -> (128)[FLOAT]], [conv5.1.bias -> (128)[FLOAT]], [conv5.1.running_mean -> (128)[FLOAT]], [conv5.1.running_var -> (128)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: BatchNormalization_2497 for ONNX node: BatchNormalization_2497
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2608 for ONNX tensor: 2608
[03/01/2023-10:41:05] [V] [TRT] BatchNormalization_2497 [BatchNormalization] outputs: [2608 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Relu_2498 [Relu]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2608
[03/01/2023-10:41:05] [V] [TRT] Relu_2498 [Relu] inputs: [2608 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Relu_2498 for ONNX node: Relu_2498
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2609 for ONNX tensor: 2609
[03/01/2023-10:41:05] [V] [TRT] Relu_2498 [Relu] outputs: [2609 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2499 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2499 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2499 [Constant] outputs: [2610 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2500 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2500 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2500 [Constant] outputs: [2611 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: QuantizeLinear_2501 [QuantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2609
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2610
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2611
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2501 [QuantizeLinear] inputs: [2609 -> (1, 128, 8, 8)[FLOAT]], [2610 -> ()[FLOAT]], [2611 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2610 for ONNX node: 2610
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2611 for ONNX node: 2611
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2612 for ONNX tensor: 2612
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2501 [QuantizeLinear] outputs: [2612 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2502 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2502 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2502 [Constant] outputs: [2613 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2503 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2503 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2503 [Constant] outputs: [2614 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: DequantizeLinear_2504 [DequantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2612
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2613
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2614
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2504 [DequantizeLinear] inputs: [2612 -> (1, 128, 8, 8)[FLOAT]], [2613 -> ()[FLOAT]], [2614 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2613 for ONNX node: 2613
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2614 for ONNX node: 2614
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2615 for ONNX tensor: 2615
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2504 [DequantizeLinear] outputs: [2615 -> (1, 128, 8, 8)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2505 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2505 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2505 [Constant] outputs: [2616 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2506 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2506 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2506 [Constant] outputs: [2617 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: QuantizeLinear_2507 [QuantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.3.weight
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2616
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2617
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2507 [QuantizeLinear] inputs: [conv5.3.weight -> (128, 128, 3, 3)[FLOAT]], [2616 -> ()[FLOAT]], [2617 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2616 for ONNX node: 2616
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2617 for ONNX node: 2617
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2618 for ONNX tensor: 2618
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2507 [QuantizeLinear] outputs: [2618 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2508 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2508 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2508 [Constant] outputs: [2619 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2509 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2509 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2509 [Constant] outputs: [2620 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: DequantizeLinear_2510 [DequantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2618
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2619
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2620
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2510 [DequantizeLinear] inputs: [2618 -> (128, 128, 3, 3)[FLOAT]], [2619 -> ()[FLOAT]], [2620 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2619 for ONNX node: 2619
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2620 for ONNX node: 2620
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2621 for ONNX tensor: 2621
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2510 [DequantizeLinear] outputs: [2621 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Conv_2511 [Conv]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2615
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2621
[03/01/2023-10:41:05] [V] [TRT] Conv_2511 [Conv] inputs: [2615 -> (1, 128, 8, 8)[FLOAT]], [2621 -> (128, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Conv_2511 for ONNX node: Conv_2511
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2622 for ONNX tensor: 2622
[03/01/2023-10:41:05] [V] [TRT] Conv_2511 [Conv] outputs: [2622 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: BatchNormalization_2512 [BatchNormalization]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2622
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.4.weight
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.4.bias
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.4.running_mean
[03/01/2023-10:41:05] [V] [TRT] Searching for input: conv5.4.running_var
[03/01/2023-10:41:05] [V] [TRT] BatchNormalization_2512 [BatchNormalization] inputs: [2622 -> (1, 128, 6, 6)[FLOAT]], [conv5.4.weight -> (128)[FLOAT]], [conv5.4.bias -> (128)[FLOAT]], [conv5.4.running_mean -> (128)[FLOAT]], [conv5.4.running_var -> (128)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: BatchNormalization_2512 for ONNX node: BatchNormalization_2512
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2623 for ONNX tensor: 2623
[03/01/2023-10:41:05] [V] [TRT] BatchNormalization_2512 [BatchNormalization] outputs: [2623 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Relu_2513 [Relu]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2623
[03/01/2023-10:41:05] [V] [TRT] Relu_2513 [Relu] inputs: [2623 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Relu_2513 for ONNX node: Relu_2513
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2624 for ONNX tensor: 2624
[03/01/2023-10:41:05] [V] [TRT] Relu_2513 [Relu] outputs: [2624 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: MaxPool_2514 [MaxPool]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2624
[03/01/2023-10:41:05] [V] [TRT] MaxPool_2514 [MaxPool] inputs: [2624 -> (1, 128, 6, 6)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: MaxPool_2514 for ONNX node: MaxPool_2514
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2625 for ONNX tensor: 2625
[03/01/2023-10:41:05] [V] [TRT] MaxPool_2514 [MaxPool] outputs: [2625 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: ReduceMean_2515 [ReduceMean]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2625
[03/01/2023-10:41:05] [V] [TRT] ReduceMean_2515 [ReduceMean] inputs: [2625 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: ReduceMean_2515 for ONNX node: ReduceMean_2515
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2626 for ONNX tensor: 2626
[03/01/2023-10:41:05] [V] [TRT] ReduceMean_2515 [ReduceMean] outputs: [2626 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: ReduceMax_2516 [ReduceMax]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2625
[03/01/2023-10:41:05] [V] [TRT] ReduceMax_2516 [ReduceMax] inputs: [2625 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: ReduceMax_2516 for ONNX node: ReduceMax_2516
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2627 for ONNX tensor: 2627
[03/01/2023-10:41:05] [V] [TRT] ReduceMax_2516 [ReduceMax] outputs: [2627 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Concat_2517 [Concat]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2626
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2627
[03/01/2023-10:41:05] [V] [TRT] Concat_2517 [Concat] inputs: [2626 -> (1, 1, 3, 3)[FLOAT]], [2627 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Concat_2517 for ONNX node: Concat_2517
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2628 for ONNX tensor: 2628
[03/01/2023-10:41:05] [V] [TRT] Concat_2517 [Concat] outputs: [2628 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2518 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2518 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2518 [Constant] outputs: [2629 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2519 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2519 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2519 [Constant] outputs: [2630 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: QuantizeLinear_2520 [QuantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2628
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2629
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2630
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2520 [QuantizeLinear] inputs: [2628 -> (1, 2, 3, 3)[FLOAT]], [2629 -> ()[FLOAT]], [2630 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2629 for ONNX node: 2629
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2630 for ONNX node: 2630
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2631 for ONNX tensor: 2631
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2520 [QuantizeLinear] outputs: [2631 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2521 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2521 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2521 [Constant] outputs: [2632 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2522 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2522 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2522 [Constant] outputs: [2633 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: DequantizeLinear_2523 [DequantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2631
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2632
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2633
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2523 [DequantizeLinear] inputs: [2631 -> (1, 2, 3, 3)[FLOAT]], [2632 -> ()[FLOAT]], [2633 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2632 for ONNX node: 2632
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2633 for ONNX node: 2633
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2634 for ONNX tensor: 2634
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2523 [DequantizeLinear] outputs: [2634 -> (1, 2, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2524 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2524 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2524 [Constant] outputs: [2635 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2525 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2525 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2525 [Constant] outputs: [2636 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: QuantizeLinear_2526 [QuantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: patchattention_spatial.conv1.weight
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2635
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2636
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2526 [QuantizeLinear] inputs: [patchattention_spatial.conv1.weight -> (1, 2, 7, 7)[FLOAT]], [2635 -> ()[FLOAT]], [2636 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2635 for ONNX node: 2635
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2636 for ONNX node: 2636
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2637 for ONNX tensor: 2637
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2526 [QuantizeLinear] outputs: [2637 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2527 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2527 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2527 [Constant] outputs: [2638 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2528 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2528 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2528 [Constant] outputs: [2639 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: DequantizeLinear_2529 [DequantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2637
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2638
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2639
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2529 [DequantizeLinear] inputs: [2637 -> (1, 2, 7, 7)[FLOAT]], [2638 -> ()[FLOAT]], [2639 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2638 for ONNX node: 2638
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2639 for ONNX node: 2639
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2640 for ONNX tensor: 2640
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2529 [DequantizeLinear] outputs: [2640 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Conv_2530 [Conv]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2634
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2640
[03/01/2023-10:41:05] [V] [TRT] Conv_2530 [Conv] inputs: [2634 -> (1, 2, 3, 3)[FLOAT]], [2640 -> (1, 2, 7, 7)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Conv_2530 for ONNX node: Conv_2530
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2641 for ONNX tensor: 2641
[03/01/2023-10:41:05] [V] [TRT] Conv_2530 [Conv] outputs: [2641 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Sigmoid_2531 [Sigmoid]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2641
[03/01/2023-10:41:05] [V] [TRT] Sigmoid_2531 [Sigmoid] inputs: [2641 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Sigmoid_2531 for ONNX node: Sigmoid_2531
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2642 for ONNX tensor: 2642
[03/01/2023-10:41:05] [V] [TRT] Sigmoid_2531 [Sigmoid] outputs: [2642 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Mul_2532 [Mul]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2625
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2642
[03/01/2023-10:41:05] [V] [TRT] Mul_2532 [Mul] inputs: [2625 -> (1, 128, 3, 3)[FLOAT]], [2642 -> (1, 1, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Mul_2532 for ONNX node: Mul_2532
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2643 for ONNX tensor: 2643
[03/01/2023-10:41:05] [V] [TRT] Mul_2532 [Mul] outputs: [2643 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: GlobalAveragePool_2533 [GlobalAveragePool]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2643
[03/01/2023-10:41:05] [V] [TRT] GlobalAveragePool_2533 [GlobalAveragePool] inputs: [2643 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:41:05] [V] [TRT] Registering layer: GlobalAveragePool_2533 for ONNX node: GlobalAveragePool_2533
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2644 for ONNX tensor: 2644
[03/01/2023-10:41:05] [V] [TRT] GlobalAveragePool_2533 [GlobalAveragePool] outputs: [2644 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2534 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2534 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2534 [Constant] outputs: [2645 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2535 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2535 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2535 [Constant] outputs: [2646 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: QuantizeLinear_2536 [QuantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2644
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2645
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2646
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2536 [QuantizeLinear] inputs: [2644 -> (1, 128, 1, 1)[FLOAT]], [2645 -> ()[FLOAT]], [2646 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2645 for ONNX node: 2645
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2646 for ONNX node: 2646
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2647 for ONNX tensor: 2647
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2536 [QuantizeLinear] outputs: [2647 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2537 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2537 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2537 [Constant] outputs: [2648 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2538 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2538 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2538 [Constant] outputs: [2649 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: DequantizeLinear_2539 [DequantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2647
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2648
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2649
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2539 [DequantizeLinear] inputs: [2647 -> (1, 128, 1, 1)[FLOAT]], [2648 -> ()[FLOAT]], [2649 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2648 for ONNX node: 2648
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2649 for ONNX node: 2649
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2650 for ONNX tensor: 2650
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2539 [DequantizeLinear] outputs: [2650 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2540 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2540 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2540 [Constant] outputs: [2651 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2541 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2541 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2541 [Constant] outputs: [2652 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: QuantizeLinear_2542 [QuantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2651
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2652
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2542 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2651 -> ()[FLOAT]], [2652 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2651 for ONNX node: 2651
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2652 for ONNX node: 2652
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2653 for ONNX tensor: 2653
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2542 [QuantizeLinear] outputs: [2653 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2543 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2543 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2543 [Constant] outputs: [2654 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2544 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2544 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2544 [Constant] outputs: [2655 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: DequantizeLinear_2545 [DequantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2653
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2654
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2655
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2545 [DequantizeLinear] inputs: [2653 -> (8, 128, 1, 1)[FLOAT]], [2654 -> ()[FLOAT]], [2655 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2654 for ONNX node: 2654
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2655 for ONNX node: 2655
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2656 for ONNX tensor: 2656
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2545 [DequantizeLinear] outputs: [2656 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Conv_2546 [Conv]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2650
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2656
[03/01/2023-10:41:05] [V] [TRT] Conv_2546 [Conv] inputs: [2650 -> (1, 128, 1, 1)[FLOAT]], [2656 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Conv_2546 for ONNX node: Conv_2546
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2657 for ONNX tensor: 2657
[03/01/2023-10:41:05] [V] [TRT] Conv_2546 [Conv] outputs: [2657 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Relu_2547 [Relu]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2657
[03/01/2023-10:41:05] [V] [TRT] Relu_2547 [Relu] inputs: [2657 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: Relu_2547 for ONNX node: Relu_2547
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2658 for ONNX tensor: 2658
[03/01/2023-10:41:05] [V] [TRT] Relu_2547 [Relu] outputs: [2658 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2548 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2548 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2548 [Constant] outputs: [2659 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2549 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2549 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2549 [Constant] outputs: [2660 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: QuantizeLinear_2550 [QuantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2658
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2659
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2660
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2550 [QuantizeLinear] inputs: [2658 -> (1, 8, 1, 1)[FLOAT]], [2659 -> ()[FLOAT]], [2660 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2659 for ONNX node: 2659
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2660 for ONNX node: 2660
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2661 for ONNX tensor: 2661
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2550 [QuantizeLinear] outputs: [2661 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2551 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2551 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2551 [Constant] outputs: [2662 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2552 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2552 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2552 [Constant] outputs: [2663 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: DequantizeLinear_2553 [DequantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2661
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2662
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2663
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2553 [DequantizeLinear] inputs: [2661 -> (1, 8, 1, 1)[FLOAT]], [2662 -> ()[FLOAT]], [2663 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2662 for ONNX node: 2662
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2663 for ONNX node: 2663
[03/01/2023-10:41:05] [V] [TRT] Registering tensor: 2664 for ONNX tensor: 2664
[03/01/2023-10:41:05] [V] [TRT] DequantizeLinear_2553 [DequantizeLinear] outputs: [2664 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2554 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2554 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2554 [Constant] outputs: [2665 -> ()[FLOAT]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: Constant_2555 [Constant]
[03/01/2023-10:41:05] [V] [TRT] Constant_2555 [Constant] inputs: 
[03/01/2023-10:41:05] [V] [TRT] Constant_2555 [Constant] outputs: [2666 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Parsing node: QuantizeLinear_2556 [QuantizeLinear]
[03/01/2023-10:41:05] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2665
[03/01/2023-10:41:05] [V] [TRT] Searching for input: 2666
[03/01/2023-10:41:05] [V] [TRT] QuantizeLinear_2556 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2665 -> ()[FLOAT]], [2666 -> ()[INT8]], 
[03/01/2023-10:41:05] [V] [TRT] Registering layer: 2665 for ONNX node: 2665
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2666 for ONNX node: 2666
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2667 for ONNX tensor: 2667
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2556 [QuantizeLinear] outputs: [2667 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2557 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2557 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2557 [Constant] outputs: [2668 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2558 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2558 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2558 [Constant] outputs: [2669 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: DequantizeLinear_2559 [DequantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2667
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2668
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2669
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2559 [DequantizeLinear] inputs: [2667 -> (128, 8, 1, 1)[FLOAT]], [2668 -> ()[FLOAT]], [2669 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2668 for ONNX node: 2668
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2669 for ONNX node: 2669
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2670 for ONNX tensor: 2670
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2559 [DequantizeLinear] outputs: [2670 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Conv_2560 [Conv]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2664
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2670
[03/01/2023-10:41:06] [V] [TRT] Conv_2560 [Conv] inputs: [2664 -> (1, 8, 1, 1)[FLOAT]], [2670 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Conv_2560 for ONNX node: Conv_2560
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2671 for ONNX tensor: 2671
[03/01/2023-10:41:06] [V] [TRT] Conv_2560 [Conv] outputs: [2671 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: MaxPool_2561 [MaxPool]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2643
[03/01/2023-10:41:06] [V] [TRT] MaxPool_2561 [MaxPool] inputs: [2643 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: MaxPool_2561 for ONNX node: MaxPool_2561
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2672 for ONNX tensor: 2672
[03/01/2023-10:41:06] [V] [TRT] MaxPool_2561 [MaxPool] outputs: [2672 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2562 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2562 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2562 [Constant] outputs: [2673 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2563 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2563 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2563 [Constant] outputs: [2674 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: QuantizeLinear_2564 [QuantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2672
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2673
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2674
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2564 [QuantizeLinear] inputs: [2672 -> (1, 128, 1, 1)[FLOAT]], [2673 -> ()[FLOAT]], [2674 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2673 for ONNX node: 2673
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2674 for ONNX node: 2674
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2675 for ONNX tensor: 2675
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2564 [QuantizeLinear] outputs: [2675 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2565 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2565 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2565 [Constant] outputs: [2676 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2566 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2566 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2566 [Constant] outputs: [2677 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: DequantizeLinear_2567 [DequantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2675
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2676
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2677
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2567 [DequantizeLinear] inputs: [2675 -> (1, 128, 1, 1)[FLOAT]], [2676 -> ()[FLOAT]], [2677 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2676 for ONNX node: 2676
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2677 for ONNX node: 2677
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2678 for ONNX tensor: 2678
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2567 [DequantizeLinear] outputs: [2678 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2568 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2568 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2568 [Constant] outputs: [2679 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2569 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2569 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2569 [Constant] outputs: [2680 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: QuantizeLinear_2570 [QuantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: patchattention_channel.fc.0.weight
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2679
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2680
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2570 [QuantizeLinear] inputs: [patchattention_channel.fc.0.weight -> (8, 128, 1, 1)[FLOAT]], [2679 -> ()[FLOAT]], [2680 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2679 for ONNX node: 2679
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2680 for ONNX node: 2680
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2681 for ONNX tensor: 2681
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2570 [QuantizeLinear] outputs: [2681 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2571 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2571 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2571 [Constant] outputs: [2682 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2572 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2572 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2572 [Constant] outputs: [2683 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: DequantizeLinear_2573 [DequantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2681
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2682
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2683
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2573 [DequantizeLinear] inputs: [2681 -> (8, 128, 1, 1)[FLOAT]], [2682 -> ()[FLOAT]], [2683 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2682 for ONNX node: 2682
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2683 for ONNX node: 2683
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2684 for ONNX tensor: 2684
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2573 [DequantizeLinear] outputs: [2684 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Conv_2574 [Conv]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2678
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2684
[03/01/2023-10:41:06] [V] [TRT] Conv_2574 [Conv] inputs: [2678 -> (1, 128, 1, 1)[FLOAT]], [2684 -> (8, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Conv_2574 for ONNX node: Conv_2574
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2685 for ONNX tensor: 2685
[03/01/2023-10:41:06] [V] [TRT] Conv_2574 [Conv] outputs: [2685 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Relu_2575 [Relu]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2685
[03/01/2023-10:41:06] [V] [TRT] Relu_2575 [Relu] inputs: [2685 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Relu_2575 for ONNX node: Relu_2575
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2686 for ONNX tensor: 2686
[03/01/2023-10:41:06] [V] [TRT] Relu_2575 [Relu] outputs: [2686 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2576 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2576 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2576 [Constant] outputs: [2687 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2577 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2577 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2577 [Constant] outputs: [2688 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: QuantizeLinear_2578 [QuantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2686
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2687
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2688
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2578 [QuantizeLinear] inputs: [2686 -> (1, 8, 1, 1)[FLOAT]], [2687 -> ()[FLOAT]], [2688 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2687 for ONNX node: 2687
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2688 for ONNX node: 2688
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2689 for ONNX tensor: 2689
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2578 [QuantizeLinear] outputs: [2689 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2579 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2579 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2579 [Constant] outputs: [2690 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2580 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2580 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2580 [Constant] outputs: [2691 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: DequantizeLinear_2581 [DequantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2689
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2690
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2691
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2581 [DequantizeLinear] inputs: [2689 -> (1, 8, 1, 1)[FLOAT]], [2690 -> ()[FLOAT]], [2691 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2690 for ONNX node: 2690
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2691 for ONNX node: 2691
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2692 for ONNX tensor: 2692
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2581 [DequantizeLinear] outputs: [2692 -> (1, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2582 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2582 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2582 [Constant] outputs: [2693 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2583 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2583 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2583 [Constant] outputs: [2694 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: QuantizeLinear_2584 [QuantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: patchattention_channel.fc.2.weight
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2693
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2694
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2584 [QuantizeLinear] inputs: [patchattention_channel.fc.2.weight -> (128, 8, 1, 1)[FLOAT]], [2693 -> ()[FLOAT]], [2694 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2693 for ONNX node: 2693
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2694 for ONNX node: 2694
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2695 for ONNX tensor: 2695
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2584 [QuantizeLinear] outputs: [2695 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2585 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2585 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2585 [Constant] outputs: [2696 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2586 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2586 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2586 [Constant] outputs: [2697 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: DequantizeLinear_2587 [DequantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2695
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2696
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2697
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2587 [DequantizeLinear] inputs: [2695 -> (128, 8, 1, 1)[FLOAT]], [2696 -> ()[FLOAT]], [2697 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2696 for ONNX node: 2696
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2697 for ONNX node: 2697
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2698 for ONNX tensor: 2698
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2587 [DequantizeLinear] outputs: [2698 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Conv_2588 [Conv]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2692
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2698
[03/01/2023-10:41:06] [V] [TRT] Conv_2588 [Conv] inputs: [2692 -> (1, 8, 1, 1)[FLOAT]], [2698 -> (128, 8, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Conv_2588 for ONNX node: Conv_2588
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2699 for ONNX tensor: 2699
[03/01/2023-10:41:06] [V] [TRT] Conv_2588 [Conv] outputs: [2699 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Add_2589 [Add]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2671
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2699
[03/01/2023-10:41:06] [V] [TRT] Add_2589 [Add] inputs: [2671 -> (1, 128, 1, 1)[FLOAT]], [2699 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Add_2589 for ONNX node: Add_2589
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2700 for ONNX tensor: 2700
[03/01/2023-10:41:06] [V] [TRT] Add_2589 [Add] outputs: [2700 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Sigmoid_2590 [Sigmoid]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2700
[03/01/2023-10:41:06] [V] [TRT] Sigmoid_2590 [Sigmoid] inputs: [2700 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Sigmoid_2590 for ONNX node: Sigmoid_2590
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2701 for ONNX tensor: 2701
[03/01/2023-10:41:06] [V] [TRT] Sigmoid_2590 [Sigmoid] outputs: [2701 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Mul_2591 [Mul]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2643
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2701
[03/01/2023-10:41:06] [V] [TRT] Mul_2591 [Mul] inputs: [2643 -> (1, 128, 3, 3)[FLOAT]], [2701 -> (1, 128, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Mul_2591 for ONNX node: Mul_2591
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2702 for ONNX tensor: 2702
[03/01/2023-10:41:06] [V] [TRT] Mul_2591 [Mul] outputs: [2702 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Concat_2592 [Concat]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2553
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2702
[03/01/2023-10:41:06] [V] [TRT] Concat_2592 [Concat] inputs: [2553 -> (1, 1920, 3, 3)[FLOAT]], [2702 -> (1, 128, 3, 3)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Concat_2592 for ONNX node: Concat_2592
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2703 for ONNX tensor: 2703
[03/01/2023-10:41:06] [V] [TRT] Concat_2592 [Concat] outputs: [2703 -> (1, 2048, 3, 3)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: GlobalAveragePool_2593 [GlobalAveragePool]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2703
[03/01/2023-10:41:06] [V] [TRT] GlobalAveragePool_2593 [GlobalAveragePool] inputs: [2703 -> (1, 2048, 3, 3)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[03/01/2023-10:41:06] [V] [TRT] Registering layer: GlobalAveragePool_2593 for ONNX node: GlobalAveragePool_2593
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2704 for ONNX tensor: 2704
[03/01/2023-10:41:06] [V] [TRT] GlobalAveragePool_2593 [GlobalAveragePool] outputs: [2704 -> (1, 2048, 1, 1)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2594 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2594 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2594 [Constant] outputs: [2705 -> (2)[INT32]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Reshape_2595 [Reshape]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2704
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2705
[03/01/2023-10:41:06] [V] [TRT] Reshape_2595 [Reshape] inputs: [2704 -> (1, 2048, 1, 1)[FLOAT]], [2705 -> (2)[INT32]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Reshape_2595 for ONNX node: Reshape_2595
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2706 for ONNX tensor: 2706
[03/01/2023-10:41:06] [V] [TRT] Reshape_2595 [Reshape] outputs: [2706 -> (1, 2048)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2596 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2596 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2596 [Constant] outputs: [2707 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2597 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2597 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2597 [Constant] outputs: [2708 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: QuantizeLinear_2598 [QuantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2706
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2707
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2708
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2598 [QuantizeLinear] inputs: [2706 -> (1, 2048)[FLOAT]], [2707 -> ()[FLOAT]], [2708 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2707 for ONNX node: 2707
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2708 for ONNX node: 2708
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2709 for ONNX tensor: 2709
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2598 [QuantizeLinear] outputs: [2709 -> (1, 2048)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2599 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2599 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2599 [Constant] outputs: [2710 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2600 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2600 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2600 [Constant] outputs: [2711 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: DequantizeLinear_2601 [DequantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2709
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2710
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2711
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2601 [DequantizeLinear] inputs: [2709 -> (1, 2048)[FLOAT]], [2710 -> ()[FLOAT]], [2711 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2710 for ONNX node: 2710
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2711 for ONNX node: 2711
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2712 for ONNX tensor: 2712
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2601 [DequantizeLinear] outputs: [2712 -> (1, 2048)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2602 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2602 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2602 [Constant] outputs: [2713 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2603 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2603 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2603 [Constant] outputs: [2714 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: QuantizeLinear_2604 [QuantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: classfier2.weight
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2713
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2714
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2604 [QuantizeLinear] inputs: [classfier2.weight -> (6, 2048)[FLOAT]], [2713 -> ()[FLOAT]], [2714 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: classfier2.weight for ONNX node: classfier2.weight
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2713 for ONNX node: 2713
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2714 for ONNX node: 2714
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2715 for ONNX tensor: 2715
[03/01/2023-10:41:06] [V] [TRT] QuantizeLinear_2604 [QuantizeLinear] outputs: [2715 -> (6, 2048)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2605 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2605 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2605 [Constant] outputs: [2716 -> ()[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Constant_2606 [Constant]
[03/01/2023-10:41:06] [V] [TRT] Constant_2606 [Constant] inputs: 
[03/01/2023-10:41:06] [V] [TRT] Constant_2606 [Constant] outputs: [2717 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: DequantizeLinear_2607 [DequantizeLinear]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2715
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2716
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2717
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2607 [DequantizeLinear] inputs: [2715 -> (6, 2048)[FLOAT]], [2716 -> ()[FLOAT]], [2717 -> ()[INT8]], 
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2716 for ONNX node: 2716
[03/01/2023-10:41:06] [V] [TRT] Registering layer: 2717 for ONNX node: 2717
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2718 for ONNX tensor: 2718
[03/01/2023-10:41:06] [V] [TRT] DequantizeLinear_2607 [DequantizeLinear] outputs: [2718 -> (6, 2048)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Parsing node: Gemm_2608 [Gemm]
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2712
[03/01/2023-10:41:06] [V] [TRT] Searching for input: 2718
[03/01/2023-10:41:06] [V] [TRT] Searching for input: classfier2.bias
[03/01/2023-10:41:06] [V] [TRT] Gemm_2608 [Gemm] inputs: [2712 -> (1, 2048)[FLOAT]], [2718 -> (6, 2048)[FLOAT]], [classfier2.bias -> (6)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Using opA: 0 opB: 1
[03/01/2023-10:41:06] [V] [TRT] Registering layer: Gemm_2608 for ONNX node: Gemm_2608
[03/01/2023-10:41:06] [V] [TRT] Registering layer: classfier2.bias for ONNX node: classfier2.bias
[03/01/2023-10:41:06] [V] [TRT] Registering tensor: 2719_902 for ONNX tensor: 2719
[03/01/2023-10:41:06] [V] [TRT] Gemm_2608 [Gemm] outputs: [2719 -> (1, 6)[FLOAT]], 
[03/01/2023-10:41:06] [V] [TRT] Marking output_64 as output: output
[03/01/2023-10:41:06] [V] [TRT] Marking 2719_902 as output: 2719
[03/01/2023-10:41:06] [I] Finish parsing network model
[03/01/2023-10:41:06] [I] FP32 and INT8 precisions have been specified - more performance might be enabled by additionally specifying --fp16 or --best
[03/01/2023-10:41:06] [V] Trying to set exclusive file lock ./timing.cache.lock
[03/01/2023-10:41:06] [V] File locked in 6.312e-06 seconds.
[03/01/2023-10:41:06] [W] Could not read timing cache from: ./timing.cache. A new timing cache will be generated and written.
[03/01/2023-10:41:06] [V] Trying to remove exclusive file lock ./timing.cache.lock
[03/01/2023-10:41:06] [V] File unlocked in 9.967e-06 seconds.
[03/01/2023-10:41:06] [W] [TRT] Calibrator won't be used in explicit precision mode. Use quantization aware training to generate network with Quantize/Dequantize nodes.
[03/01/2023-10:41:06] [V] [TRT] Original: 2497 layers
[03/01/2023-10:41:06] [V] [TRT] After dead-layer removal: 2497 layers
[03/01/2023-10:41:06] [V] [TRT] Applying generic optimizations to the graph for inference.
[03/01/2023-10:41:06] [V] [TRT] Running: ConstShuffleFusion on classfier1.bias
[03/01/2023-10:41:06] [V] [TRT] ConstShuffleFusion: Fusing classfier1.bias with (Unnamed Layer* 202) [Shuffle]
[03/01/2023-10:41:06] [V] [TRT] Running: ConstShuffleFusion on classfier2.bias
[03/01/2023-10:41:06] [V] [TRT] ConstShuffleFusion: Fusing classfier2.bias with (Unnamed Layer* 2499) [Shuffle]
[03/01/2023-10:41:07] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2
[03/01/2023-10:41:07] [V] [TRT] Removing 108
[03/01/2023-10:41:07] [V] [TRT] Removing 107
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_23
[03/01/2023-10:41:07] [V] [TRT] Removing 129
[03/01/2023-10:41:07] [V] [TRT] Removing 128
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_54
[03/01/2023-10:41:07] [V] [TRT] Removing 160
[03/01/2023-10:41:07] [V] [TRT] Removing 159
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_92
[03/01/2023-10:41:07] [V] [TRT] Removing 202
[03/01/2023-10:41:07] [V] [TRT] Removing 201
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_128
[03/01/2023-10:41:07] [V] [TRT] Removing 238
[03/01/2023-10:41:07] [V] [TRT] Removing 237
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_156
[03/01/2023-10:41:07] [V] [TRT] Removing 266
[03/01/2023-10:41:07] [V] [TRT] Removing 265
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_189
[03/01/2023-10:41:07] [V] [TRT] Removing 299
[03/01/2023-10:41:07] [V] [TRT] Removing 298
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_227
[03/01/2023-10:41:07] [V] [TRT] Removing 337
[03/01/2023-10:41:07] [V] [TRT] Removing 336
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_258
[03/01/2023-10:41:07] [V] [TRT] Removing 368
[03/01/2023-10:41:07] [V] [TRT] Removing 367
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_293
[03/01/2023-10:41:07] [V] [TRT] Removing 403
[03/01/2023-10:41:07] [V] [TRT] Removing 402
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_321
[03/01/2023-10:41:07] [V] [TRT] Removing 431
[03/01/2023-10:41:07] [V] [TRT] Removing 430
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_361
[03/01/2023-10:41:07] [V] [TRT] Removing 471
[03/01/2023-10:41:07] [V] [TRT] Removing 470
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_392
[03/01/2023-10:41:07] [V] [TRT] Removing 502
[03/01/2023-10:41:07] [V] [TRT] Removing 501
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_426
[03/01/2023-10:41:07] [V] [TRT] Removing 536
[03/01/2023-10:41:07] [V] [TRT] Removing 535
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_456
[03/01/2023-10:41:07] [V] [TRT] Removing 566
[03/01/2023-10:41:07] [V] [TRT] Removing 565
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_484
[03/01/2023-10:41:07] [V] [TRT] Removing 594
[03/01/2023-10:41:07] [V] [TRT] Removing 593
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_526
[03/01/2023-10:41:07] [V] [TRT] Removing 636
[03/01/2023-10:41:07] [V] [TRT] Removing 635
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_557
[03/01/2023-10:41:07] [V] [TRT] Removing 667
[03/01/2023-10:41:07] [V] [TRT] Removing 666
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_592
[03/01/2023-10:41:07] [V] [TRT] Removing 702
[03/01/2023-10:41:07] [V] [TRT] Removing 701
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_620
[03/01/2023-10:41:07] [V] [TRT] Removing 730
[03/01/2023-10:41:07] [V] [TRT] Removing 729
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_661
[03/01/2023-10:41:07] [V] [TRT] Removing 771
[03/01/2023-10:41:07] [V] [TRT] Removing 770
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_692
[03/01/2023-10:41:07] [V] [TRT] Removing 802
[03/01/2023-10:41:07] [V] [TRT] Removing 801
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_726
[03/01/2023-10:41:07] [V] [TRT] Removing 836
[03/01/2023-10:41:07] [V] [TRT] Removing 835
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_756
[03/01/2023-10:41:07] [V] [TRT] Removing 866
[03/01/2023-10:41:07] [V] [TRT] Removing 865
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_784
[03/01/2023-10:41:07] [V] [TRT] Removing 894
[03/01/2023-10:41:07] [V] [TRT] Removing 893
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_826
[03/01/2023-10:41:07] [V] [TRT] Removing 936
[03/01/2023-10:41:07] [V] [TRT] Removing 935
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_857
[03/01/2023-10:41:07] [V] [TRT] Removing 967
[03/01/2023-10:41:07] [V] [TRT] Removing 966
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_892
[03/01/2023-10:41:07] [V] [TRT] Removing 1002
[03/01/2023-10:41:07] [V] [TRT] Removing 1001
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_920
[03/01/2023-10:41:07] [V] [TRT] Removing 1030
[03/01/2023-10:41:07] [V] [TRT] Removing 1029
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_961
[03/01/2023-10:41:07] [V] [TRT] Removing 1071
[03/01/2023-10:41:07] [V] [TRT] Removing 1070
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_992
[03/01/2023-10:41:07] [V] [TRT] Removing 1102
[03/01/2023-10:41:07] [V] [TRT] Removing 1101
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1026
[03/01/2023-10:41:07] [V] [TRT] Removing 1136
[03/01/2023-10:41:07] [V] [TRT] Removing 1135
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1056
[03/01/2023-10:41:07] [V] [TRT] Removing 1166
[03/01/2023-10:41:07] [V] [TRT] Removing 1165
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1084
[03/01/2023-10:41:07] [V] [TRT] Removing 1194
[03/01/2023-10:41:07] [V] [TRT] Removing 1193
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1126
[03/01/2023-10:41:07] [V] [TRT] Removing 1236
[03/01/2023-10:41:07] [V] [TRT] Removing 1235
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1157
[03/01/2023-10:41:07] [V] [TRT] Removing 1267
[03/01/2023-10:41:07] [V] [TRT] Removing 1266
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1192
[03/01/2023-10:41:07] [V] [TRT] Removing 1302
[03/01/2023-10:41:07] [V] [TRT] Removing 1301
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1220
[03/01/2023-10:41:07] [V] [TRT] Removing 1330
[03/01/2023-10:41:07] [V] [TRT] Removing 1329
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1261
[03/01/2023-10:41:07] [V] [TRT] Removing 1371
[03/01/2023-10:41:07] [V] [TRT] Removing 1370
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1292
[03/01/2023-10:41:07] [V] [TRT] Removing 1402
[03/01/2023-10:41:07] [V] [TRT] Removing 1401
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1326
[03/01/2023-10:41:07] [V] [TRT] Removing 1436
[03/01/2023-10:41:07] [V] [TRT] Removing 1435
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1356
[03/01/2023-10:41:07] [V] [TRT] Removing 1466
[03/01/2023-10:41:07] [V] [TRT] Removing 1465
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1384
[03/01/2023-10:41:07] [V] [TRT] Removing 1494
[03/01/2023-10:41:07] [V] [TRT] Removing 1493
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1426
[03/01/2023-10:41:07] [V] [TRT] Removing 1536
[03/01/2023-10:41:07] [V] [TRT] Removing 1535
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1457
[03/01/2023-10:41:07] [V] [TRT] Removing 1567
[03/01/2023-10:41:07] [V] [TRT] Removing 1566
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1492
[03/01/2023-10:41:07] [V] [TRT] Removing 1602
[03/01/2023-10:41:07] [V] [TRT] Removing 1601
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1520
[03/01/2023-10:41:07] [V] [TRT] Removing 1630
[03/01/2023-10:41:07] [V] [TRT] Removing 1629
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1561
[03/01/2023-10:41:07] [V] [TRT] Removing 1671
[03/01/2023-10:41:07] [V] [TRT] Removing 1670
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1592
[03/01/2023-10:41:07] [V] [TRT] Removing 1702
[03/01/2023-10:41:07] [V] [TRT] Removing 1701
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1626
[03/01/2023-10:41:07] [V] [TRT] Removing 1736
[03/01/2023-10:41:07] [V] [TRT] Removing 1735
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1656
[03/01/2023-10:41:07] [V] [TRT] Removing 1766
[03/01/2023-10:41:07] [V] [TRT] Removing 1765
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1684
[03/01/2023-10:41:07] [V] [TRT] Removing 1794
[03/01/2023-10:41:07] [V] [TRT] Removing 1793
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1726
[03/01/2023-10:41:07] [V] [TRT] Removing 1836
[03/01/2023-10:41:07] [V] [TRT] Removing 1835
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1757
[03/01/2023-10:41:07] [V] [TRT] Removing 1867
[03/01/2023-10:41:07] [V] [TRT] Removing 1866
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1792
[03/01/2023-10:41:07] [V] [TRT] Removing 1902
[03/01/2023-10:41:07] [V] [TRT] Removing 1901
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1820
[03/01/2023-10:41:07] [V] [TRT] Removing 1930
[03/01/2023-10:41:07] [V] [TRT] Removing 1929
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1861
[03/01/2023-10:41:07] [V] [TRT] Removing 1971
[03/01/2023-10:41:07] [V] [TRT] Removing 1970
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1892
[03/01/2023-10:41:07] [V] [TRT] Removing 2002
[03/01/2023-10:41:07] [V] [TRT] Removing 2001
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1926
[03/01/2023-10:41:07] [V] [TRT] Removing 2036
[03/01/2023-10:41:07] [V] [TRT] Removing 2035
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1956
[03/01/2023-10:41:07] [V] [TRT] Removing 2066
[03/01/2023-10:41:07] [V] [TRT] Removing 2065
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1984
[03/01/2023-10:41:07] [V] [TRT] Removing 2094
[03/01/2023-10:41:07] [V] [TRT] Removing 2093
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2026
[03/01/2023-10:41:07] [V] [TRT] Removing 2136
[03/01/2023-10:41:07] [V] [TRT] Removing 2135
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2057
[03/01/2023-10:41:07] [V] [TRT] Removing 2167
[03/01/2023-10:41:07] [V] [TRT] Removing 2166
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2092
[03/01/2023-10:41:07] [V] [TRT] Removing 2202
[03/01/2023-10:41:07] [V] [TRT] Removing 2201
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2120
[03/01/2023-10:41:07] [V] [TRT] Removing 2230
[03/01/2023-10:41:07] [V] [TRT] Removing 2229
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2161
[03/01/2023-10:41:07] [V] [TRT] Removing 2271
[03/01/2023-10:41:07] [V] [TRT] Removing 2270
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2192
[03/01/2023-10:41:07] [V] [TRT] Removing 2302
[03/01/2023-10:41:07] [V] [TRT] Removing 2301
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2226
[03/01/2023-10:41:07] [V] [TRT] Removing 2336
[03/01/2023-10:41:07] [V] [TRT] Removing 2335
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2256
[03/01/2023-10:41:07] [V] [TRT] Removing 2366
[03/01/2023-10:41:07] [V] [TRT] Removing 2365
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2284
[03/01/2023-10:41:07] [V] [TRT] Removing 2394
[03/01/2023-10:41:07] [V] [TRT] Removing 2393
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2326
[03/01/2023-10:41:07] [V] [TRT] Removing 2436
[03/01/2023-10:41:07] [V] [TRT] Removing 2435
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2357
[03/01/2023-10:41:07] [V] [TRT] Removing 2467
[03/01/2023-10:41:07] [V] [TRT] Removing 2466
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2392
[03/01/2023-10:41:07] [V] [TRT] Removing 2502
[03/01/2023-10:41:07] [V] [TRT] Removing 2501
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2420
[03/01/2023-10:41:07] [V] [TRT] Removing 2530
[03/01/2023-10:41:07] [V] [TRT] Removing 2529
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2461
[03/01/2023-10:41:07] [V] [TRT] Removing 2571
[03/01/2023-10:41:07] [V] [TRT] Removing 2570
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2492
[03/01/2023-10:41:07] [V] [TRT] Removing 2602
[03/01/2023-10:41:07] [V] [TRT] Removing 2601
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2526
[03/01/2023-10:41:07] [V] [TRT] Removing 2636
[03/01/2023-10:41:07] [V] [TRT] Removing 2635
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2556
[03/01/2023-10:41:07] [V] [TRT] Removing 2666
[03/01/2023-10:41:07] [V] [TRT] Removing 2665
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2584
[03/01/2023-10:41:07] [V] [TRT] Removing 2694
[03/01/2023-10:41:07] [V] [TRT] Removing 2693
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_5
[03/01/2023-10:41:07] [V] [TRT] Removing 111
[03/01/2023-10:41:07] [V] [TRT] Removing 110
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_26
[03/01/2023-10:41:07] [V] [TRT] Removing 132
[03/01/2023-10:41:07] [V] [TRT] Removing 131
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_57
[03/01/2023-10:41:07] [V] [TRT] Removing 163
[03/01/2023-10:41:07] [V] [TRT] Removing 162
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_95
[03/01/2023-10:41:07] [V] [TRT] Removing 205
[03/01/2023-10:41:07] [V] [TRT] Removing 204
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_131
[03/01/2023-10:41:07] [V] [TRT] Removing 241
[03/01/2023-10:41:07] [V] [TRT] Removing 240
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_159
[03/01/2023-10:41:07] [V] [TRT] Removing 269
[03/01/2023-10:41:07] [V] [TRT] Removing 268
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_192
[03/01/2023-10:41:07] [V] [TRT] Removing 302
[03/01/2023-10:41:07] [V] [TRT] Removing 301
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_230
[03/01/2023-10:41:07] [V] [TRT] Removing 340
[03/01/2023-10:41:07] [V] [TRT] Removing 339
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_261
[03/01/2023-10:41:07] [V] [TRT] Removing 371
[03/01/2023-10:41:07] [V] [TRT] Removing 370
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_296
[03/01/2023-10:41:07] [V] [TRT] Removing 406
[03/01/2023-10:41:07] [V] [TRT] Removing 405
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_324
[03/01/2023-10:41:07] [V] [TRT] Removing 434
[03/01/2023-10:41:07] [V] [TRT] Removing 433
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_364
[03/01/2023-10:41:07] [V] [TRT] Removing 474
[03/01/2023-10:41:07] [V] [TRT] Removing 473
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_395
[03/01/2023-10:41:07] [V] [TRT] Removing 505
[03/01/2023-10:41:07] [V] [TRT] Removing 504
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_429
[03/01/2023-10:41:07] [V] [TRT] Removing 539
[03/01/2023-10:41:07] [V] [TRT] Removing 538
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_459
[03/01/2023-10:41:07] [V] [TRT] Removing 569
[03/01/2023-10:41:07] [V] [TRT] Removing 568
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_487
[03/01/2023-10:41:07] [V] [TRT] Removing 597
[03/01/2023-10:41:07] [V] [TRT] Removing 596
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_529
[03/01/2023-10:41:07] [V] [TRT] Removing 639
[03/01/2023-10:41:07] [V] [TRT] Removing 638
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_560
[03/01/2023-10:41:07] [V] [TRT] Removing 670
[03/01/2023-10:41:07] [V] [TRT] Removing 669
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_595
[03/01/2023-10:41:07] [V] [TRT] Removing 705
[03/01/2023-10:41:07] [V] [TRT] Removing 704
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_623
[03/01/2023-10:41:07] [V] [TRT] Removing 733
[03/01/2023-10:41:07] [V] [TRT] Removing 732
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_664
[03/01/2023-10:41:07] [V] [TRT] Removing 774
[03/01/2023-10:41:07] [V] [TRT] Removing 773
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_695
[03/01/2023-10:41:07] [V] [TRT] Removing 805
[03/01/2023-10:41:07] [V] [TRT] Removing 804
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_729
[03/01/2023-10:41:07] [V] [TRT] Removing 839
[03/01/2023-10:41:07] [V] [TRT] Removing 838
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_759
[03/01/2023-10:41:07] [V] [TRT] Removing 869
[03/01/2023-10:41:07] [V] [TRT] Removing 868
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_787
[03/01/2023-10:41:07] [V] [TRT] Removing 897
[03/01/2023-10:41:07] [V] [TRT] Removing 896
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_829
[03/01/2023-10:41:07] [V] [TRT] Removing 939
[03/01/2023-10:41:07] [V] [TRT] Removing 938
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_860
[03/01/2023-10:41:07] [V] [TRT] Removing 970
[03/01/2023-10:41:07] [V] [TRT] Removing 969
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_895
[03/01/2023-10:41:07] [V] [TRT] Removing 1005
[03/01/2023-10:41:07] [V] [TRT] Removing 1004
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_923
[03/01/2023-10:41:07] [V] [TRT] Removing 1033
[03/01/2023-10:41:07] [V] [TRT] Removing 1032
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_964
[03/01/2023-10:41:07] [V] [TRT] Removing 1074
[03/01/2023-10:41:07] [V] [TRT] Removing 1073
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_995
[03/01/2023-10:41:07] [V] [TRT] Removing 1105
[03/01/2023-10:41:07] [V] [TRT] Removing 1104
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1029
[03/01/2023-10:41:07] [V] [TRT] Removing 1139
[03/01/2023-10:41:07] [V] [TRT] Removing 1138
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1059
[03/01/2023-10:41:07] [V] [TRT] Removing 1169
[03/01/2023-10:41:07] [V] [TRT] Removing 1168
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1087
[03/01/2023-10:41:07] [V] [TRT] Removing 1197
[03/01/2023-10:41:07] [V] [TRT] Removing 1196
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1129
[03/01/2023-10:41:07] [V] [TRT] Removing 1239
[03/01/2023-10:41:07] [V] [TRT] Removing 1238
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1160
[03/01/2023-10:41:07] [V] [TRT] Removing 1270
[03/01/2023-10:41:07] [V] [TRT] Removing 1269
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1195
[03/01/2023-10:41:07] [V] [TRT] Removing 1305
[03/01/2023-10:41:07] [V] [TRT] Removing 1304
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1223
[03/01/2023-10:41:07] [V] [TRT] Removing 1333
[03/01/2023-10:41:07] [V] [TRT] Removing 1332
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1264
[03/01/2023-10:41:07] [V] [TRT] Removing 1374
[03/01/2023-10:41:07] [V] [TRT] Removing 1373
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1295
[03/01/2023-10:41:07] [V] [TRT] Removing 1405
[03/01/2023-10:41:07] [V] [TRT] Removing 1404
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1329
[03/01/2023-10:41:07] [V] [TRT] Removing 1439
[03/01/2023-10:41:07] [V] [TRT] Removing 1438
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1359
[03/01/2023-10:41:07] [V] [TRT] Removing 1469
[03/01/2023-10:41:07] [V] [TRT] Removing 1468
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1387
[03/01/2023-10:41:07] [V] [TRT] Removing 1497
[03/01/2023-10:41:07] [V] [TRT] Removing 1496
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1429
[03/01/2023-10:41:07] [V] [TRT] Removing 1539
[03/01/2023-10:41:07] [V] [TRT] Removing 1538
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1460
[03/01/2023-10:41:07] [V] [TRT] Removing 1570
[03/01/2023-10:41:07] [V] [TRT] Removing 1569
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1495
[03/01/2023-10:41:07] [V] [TRT] Removing 1605
[03/01/2023-10:41:07] [V] [TRT] Removing 1604
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1523
[03/01/2023-10:41:07] [V] [TRT] Removing 1633
[03/01/2023-10:41:07] [V] [TRT] Removing 1632
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1564
[03/01/2023-10:41:07] [V] [TRT] Removing 1674
[03/01/2023-10:41:07] [V] [TRT] Removing 1673
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1595
[03/01/2023-10:41:07] [V] [TRT] Removing 1705
[03/01/2023-10:41:07] [V] [TRT] Removing 1704
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1629
[03/01/2023-10:41:07] [V] [TRT] Removing 1739
[03/01/2023-10:41:07] [V] [TRT] Removing 1738
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1659
[03/01/2023-10:41:07] [V] [TRT] Removing 1769
[03/01/2023-10:41:07] [V] [TRT] Removing 1768
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1687
[03/01/2023-10:41:07] [V] [TRT] Removing 1797
[03/01/2023-10:41:07] [V] [TRT] Removing 1796
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1729
[03/01/2023-10:41:07] [V] [TRT] Removing 1839
[03/01/2023-10:41:07] [V] [TRT] Removing 1838
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1760
[03/01/2023-10:41:07] [V] [TRT] Removing 1870
[03/01/2023-10:41:07] [V] [TRT] Removing 1869
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1795
[03/01/2023-10:41:07] [V] [TRT] Removing 1905
[03/01/2023-10:41:07] [V] [TRT] Removing 1904
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1823
[03/01/2023-10:41:07] [V] [TRT] Removing 1933
[03/01/2023-10:41:07] [V] [TRT] Removing 1932
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1864
[03/01/2023-10:41:07] [V] [TRT] Removing 1974
[03/01/2023-10:41:07] [V] [TRT] Removing 1973
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1895
[03/01/2023-10:41:07] [V] [TRT] Removing 2005
[03/01/2023-10:41:07] [V] [TRT] Removing 2004
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1929
[03/01/2023-10:41:07] [V] [TRT] Removing 2039
[03/01/2023-10:41:07] [V] [TRT] Removing 2038
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1959
[03/01/2023-10:41:07] [V] [TRT] Removing 2069
[03/01/2023-10:41:07] [V] [TRT] Removing 2068
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1987
[03/01/2023-10:41:07] [V] [TRT] Removing 2097
[03/01/2023-10:41:07] [V] [TRT] Removing 2096
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2029
[03/01/2023-10:41:07] [V] [TRT] Removing 2139
[03/01/2023-10:41:07] [V] [TRT] Removing 2138
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2060
[03/01/2023-10:41:07] [V] [TRT] Removing 2170
[03/01/2023-10:41:07] [V] [TRT] Removing 2169
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2095
[03/01/2023-10:41:07] [V] [TRT] Removing 2205
[03/01/2023-10:41:07] [V] [TRT] Removing 2204
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2123
[03/01/2023-10:41:07] [V] [TRT] Removing 2233
[03/01/2023-10:41:07] [V] [TRT] Removing 2232
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2164
[03/01/2023-10:41:07] [V] [TRT] Removing 2274
[03/01/2023-10:41:07] [V] [TRT] Removing 2273
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2195
[03/01/2023-10:41:07] [V] [TRT] Removing 2305
[03/01/2023-10:41:07] [V] [TRT] Removing 2304
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2229
[03/01/2023-10:41:07] [V] [TRT] Removing 2339
[03/01/2023-10:41:07] [V] [TRT] Removing 2338
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2259
[03/01/2023-10:41:07] [V] [TRT] Removing 2369
[03/01/2023-10:41:07] [V] [TRT] Removing 2368
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2287
[03/01/2023-10:41:07] [V] [TRT] Removing 2397
[03/01/2023-10:41:07] [V] [TRT] Removing 2396
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2329
[03/01/2023-10:41:07] [V] [TRT] Removing 2439
[03/01/2023-10:41:07] [V] [TRT] Removing 2438
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2360
[03/01/2023-10:41:07] [V] [TRT] Removing 2470
[03/01/2023-10:41:07] [V] [TRT] Removing 2469
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2395
[03/01/2023-10:41:07] [V] [TRT] Removing 2505
[03/01/2023-10:41:07] [V] [TRT] Removing 2504
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2423
[03/01/2023-10:41:07] [V] [TRT] Removing 2533
[03/01/2023-10:41:07] [V] [TRT] Removing 2532
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2464
[03/01/2023-10:41:07] [V] [TRT] Removing 2574
[03/01/2023-10:41:07] [V] [TRT] Removing 2573
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2495
[03/01/2023-10:41:07] [V] [TRT] Removing 2605
[03/01/2023-10:41:07] [V] [TRT] Removing 2604
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2529
[03/01/2023-10:41:07] [V] [TRT] Removing 2639
[03/01/2023-10:41:07] [V] [TRT] Removing 2638
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2559
[03/01/2023-10:41:07] [V] [TRT] Removing 2669
[03/01/2023-10:41:07] [V] [TRT] Removing 2668
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2587
[03/01/2023-10:41:07] [V] [TRT] Removing 2697
[03/01/2023-10:41:07] [V] [TRT] Removing 2696
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_206
[03/01/2023-10:41:07] [V] [TRT] Removing 316
[03/01/2023-10:41:07] [V] [TRT] Removing 315
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_505
[03/01/2023-10:41:07] [V] [TRT] Removing 615
[03/01/2023-10:41:07] [V] [TRT] Removing 614
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_805
[03/01/2023-10:41:07] [V] [TRT] Removing 915
[03/01/2023-10:41:07] [V] [TRT] Removing 914
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1105
[03/01/2023-10:41:07] [V] [TRT] Removing 1215
[03/01/2023-10:41:07] [V] [TRT] Removing 1214
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1405
[03/01/2023-10:41:07] [V] [TRT] Removing 1515
[03/01/2023-10:41:07] [V] [TRT] Removing 1514
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1705
[03/01/2023-10:41:07] [V] [TRT] Removing 1815
[03/01/2023-10:41:07] [V] [TRT] Removing 1814
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2005
[03/01/2023-10:41:07] [V] [TRT] Removing 2115
[03/01/2023-10:41:07] [V] [TRT] Removing 2114
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2305
[03/01/2023-10:41:07] [V] [TRT] Removing 2415
[03/01/2023-10:41:07] [V] [TRT] Removing 2414
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_209
[03/01/2023-10:41:07] [V] [TRT] Removing 319
[03/01/2023-10:41:07] [V] [TRT] Removing 318
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_508
[03/01/2023-10:41:07] [V] [TRT] Removing 618
[03/01/2023-10:41:07] [V] [TRT] Removing 617
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_808
[03/01/2023-10:41:07] [V] [TRT] Removing 918
[03/01/2023-10:41:07] [V] [TRT] Removing 917
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1108
[03/01/2023-10:41:07] [V] [TRT] Removing 1218
[03/01/2023-10:41:07] [V] [TRT] Removing 1217
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1408
[03/01/2023-10:41:07] [V] [TRT] Removing 1518
[03/01/2023-10:41:07] [V] [TRT] Removing 1517
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1708
[03/01/2023-10:41:07] [V] [TRT] Removing 1818
[03/01/2023-10:41:07] [V] [TRT] Removing 1817
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2008
[03/01/2023-10:41:07] [V] [TRT] Removing 2118
[03/01/2023-10:41:07] [V] [TRT] Removing 2117
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2308
[03/01/2023-10:41:07] [V] [TRT] Removing 2418
[03/01/2023-10:41:07] [V] [TRT] Removing 2417
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_17
[03/01/2023-10:41:07] [V] [TRT] Removing 123
[03/01/2023-10:41:07] [V] [TRT] Removing 122
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_20
[03/01/2023-10:41:07] [V] [TRT] Removing 126
[03/01/2023-10:41:07] [V] [TRT] Removing 125
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_370
[03/01/2023-10:41:07] [V] [TRT] Removing 480
[03/01/2023-10:41:07] [V] [TRT] Removing 479
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_670
[03/01/2023-10:41:07] [V] [TRT] Removing 780
[03/01/2023-10:41:07] [V] [TRT] Removing 779
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_970
[03/01/2023-10:41:07] [V] [TRT] Removing 1080
[03/01/2023-10:41:07] [V] [TRT] Removing 1079
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1270
[03/01/2023-10:41:07] [V] [TRT] Removing 1380
[03/01/2023-10:41:07] [V] [TRT] Removing 1379
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1570
[03/01/2023-10:41:07] [V] [TRT] Removing 1680
[03/01/2023-10:41:07] [V] [TRT] Removing 1679
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1870
[03/01/2023-10:41:07] [V] [TRT] Removing 1980
[03/01/2023-10:41:07] [V] [TRT] Removing 1979
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2170
[03/01/2023-10:41:07] [V] [TRT] Removing 2280
[03/01/2023-10:41:07] [V] [TRT] Removing 2279
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2470
[03/01/2023-10:41:07] [V] [TRT] Removing 2580
[03/01/2023-10:41:07] [V] [TRT] Removing 2579
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_224
[03/01/2023-10:41:07] [V] [TRT] Removing 334
[03/01/2023-10:41:07] [V] [TRT] Removing 333
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_523
[03/01/2023-10:41:07] [V] [TRT] Removing 633
[03/01/2023-10:41:07] [V] [TRT] Removing 632
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_823
[03/01/2023-10:41:07] [V] [TRT] Removing 933
[03/01/2023-10:41:07] [V] [TRT] Removing 932
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1123
[03/01/2023-10:41:07] [V] [TRT] Removing 1233
[03/01/2023-10:41:07] [V] [TRT] Removing 1232
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1423
[03/01/2023-10:41:07] [V] [TRT] Removing 1533
[03/01/2023-10:41:07] [V] [TRT] Removing 1532
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1723
[03/01/2023-10:41:07] [V] [TRT] Removing 1833
[03/01/2023-10:41:07] [V] [TRT] Removing 1832
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2023
[03/01/2023-10:41:07] [V] [TRT] Removing 2133
[03/01/2023-10:41:07] [V] [TRT] Removing 2132
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2323
[03/01/2023-10:41:07] [V] [TRT] Removing 2433
[03/01/2023-10:41:07] [V] [TRT] Removing 2432
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_33
[03/01/2023-10:41:07] [V] [TRT] Removing 139
[03/01/2023-10:41:07] [V] [TRT] Removing 138
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_36
[03/01/2023-10:41:07] [V] [TRT] Removing 142
[03/01/2023-10:41:07] [V] [TRT] Removing 141
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_386
[03/01/2023-10:41:07] [V] [TRT] Removing 496
[03/01/2023-10:41:07] [V] [TRT] Removing 495
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_686
[03/01/2023-10:41:07] [V] [TRT] Removing 796
[03/01/2023-10:41:07] [V] [TRT] Removing 795
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_986
[03/01/2023-10:41:07] [V] [TRT] Removing 1096
[03/01/2023-10:41:07] [V] [TRT] Removing 1095
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1286
[03/01/2023-10:41:07] [V] [TRT] Removing 1396
[03/01/2023-10:41:07] [V] [TRT] Removing 1395
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1586
[03/01/2023-10:41:07] [V] [TRT] Removing 1696
[03/01/2023-10:41:07] [V] [TRT] Removing 1695
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1886
[03/01/2023-10:41:07] [V] [TRT] Removing 1996
[03/01/2023-10:41:07] [V] [TRT] Removing 1995
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2186
[03/01/2023-10:41:07] [V] [TRT] Removing 2296
[03/01/2023-10:41:07] [V] [TRT] Removing 2295
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2486
[03/01/2023-10:41:07] [V] [TRT] Removing 2596
[03/01/2023-10:41:07] [V] [TRT] Removing 2595
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_240
[03/01/2023-10:41:07] [V] [TRT] Removing 350
[03/01/2023-10:41:07] [V] [TRT] Removing 349
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_539
[03/01/2023-10:41:07] [V] [TRT] Removing 649
[03/01/2023-10:41:07] [V] [TRT] Removing 648
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_839
[03/01/2023-10:41:07] [V] [TRT] Removing 949
[03/01/2023-10:41:07] [V] [TRT] Removing 948
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1139
[03/01/2023-10:41:07] [V] [TRT] Removing 1249
[03/01/2023-10:41:07] [V] [TRT] Removing 1248
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1439
[03/01/2023-10:41:07] [V] [TRT] Removing 1549
[03/01/2023-10:41:07] [V] [TRT] Removing 1548
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1739
[03/01/2023-10:41:07] [V] [TRT] Removing 1849
[03/01/2023-10:41:07] [V] [TRT] Removing 1848
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2039
[03/01/2023-10:41:07] [V] [TRT] Removing 2149
[03/01/2023-10:41:07] [V] [TRT] Removing 2148
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2339
[03/01/2023-10:41:07] [V] [TRT] Removing 2449
[03/01/2023-10:41:07] [V] [TRT] Removing 2448
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_48
[03/01/2023-10:41:07] [V] [TRT] Removing 154
[03/01/2023-10:41:07] [V] [TRT] Removing 153
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_51
[03/01/2023-10:41:07] [V] [TRT] Removing 157
[03/01/2023-10:41:07] [V] [TRT] Removing 156
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_401
[03/01/2023-10:41:07] [V] [TRT] Removing 511
[03/01/2023-10:41:07] [V] [TRT] Removing 510
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_701
[03/01/2023-10:41:07] [V] [TRT] Removing 811
[03/01/2023-10:41:07] [V] [TRT] Removing 810
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1001
[03/01/2023-10:41:07] [V] [TRT] Removing 1111
[03/01/2023-10:41:07] [V] [TRT] Removing 1110
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1301
[03/01/2023-10:41:07] [V] [TRT] Removing 1411
[03/01/2023-10:41:07] [V] [TRT] Removing 1410
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1601
[03/01/2023-10:41:07] [V] [TRT] Removing 1711
[03/01/2023-10:41:07] [V] [TRT] Removing 1710
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1901
[03/01/2023-10:41:07] [V] [TRT] Removing 2011
[03/01/2023-10:41:07] [V] [TRT] Removing 2010
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2201
[03/01/2023-10:41:07] [V] [TRT] Removing 2311
[03/01/2023-10:41:07] [V] [TRT] Removing 2310
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2501
[03/01/2023-10:41:07] [V] [TRT] Removing 2611
[03/01/2023-10:41:07] [V] [TRT] Removing 2610
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_255
[03/01/2023-10:41:07] [V] [TRT] Removing 365
[03/01/2023-10:41:07] [V] [TRT] Removing 364
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_554
[03/01/2023-10:41:07] [V] [TRT] Removing 664
[03/01/2023-10:41:07] [V] [TRT] Removing 663
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_854
[03/01/2023-10:41:07] [V] [TRT] Removing 964
[03/01/2023-10:41:07] [V] [TRT] Removing 963
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1154
[03/01/2023-10:41:07] [V] [TRT] Removing 1264
[03/01/2023-10:41:07] [V] [TRT] Removing 1263
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1454
[03/01/2023-10:41:07] [V] [TRT] Removing 1564
[03/01/2023-10:41:07] [V] [TRT] Removing 1563
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1754
[03/01/2023-10:41:07] [V] [TRT] Removing 1864
[03/01/2023-10:41:07] [V] [TRT] Removing 1863
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2054
[03/01/2023-10:41:07] [V] [TRT] Removing 2164
[03/01/2023-10:41:07] [V] [TRT] Removing 2163
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2354
[03/01/2023-10:41:07] [V] [TRT] Removing 2464
[03/01/2023-10:41:07] [V] [TRT] Removing 2463
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_71
[03/01/2023-10:41:07] [V] [TRT] Removing 181
[03/01/2023-10:41:07] [V] [TRT] Removing 180
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_74
[03/01/2023-10:41:07] [V] [TRT] Removing 184
[03/01/2023-10:41:07] [V] [TRT] Removing 183
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_271
[03/01/2023-10:41:07] [V] [TRT] Removing 381
[03/01/2023-10:41:07] [V] [TRT] Removing 380
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_570
[03/01/2023-10:41:07] [V] [TRT] Removing 680
[03/01/2023-10:41:07] [V] [TRT] Removing 679
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_870
[03/01/2023-10:41:07] [V] [TRT] Removing 980
[03/01/2023-10:41:07] [V] [TRT] Removing 979
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1170
[03/01/2023-10:41:07] [V] [TRT] Removing 1280
[03/01/2023-10:41:07] [V] [TRT] Removing 1279
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1470
[03/01/2023-10:41:07] [V] [TRT] Removing 1580
[03/01/2023-10:41:07] [V] [TRT] Removing 1579
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1770
[03/01/2023-10:41:07] [V] [TRT] Removing 1880
[03/01/2023-10:41:07] [V] [TRT] Removing 1879
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2070
[03/01/2023-10:41:07] [V] [TRT] Removing 2180
[03/01/2023-10:41:07] [V] [TRT] Removing 2179
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2370
[03/01/2023-10:41:07] [V] [TRT] Removing 2480
[03/01/2023-10:41:07] [V] [TRT] Removing 2479
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_274
[03/01/2023-10:41:07] [V] [TRT] Removing 384
[03/01/2023-10:41:07] [V] [TRT] Removing 383
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_573
[03/01/2023-10:41:07] [V] [TRT] Removing 683
[03/01/2023-10:41:07] [V] [TRT] Removing 682
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_873
[03/01/2023-10:41:07] [V] [TRT] Removing 983
[03/01/2023-10:41:07] [V] [TRT] Removing 982
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1173
[03/01/2023-10:41:07] [V] [TRT] Removing 1283
[03/01/2023-10:41:07] [V] [TRT] Removing 1282
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1473
[03/01/2023-10:41:07] [V] [TRT] Removing 1583
[03/01/2023-10:41:07] [V] [TRT] Removing 1582
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1773
[03/01/2023-10:41:07] [V] [TRT] Removing 1883
[03/01/2023-10:41:07] [V] [TRT] Removing 1882
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2073
[03/01/2023-10:41:07] [V] [TRT] Removing 2183
[03/01/2023-10:41:07] [V] [TRT] Removing 2182
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2373
[03/01/2023-10:41:07] [V] [TRT] Removing 2483
[03/01/2023-10:41:07] [V] [TRT] Removing 2482
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_86
[03/01/2023-10:41:07] [V] [TRT] Removing 196
[03/01/2023-10:41:07] [V] [TRT] Removing 195
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_89
[03/01/2023-10:41:07] [V] [TRT] Removing 199
[03/01/2023-10:41:07] [V] [TRT] Removing 198
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_287
[03/01/2023-10:41:07] [V] [TRT] Removing 397
[03/01/2023-10:41:07] [V] [TRT] Removing 396
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_436
[03/01/2023-10:41:07] [V] [TRT] Removing 546
[03/01/2023-10:41:07] [V] [TRT] Removing 545
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_586
[03/01/2023-10:41:07] [V] [TRT] Removing 696
[03/01/2023-10:41:07] [V] [TRT] Removing 695
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_736
[03/01/2023-10:41:07] [V] [TRT] Removing 846
[03/01/2023-10:41:07] [V] [TRT] Removing 845
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_886
[03/01/2023-10:41:07] [V] [TRT] Removing 996
[03/01/2023-10:41:07] [V] [TRT] Removing 995
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1036
[03/01/2023-10:41:07] [V] [TRT] Removing 1146
[03/01/2023-10:41:07] [V] [TRT] Removing 1145
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1186
[03/01/2023-10:41:07] [V] [TRT] Removing 1296
[03/01/2023-10:41:07] [V] [TRT] Removing 1295
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1336
[03/01/2023-10:41:07] [V] [TRT] Removing 1446
[03/01/2023-10:41:07] [V] [TRT] Removing 1445
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1486
[03/01/2023-10:41:07] [V] [TRT] Removing 1596
[03/01/2023-10:41:07] [V] [TRT] Removing 1595
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1636
[03/01/2023-10:41:07] [V] [TRT] Removing 1746
[03/01/2023-10:41:07] [V] [TRT] Removing 1745
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1786
[03/01/2023-10:41:07] [V] [TRT] Removing 1896
[03/01/2023-10:41:07] [V] [TRT] Removing 1895
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1936
[03/01/2023-10:41:07] [V] [TRT] Removing 2046
[03/01/2023-10:41:07] [V] [TRT] Removing 2045
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2086
[03/01/2023-10:41:07] [V] [TRT] Removing 2196
[03/01/2023-10:41:07] [V] [TRT] Removing 2195
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2236
[03/01/2023-10:41:07] [V] [TRT] Removing 2346
[03/01/2023-10:41:07] [V] [TRT] Removing 2345
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2386
[03/01/2023-10:41:07] [V] [TRT] Removing 2496
[03/01/2023-10:41:07] [V] [TRT] Removing 2495
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2536
[03/01/2023-10:41:07] [V] [TRT] Removing 2646
[03/01/2023-10:41:07] [V] [TRT] Removing 2645
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_290
[03/01/2023-10:41:07] [V] [TRT] Removing 400
[03/01/2023-10:41:07] [V] [TRT] Removing 399
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_439
[03/01/2023-10:41:07] [V] [TRT] Removing 549
[03/01/2023-10:41:07] [V] [TRT] Removing 548
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_589
[03/01/2023-10:41:07] [V] [TRT] Removing 699
[03/01/2023-10:41:07] [V] [TRT] Removing 698
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_739
[03/01/2023-10:41:07] [V] [TRT] Removing 849
[03/01/2023-10:41:07] [V] [TRT] Removing 848
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_889
[03/01/2023-10:41:07] [V] [TRT] Removing 999
[03/01/2023-10:41:07] [V] [TRT] Removing 998
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1039
[03/01/2023-10:41:07] [V] [TRT] Removing 1149
[03/01/2023-10:41:07] [V] [TRT] Removing 1148
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1189
[03/01/2023-10:41:07] [V] [TRT] Removing 1299
[03/01/2023-10:41:07] [V] [TRT] Removing 1298
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1339
[03/01/2023-10:41:07] [V] [TRT] Removing 1449
[03/01/2023-10:41:07] [V] [TRT] Removing 1448
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1489
[03/01/2023-10:41:07] [V] [TRT] Removing 1599
[03/01/2023-10:41:07] [V] [TRT] Removing 1598
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1639
[03/01/2023-10:41:07] [V] [TRT] Removing 1749
[03/01/2023-10:41:07] [V] [TRT] Removing 1748
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1789
[03/01/2023-10:41:07] [V] [TRT] Removing 1899
[03/01/2023-10:41:07] [V] [TRT] Removing 1898
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1939
[03/01/2023-10:41:07] [V] [TRT] Removing 2049
[03/01/2023-10:41:07] [V] [TRT] Removing 2048
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2089
[03/01/2023-10:41:07] [V] [TRT] Removing 2199
[03/01/2023-10:41:07] [V] [TRT] Removing 2198
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2239
[03/01/2023-10:41:07] [V] [TRT] Removing 2349
[03/01/2023-10:41:07] [V] [TRT] Removing 2348
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2389
[03/01/2023-10:41:07] [V] [TRT] Removing 2499
[03/01/2023-10:41:07] [V] [TRT] Removing 2498
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2539
[03/01/2023-10:41:07] [V] [TRT] Removing 2649
[03/01/2023-10:41:07] [V] [TRT] Removing 2648
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_301
[03/01/2023-10:41:07] [V] [TRT] Removing 411
[03/01/2023-10:41:07] [V] [TRT] Removing 410
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_450
[03/01/2023-10:41:07] [V] [TRT] Removing 560
[03/01/2023-10:41:07] [V] [TRT] Removing 559
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_600
[03/01/2023-10:41:07] [V] [TRT] Removing 710
[03/01/2023-10:41:07] [V] [TRT] Removing 709
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_750
[03/01/2023-10:41:07] [V] [TRT] Removing 860
[03/01/2023-10:41:07] [V] [TRT] Removing 859
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_900
[03/01/2023-10:41:07] [V] [TRT] Removing 1010
[03/01/2023-10:41:07] [V] [TRT] Removing 1009
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1050
[03/01/2023-10:41:07] [V] [TRT] Removing 1160
[03/01/2023-10:41:07] [V] [TRT] Removing 1159
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1200
[03/01/2023-10:41:07] [V] [TRT] Removing 1310
[03/01/2023-10:41:07] [V] [TRT] Removing 1309
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1350
[03/01/2023-10:41:07] [V] [TRT] Removing 1460
[03/01/2023-10:41:07] [V] [TRT] Removing 1459
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1500
[03/01/2023-10:41:07] [V] [TRT] Removing 1610
[03/01/2023-10:41:07] [V] [TRT] Removing 1609
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1650
[03/01/2023-10:41:07] [V] [TRT] Removing 1760
[03/01/2023-10:41:07] [V] [TRT] Removing 1759
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1800
[03/01/2023-10:41:07] [V] [TRT] Removing 1910
[03/01/2023-10:41:07] [V] [TRT] Removing 1909
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1950
[03/01/2023-10:41:07] [V] [TRT] Removing 2060
[03/01/2023-10:41:07] [V] [TRT] Removing 2059
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2100
[03/01/2023-10:41:07] [V] [TRT] Removing 2210
[03/01/2023-10:41:07] [V] [TRT] Removing 2209
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2250
[03/01/2023-10:41:07] [V] [TRT] Removing 2360
[03/01/2023-10:41:07] [V] [TRT] Removing 2359
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2400
[03/01/2023-10:41:07] [V] [TRT] Removing 2510
[03/01/2023-10:41:07] [V] [TRT] Removing 2509
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2550
[03/01/2023-10:41:07] [V] [TRT] Removing 2660
[03/01/2023-10:41:07] [V] [TRT] Removing 2659
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_106
[03/01/2023-10:41:07] [V] [TRT] Removing 216
[03/01/2023-10:41:07] [V] [TRT] Removing 215
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_332
[03/01/2023-10:41:07] [V] [TRT] Removing 442
[03/01/2023-10:41:07] [V] [TRT] Removing 441
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_481
[03/01/2023-10:41:07] [V] [TRT] Removing 591
[03/01/2023-10:41:07] [V] [TRT] Removing 590
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_631
[03/01/2023-10:41:07] [V] [TRT] Removing 741
[03/01/2023-10:41:07] [V] [TRT] Removing 740
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_781
[03/01/2023-10:41:07] [V] [TRT] Removing 891
[03/01/2023-10:41:07] [V] [TRT] Removing 890
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_931
[03/01/2023-10:41:07] [V] [TRT] Removing 1041
[03/01/2023-10:41:07] [V] [TRT] Removing 1040
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1081
[03/01/2023-10:41:07] [V] [TRT] Removing 1191
[03/01/2023-10:41:07] [V] [TRT] Removing 1190
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1231
[03/01/2023-10:41:07] [V] [TRT] Removing 1341
[03/01/2023-10:41:07] [V] [TRT] Removing 1340
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1381
[03/01/2023-10:41:07] [V] [TRT] Removing 1491
[03/01/2023-10:41:07] [V] [TRT] Removing 1490
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1531
[03/01/2023-10:41:07] [V] [TRT] Removing 1641
[03/01/2023-10:41:07] [V] [TRT] Removing 1640
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1681
[03/01/2023-10:41:07] [V] [TRT] Removing 1791
[03/01/2023-10:41:07] [V] [TRT] Removing 1790
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1831
[03/01/2023-10:41:07] [V] [TRT] Removing 1941
[03/01/2023-10:41:07] [V] [TRT] Removing 1940
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1981
[03/01/2023-10:41:07] [V] [TRT] Removing 2091
[03/01/2023-10:41:07] [V] [TRT] Removing 2090
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2131
[03/01/2023-10:41:07] [V] [TRT] Removing 2241
[03/01/2023-10:41:07] [V] [TRT] Removing 2240
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2281
[03/01/2023-10:41:07] [V] [TRT] Removing 2391
[03/01/2023-10:41:07] [V] [TRT] Removing 2390
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2431
[03/01/2023-10:41:07] [V] [TRT] Removing 2541
[03/01/2023-10:41:07] [V] [TRT] Removing 2540
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2581
[03/01/2023-10:41:07] [V] [TRT] Removing 2691
[03/01/2023-10:41:07] [V] [TRT] Removing 2690
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_122
[03/01/2023-10:41:07] [V] [TRT] Removing 232
[03/01/2023-10:41:07] [V] [TRT] Removing 231
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_125
[03/01/2023-10:41:07] [V] [TRT] Removing 235
[03/01/2023-10:41:07] [V] [TRT] Removing 234
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_136
[03/01/2023-10:41:07] [V] [TRT] Removing 246
[03/01/2023-10:41:07] [V] [TRT] Removing 245
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_139
[03/01/2023-10:41:07] [V] [TRT] Removing 249
[03/01/2023-10:41:07] [V] [TRT] Removing 248
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_183
[03/01/2023-10:41:07] [V] [TRT] Removing 293
[03/01/2023-10:41:07] [V] [TRT] Removing 292
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_186
[03/01/2023-10:41:07] [V] [TRT] Removing 296
[03/01/2023-10:41:07] [V] [TRT] Removing 295
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2598
[03/01/2023-10:41:07] [V] [TRT] Removing 2708
[03/01/2023-10:41:07] [V] [TRT] Removing 2707
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_8
[03/01/2023-10:41:07] [V] [TRT] Removing 114
[03/01/2023-10:41:07] [V] [TRT] Removing 113
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_39
[03/01/2023-10:41:07] [V] [TRT] Removing 145
[03/01/2023-10:41:07] [V] [TRT] Removing 144
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_77
[03/01/2023-10:41:07] [V] [TRT] Removing 187
[03/01/2023-10:41:07] [V] [TRT] Removing 186
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_112
[03/01/2023-10:41:07] [V] [TRT] Removing 222
[03/01/2023-10:41:07] [V] [TRT] Removing 221
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_142
[03/01/2023-10:41:07] [V] [TRT] Removing 252
[03/01/2023-10:41:07] [V] [TRT] Removing 251
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_170
[03/01/2023-10:41:07] [V] [TRT] Removing 280
[03/01/2023-10:41:07] [V] [TRT] Removing 279
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_212
[03/01/2023-10:41:07] [V] [TRT] Removing 322
[03/01/2023-10:41:07] [V] [TRT] Removing 321
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_243
[03/01/2023-10:41:07] [V] [TRT] Removing 353
[03/01/2023-10:41:07] [V] [TRT] Removing 352
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_277
[03/01/2023-10:41:07] [V] [TRT] Removing 387
[03/01/2023-10:41:07] [V] [TRT] Removing 386
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_307
[03/01/2023-10:41:07] [V] [TRT] Removing 417
[03/01/2023-10:41:07] [V] [TRT] Removing 416
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_335
[03/01/2023-10:41:07] [V] [TRT] Removing 445
[03/01/2023-10:41:07] [V] [TRT] Removing 444
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_376
[03/01/2023-10:41:07] [V] [TRT] Removing 486
[03/01/2023-10:41:07] [V] [TRT] Removing 485
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_407
[03/01/2023-10:41:07] [V] [TRT] Removing 517
[03/01/2023-10:41:07] [V] [TRT] Removing 516
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_442
[03/01/2023-10:41:07] [V] [TRT] Removing 552
[03/01/2023-10:41:07] [V] [TRT] Removing 551
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_470
[03/01/2023-10:41:07] [V] [TRT] Removing 580
[03/01/2023-10:41:07] [V] [TRT] Removing 579
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_511
[03/01/2023-10:41:07] [V] [TRT] Removing 621
[03/01/2023-10:41:07] [V] [TRT] Removing 620
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_542
[03/01/2023-10:41:07] [V] [TRT] Removing 652
[03/01/2023-10:41:07] [V] [TRT] Removing 651
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_576
[03/01/2023-10:41:07] [V] [TRT] Removing 686
[03/01/2023-10:41:07] [V] [TRT] Removing 685
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_606
[03/01/2023-10:41:07] [V] [TRT] Removing 716
[03/01/2023-10:41:07] [V] [TRT] Removing 715
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_634
[03/01/2023-10:41:07] [V] [TRT] Removing 744
[03/01/2023-10:41:07] [V] [TRT] Removing 743
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_676
[03/01/2023-10:41:07] [V] [TRT] Removing 786
[03/01/2023-10:41:07] [V] [TRT] Removing 785
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_707
[03/01/2023-10:41:07] [V] [TRT] Removing 817
[03/01/2023-10:41:07] [V] [TRT] Removing 816
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_742
[03/01/2023-10:41:07] [V] [TRT] Removing 852
[03/01/2023-10:41:07] [V] [TRT] Removing 851
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_770
[03/01/2023-10:41:07] [V] [TRT] Removing 880
[03/01/2023-10:41:07] [V] [TRT] Removing 879
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_811
[03/01/2023-10:41:07] [V] [TRT] Removing 921
[03/01/2023-10:41:07] [V] [TRT] Removing 920
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_842
[03/01/2023-10:41:07] [V] [TRT] Removing 952
[03/01/2023-10:41:07] [V] [TRT] Removing 951
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_876
[03/01/2023-10:41:07] [V] [TRT] Removing 986
[03/01/2023-10:41:07] [V] [TRT] Removing 985
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_906
[03/01/2023-10:41:07] [V] [TRT] Removing 1016
[03/01/2023-10:41:07] [V] [TRT] Removing 1015
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_934
[03/01/2023-10:41:07] [V] [TRT] Removing 1044
[03/01/2023-10:41:07] [V] [TRT] Removing 1043
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_976
[03/01/2023-10:41:07] [V] [TRT] Removing 1086
[03/01/2023-10:41:07] [V] [TRT] Removing 1085
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1007
[03/01/2023-10:41:07] [V] [TRT] Removing 1117
[03/01/2023-10:41:07] [V] [TRT] Removing 1116
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1042
[03/01/2023-10:41:07] [V] [TRT] Removing 1152
[03/01/2023-10:41:07] [V] [TRT] Removing 1151
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1070
[03/01/2023-10:41:07] [V] [TRT] Removing 1180
[03/01/2023-10:41:07] [V] [TRT] Removing 1179
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1111
[03/01/2023-10:41:07] [V] [TRT] Removing 1221
[03/01/2023-10:41:07] [V] [TRT] Removing 1220
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1142
[03/01/2023-10:41:07] [V] [TRT] Removing 1252
[03/01/2023-10:41:07] [V] [TRT] Removing 1251
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1176
[03/01/2023-10:41:07] [V] [TRT] Removing 1286
[03/01/2023-10:41:07] [V] [TRT] Removing 1285
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1206
[03/01/2023-10:41:07] [V] [TRT] Removing 1316
[03/01/2023-10:41:07] [V] [TRT] Removing 1315
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1234
[03/01/2023-10:41:07] [V] [TRT] Removing 1344
[03/01/2023-10:41:07] [V] [TRT] Removing 1343
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1276
[03/01/2023-10:41:07] [V] [TRT] Removing 1386
[03/01/2023-10:41:07] [V] [TRT] Removing 1385
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1307
[03/01/2023-10:41:07] [V] [TRT] Removing 1417
[03/01/2023-10:41:07] [V] [TRT] Removing 1416
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1342
[03/01/2023-10:41:07] [V] [TRT] Removing 1452
[03/01/2023-10:41:07] [V] [TRT] Removing 1451
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1370
[03/01/2023-10:41:07] [V] [TRT] Removing 1480
[03/01/2023-10:41:07] [V] [TRT] Removing 1479
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1411
[03/01/2023-10:41:07] [V] [TRT] Removing 1521
[03/01/2023-10:41:07] [V] [TRT] Removing 1520
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1442
[03/01/2023-10:41:07] [V] [TRT] Removing 1552
[03/01/2023-10:41:07] [V] [TRT] Removing 1551
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1476
[03/01/2023-10:41:07] [V] [TRT] Removing 1586
[03/01/2023-10:41:07] [V] [TRT] Removing 1585
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1506
[03/01/2023-10:41:07] [V] [TRT] Removing 1616
[03/01/2023-10:41:07] [V] [TRT] Removing 1615
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1534
[03/01/2023-10:41:07] [V] [TRT] Removing 1644
[03/01/2023-10:41:07] [V] [TRT] Removing 1643
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1576
[03/01/2023-10:41:07] [V] [TRT] Removing 1686
[03/01/2023-10:41:07] [V] [TRT] Removing 1685
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1607
[03/01/2023-10:41:07] [V] [TRT] Removing 1717
[03/01/2023-10:41:07] [V] [TRT] Removing 1716
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1642
[03/01/2023-10:41:07] [V] [TRT] Removing 1752
[03/01/2023-10:41:07] [V] [TRT] Removing 1751
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1670
[03/01/2023-10:41:07] [V] [TRT] Removing 1780
[03/01/2023-10:41:07] [V] [TRT] Removing 1779
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1711
[03/01/2023-10:41:07] [V] [TRT] Removing 1821
[03/01/2023-10:41:07] [V] [TRT] Removing 1820
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1742
[03/01/2023-10:41:07] [V] [TRT] Removing 1852
[03/01/2023-10:41:07] [V] [TRT] Removing 1851
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1776
[03/01/2023-10:41:07] [V] [TRT] Removing 1886
[03/01/2023-10:41:07] [V] [TRT] Removing 1885
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1806
[03/01/2023-10:41:07] [V] [TRT] Removing 1916
[03/01/2023-10:41:07] [V] [TRT] Removing 1915
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1834
[03/01/2023-10:41:07] [V] [TRT] Removing 1944
[03/01/2023-10:41:07] [V] [TRT] Removing 1943
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1876
[03/01/2023-10:41:07] [V] [TRT] Removing 1986
[03/01/2023-10:41:07] [V] [TRT] Removing 1985
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1907
[03/01/2023-10:41:07] [V] [TRT] Removing 2017
[03/01/2023-10:41:07] [V] [TRT] Removing 2016
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1942
[03/01/2023-10:41:07] [V] [TRT] Removing 2052
[03/01/2023-10:41:07] [V] [TRT] Removing 2051
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1970
[03/01/2023-10:41:07] [V] [TRT] Removing 2080
[03/01/2023-10:41:07] [V] [TRT] Removing 2079
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2011
[03/01/2023-10:41:07] [V] [TRT] Removing 2121
[03/01/2023-10:41:07] [V] [TRT] Removing 2120
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2042
[03/01/2023-10:41:07] [V] [TRT] Removing 2152
[03/01/2023-10:41:07] [V] [TRT] Removing 2151
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2076
[03/01/2023-10:41:07] [V] [TRT] Removing 2186
[03/01/2023-10:41:07] [V] [TRT] Removing 2185
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2106
[03/01/2023-10:41:07] [V] [TRT] Removing 2216
[03/01/2023-10:41:07] [V] [TRT] Removing 2215
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2134
[03/01/2023-10:41:07] [V] [TRT] Removing 2244
[03/01/2023-10:41:07] [V] [TRT] Removing 2243
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2176
[03/01/2023-10:41:07] [V] [TRT] Removing 2286
[03/01/2023-10:41:07] [V] [TRT] Removing 2285
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2207
[03/01/2023-10:41:07] [V] [TRT] Removing 2317
[03/01/2023-10:41:07] [V] [TRT] Removing 2316
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2242
[03/01/2023-10:41:07] [V] [TRT] Removing 2352
[03/01/2023-10:41:07] [V] [TRT] Removing 2351
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2270
[03/01/2023-10:41:07] [V] [TRT] Removing 2380
[03/01/2023-10:41:07] [V] [TRT] Removing 2379
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2311
[03/01/2023-10:41:07] [V] [TRT] Removing 2421
[03/01/2023-10:41:07] [V] [TRT] Removing 2420
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2342
[03/01/2023-10:41:07] [V] [TRT] Removing 2452
[03/01/2023-10:41:07] [V] [TRT] Removing 2451
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2376
[03/01/2023-10:41:07] [V] [TRT] Removing 2486
[03/01/2023-10:41:07] [V] [TRT] Removing 2485
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2406
[03/01/2023-10:41:07] [V] [TRT] Removing 2516
[03/01/2023-10:41:07] [V] [TRT] Removing 2515
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2434
[03/01/2023-10:41:07] [V] [TRT] Removing 2544
[03/01/2023-10:41:07] [V] [TRT] Removing 2543
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2476
[03/01/2023-10:41:07] [V] [TRT] Removing 2586
[03/01/2023-10:41:07] [V] [TRT] Removing 2585
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2507
[03/01/2023-10:41:07] [V] [TRT] Removing 2617
[03/01/2023-10:41:07] [V] [TRT] Removing 2616
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2542
[03/01/2023-10:41:07] [V] [TRT] Removing 2652
[03/01/2023-10:41:07] [V] [TRT] Removing 2651
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2570
[03/01/2023-10:41:07] [V] [TRT] Removing 2680
[03/01/2023-10:41:07] [V] [TRT] Removing 2679
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2604
[03/01/2023-10:41:07] [V] [TRT] Removing 2714
[03/01/2023-10:41:07] [V] [TRT] Removing 2713
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_11
[03/01/2023-10:41:07] [V] [TRT] Removing 117
[03/01/2023-10:41:07] [V] [TRT] Removing 116
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_42
[03/01/2023-10:41:07] [V] [TRT] Removing 148
[03/01/2023-10:41:07] [V] [TRT] Removing 147
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_80
[03/01/2023-10:41:07] [V] [TRT] Removing 190
[03/01/2023-10:41:07] [V] [TRT] Removing 189
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_115
[03/01/2023-10:41:07] [V] [TRT] Removing 225
[03/01/2023-10:41:07] [V] [TRT] Removing 224
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_145
[03/01/2023-10:41:07] [V] [TRT] Removing 255
[03/01/2023-10:41:07] [V] [TRT] Removing 254
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_173
[03/01/2023-10:41:07] [V] [TRT] Removing 283
[03/01/2023-10:41:07] [V] [TRT] Removing 282
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_215
[03/01/2023-10:41:07] [V] [TRT] Removing 325
[03/01/2023-10:41:07] [V] [TRT] Removing 324
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_246
[03/01/2023-10:41:07] [V] [TRT] Removing 356
[03/01/2023-10:41:07] [V] [TRT] Removing 355
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_280
[03/01/2023-10:41:07] [V] [TRT] Removing 390
[03/01/2023-10:41:07] [V] [TRT] Removing 389
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_310
[03/01/2023-10:41:07] [V] [TRT] Removing 420
[03/01/2023-10:41:07] [V] [TRT] Removing 419
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_338
[03/01/2023-10:41:07] [V] [TRT] Removing 448
[03/01/2023-10:41:07] [V] [TRT] Removing 447
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_379
[03/01/2023-10:41:07] [V] [TRT] Removing 489
[03/01/2023-10:41:07] [V] [TRT] Removing 488
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_410
[03/01/2023-10:41:07] [V] [TRT] Removing 520
[03/01/2023-10:41:07] [V] [TRT] Removing 519
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_445
[03/01/2023-10:41:07] [V] [TRT] Removing 555
[03/01/2023-10:41:07] [V] [TRT] Removing 554
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_473
[03/01/2023-10:41:07] [V] [TRT] Removing 583
[03/01/2023-10:41:07] [V] [TRT] Removing 582
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_514
[03/01/2023-10:41:07] [V] [TRT] Removing 624
[03/01/2023-10:41:07] [V] [TRT] Removing 623
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_545
[03/01/2023-10:41:07] [V] [TRT] Removing 655
[03/01/2023-10:41:07] [V] [TRT] Removing 654
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_579
[03/01/2023-10:41:07] [V] [TRT] Removing 689
[03/01/2023-10:41:07] [V] [TRT] Removing 688
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_609
[03/01/2023-10:41:07] [V] [TRT] Removing 719
[03/01/2023-10:41:07] [V] [TRT] Removing 718
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_637
[03/01/2023-10:41:07] [V] [TRT] Removing 747
[03/01/2023-10:41:07] [V] [TRT] Removing 746
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_679
[03/01/2023-10:41:07] [V] [TRT] Removing 789
[03/01/2023-10:41:07] [V] [TRT] Removing 788
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_710
[03/01/2023-10:41:07] [V] [TRT] Removing 820
[03/01/2023-10:41:07] [V] [TRT] Removing 819
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_745
[03/01/2023-10:41:07] [V] [TRT] Removing 855
[03/01/2023-10:41:07] [V] [TRT] Removing 854
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_773
[03/01/2023-10:41:07] [V] [TRT] Removing 883
[03/01/2023-10:41:07] [V] [TRT] Removing 882
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_814
[03/01/2023-10:41:07] [V] [TRT] Removing 924
[03/01/2023-10:41:07] [V] [TRT] Removing 923
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_845
[03/01/2023-10:41:07] [V] [TRT] Removing 955
[03/01/2023-10:41:07] [V] [TRT] Removing 954
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_879
[03/01/2023-10:41:07] [V] [TRT] Removing 989
[03/01/2023-10:41:07] [V] [TRT] Removing 988
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_909
[03/01/2023-10:41:07] [V] [TRT] Removing 1019
[03/01/2023-10:41:07] [V] [TRT] Removing 1018
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_937
[03/01/2023-10:41:07] [V] [TRT] Removing 1047
[03/01/2023-10:41:07] [V] [TRT] Removing 1046
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_979
[03/01/2023-10:41:07] [V] [TRT] Removing 1089
[03/01/2023-10:41:07] [V] [TRT] Removing 1088
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1010
[03/01/2023-10:41:07] [V] [TRT] Removing 1120
[03/01/2023-10:41:07] [V] [TRT] Removing 1119
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1045
[03/01/2023-10:41:07] [V] [TRT] Removing 1155
[03/01/2023-10:41:07] [V] [TRT] Removing 1154
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1073
[03/01/2023-10:41:07] [V] [TRT] Removing 1183
[03/01/2023-10:41:07] [V] [TRT] Removing 1182
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1114
[03/01/2023-10:41:07] [V] [TRT] Removing 1224
[03/01/2023-10:41:07] [V] [TRT] Removing 1223
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1145
[03/01/2023-10:41:07] [V] [TRT] Removing 1255
[03/01/2023-10:41:07] [V] [TRT] Removing 1254
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1179
[03/01/2023-10:41:07] [V] [TRT] Removing 1289
[03/01/2023-10:41:07] [V] [TRT] Removing 1288
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1209
[03/01/2023-10:41:07] [V] [TRT] Removing 1319
[03/01/2023-10:41:07] [V] [TRT] Removing 1318
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1237
[03/01/2023-10:41:07] [V] [TRT] Removing 1347
[03/01/2023-10:41:07] [V] [TRT] Removing 1346
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1279
[03/01/2023-10:41:07] [V] [TRT] Removing 1389
[03/01/2023-10:41:07] [V] [TRT] Removing 1388
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1310
[03/01/2023-10:41:07] [V] [TRT] Removing 1420
[03/01/2023-10:41:07] [V] [TRT] Removing 1419
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1345
[03/01/2023-10:41:07] [V] [TRT] Removing 1455
[03/01/2023-10:41:07] [V] [TRT] Removing 1454
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1373
[03/01/2023-10:41:07] [V] [TRT] Removing 1483
[03/01/2023-10:41:07] [V] [TRT] Removing 1482
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1414
[03/01/2023-10:41:07] [V] [TRT] Removing 1524
[03/01/2023-10:41:07] [V] [TRT] Removing 1523
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1445
[03/01/2023-10:41:07] [V] [TRT] Removing 1555
[03/01/2023-10:41:07] [V] [TRT] Removing 1554
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1479
[03/01/2023-10:41:07] [V] [TRT] Removing 1589
[03/01/2023-10:41:07] [V] [TRT] Removing 1588
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1509
[03/01/2023-10:41:07] [V] [TRT] Removing 1619
[03/01/2023-10:41:07] [V] [TRT] Removing 1618
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1537
[03/01/2023-10:41:07] [V] [TRT] Removing 1647
[03/01/2023-10:41:07] [V] [TRT] Removing 1646
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1579
[03/01/2023-10:41:07] [V] [TRT] Removing 1689
[03/01/2023-10:41:07] [V] [TRT] Removing 1688
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1610
[03/01/2023-10:41:07] [V] [TRT] Removing 1720
[03/01/2023-10:41:07] [V] [TRT] Removing 1719
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1645
[03/01/2023-10:41:07] [V] [TRT] Removing 1755
[03/01/2023-10:41:07] [V] [TRT] Removing 1754
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1673
[03/01/2023-10:41:07] [V] [TRT] Removing 1783
[03/01/2023-10:41:07] [V] [TRT] Removing 1782
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1714
[03/01/2023-10:41:07] [V] [TRT] Removing 1824
[03/01/2023-10:41:07] [V] [TRT] Removing 1823
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1745
[03/01/2023-10:41:07] [V] [TRT] Removing 1855
[03/01/2023-10:41:07] [V] [TRT] Removing 1854
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1779
[03/01/2023-10:41:07] [V] [TRT] Removing 1889
[03/01/2023-10:41:07] [V] [TRT] Removing 1888
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1809
[03/01/2023-10:41:07] [V] [TRT] Removing 1919
[03/01/2023-10:41:07] [V] [TRT] Removing 1918
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1837
[03/01/2023-10:41:07] [V] [TRT] Removing 1947
[03/01/2023-10:41:07] [V] [TRT] Removing 1946
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1879
[03/01/2023-10:41:07] [V] [TRT] Removing 1989
[03/01/2023-10:41:07] [V] [TRT] Removing 1988
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1910
[03/01/2023-10:41:07] [V] [TRT] Removing 2020
[03/01/2023-10:41:07] [V] [TRT] Removing 2019
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1945
[03/01/2023-10:41:07] [V] [TRT] Removing 2055
[03/01/2023-10:41:07] [V] [TRT] Removing 2054
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1973
[03/01/2023-10:41:07] [V] [TRT] Removing 2083
[03/01/2023-10:41:07] [V] [TRT] Removing 2082
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2014
[03/01/2023-10:41:07] [V] [TRT] Removing 2124
[03/01/2023-10:41:07] [V] [TRT] Removing 2123
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2045
[03/01/2023-10:41:07] [V] [TRT] Removing 2155
[03/01/2023-10:41:07] [V] [TRT] Removing 2154
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2079
[03/01/2023-10:41:07] [V] [TRT] Removing 2189
[03/01/2023-10:41:07] [V] [TRT] Removing 2188
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2109
[03/01/2023-10:41:07] [V] [TRT] Removing 2219
[03/01/2023-10:41:07] [V] [TRT] Removing 2218
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2137
[03/01/2023-10:41:07] [V] [TRT] Removing 2247
[03/01/2023-10:41:07] [V] [TRT] Removing 2246
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2179
[03/01/2023-10:41:07] [V] [TRT] Removing 2289
[03/01/2023-10:41:07] [V] [TRT] Removing 2288
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2210
[03/01/2023-10:41:07] [V] [TRT] Removing 2320
[03/01/2023-10:41:07] [V] [TRT] Removing 2319
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2245
[03/01/2023-10:41:07] [V] [TRT] Removing 2355
[03/01/2023-10:41:07] [V] [TRT] Removing 2354
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2273
[03/01/2023-10:41:07] [V] [TRT] Removing 2383
[03/01/2023-10:41:07] [V] [TRT] Removing 2382
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2314
[03/01/2023-10:41:07] [V] [TRT] Removing 2424
[03/01/2023-10:41:07] [V] [TRT] Removing 2423
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2345
[03/01/2023-10:41:07] [V] [TRT] Removing 2455
[03/01/2023-10:41:07] [V] [TRT] Removing 2454
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2379
[03/01/2023-10:41:07] [V] [TRT] Removing 2489
[03/01/2023-10:41:07] [V] [TRT] Removing 2488
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2409
[03/01/2023-10:41:07] [V] [TRT] Removing 2519
[03/01/2023-10:41:07] [V] [TRT] Removing 2518
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2437
[03/01/2023-10:41:07] [V] [TRT] Removing 2547
[03/01/2023-10:41:07] [V] [TRT] Removing 2546
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2479
[03/01/2023-10:41:07] [V] [TRT] Removing 2589
[03/01/2023-10:41:07] [V] [TRT] Removing 2588
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2510
[03/01/2023-10:41:07] [V] [TRT] Removing 2620
[03/01/2023-10:41:07] [V] [TRT] Removing 2619
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2545
[03/01/2023-10:41:07] [V] [TRT] Removing 2655
[03/01/2023-10:41:07] [V] [TRT] Removing 2654
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2573
[03/01/2023-10:41:07] [V] [TRT] Removing 2683
[03/01/2023-10:41:07] [V] [TRT] Removing 2682
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2607
[03/01/2023-10:41:07] [V] [TRT] Removing 2717
[03/01/2023-10:41:07] [V] [TRT] Removing 2716
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_355
[03/01/2023-10:41:07] [V] [TRT] Removing 465
[03/01/2023-10:41:07] [V] [TRT] Removing 464
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_655
[03/01/2023-10:41:07] [V] [TRT] Removing 765
[03/01/2023-10:41:07] [V] [TRT] Removing 764
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_955
[03/01/2023-10:41:07] [V] [TRT] Removing 1065
[03/01/2023-10:41:07] [V] [TRT] Removing 1064
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1255
[03/01/2023-10:41:07] [V] [TRT] Removing 1365
[03/01/2023-10:41:07] [V] [TRT] Removing 1364
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1555
[03/01/2023-10:41:07] [V] [TRT] Removing 1665
[03/01/2023-10:41:07] [V] [TRT] Removing 1664
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1855
[03/01/2023-10:41:07] [V] [TRT] Removing 1965
[03/01/2023-10:41:07] [V] [TRT] Removing 1964
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2155
[03/01/2023-10:41:07] [V] [TRT] Removing 2265
[03/01/2023-10:41:07] [V] [TRT] Removing 2264
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2455
[03/01/2023-10:41:07] [V] [TRT] Removing 2565
[03/01/2023-10:41:07] [V] [TRT] Removing 2564
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_358
[03/01/2023-10:41:07] [V] [TRT] Removing 468
[03/01/2023-10:41:07] [V] [TRT] Removing 467
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_658
[03/01/2023-10:41:07] [V] [TRT] Removing 768
[03/01/2023-10:41:07] [V] [TRT] Removing 767
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_958
[03/01/2023-10:41:07] [V] [TRT] Removing 1068
[03/01/2023-10:41:07] [V] [TRT] Removing 1067
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1258
[03/01/2023-10:41:07] [V] [TRT] Removing 1368
[03/01/2023-10:41:07] [V] [TRT] Removing 1367
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1558
[03/01/2023-10:41:07] [V] [TRT] Removing 1668
[03/01/2023-10:41:07] [V] [TRT] Removing 1667
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1858
[03/01/2023-10:41:07] [V] [TRT] Removing 1968
[03/01/2023-10:41:07] [V] [TRT] Removing 1967
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2158
[03/01/2023-10:41:07] [V] [TRT] Removing 2268
[03/01/2023-10:41:07] [V] [TRT] Removing 2267
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2458
[03/01/2023-10:41:07] [V] [TRT] Removing 2568
[03/01/2023-10:41:07] [V] [TRT] Removing 2567
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_221
[03/01/2023-10:41:07] [V] [TRT] Removing 331
[03/01/2023-10:41:07] [V] [TRT] Removing 330
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_520
[03/01/2023-10:41:07] [V] [TRT] Removing 630
[03/01/2023-10:41:07] [V] [TRT] Removing 629
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_820
[03/01/2023-10:41:07] [V] [TRT] Removing 930
[03/01/2023-10:41:07] [V] [TRT] Removing 929
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1120
[03/01/2023-10:41:07] [V] [TRT] Removing 1230
[03/01/2023-10:41:07] [V] [TRT] Removing 1229
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1420
[03/01/2023-10:41:07] [V] [TRT] Removing 1530
[03/01/2023-10:41:07] [V] [TRT] Removing 1529
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1720
[03/01/2023-10:41:07] [V] [TRT] Removing 1830
[03/01/2023-10:41:07] [V] [TRT] Removing 1829
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2020
[03/01/2023-10:41:07] [V] [TRT] Removing 2130
[03/01/2023-10:41:07] [V] [TRT] Removing 2129
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2320
[03/01/2023-10:41:07] [V] [TRT] Removing 2430
[03/01/2023-10:41:07] [V] [TRT] Removing 2429
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_373
[03/01/2023-10:41:07] [V] [TRT] Removing 483
[03/01/2023-10:41:07] [V] [TRT] Removing 482
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_673
[03/01/2023-10:41:07] [V] [TRT] Removing 783
[03/01/2023-10:41:07] [V] [TRT] Removing 782
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_973
[03/01/2023-10:41:07] [V] [TRT] Removing 1083
[03/01/2023-10:41:07] [V] [TRT] Removing 1082
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1273
[03/01/2023-10:41:07] [V] [TRT] Removing 1383
[03/01/2023-10:41:07] [V] [TRT] Removing 1382
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1573
[03/01/2023-10:41:07] [V] [TRT] Removing 1683
[03/01/2023-10:41:07] [V] [TRT] Removing 1682
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1873
[03/01/2023-10:41:07] [V] [TRT] Removing 1983
[03/01/2023-10:41:07] [V] [TRT] Removing 1982
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2173
[03/01/2023-10:41:07] [V] [TRT] Removing 2283
[03/01/2023-10:41:07] [V] [TRT] Removing 2282
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2473
[03/01/2023-10:41:07] [V] [TRT] Removing 2583
[03/01/2023-10:41:07] [V] [TRT] Removing 2582
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_237
[03/01/2023-10:41:07] [V] [TRT] Removing 347
[03/01/2023-10:41:07] [V] [TRT] Removing 346
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_536
[03/01/2023-10:41:07] [V] [TRT] Removing 646
[03/01/2023-10:41:07] [V] [TRT] Removing 645
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_836
[03/01/2023-10:41:07] [V] [TRT] Removing 946
[03/01/2023-10:41:07] [V] [TRT] Removing 945
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1136
[03/01/2023-10:41:07] [V] [TRT] Removing 1246
[03/01/2023-10:41:07] [V] [TRT] Removing 1245
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1436
[03/01/2023-10:41:07] [V] [TRT] Removing 1546
[03/01/2023-10:41:07] [V] [TRT] Removing 1545
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1736
[03/01/2023-10:41:07] [V] [TRT] Removing 1846
[03/01/2023-10:41:07] [V] [TRT] Removing 1845
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2036
[03/01/2023-10:41:07] [V] [TRT] Removing 2146
[03/01/2023-10:41:07] [V] [TRT] Removing 2145
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2336
[03/01/2023-10:41:07] [V] [TRT] Removing 2446
[03/01/2023-10:41:07] [V] [TRT] Removing 2445
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_389
[03/01/2023-10:41:07] [V] [TRT] Removing 499
[03/01/2023-10:41:07] [V] [TRT] Removing 498
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_689
[03/01/2023-10:41:07] [V] [TRT] Removing 799
[03/01/2023-10:41:07] [V] [TRT] Removing 798
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_989
[03/01/2023-10:41:07] [V] [TRT] Removing 1099
[03/01/2023-10:41:07] [V] [TRT] Removing 1098
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1289
[03/01/2023-10:41:07] [V] [TRT] Removing 1399
[03/01/2023-10:41:07] [V] [TRT] Removing 1398
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1589
[03/01/2023-10:41:07] [V] [TRT] Removing 1699
[03/01/2023-10:41:07] [V] [TRT] Removing 1698
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1889
[03/01/2023-10:41:07] [V] [TRT] Removing 1999
[03/01/2023-10:41:07] [V] [TRT] Removing 1998
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2189
[03/01/2023-10:41:07] [V] [TRT] Removing 2299
[03/01/2023-10:41:07] [V] [TRT] Removing 2298
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2489
[03/01/2023-10:41:07] [V] [TRT] Removing 2599
[03/01/2023-10:41:07] [V] [TRT] Removing 2598
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_252
[03/01/2023-10:41:07] [V] [TRT] Removing 362
[03/01/2023-10:41:07] [V] [TRT] Removing 361
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_551
[03/01/2023-10:41:07] [V] [TRT] Removing 661
[03/01/2023-10:41:07] [V] [TRT] Removing 660
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_851
[03/01/2023-10:41:07] [V] [TRT] Removing 961
[03/01/2023-10:41:07] [V] [TRT] Removing 960
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1151
[03/01/2023-10:41:07] [V] [TRT] Removing 1261
[03/01/2023-10:41:07] [V] [TRT] Removing 1260
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1451
[03/01/2023-10:41:07] [V] [TRT] Removing 1561
[03/01/2023-10:41:07] [V] [TRT] Removing 1560
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1751
[03/01/2023-10:41:07] [V] [TRT] Removing 1861
[03/01/2023-10:41:07] [V] [TRT] Removing 1860
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2051
[03/01/2023-10:41:07] [V] [TRT] Removing 2161
[03/01/2023-10:41:07] [V] [TRT] Removing 2160
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2351
[03/01/2023-10:41:07] [V] [TRT] Removing 2461
[03/01/2023-10:41:07] [V] [TRT] Removing 2460
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_404
[03/01/2023-10:41:07] [V] [TRT] Removing 514
[03/01/2023-10:41:07] [V] [TRT] Removing 513
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_704
[03/01/2023-10:41:07] [V] [TRT] Removing 814
[03/01/2023-10:41:07] [V] [TRT] Removing 813
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1004
[03/01/2023-10:41:07] [V] [TRT] Removing 1114
[03/01/2023-10:41:07] [V] [TRT] Removing 1113
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1304
[03/01/2023-10:41:07] [V] [TRT] Removing 1414
[03/01/2023-10:41:07] [V] [TRT] Removing 1413
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1604
[03/01/2023-10:41:07] [V] [TRT] Removing 1714
[03/01/2023-10:41:07] [V] [TRT] Removing 1713
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1904
[03/01/2023-10:41:07] [V] [TRT] Removing 2014
[03/01/2023-10:41:07] [V] [TRT] Removing 2013
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2204
[03/01/2023-10:41:07] [V] [TRT] Removing 2314
[03/01/2023-10:41:07] [V] [TRT] Removing 2313
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2504
[03/01/2023-10:41:07] [V] [TRT] Removing 2614
[03/01/2023-10:41:07] [V] [TRT] Removing 2613
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_420
[03/01/2023-10:41:07] [V] [TRT] Removing 530
[03/01/2023-10:41:07] [V] [TRT] Removing 529
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_720
[03/01/2023-10:41:07] [V] [TRT] Removing 830
[03/01/2023-10:41:07] [V] [TRT] Removing 829
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1020
[03/01/2023-10:41:07] [V] [TRT] Removing 1130
[03/01/2023-10:41:07] [V] [TRT] Removing 1129
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1320
[03/01/2023-10:41:07] [V] [TRT] Removing 1430
[03/01/2023-10:41:07] [V] [TRT] Removing 1429
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1620
[03/01/2023-10:41:07] [V] [TRT] Removing 1730
[03/01/2023-10:41:07] [V] [TRT] Removing 1729
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1920
[03/01/2023-10:41:07] [V] [TRT] Removing 2030
[03/01/2023-10:41:07] [V] [TRT] Removing 2029
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2220
[03/01/2023-10:41:07] [V] [TRT] Removing 2330
[03/01/2023-10:41:07] [V] [TRT] Removing 2329
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2520
[03/01/2023-10:41:07] [V] [TRT] Removing 2630
[03/01/2023-10:41:07] [V] [TRT] Removing 2629
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_423
[03/01/2023-10:41:07] [V] [TRT] Removing 533
[03/01/2023-10:41:07] [V] [TRT] Removing 532
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_723
[03/01/2023-10:41:07] [V] [TRT] Removing 833
[03/01/2023-10:41:07] [V] [TRT] Removing 832
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1023
[03/01/2023-10:41:07] [V] [TRT] Removing 1133
[03/01/2023-10:41:07] [V] [TRT] Removing 1132
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1323
[03/01/2023-10:41:07] [V] [TRT] Removing 1433
[03/01/2023-10:41:07] [V] [TRT] Removing 1432
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1623
[03/01/2023-10:41:07] [V] [TRT] Removing 1733
[03/01/2023-10:41:07] [V] [TRT] Removing 1732
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1923
[03/01/2023-10:41:07] [V] [TRT] Removing 2033
[03/01/2023-10:41:07] [V] [TRT] Removing 2032
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2223
[03/01/2023-10:41:07] [V] [TRT] Removing 2333
[03/01/2023-10:41:07] [V] [TRT] Removing 2332
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2523
[03/01/2023-10:41:07] [V] [TRT] Removing 2633
[03/01/2023-10:41:07] [V] [TRT] Removing 2632
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_315
[03/01/2023-10:41:07] [V] [TRT] Removing 425
[03/01/2023-10:41:07] [V] [TRT] Removing 424
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_464
[03/01/2023-10:41:07] [V] [TRT] Removing 574
[03/01/2023-10:41:07] [V] [TRT] Removing 573
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_614
[03/01/2023-10:41:07] [V] [TRT] Removing 724
[03/01/2023-10:41:07] [V] [TRT] Removing 723
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_764
[03/01/2023-10:41:07] [V] [TRT] Removing 874
[03/01/2023-10:41:07] [V] [TRT] Removing 873
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_914
[03/01/2023-10:41:07] [V] [TRT] Removing 1024
[03/01/2023-10:41:07] [V] [TRT] Removing 1023
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1064
[03/01/2023-10:41:07] [V] [TRT] Removing 1174
[03/01/2023-10:41:07] [V] [TRT] Removing 1173
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1214
[03/01/2023-10:41:07] [V] [TRT] Removing 1324
[03/01/2023-10:41:07] [V] [TRT] Removing 1323
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1364
[03/01/2023-10:41:07] [V] [TRT] Removing 1474
[03/01/2023-10:41:07] [V] [TRT] Removing 1473
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1514
[03/01/2023-10:41:07] [V] [TRT] Removing 1624
[03/01/2023-10:41:07] [V] [TRT] Removing 1623
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1664
[03/01/2023-10:41:07] [V] [TRT] Removing 1774
[03/01/2023-10:41:07] [V] [TRT] Removing 1773
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1814
[03/01/2023-10:41:07] [V] [TRT] Removing 1924
[03/01/2023-10:41:07] [V] [TRT] Removing 1923
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1964
[03/01/2023-10:41:07] [V] [TRT] Removing 2074
[03/01/2023-10:41:07] [V] [TRT] Removing 2073
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2114
[03/01/2023-10:41:07] [V] [TRT] Removing 2224
[03/01/2023-10:41:07] [V] [TRT] Removing 2223
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2264
[03/01/2023-10:41:07] [V] [TRT] Removing 2374
[03/01/2023-10:41:07] [V] [TRT] Removing 2373
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2414
[03/01/2023-10:41:07] [V] [TRT] Removing 2524
[03/01/2023-10:41:07] [V] [TRT] Removing 2523
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2564
[03/01/2023-10:41:07] [V] [TRT] Removing 2674
[03/01/2023-10:41:07] [V] [TRT] Removing 2673
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_318
[03/01/2023-10:41:07] [V] [TRT] Removing 428
[03/01/2023-10:41:07] [V] [TRT] Removing 427
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_467
[03/01/2023-10:41:07] [V] [TRT] Removing 577
[03/01/2023-10:41:07] [V] [TRT] Removing 576
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_617
[03/01/2023-10:41:07] [V] [TRT] Removing 727
[03/01/2023-10:41:07] [V] [TRT] Removing 726
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_767
[03/01/2023-10:41:07] [V] [TRT] Removing 877
[03/01/2023-10:41:07] [V] [TRT] Removing 876
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_917
[03/01/2023-10:41:07] [V] [TRT] Removing 1027
[03/01/2023-10:41:07] [V] [TRT] Removing 1026
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1067
[03/01/2023-10:41:07] [V] [TRT] Removing 1177
[03/01/2023-10:41:07] [V] [TRT] Removing 1176
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1217
[03/01/2023-10:41:07] [V] [TRT] Removing 1327
[03/01/2023-10:41:07] [V] [TRT] Removing 1326
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1367
[03/01/2023-10:41:07] [V] [TRT] Removing 1477
[03/01/2023-10:41:07] [V] [TRT] Removing 1476
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1517
[03/01/2023-10:41:07] [V] [TRT] Removing 1627
[03/01/2023-10:41:07] [V] [TRT] Removing 1626
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1667
[03/01/2023-10:41:07] [V] [TRT] Removing 1777
[03/01/2023-10:41:07] [V] [TRT] Removing 1776
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1817
[03/01/2023-10:41:07] [V] [TRT] Removing 1927
[03/01/2023-10:41:07] [V] [TRT] Removing 1926
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1967
[03/01/2023-10:41:07] [V] [TRT] Removing 2077
[03/01/2023-10:41:07] [V] [TRT] Removing 2076
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2117
[03/01/2023-10:41:07] [V] [TRT] Removing 2227
[03/01/2023-10:41:07] [V] [TRT] Removing 2226
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2267
[03/01/2023-10:41:07] [V] [TRT] Removing 2377
[03/01/2023-10:41:07] [V] [TRT] Removing 2376
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2417
[03/01/2023-10:41:07] [V] [TRT] Removing 2527
[03/01/2023-10:41:07] [V] [TRT] Removing 2526
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2567
[03/01/2023-10:41:07] [V] [TRT] Removing 2677
[03/01/2023-10:41:07] [V] [TRT] Removing 2676
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_329
[03/01/2023-10:41:07] [V] [TRT] Removing 439
[03/01/2023-10:41:07] [V] [TRT] Removing 438
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_478
[03/01/2023-10:41:07] [V] [TRT] Removing 588
[03/01/2023-10:41:07] [V] [TRT] Removing 587
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_628
[03/01/2023-10:41:07] [V] [TRT] Removing 738
[03/01/2023-10:41:07] [V] [TRT] Removing 737
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_778
[03/01/2023-10:41:07] [V] [TRT] Removing 888
[03/01/2023-10:41:07] [V] [TRT] Removing 887
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_928
[03/01/2023-10:41:07] [V] [TRT] Removing 1038
[03/01/2023-10:41:07] [V] [TRT] Removing 1037
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1078
[03/01/2023-10:41:07] [V] [TRT] Removing 1188
[03/01/2023-10:41:07] [V] [TRT] Removing 1187
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1228
[03/01/2023-10:41:07] [V] [TRT] Removing 1338
[03/01/2023-10:41:07] [V] [TRT] Removing 1337
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1378
[03/01/2023-10:41:07] [V] [TRT] Removing 1488
[03/01/2023-10:41:07] [V] [TRT] Removing 1487
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1528
[03/01/2023-10:41:07] [V] [TRT] Removing 1638
[03/01/2023-10:41:07] [V] [TRT] Removing 1637
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1678
[03/01/2023-10:41:07] [V] [TRT] Removing 1788
[03/01/2023-10:41:07] [V] [TRT] Removing 1787
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1828
[03/01/2023-10:41:07] [V] [TRT] Removing 1938
[03/01/2023-10:41:07] [V] [TRT] Removing 1937
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_1978
[03/01/2023-10:41:07] [V] [TRT] Removing 2088
[03/01/2023-10:41:07] [V] [TRT] Removing 2087
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2128
[03/01/2023-10:41:07] [V] [TRT] Removing 2238
[03/01/2023-10:41:07] [V] [TRT] Removing 2237
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2278
[03/01/2023-10:41:07] [V] [TRT] Removing 2388
[03/01/2023-10:41:07] [V] [TRT] Removing 2387
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2428
[03/01/2023-10:41:07] [V] [TRT] Removing 2538
[03/01/2023-10:41:07] [V] [TRT] Removing 2537
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2578
[03/01/2023-10:41:07] [V] [TRT] Removing 2688
[03/01/2023-10:41:07] [V] [TRT] Removing 2687
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_304
[03/01/2023-10:41:07] [V] [TRT] Removing 414
[03/01/2023-10:41:07] [V] [TRT] Removing 413
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_453
[03/01/2023-10:41:07] [V] [TRT] Removing 563
[03/01/2023-10:41:07] [V] [TRT] Removing 562
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_603
[03/01/2023-10:41:07] [V] [TRT] Removing 713
[03/01/2023-10:41:07] [V] [TRT] Removing 712
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_753
[03/01/2023-10:41:07] [V] [TRT] Removing 863
[03/01/2023-10:41:07] [V] [TRT] Removing 862
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_903
[03/01/2023-10:41:07] [V] [TRT] Removing 1013
[03/01/2023-10:41:07] [V] [TRT] Removing 1012
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1053
[03/01/2023-10:41:07] [V] [TRT] Removing 1163
[03/01/2023-10:41:07] [V] [TRT] Removing 1162
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1203
[03/01/2023-10:41:07] [V] [TRT] Removing 1313
[03/01/2023-10:41:07] [V] [TRT] Removing 1312
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1353
[03/01/2023-10:41:07] [V] [TRT] Removing 1463
[03/01/2023-10:41:07] [V] [TRT] Removing 1462
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1503
[03/01/2023-10:41:07] [V] [TRT] Removing 1613
[03/01/2023-10:41:07] [V] [TRT] Removing 1612
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1653
[03/01/2023-10:41:07] [V] [TRT] Removing 1763
[03/01/2023-10:41:07] [V] [TRT] Removing 1762
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1803
[03/01/2023-10:41:07] [V] [TRT] Removing 1913
[03/01/2023-10:41:07] [V] [TRT] Removing 1912
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_1953
[03/01/2023-10:41:07] [V] [TRT] Removing 2063
[03/01/2023-10:41:07] [V] [TRT] Removing 2062
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2103
[03/01/2023-10:41:07] [V] [TRT] Removing 2213
[03/01/2023-10:41:07] [V] [TRT] Removing 2212
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2253
[03/01/2023-10:41:07] [V] [TRT] Removing 2363
[03/01/2023-10:41:07] [V] [TRT] Removing 2362
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2403
[03/01/2023-10:41:07] [V] [TRT] Removing 2513
[03/01/2023-10:41:07] [V] [TRT] Removing 2512
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2553
[03/01/2023-10:41:07] [V] [TRT] Removing 2663
[03/01/2023-10:41:07] [V] [TRT] Removing 2662
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_109
[03/01/2023-10:41:07] [V] [TRT] Removing 219
[03/01/2023-10:41:07] [V] [TRT] Removing 218
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_150
[03/01/2023-10:41:07] [V] [TRT] Removing 260
[03/01/2023-10:41:07] [V] [TRT] Removing 259
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_153
[03/01/2023-10:41:07] [V] [TRT] Removing 263
[03/01/2023-10:41:07] [V] [TRT] Removing 262
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_164
[03/01/2023-10:41:07] [V] [TRT] Removing 274
[03/01/2023-10:41:07] [V] [TRT] Removing 273
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_167
[03/01/2023-10:41:07] [V] [TRT] Removing 277
[03/01/2023-10:41:07] [V] [TRT] Removing 276
[03/01/2023-10:41:07] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_2601
[03/01/2023-10:41:07] [V] [TRT] Removing 2711
[03/01/2023-10:41:07] [V] [TRT] Removing 2710
[03/01/2023-10:41:07] [V] [TRT] After Myelin optimization: 1239 layers
[03/01/2023-10:41:07] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[03/01/2023-10:41:07] [V] [TRT] QDQ graph optimizer forward pass - DQ motions and fusions
[03/01/2023-10:41:07] [V] [TRT] QDQ graph optimizer backward pass
[03/01/2023-10:41:07] [V] [TRT] QDQ graph optimizer quantization pass - Generate quantized ops
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_13
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_13 with Relu_14
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_217
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_217 with Relu_218
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_366
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_366 with Relu_367
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_516
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_516 with Relu_517
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_666
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_666 with Relu_667
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_816
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_816 with Relu_817
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_966
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_966 with Relu_967
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1116
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1116 with Relu_1117
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1266
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1266 with Relu_1267
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1416
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1416 with Relu_1417
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1566
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1566 with Relu_1567
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1716
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1716 with Relu_1717
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1866
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1866 with Relu_1867
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2016
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2016 with Relu_2017
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2166
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2166 with Relu_2167
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2316
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2316 with Relu_2317
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2466
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2466 with Relu_2467
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_28
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_28 with Relu_29
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_232
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_232 with Relu_233
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_381
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_381 with Relu_382
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_531
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_531 with Relu_532
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_681
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_681 with Relu_682
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_831
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_831 with Relu_832
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_981
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_981 with Relu_982
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1131
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1131 with Relu_1132
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1281
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1281 with Relu_1282
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1431
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1431 with Relu_1432
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1581
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1581 with Relu_1582
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1731
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1731 with Relu_1732
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1881
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1881 with Relu_1882
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2031
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2031 with Relu_2032
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2181
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2181 with Relu_2182
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2331
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2331 with Relu_2332
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2481
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2481 with Relu_2482
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_44
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_44 with Relu_45
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_248
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_248 with Relu_249
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_397
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_397 with Relu_398
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_547
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_547 with Relu_548
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_697
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_697 with Relu_698
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_847
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_847 with Relu_848
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_997
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_997 with Relu_998
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1147
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1147 with Relu_1148
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1297
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1297 with Relu_1298
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1447
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1447 with Relu_1448
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1597
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1597 with Relu_1598
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1747
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1747 with Relu_1748
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1897
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1897 with Relu_1898
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2047
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2047 with Relu_2048
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2197
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2197 with Relu_2198
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2347
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2347 with Relu_2348
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2497
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2497 with Relu_2498
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_59
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_59 with Relu_60
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_263
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_263 with Relu_264
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_412
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_412 with Relu_413
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_562
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_562 with Relu_563
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_712
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_712 with Relu_713
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_862
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_862 with Relu_863
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1012
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1012 with Relu_1013
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1162
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1162 with Relu_1163
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1312
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1312 with Relu_1313
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1462
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1462 with Relu_1463
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1612
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1612 with Relu_1613
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1762
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1762 with Relu_1763
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_1912
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_1912 with Relu_1913
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2062
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2062 with Relu_2063
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2212
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2212 with Relu_2213
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2362
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2362 with Relu_2363
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_2512
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_2512 with Relu_2513
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_82
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_82 with Relu_83
[03/01/2023-10:41:07] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_97
[03/01/2023-10:41:07] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_97 with Relu_98
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_284
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_284 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_433
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_433 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_583
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_583 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_733
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_733 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_883
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_883 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_1033
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_1033 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_1183
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_1183 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_1333
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_1333 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_1483
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_1483 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_1633
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_1633 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_1783
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_1783 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_1933
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_1933 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_2083
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_2083 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_2233
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_2233 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_2383
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_2383 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_2533
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_2533 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_119
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_119 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_178
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_178 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_2593
[03/01/2023-10:41:07] [V] [TRT] Swap the layer type of GlobalAveragePool_2593 from REDUCE to POOLING
[03/01/2023-10:41:07] [V] [TRT] Running: SplitConstAcrossQuantizeFanOut on attention_channel.fc.0.weight
[03/01/2023-10:41:07] [V] [TRT] Removing attention_channel.fc.0.weight
[03/01/2023-10:41:07] [V] [TRT] Running: SplitConstAcrossQuantizeFanOut on attention_channel.fc.2.weight
[03/01/2023-10:41:07] [V] [TRT] Removing attention_channel.fc.2.weight
[03/01/2023-10:41:07] [V] [TRT] Running: SplitConstAcrossQuantizeFanOut on conv4.0.weight
[03/01/2023-10:41:07] [V] [TRT] Removing conv4.0.weight
[03/01/2023-10:41:07] [V] [TRT] Running: SplitConstAcrossQuantizeFanOut on conv4.3.weight
[03/01/2023-10:41:07] [V] [TRT] Removing conv4.3.weight
[03/01/2023-10:41:07] [V] [TRT] Running: SplitConstAcrossQuantizeFanOut on conv5.0.weight
[03/01/2023-10:41:07] [V] [TRT] Removing conv5.0.weight
[03/01/2023-10:41:07] [V] [TRT] Running: SplitConstAcrossQuantizeFanOut on conv5.3.weight
[03/01/2023-10:41:07] [V] [TRT] Removing conv5.3.weight
[03/01/2023-10:41:07] [V] [TRT] Running: SplitConstAcrossQuantizeFanOut on patchattention_spatial.conv1.weight
[03/01/2023-10:41:07] [V] [TRT] Removing patchattention_spatial.conv1.weight
[03/01/2023-10:41:07] [V] [TRT] Running: SplitConstAcrossQuantizeFanOut on patchattention_channel.fc.0.weight
[03/01/2023-10:41:07] [V] [TRT] Removing patchattention_channel.fc.0.weight
[03/01/2023-10:41:07] [V] [TRT] Running: SplitConstAcrossQuantizeFanOut on patchattention_channel.fc.2.weight
[03/01/2023-10:41:07] [V] [TRT] Removing patchattention_channel.fc.2.weight
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv1.0.weight
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv1.0.weight with QuantizeLinear_8
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv1.3.weight
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv1.3.weight with QuantizeLinear_23
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv2.0.weight
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv2.0.weight with QuantizeLinear_39
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv2.3.weight
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv2.3.weight with QuantizeLinear_54
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv3.0.weight
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv3.0.weight with QuantizeLinear_77
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv3.3.weight
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv3.3.weight with QuantizeLinear_92
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on attention_spatial.conv1.weight
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing attention_spatial.conv1.weight with QuantizeLinear_112
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on attention_channel.fc.0.weight_clone_1
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing attention_channel.fc.0.weight_clone_1 with QuantizeLinear_156
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on attention_channel.fc.0.weight_clone_0
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing attention_channel.fc.0.weight_clone_0 with QuantizeLinear_128
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on attention_channel.fc.2.weight_clone_1
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing attention_channel.fc.2.weight_clone_1 with QuantizeLinear_170
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on attention_channel.fc.2.weight_clone_0
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing attention_channel.fc.2.weight_clone_0 with QuantizeLinear_142
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on classfier1.weight
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing classfier1.weight with QuantizeLinear_189
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_15
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_15 with QuantizeLinear_2461
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_14
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_14 with QuantizeLinear_2311
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_13
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_13 with QuantizeLinear_2161
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_12
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_12 with QuantizeLinear_2011
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_11
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_11 with QuantizeLinear_1861
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_10
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_10 with QuantizeLinear_1711
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_9
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_9 with QuantizeLinear_1561
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_8
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_8 with QuantizeLinear_1411
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_7
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_7 with QuantizeLinear_1261
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_6
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_6 with QuantizeLinear_1111
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_5
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_5 with QuantizeLinear_961
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_4
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_4 with QuantizeLinear_811
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_3
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_3 with QuantizeLinear_661
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_2
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_2 with QuantizeLinear_511
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_1
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_1 with QuantizeLinear_361
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.0.weight_clone_0
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.0.weight_clone_0 with QuantizeLinear_212
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_15
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_15 with QuantizeLinear_2476
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_14
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_14 with QuantizeLinear_2326
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_13
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_13 with QuantizeLinear_2176
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_12
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_12 with QuantizeLinear_2026
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_11
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_11 with QuantizeLinear_1876
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_10
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_10 with QuantizeLinear_1726
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_9
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_9 with QuantizeLinear_1576
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_8
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_8 with QuantizeLinear_1426
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_7
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_7 with QuantizeLinear_1276
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_6
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_6 with QuantizeLinear_1126
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_5
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_5 with QuantizeLinear_976
[03/01/2023-10:41:07] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_4
[03/01/2023-10:41:07] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_4 with QuantizeLinear_826
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_3
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_3 with QuantizeLinear_676
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_2
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_2 with QuantizeLinear_526
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_1
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_1 with QuantizeLinear_376
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv4.3.weight_clone_0
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv4.3.weight_clone_0 with QuantizeLinear_227
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_15
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_15 with QuantizeLinear_2492
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_14
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_14 with QuantizeLinear_2342
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_13
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_13 with QuantizeLinear_2192
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_12
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_12 with QuantizeLinear_2042
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_11
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_11 with QuantizeLinear_1892
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_10
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_10 with QuantizeLinear_1742
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_9
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_9 with QuantizeLinear_1592
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_8
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_8 with QuantizeLinear_1442
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_7
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_7 with QuantizeLinear_1292
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_6
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_6 with QuantizeLinear_1142
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_5
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_5 with QuantizeLinear_992
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_4
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_4 with QuantizeLinear_842
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_3
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_3 with QuantizeLinear_692
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_2
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_2 with QuantizeLinear_542
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_1
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_1 with QuantizeLinear_392
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.0.weight_clone_0
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.0.weight_clone_0 with QuantizeLinear_243
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_15
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_15 with QuantizeLinear_2507
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_14
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_14 with QuantizeLinear_2357
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_13
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_13 with QuantizeLinear_2207
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_12
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_12 with QuantizeLinear_2057
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_11
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_11 with QuantizeLinear_1907
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_10
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_10 with QuantizeLinear_1757
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_9
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_9 with QuantizeLinear_1607
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_8
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_8 with QuantizeLinear_1457
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_7
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_7 with QuantizeLinear_1307
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_6
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_6 with QuantizeLinear_1157
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_5
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_5 with QuantizeLinear_1007
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_4
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_4 with QuantizeLinear_857
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_3
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_3 with QuantizeLinear_707
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_2
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_2 with QuantizeLinear_557
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_1
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_1 with QuantizeLinear_407
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv5.3.weight_clone_0
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv5.3.weight_clone_0 with QuantizeLinear_258
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_15
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_15 with QuantizeLinear_2526
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_14
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_14 with QuantizeLinear_2376
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_13
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_13 with QuantizeLinear_2226
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_12
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_12 with QuantizeLinear_2076
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_11
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_11 with QuantizeLinear_1926
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_10
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_10 with QuantizeLinear_1776
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_9
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_9 with QuantizeLinear_1626
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_8
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_8 with QuantizeLinear_1476
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_7
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_7 with QuantizeLinear_1326
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_6
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_6 with QuantizeLinear_1176
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_5
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_5 with QuantizeLinear_1026
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_4
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_4 with QuantizeLinear_876
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_3
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_3 with QuantizeLinear_726
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_2
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_2 with QuantizeLinear_576
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_1
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_1 with QuantizeLinear_426
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_spatial.conv1.weight_clone_0
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_spatial.conv1.weight_clone_0 with QuantizeLinear_277
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_31
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_31 with QuantizeLinear_2570
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_30
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_30 with QuantizeLinear_2542
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_29
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_29 with QuantizeLinear_2420
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_28
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_28 with QuantizeLinear_2392
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_27
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_27 with QuantizeLinear_2270
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_26
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_26 with QuantizeLinear_2242
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_25
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_25 with QuantizeLinear_2120
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_24
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_24 with QuantizeLinear_2092
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_23
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_23 with QuantizeLinear_1970
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_22
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_22 with QuantizeLinear_1942
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_21
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_21 with QuantizeLinear_1820
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_20
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_20 with QuantizeLinear_1792
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_19
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_19 with QuantizeLinear_1670
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_18
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_18 with QuantizeLinear_1642
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_17
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_17 with QuantizeLinear_1520
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_16
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_16 with QuantizeLinear_1492
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_15
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_15 with QuantizeLinear_1370
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_14
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_14 with QuantizeLinear_1342
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_13
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_13 with QuantizeLinear_1220
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_12
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_12 with QuantizeLinear_1192
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_11
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_11 with QuantizeLinear_1070
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_10
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_10 with QuantizeLinear_1042
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_9
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_9 with QuantizeLinear_920
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_8
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_8 with QuantizeLinear_892
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_7
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_7 with QuantizeLinear_770
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_6
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_6 with QuantizeLinear_742
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_5
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_5 with QuantizeLinear_620
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_4
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_4 with QuantizeLinear_592
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_3
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_3 with QuantizeLinear_470
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_2
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_2 with QuantizeLinear_442
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_1
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_1 with QuantizeLinear_321
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.0.weight_clone_0
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.0.weight_clone_0 with QuantizeLinear_293
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_31
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_31 with QuantizeLinear_2584
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_30
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_30 with QuantizeLinear_2556
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_29
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_29 with QuantizeLinear_2434
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_28
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_28 with QuantizeLinear_2406
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_27
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_27 with QuantizeLinear_2284
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_26
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_26 with QuantizeLinear_2256
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_25
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_25 with QuantizeLinear_2134
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_24
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_24 with QuantizeLinear_2106
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_23
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_23 with QuantizeLinear_1984
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_22
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_22 with QuantizeLinear_1956
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_21
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_21 with QuantizeLinear_1834
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_20
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_20 with QuantizeLinear_1806
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_19
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_19 with QuantizeLinear_1684
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_18
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_18 with QuantizeLinear_1656
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_17
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_17 with QuantizeLinear_1534
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_16
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_16 with QuantizeLinear_1506
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_15
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_15 with QuantizeLinear_1384
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_14
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_14 with QuantizeLinear_1356
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_13
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_13 with QuantizeLinear_1234
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_12
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_12 with QuantizeLinear_1206
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_11
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_11 with QuantizeLinear_1084
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_10
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_10 with QuantizeLinear_1056
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_9
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_9 with QuantizeLinear_934
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_8
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_8 with QuantizeLinear_906
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_7
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_7 with QuantizeLinear_784
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_6
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_6 with QuantizeLinear_756
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_5
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_5 with QuantizeLinear_634
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_4
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_4 with QuantizeLinear_606
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_3
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_3 with QuantizeLinear_484
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_2
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_2 with QuantizeLinear_456
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_1
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_1 with QuantizeLinear_335
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on patchattention_channel.fc.2.weight_clone_0
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing patchattention_channel.fc.2.weight_clone_0 with QuantizeLinear_307
[03/01/2023-10:41:08] [V] [TRT] Running: ConstWeightsQuantizeFusion on classfier2.weight
[03/01/2023-10:41:08] [V] [TRT] ConstWeightsQuantizeFusion: Fusing classfier2.weight with QuantizeLinear_2604
[03/01/2023-10:41:08] [V] [TRT] Running: MatMulToConvTransform on Gemm_193
[03/01/2023-10:41:08] [V] [TRT] Convert layer type of Gemm_193 from MATRIX_MULTIPLY to CONVOLUTION
[03/01/2023-10:41:08] [V] [TRT] Running: MatMulToConvTransform on Gemm_2608
[03/01/2023-10:41:08] [V] [TRT] Convert layer type of Gemm_2608 from MATRIX_MULTIPLY to CONVOLUTION
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithPreceedingDQ on DequantizeLinear_192
[03/01/2023-10:41:08] [V] [TRT] Swapping DequantizeLinear_192 with transpose_before_Gemm_193
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithPreceedingDQ on DequantizeLinear_2607
[03/01/2023-10:41:08] [V] [TRT] Swapping DequantizeLinear_2607 with transpose_before_Gemm_2608
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithPreceedingDQ on DequantizeLinear_186
[03/01/2023-10:41:08] [V] [TRT] Swapping DequantizeLinear_186 with reshape_before_Gemm_193
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithPreceedingDQ on DequantizeLinear_2601
[03/01/2023-10:41:08] [V] [TRT] Swapping DequantizeLinear_2601 with reshape_before_Gemm_2608
[03/01/2023-10:41:08] [V] [TRT] Running: ConstShuffleFusion on classfier1.weight + QuantizeLinear_189
[03/01/2023-10:41:08] [V] [TRT] ConstShuffleFusion: Fusing classfier1.weight + QuantizeLinear_189 with transpose_before_Gemm_193
[03/01/2023-10:41:08] [V] [TRT] Running: ConstShuffleFusion on classfier2.weight + QuantizeLinear_2604
[03/01/2023-10:41:08] [V] [TRT] ConstShuffleFusion: Fusing classfier2.weight + QuantizeLinear_2604 with transpose_before_Gemm_2608
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_297
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_297 with Relu_298
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_325
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_325 with Relu_326
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_446
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_446 with Relu_447
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_474
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_474 with Relu_475
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_596
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_596 with Relu_597
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_624
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_624 with Relu_625
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_746
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_746 with Relu_747
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_774
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_774 with Relu_775
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_896
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_896 with Relu_897
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_924
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_924 with Relu_925
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1046
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1046 with Relu_1047
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1074
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1074 with Relu_1075
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1196
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1196 with Relu_1197
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1224
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1224 with Relu_1225
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1346
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1346 with Relu_1347
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1374
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1374 with Relu_1375
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1496
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1496 with Relu_1497
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1524
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1524 with Relu_1525
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1646
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1646 with Relu_1647
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1674
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1674 with Relu_1675
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1796
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1796 with Relu_1797
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1824
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1824 with Relu_1825
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1946
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1946 with Relu_1947
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_1974
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_1974 with Relu_1975
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_2096
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_2096 with Relu_2097
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_2124
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_2124 with Relu_2125
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_2246
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_2246 with Relu_2247
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_2274
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_2274 with Relu_2275
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_2396
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_2396 with Relu_2397
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_2424
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_2424 with Relu_2425
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_2546
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_2546 with Relu_2547
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_2574
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_2574 with Relu_2575
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_132
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_132 with Relu_133
[03/01/2023-10:41:08] [V] [TRT] Running: ConvReluFusion on Conv_160
[03/01/2023-10:41:08] [V] [TRT] ConvReluFusion: Fusing Conv_160 with Relu_161
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_203
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_203 with QuantizeLinear_206
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_352
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_352 with QuantizeLinear_355
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_502
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_502 with QuantizeLinear_505
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_652
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_652 with QuantizeLinear_655
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_802
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_802 with QuantizeLinear_805
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_952
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_952 with QuantizeLinear_955
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1102
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_1102 with QuantizeLinear_1105
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1252
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_1252 with QuantizeLinear_1255
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1402
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_1402 with QuantizeLinear_1405
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1552
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_1552 with QuantizeLinear_1555
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1702
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_1702 with QuantizeLinear_1705
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1852
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_1852 with QuantizeLinear_1855
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_2002
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_2002 with QuantizeLinear_2005
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_2152
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_2152 with QuantizeLinear_2155
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_2302
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_2302 with QuantizeLinear_2305
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_2452
[03/01/2023-10:41:08] [V] [TRT] Swapping Slice_2452 with QuantizeLinear_2455
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_30
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_30 with QuantizeLinear_33
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_234
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_234 with QuantizeLinear_237
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_383
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_383 with QuantizeLinear_386
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_533
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_533 with QuantizeLinear_536
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_683
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_683 with QuantizeLinear_686
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_833
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_833 with QuantizeLinear_836
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_983
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_983 with QuantizeLinear_986
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1133
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_1133 with QuantizeLinear_1136
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1283
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_1283 with QuantizeLinear_1286
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1433
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_1433 with QuantizeLinear_1436
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1583
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_1583 with QuantizeLinear_1586
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1733
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_1733 with QuantizeLinear_1736
[03/01/2023-10:41:08] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1883
[03/01/2023-10:41:08] [V] [TRT] Swapping MaxPool_1883 with QuantizeLinear_1886
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_2033
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_2033 with QuantizeLinear_2036
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_2183
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_2183 with QuantizeLinear_2186
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_2333
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_2333 with QuantizeLinear_2336
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_2483
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_2483 with QuantizeLinear_2486
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_312
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_312 with QuantizeLinear_315
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_461
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_461 with QuantizeLinear_464
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_611
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_611 with QuantizeLinear_614
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_761
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_761 with QuantizeLinear_764
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_911
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_911 with QuantizeLinear_914
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1061
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_1061 with QuantizeLinear_1064
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1211
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_1211 with QuantizeLinear_1214
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1361
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_1361 with QuantizeLinear_1364
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1511
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_1511 with QuantizeLinear_1514
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1661
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_1661 with QuantizeLinear_1664
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1811
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_1811 with QuantizeLinear_1814
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_1961
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_1961 with QuantizeLinear_1964
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_2111
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_2111 with QuantizeLinear_2114
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_2261
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_2261 with QuantizeLinear_2264
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_2411
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_2411 with QuantizeLinear_2414
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_2561
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_2561 with QuantizeLinear_2564
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_147
[03/01/2023-10:41:09] [V] [TRT] Swapping MaxPool_147 with QuantizeLinear_150
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Reshape_180
[03/01/2023-10:41:09] [V] [TRT] Swapping Reshape_180 with QuantizeLinear_183
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Reshape_2595
[03/01/2023-10:41:09] [V] [TRT] Swapping Reshape_2595 with QuantizeLinear_2598
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_198
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_198 with QuantizeLinear_206
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_347
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_347 with QuantizeLinear_355
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_497
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_497 with QuantizeLinear_505
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_647
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_647 with QuantizeLinear_655
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_797
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_797 with QuantizeLinear_805
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_947
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_947 with QuantizeLinear_955
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1097
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_1097 with QuantizeLinear_1105
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1247
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_1247 with QuantizeLinear_1255
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1397
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_1397 with QuantizeLinear_1405
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1547
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_1547 with QuantizeLinear_1555
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1697
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_1697 with QuantizeLinear_1705
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1847
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_1847 with QuantizeLinear_1855
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_1997
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_1997 with QuantizeLinear_2005
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_2147
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_2147 with QuantizeLinear_2155
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_2297
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_2297 with QuantizeLinear_2305
[03/01/2023-10:41:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on Slice_2447
[03/01/2023-10:41:09] [V] [TRT] Swapping Slice_2447 with QuantizeLinear_2455
[03/01/2023-10:41:10] [V] [TRT] Running: HorizontalMergeQNodes on QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_355 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_505 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_655 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_805 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_955 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_1105 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_1255 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_1405 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_1555 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_1705 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_1855 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_2005 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_2155 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_2305 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Eliminating QuantizeLinear_2455 which duplicates (Q) QuantizeLinear_206
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_355
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_505
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_655
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_805
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_955
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_1105
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_1255
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_1405
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_1555
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_1705
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_1855
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_2005
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_2155
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_2305
[03/01/2023-10:41:10] [V] [TRT] Removing QuantizeLinear_2455
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_268
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_417
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_567
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_717
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_867
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_1017
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_1167
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_1317
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_1467
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_1617
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_1767
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_1917
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_2067
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_2217
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_2367
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_2517
[03/01/2023-10:41:10] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on Concat_103
[03/01/2023-10:41:11] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_180
[03/01/2023-10:41:11] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_180 with reshape_before_Gemm_193
[03/01/2023-10:41:11] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2595
[03/01/2023-10:41:11] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2595 with reshape_before_Gemm_2608
[03/01/2023-10:41:12] [V] [TRT] Running: ShuffleErasure on Reshape_180 + reshape_before_Gemm_193
[03/01/2023-10:41:12] [V] [TRT] Removing Reshape_180 + reshape_before_Gemm_193
[03/01/2023-10:41:12] [V] [TRT] Running: ShuffleErasure on Reshape_2595 + reshape_before_Gemm_2608
[03/01/2023-10:41:12] [V] [TRT] Removing Reshape_2595 + reshape_before_Gemm_2608
[03/01/2023-10:41:12] [V] [TRT] Running: SqueezePushDownJoin on reshape_after_Gemm_193
[03/01/2023-10:41:12] [V] [TRT] -----------SqueezePushDown kSQUEEZE_JOIN case: Gemm_193 --> reshape_after_Gemm_193 --> (Unnamed Layer* 203) [ElementWise]
[03/01/2023-10:41:12] [V] [TRT] Running: SqueezePushDownJoin on reshape_after_Gemm_2608
[03/01/2023-10:41:12] [V] [TRT] -----------SqueezePushDown kSQUEEZE_JOIN case: Gemm_2608 --> reshape_after_Gemm_2608 --> (Unnamed Layer* 2500) [ElementWise]
[03/01/2023-10:41:12] [V] [TRT] Running: ConstShuffleFusion on classfier1.bias + (Unnamed Layer* 202) [Shuffle]
[03/01/2023-10:41:12] [V] [TRT] ConstShuffleFusion: Fusing classfier1.bias + (Unnamed Layer* 202) [Shuffle] with unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output
[03/01/2023-10:41:12] [V] [TRT] Running: ConstShuffleFusion on classfier2.bias + (Unnamed Layer* 2499) [Shuffle]
[03/01/2023-10:41:12] [V] [TRT] ConstShuffleFusion: Fusing classfier2.bias + (Unnamed Layer* 2499) [Shuffle] with unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output
[03/01/2023-10:41:13] [V] [TRT] Running: ConstEltFusion on classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output
[03/01/2023-10:41:13] [V] [TRT] ConstEltFusion: Fusing classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output with (Unnamed Layer* 203) [ElementWise]
[03/01/2023-10:41:13] [V] [TRT] Running: ConstEltFusion on classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output
[03/01/2023-10:41:13] [V] [TRT] ConstEltFusion: Fusing classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output with (Unnamed Layer* 2500) [ElementWise]
[03/01/2023-10:41:13] [V] [TRT] Running: ConvScaleFusion on Gemm_193
[03/01/2023-10:41:13] [V] [TRT] ConvScaleFusion: Fusing Gemm_193 with classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise]
[03/01/2023-10:41:13] [V] [TRT] Running: ConvScaleFusion on Gemm_2608
[03/01/2023-10:41:13] [V] [TRT] ConvScaleFusion: Fusing Gemm_2608 with classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise]
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_282
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_282 with Mul_283
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_431
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_431 with Mul_432
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_581
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_581 with Mul_582
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_731
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_731 with Mul_732
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_881
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_881 with Mul_882
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_1031
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_1031 with Mul_1032
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_1181
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_1181 with Mul_1182
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_1331
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_1331 with Mul_1332
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_1481
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_1481 with Mul_1482
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_1631
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_1631 with Mul_1632
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_1781
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_1781 with Mul_1782
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_1931
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_1931 with Mul_1932
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_2081
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_2081 with Mul_2082
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_2231
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_2231 with Mul_2232
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_2381
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_2381 with Mul_2382
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_2531
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_2531 with Mul_2532
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_340
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_340 with Sigmoid_341
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_489
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_489 with Sigmoid_490
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_639
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_639 with Sigmoid_640
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_789
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_789 with Sigmoid_790
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_939
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_939 with Sigmoid_940
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_1089
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_1089 with Sigmoid_1090
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_1239
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_1239 with Sigmoid_1240
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_1389
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_1389 with Sigmoid_1390
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_1539
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_1539 with Sigmoid_1540
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_1689
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_1689 with Sigmoid_1690
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_1839
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_1839 with Sigmoid_1840
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_1989
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_1989 with Sigmoid_1990
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_2139
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_2139 with Sigmoid_2140
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_2289
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_2289 with Sigmoid_2290
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_2439
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_2439 with Sigmoid_2440
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_2589
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_2589 with Sigmoid_2590
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Sigmoid_117
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Sigmoid_117 with Mul_118
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_340, Sigmoid_341)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_340, Sigmoid_341) with Mul_342
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_489, Sigmoid_490)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_489, Sigmoid_490) with Mul_491
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_639, Sigmoid_640)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_639, Sigmoid_640) with Mul_641
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_789, Sigmoid_790)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_789, Sigmoid_790) with Mul_791
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_939, Sigmoid_940)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_939, Sigmoid_940) with Mul_941
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_1089, Sigmoid_1090)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_1089, Sigmoid_1090) with Mul_1091
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_1239, Sigmoid_1240)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_1239, Sigmoid_1240) with Mul_1241
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_1389, Sigmoid_1390)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_1389, Sigmoid_1390) with Mul_1391
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_1539, Sigmoid_1540)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_1539, Sigmoid_1540) with Mul_1541
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_1689, Sigmoid_1690)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_1689, Sigmoid_1690) with Mul_1691
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_1839, Sigmoid_1840)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_1839, Sigmoid_1840) with Mul_1841
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_1989, Sigmoid_1990)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_1989, Sigmoid_1990) with Mul_1991
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_2139, Sigmoid_2140)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_2139, Sigmoid_2140) with Mul_2141
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_2289, Sigmoid_2290)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_2289, Sigmoid_2290) with Mul_2291
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_2439, Sigmoid_2440)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_2439, Sigmoid_2440) with Mul_2441
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_2589, Sigmoid_2590)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_2589, Sigmoid_2590) with Mul_2591
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on Add_175
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing Add_175 with Sigmoid_176
[03/01/2023-10:41:14] [V] [TRT] Running: PointWiseFusion on PWN(Add_175, Sigmoid_176)
[03/01/2023-10:41:14] [V] [TRT] PointWiseFusion: Fusing PWN(Add_175, Sigmoid_176) with Mul_177
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_12
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_13 + Relu_14
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_216
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_217 + Relu_218
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_365
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_366 + Relu_367
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_515
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_516 + Relu_517
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_665
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_666 + Relu_667
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_815
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_816 + Relu_817
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_965
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_966 + Relu_967
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1115
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1116 + Relu_1117
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1265
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1266 + Relu_1267
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1415
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1416 + Relu_1417
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1565
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1566 + Relu_1567
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1715
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1716 + Relu_1717
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1865
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1866 + Relu_1867
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2015
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2016 + Relu_2017
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2165
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2166 + Relu_2167
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2315
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2316 + Relu_2317
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2465
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2466 + Relu_2467
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_27
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_28 + Relu_29
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_231
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_232 + Relu_233
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_380
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_381 + Relu_382
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_530
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_531 + Relu_532
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_680
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_681 + Relu_682
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_830
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_831 + Relu_832
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_980
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_981 + Relu_982
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1130
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1131 + Relu_1132
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1280
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1281 + Relu_1282
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1430
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1431 + Relu_1432
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1580
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1581 + Relu_1582
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1730
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1731 + Relu_1732
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1880
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1881 + Relu_1882
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2030
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2031 + Relu_2032
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2180
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2181 + Relu_2182
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2330
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2331 + Relu_2332
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2480
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2481 + Relu_2482
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_43
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_44 + Relu_45
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_247
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_248 + Relu_249
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_396
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_397 + Relu_398
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_546
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_547 + Relu_548
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_696
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_697 + Relu_698
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_846
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_847 + Relu_848
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_996
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_997 + Relu_998
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1146
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1147 + Relu_1148
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1296
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1297 + Relu_1298
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1446
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1447 + Relu_1448
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1596
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1597 + Relu_1598
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1746
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1747 + Relu_1748
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1896
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1897 + Relu_1898
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2046
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2047 + Relu_2048
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2196
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2197 + Relu_2198
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2346
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2347 + Relu_2348
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2496
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2497 + Relu_2498
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_58
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_59 + Relu_60
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_262
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_263 + Relu_264
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_411
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_412 + Relu_413
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_561
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_562 + Relu_563
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_711
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_712 + Relu_713
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_861
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_862 + Relu_863
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1011
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1012 + Relu_1013
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1161
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1162 + Relu_1163
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1311
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1312 + Relu_1313
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1461
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1462 + Relu_1463
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1611
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1612 + Relu_1613
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1761
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1762 + Relu_1763
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_1911
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_1912 + Relu_1913
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2061
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2062 + Relu_2063
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2211
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2212 + Relu_2213
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2361
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2362 + Relu_2363
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_2511
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_2512 + Relu_2513
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_81
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_82 + Relu_83
[03/01/2023-10:41:15] [V] [TRT] Running: QConvScaleFusion on Conv_96
[03/01/2023-10:41:15] [V] [TRT] Removing BatchNormalization_97 + Relu_98
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_12
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_17 into Conv_12
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_5 and DequantizeLinear_11) into Conv_12
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_17
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_5
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_11
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_216
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_221 into Conv_216
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_209 and DequantizeLinear_215) into Conv_216
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_221
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_209
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_215
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_515
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_520 into Conv_515
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_508 and DequantizeLinear_514) into Conv_515
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_520
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_508
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_514
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_815
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_820 into Conv_815
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_808 and DequantizeLinear_814) into Conv_815
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_820
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_808
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_814
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1115
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1120 into Conv_1115
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1108 and DequantizeLinear_1114) into Conv_1115
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1120
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1108
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1114
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1415
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1420 into Conv_1415
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1408 and DequantizeLinear_1414) into Conv_1415
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1420
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1408
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1414
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1715
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1720 into Conv_1715
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1708 and DequantizeLinear_1714) into Conv_1715
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1720
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1708
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1714
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2015
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2020 into Conv_2015
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2008 and DequantizeLinear_2014) into Conv_2015
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2020
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2008
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2014
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2315
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2320 into Conv_2315
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2308 and DequantizeLinear_2314) into Conv_2315
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2320
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2308
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2314
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_27
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_33 into Conv_27
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_20 and DequantizeLinear_26) into Conv_27
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_33
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_20
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_26
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_231
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_237 into Conv_231
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_224 and DequantizeLinear_230) into Conv_231
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_237
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_224
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_230
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_530
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_536 into Conv_530
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_523 and DequantizeLinear_529) into Conv_530
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_536
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_523
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_529
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_830
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_836 into Conv_830
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_823 and DequantizeLinear_829) into Conv_830
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_836
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_823
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_829
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1130
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1136 into Conv_1130
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1123 and DequantizeLinear_1129) into Conv_1130
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1136
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1123
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1129
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1430
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1436 into Conv_1430
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1423 and DequantizeLinear_1429) into Conv_1430
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1436
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1423
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1429
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1730
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1736 into Conv_1730
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1723 and DequantizeLinear_1729) into Conv_1730
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1736
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1723
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1729
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2030
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2036 into Conv_2030
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2023 and DequantizeLinear_2029) into Conv_2030
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2036
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2023
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2029
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2330
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2336 into Conv_2330
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2323 and DequantizeLinear_2329) into Conv_2330
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2336
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2323
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2329
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_43
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_48 into Conv_43
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_36 and DequantizeLinear_42) into Conv_43
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_48
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_36
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_42
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_247
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_252 into Conv_247
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_240 and DequantizeLinear_246) into Conv_247
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_252
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_240
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_246
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_546
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_551 into Conv_546
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_539 and DequantizeLinear_545) into Conv_546
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_551
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_539
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_545
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_846
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_851 into Conv_846
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_839 and DequantizeLinear_845) into Conv_846
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_851
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_839
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_845
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1146
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1151 into Conv_1146
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1139 and DequantizeLinear_1145) into Conv_1146
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1151
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1139
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1145
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1446
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1451 into Conv_1446
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1439 and DequantizeLinear_1445) into Conv_1446
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1451
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1439
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1445
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1746
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1751 into Conv_1746
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1739 and DequantizeLinear_1745) into Conv_1746
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1751
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1739
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1745
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2046
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2051 into Conv_2046
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2039 and DequantizeLinear_2045) into Conv_2046
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2051
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2039
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2045
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2346
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2351 into Conv_2346
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2339 and DequantizeLinear_2345) into Conv_2346
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2351
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2339
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2345
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_58
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_51 and DequantizeLinear_57) into Conv_58
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_51
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_57
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_262
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_255 and DequantizeLinear_261) into Conv_262
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_255
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_261
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_561
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_554 and DequantizeLinear_560) into Conv_561
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_554
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_560
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_861
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_854 and DequantizeLinear_860) into Conv_861
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_854
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_860
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1161
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1154 and DequantizeLinear_1160) into Conv_1161
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1154
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1160
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1461
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1454 and DequantizeLinear_1460) into Conv_1461
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1454
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1460
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1761
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1754 and DequantizeLinear_1760) into Conv_1761
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1754
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1760
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2061
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2054 and DequantizeLinear_2060) into Conv_2061
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2054
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2060
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2361
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2354 and DequantizeLinear_2360) into Conv_2361
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2354
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2360
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_81
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_86 into Conv_81
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_74 and DequantizeLinear_80) into Conv_81
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_86
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_74
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_80
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_281
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_274 and DequantizeLinear_280) into Conv_281
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_274
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_280
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_580
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_573 and DequantizeLinear_579) into Conv_580
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_573
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_579
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_880
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_873 and DequantizeLinear_879) into Conv_880
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_873
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_879
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1180
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1173 and DequantizeLinear_1179) into Conv_1180
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1173
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1179
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1480
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1473 and DequantizeLinear_1479) into Conv_1480
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1473
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1479
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1780
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1773 and DequantizeLinear_1779) into Conv_1780
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1773
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1779
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2080
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2073 and DequantizeLinear_2079) into Conv_2080
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2073
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2079
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2380
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2373 and DequantizeLinear_2379) into Conv_2380
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2373
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2379
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_96
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_89 and DequantizeLinear_95) into Conv_96
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_89
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_95
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_297 + Relu_298
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_301 into Conv_297 + Relu_298
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_290 and DequantizeLinear_296) into Conv_297 + Relu_298
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_301
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_290
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_296
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_446 + Relu_447
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_450 into Conv_446 + Relu_447
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_439 and DequantizeLinear_445) into Conv_446 + Relu_447
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_450
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_439
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_445
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_596 + Relu_597
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_600 into Conv_596 + Relu_597
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_589 and DequantizeLinear_595) into Conv_596 + Relu_597
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_600
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_589
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_595
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_746 + Relu_747
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_750 into Conv_746 + Relu_747
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_739 and DequantizeLinear_745) into Conv_746 + Relu_747
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_750
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_739
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_745
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_896 + Relu_897
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_900 into Conv_896 + Relu_897
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_889 and DequantizeLinear_895) into Conv_896 + Relu_897
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_900
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_889
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_895
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1046 + Relu_1047
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1050 into Conv_1046 + Relu_1047
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1039 and DequantizeLinear_1045) into Conv_1046 + Relu_1047
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1050
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1039
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1045
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1196 + Relu_1197
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1200 into Conv_1196 + Relu_1197
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1189 and DequantizeLinear_1195) into Conv_1196 + Relu_1197
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1200
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1189
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1195
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1346 + Relu_1347
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1350 into Conv_1346 + Relu_1347
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1339 and DequantizeLinear_1345) into Conv_1346 + Relu_1347
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1350
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1339
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1345
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1496 + Relu_1497
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1500 into Conv_1496 + Relu_1497
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1489 and DequantizeLinear_1495) into Conv_1496 + Relu_1497
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1500
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1489
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1495
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1646 + Relu_1647
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1650 into Conv_1646 + Relu_1647
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1639 and DequantizeLinear_1645) into Conv_1646 + Relu_1647
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1650
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1639
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1645
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1796 + Relu_1797
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1800 into Conv_1796 + Relu_1797
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1789 and DequantizeLinear_1795) into Conv_1796 + Relu_1797
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1800
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1789
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1795
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1946 + Relu_1947
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1950 into Conv_1946 + Relu_1947
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1939 and DequantizeLinear_1945) into Conv_1946 + Relu_1947
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_1950
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1939
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1945
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2096 + Relu_2097
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2100 into Conv_2096 + Relu_2097
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2089 and DequantizeLinear_2095) into Conv_2096 + Relu_2097
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2100
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2089
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2095
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2246 + Relu_2247
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2250 into Conv_2246 + Relu_2247
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2239 and DequantizeLinear_2245) into Conv_2246 + Relu_2247
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2250
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2239
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2245
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2396 + Relu_2397
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2400 into Conv_2396 + Relu_2397
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2389 and DequantizeLinear_2395) into Conv_2396 + Relu_2397
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2400
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2389
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2395
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2546 + Relu_2547
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2550 into Conv_2546 + Relu_2547
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2539 and DequantizeLinear_2545) into Conv_2546 + Relu_2547
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_2550
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2539
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2545
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_311
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_304 and DequantizeLinear_310) into Conv_311
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_304
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_310
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_460
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_453 and DequantizeLinear_459) into Conv_460
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_453
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_459
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_610
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_603 and DequantizeLinear_609) into Conv_610
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_603
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_609
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_760
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_753 and DequantizeLinear_759) into Conv_760
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_753
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_759
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_910
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_903 and DequantizeLinear_909) into Conv_910
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_903
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_909
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1060
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1053 and DequantizeLinear_1059) into Conv_1060
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1053
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1059
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1210
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1203 and DequantizeLinear_1209) into Conv_1210
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1203
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1209
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1360
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1353 and DequantizeLinear_1359) into Conv_1360
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1353
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1359
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1510
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1503 and DequantizeLinear_1509) into Conv_1510
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1503
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1509
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1660
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1653 and DequantizeLinear_1659) into Conv_1660
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1653
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1659
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1810
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1803 and DequantizeLinear_1809) into Conv_1810
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1803
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1809
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1960
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1953 and DequantizeLinear_1959) into Conv_1960
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1953
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_1959
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2110
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2103 and DequantizeLinear_2109) into Conv_2110
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2103
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2109
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2260
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2253 and DequantizeLinear_2259) into Conv_2260
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2253
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2259
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2410
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2403 and DequantizeLinear_2409) into Conv_2410
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2403
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2409
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2560
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2553 and DequantizeLinear_2559) into Conv_2560
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2553
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2559
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_116
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_109 and DequantizeLinear_115) into Conv_116
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_109
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_115
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_132 + Relu_133
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_136 into Conv_132 + Relu_133
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_125 and DequantizeLinear_131) into Conv_132 + Relu_133
[03/01/2023-10:41:16] [V] [TRT] Removing QuantizeLinear_136
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_125
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_131
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_146
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_139 and DequantizeLinear_145) into Conv_146
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_139
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_145
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise]
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_186 and DequantizeLinear_192) into Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise]
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_186
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_192
[03/01/2023-10:41:16] [V] [TRT] Running: QuantizeDoubleInputNodes on Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise]
[03/01/2023-10:41:16] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2601 and DequantizeLinear_2607) into Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise]
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2601
[03/01/2023-10:41:16] [V] [TRT] Removing DequantizeLinear_2607
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_365
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_370 into Conv_365
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_358 and DequantizeLinear_364) into Conv_365
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_370
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_358
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_364
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_665
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_670 into Conv_665
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_658 and DequantizeLinear_664) into Conv_665
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_670
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_658
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_664
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_965
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_970 into Conv_965
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_958 and DequantizeLinear_964) into Conv_965
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_970
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_958
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_964
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1265
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1270 into Conv_1265
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1258 and DequantizeLinear_1264) into Conv_1265
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1270
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1258
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1264
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1565
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1570 into Conv_1565
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1558 and DequantizeLinear_1564) into Conv_1565
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1570
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1558
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1564
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1865
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1870 into Conv_1865
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1858 and DequantizeLinear_1864) into Conv_1865
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1870
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1858
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1864
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2165
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2170 into Conv_2165
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2158 and DequantizeLinear_2164) into Conv_2165
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2170
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2158
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2164
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2465
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2470 into Conv_2465
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2458 and DequantizeLinear_2464) into Conv_2465
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2470
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2458
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2464
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_380
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_386 into Conv_380
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_373 and DequantizeLinear_379) into Conv_380
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_386
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_373
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_379
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_680
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_686 into Conv_680
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_673 and DequantizeLinear_679) into Conv_680
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_686
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_673
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_679
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_980
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_986 into Conv_980
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_973 and DequantizeLinear_979) into Conv_980
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_986
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_973
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_979
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1280
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1286 into Conv_1280
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1273 and DequantizeLinear_1279) into Conv_1280
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1286
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1273
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1279
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1580
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1586 into Conv_1580
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1573 and DequantizeLinear_1579) into Conv_1580
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1586
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1573
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1579
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1880
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1886 into Conv_1880
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1873 and DequantizeLinear_1879) into Conv_1880
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1886
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1873
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1879
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2180
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2186 into Conv_2180
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2173 and DequantizeLinear_2179) into Conv_2180
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2186
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2173
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2179
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2480
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2486 into Conv_2480
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2473 and DequantizeLinear_2479) into Conv_2480
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2486
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2473
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2479
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_396
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_401 into Conv_396
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_389 and DequantizeLinear_395) into Conv_396
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_401
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_389
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_395
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_696
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_701 into Conv_696
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_689 and DequantizeLinear_695) into Conv_696
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_701
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_689
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_695
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_996
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1001 into Conv_996
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_989 and DequantizeLinear_995) into Conv_996
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1001
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_989
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_995
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1296
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1301 into Conv_1296
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1289 and DequantizeLinear_1295) into Conv_1296
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1301
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1289
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1295
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1596
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1601 into Conv_1596
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1589 and DequantizeLinear_1595) into Conv_1596
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1601
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1589
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1595
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1896
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1901 into Conv_1896
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1889 and DequantizeLinear_1895) into Conv_1896
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1901
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1889
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1895
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2196
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2201 into Conv_2196
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2189 and DequantizeLinear_2195) into Conv_2196
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2201
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2189
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2195
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2496
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2501 into Conv_2496
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2489 and DequantizeLinear_2495) into Conv_2496
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2501
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2489
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2495
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_411
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_404 and DequantizeLinear_410) into Conv_411
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_404
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_410
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_711
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_704 and DequantizeLinear_710) into Conv_711
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_704
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_710
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1011
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1004 and DequantizeLinear_1010) into Conv_1011
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1004
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1010
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1311
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1304 and DequantizeLinear_1310) into Conv_1311
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1304
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1310
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1611
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1604 and DequantizeLinear_1610) into Conv_1611
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1604
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1610
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1911
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1904 and DequantizeLinear_1910) into Conv_1911
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1904
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1910
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2211
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2204 and DequantizeLinear_2210) into Conv_2211
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2204
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2210
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2511
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2504 and DequantizeLinear_2510) into Conv_2511
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2504
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2510
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_430
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_423 and DequantizeLinear_429) into Conv_430
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_423
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_429
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_730
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_723 and DequantizeLinear_729) into Conv_730
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_723
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_729
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1030
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1023 and DequantizeLinear_1029) into Conv_1030
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1023
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1029
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1330
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1323 and DequantizeLinear_1329) into Conv_1330
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1323
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1329
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1630
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1623 and DequantizeLinear_1629) into Conv_1630
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1623
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1629
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1930
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1923 and DequantizeLinear_1929) into Conv_1930
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1923
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1929
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2230
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2223 and DequantizeLinear_2229) into Conv_2230
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2223
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2229
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2530
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2523 and DequantizeLinear_2529) into Conv_2530
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2523
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2529
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_325 + Relu_326
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_329 into Conv_325 + Relu_326
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_318 and DequantizeLinear_324) into Conv_325 + Relu_326
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_329
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_318
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_324
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_474 + Relu_475
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_478 into Conv_474 + Relu_475
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_467 and DequantizeLinear_473) into Conv_474 + Relu_475
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_478
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_467
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_473
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_624 + Relu_625
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_628 into Conv_624 + Relu_625
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_617 and DequantizeLinear_623) into Conv_624 + Relu_625
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_628
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_617
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_623
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_774 + Relu_775
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_778 into Conv_774 + Relu_775
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_767 and DequantizeLinear_773) into Conv_774 + Relu_775
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_778
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_767
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_773
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_924 + Relu_925
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_928 into Conv_924 + Relu_925
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_917 and DequantizeLinear_923) into Conv_924 + Relu_925
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_928
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_917
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_923
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1074 + Relu_1075
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1078 into Conv_1074 + Relu_1075
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1067 and DequantizeLinear_1073) into Conv_1074 + Relu_1075
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1078
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1067
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1073
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1224 + Relu_1225
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1228 into Conv_1224 + Relu_1225
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1217 and DequantizeLinear_1223) into Conv_1224 + Relu_1225
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1228
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1217
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1223
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1374 + Relu_1375
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1378 into Conv_1374 + Relu_1375
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1367 and DequantizeLinear_1373) into Conv_1374 + Relu_1375
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1378
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1367
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1373
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1524 + Relu_1525
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1528 into Conv_1524 + Relu_1525
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1517 and DequantizeLinear_1523) into Conv_1524 + Relu_1525
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1528
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1517
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1523
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1674 + Relu_1675
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1678 into Conv_1674 + Relu_1675
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1667 and DequantizeLinear_1673) into Conv_1674 + Relu_1675
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1678
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1667
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1673
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1824 + Relu_1825
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1828 into Conv_1824 + Relu_1825
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1817 and DequantizeLinear_1823) into Conv_1824 + Relu_1825
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1828
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1817
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1823
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1974 + Relu_1975
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_1978 into Conv_1974 + Relu_1975
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1967 and DequantizeLinear_1973) into Conv_1974 + Relu_1975
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_1978
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1967
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1973
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2124 + Relu_2125
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2128 into Conv_2124 + Relu_2125
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2117 and DequantizeLinear_2123) into Conv_2124 + Relu_2125
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2128
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2117
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2123
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2274 + Relu_2275
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2278 into Conv_2274 + Relu_2275
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2267 and DequantizeLinear_2273) into Conv_2274 + Relu_2275
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2278
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2267
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2273
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2424 + Relu_2425
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2428 into Conv_2424 + Relu_2425
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2417 and DequantizeLinear_2423) into Conv_2424 + Relu_2425
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2428
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2417
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2423
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2574 + Relu_2575
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_2578 into Conv_2574 + Relu_2575
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2567 and DequantizeLinear_2573) into Conv_2574 + Relu_2575
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_2578
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2567
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2573
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_339
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_332 and DequantizeLinear_338) into Conv_339
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_332
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_338
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_488
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_481 and DequantizeLinear_487) into Conv_488
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_481
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_487
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_638
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_631 and DequantizeLinear_637) into Conv_638
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_631
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_637
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_788
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_781 and DequantizeLinear_787) into Conv_788
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_781
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_787
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_938
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_931 and DequantizeLinear_937) into Conv_938
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_931
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_937
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1088
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1081 and DequantizeLinear_1087) into Conv_1088
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1081
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1087
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1238
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1231 and DequantizeLinear_1237) into Conv_1238
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1231
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1237
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1388
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1381 and DequantizeLinear_1387) into Conv_1388
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1381
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1387
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1538
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1531 and DequantizeLinear_1537) into Conv_1538
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1531
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1537
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1688
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1681 and DequantizeLinear_1687) into Conv_1688
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1681
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1687
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1838
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1831 and DequantizeLinear_1837) into Conv_1838
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1831
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1837
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_1988
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_1981 and DequantizeLinear_1987) into Conv_1988
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1981
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_1987
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2138
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2131 and DequantizeLinear_2137) into Conv_2138
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2131
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2137
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2288
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2281 and DequantizeLinear_2287) into Conv_2288
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2281
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2287
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2438
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2431 and DequantizeLinear_2437) into Conv_2438
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2431
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2437
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_2588
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_2581 and DequantizeLinear_2587) into Conv_2588
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2581
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_2587
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_160 + Relu_161
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_164 into Conv_160 + Relu_161
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_153 and DequantizeLinear_159) into Conv_160 + Relu_161
[03/01/2023-10:41:17] [V] [TRT] Removing QuantizeLinear_164
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_153
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_159
[03/01/2023-10:41:17] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_174
[03/01/2023-10:41:17] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_167 and DequantizeLinear_173) into Conv_174
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_167
[03/01/2023-10:41:17] [V] [TRT] Removing DequantizeLinear_173
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv1.0.weight + QuantizeLinear_8
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv1.0.weight + QuantizeLinear_8 with Conv_12
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv1.3.weight + QuantizeLinear_23
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv1.3.weight + QuantizeLinear_23 with Conv_27
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv2.0.weight + QuantizeLinear_39
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv2.0.weight + QuantizeLinear_39 with Conv_43
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv2.3.weight + QuantizeLinear_54
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv2.3.weight + QuantizeLinear_54 with Conv_58
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv3.0.weight + QuantizeLinear_77
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv3.0.weight + QuantizeLinear_77 with Conv_81
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv3.3.weight + QuantizeLinear_92
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv3.3.weight + QuantizeLinear_92 with Conv_96
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on attention_spatial.conv1.weight + QuantizeLinear_112
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing attention_spatial.conv1.weight + QuantizeLinear_112 with Conv_116
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 with Conv_160 + Relu_161
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 with Conv_132 + Relu_133
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on attention_channel.fc.2.weight_clone_1 + QuantizeLinear_170
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing attention_channel.fc.2.weight_clone_1 + QuantizeLinear_170 with Conv_174
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 with Conv_146
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 with Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise]
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_15 + QuantizeLinear_2461
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_15 + QuantizeLinear_2461 with Conv_2465
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_14 + QuantizeLinear_2311
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_14 + QuantizeLinear_2311 with Conv_2315
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_13 + QuantizeLinear_2161
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_13 + QuantizeLinear_2161 with Conv_2165
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_12 + QuantizeLinear_2011
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_12 + QuantizeLinear_2011 with Conv_2015
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_11 + QuantizeLinear_1861
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_11 + QuantizeLinear_1861 with Conv_1865
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_10 + QuantizeLinear_1711
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_10 + QuantizeLinear_1711 with Conv_1715
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_9 + QuantizeLinear_1561
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_9 + QuantizeLinear_1561 with Conv_1565
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_8 + QuantizeLinear_1411
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_8 + QuantizeLinear_1411 with Conv_1415
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_7 + QuantizeLinear_1261
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_7 + QuantizeLinear_1261 with Conv_1265
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_6 + QuantizeLinear_1111
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_6 + QuantizeLinear_1111 with Conv_1115
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_5 + QuantizeLinear_961
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_5 + QuantizeLinear_961 with Conv_965
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_4 + QuantizeLinear_811
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_4 + QuantizeLinear_811 with Conv_815
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_3 + QuantizeLinear_661
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_3 + QuantizeLinear_661 with Conv_665
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_2 + QuantizeLinear_511
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_2 + QuantizeLinear_511 with Conv_515
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_1 + QuantizeLinear_361
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_1 + QuantizeLinear_361 with Conv_365
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.0.weight_clone_0 + QuantizeLinear_212
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.0.weight_clone_0 + QuantizeLinear_212 with Conv_216
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_15 + QuantizeLinear_2476
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_15 + QuantizeLinear_2476 with Conv_2480
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_14 + QuantizeLinear_2326
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_14 + QuantizeLinear_2326 with Conv_2330
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_13 + QuantizeLinear_2176
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_13 + QuantizeLinear_2176 with Conv_2180
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_12 + QuantizeLinear_2026
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_12 + QuantizeLinear_2026 with Conv_2030
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_11 + QuantizeLinear_1876
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_11 + QuantizeLinear_1876 with Conv_1880
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_10 + QuantizeLinear_1726
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_10 + QuantizeLinear_1726 with Conv_1730
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_9 + QuantizeLinear_1576
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_9 + QuantizeLinear_1576 with Conv_1580
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_8 + QuantizeLinear_1426
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_8 + QuantizeLinear_1426 with Conv_1430
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_7 + QuantizeLinear_1276
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_7 + QuantizeLinear_1276 with Conv_1280
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_6 + QuantizeLinear_1126
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_6 + QuantizeLinear_1126 with Conv_1130
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_5 + QuantizeLinear_976
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_5 + QuantizeLinear_976 with Conv_980
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_4 + QuantizeLinear_826
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_4 + QuantizeLinear_826 with Conv_830
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_3 + QuantizeLinear_676
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_3 + QuantizeLinear_676 with Conv_680
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_2 + QuantizeLinear_526
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_2 + QuantizeLinear_526 with Conv_530
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_1 + QuantizeLinear_376
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_1 + QuantizeLinear_376 with Conv_380
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv4.3.weight_clone_0 + QuantizeLinear_227
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv4.3.weight_clone_0 + QuantizeLinear_227 with Conv_231
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_15 + QuantizeLinear_2492
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_15 + QuantizeLinear_2492 with Conv_2496
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_14 + QuantizeLinear_2342
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_14 + QuantizeLinear_2342 with Conv_2346
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_13 + QuantizeLinear_2192
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_13 + QuantizeLinear_2192 with Conv_2196
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_12 + QuantizeLinear_2042
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_12 + QuantizeLinear_2042 with Conv_2046
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_11 + QuantizeLinear_1892
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_11 + QuantizeLinear_1892 with Conv_1896
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_10 + QuantizeLinear_1742
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_10 + QuantizeLinear_1742 with Conv_1746
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_9 + QuantizeLinear_1592
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_9 + QuantizeLinear_1592 with Conv_1596
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_8 + QuantizeLinear_1442
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_8 + QuantizeLinear_1442 with Conv_1446
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_7 + QuantizeLinear_1292
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_7 + QuantizeLinear_1292 with Conv_1296
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_6 + QuantizeLinear_1142
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_6 + QuantizeLinear_1142 with Conv_1146
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_5 + QuantizeLinear_992
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_5 + QuantizeLinear_992 with Conv_996
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_4 + QuantizeLinear_842
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_4 + QuantizeLinear_842 with Conv_846
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_3 + QuantizeLinear_692
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_3 + QuantizeLinear_692 with Conv_696
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_2 + QuantizeLinear_542
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_2 + QuantizeLinear_542 with Conv_546
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_1 + QuantizeLinear_392
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_1 + QuantizeLinear_392 with Conv_396
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.0.weight_clone_0 + QuantizeLinear_243
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.0.weight_clone_0 + QuantizeLinear_243 with Conv_247
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_15 + QuantizeLinear_2507
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_15 + QuantizeLinear_2507 with Conv_2511
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_14 + QuantizeLinear_2357
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_14 + QuantizeLinear_2357 with Conv_2361
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_13 + QuantizeLinear_2207
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_13 + QuantizeLinear_2207 with Conv_2211
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_12 + QuantizeLinear_2057
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_12 + QuantizeLinear_2057 with Conv_2061
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_11 + QuantizeLinear_1907
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_11 + QuantizeLinear_1907 with Conv_1911
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_10 + QuantizeLinear_1757
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_10 + QuantizeLinear_1757 with Conv_1761
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_9 + QuantizeLinear_1607
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_9 + QuantizeLinear_1607 with Conv_1611
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_8 + QuantizeLinear_1457
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_8 + QuantizeLinear_1457 with Conv_1461
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_7 + QuantizeLinear_1307
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_7 + QuantizeLinear_1307 with Conv_1311
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_6 + QuantizeLinear_1157
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_6 + QuantizeLinear_1157 with Conv_1161
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_5 + QuantizeLinear_1007
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_5 + QuantizeLinear_1007 with Conv_1011
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_4 + QuantizeLinear_857
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_4 + QuantizeLinear_857 with Conv_861
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_3 + QuantizeLinear_707
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_3 + QuantizeLinear_707 with Conv_711
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_2 + QuantizeLinear_557
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_2 + QuantizeLinear_557 with Conv_561
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_1 + QuantizeLinear_407
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_1 + QuantizeLinear_407 with Conv_411
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on conv5.3.weight_clone_0 + QuantizeLinear_258
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing conv5.3.weight_clone_0 + QuantizeLinear_258 with Conv_262
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_15 + QuantizeLinear_2526
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_15 + QuantizeLinear_2526 with Conv_2530
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_14 + QuantizeLinear_2376
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_14 + QuantizeLinear_2376 with Conv_2380
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_13 + QuantizeLinear_2226
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_13 + QuantizeLinear_2226 with Conv_2230
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_12 + QuantizeLinear_2076
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_12 + QuantizeLinear_2076 with Conv_2080
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_11 + QuantizeLinear_1926
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_11 + QuantizeLinear_1926 with Conv_1930
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_10 + QuantizeLinear_1776
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_10 + QuantizeLinear_1776 with Conv_1780
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_9 + QuantizeLinear_1626
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_9 + QuantizeLinear_1626 with Conv_1630
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_8 + QuantizeLinear_1476
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_8 + QuantizeLinear_1476 with Conv_1480
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_7 + QuantizeLinear_1326
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_7 + QuantizeLinear_1326 with Conv_1330
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_6 + QuantizeLinear_1176
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_6 + QuantizeLinear_1176 with Conv_1180
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_5 + QuantizeLinear_1026
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_5 + QuantizeLinear_1026 with Conv_1030
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_4 + QuantizeLinear_876
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_4 + QuantizeLinear_876 with Conv_880
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_3 + QuantizeLinear_726
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_3 + QuantizeLinear_726 with Conv_730
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_2 + QuantizeLinear_576
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_2 + QuantizeLinear_576 with Conv_580
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_1 + QuantizeLinear_426
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_1 + QuantizeLinear_426 with Conv_430
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 with Conv_281
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 with Conv_2574 + Relu_2575
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 with Conv_2546 + Relu_2547
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 with Conv_2424 + Relu_2425
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 with Conv_2396 + Relu_2397
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 with Conv_2274 + Relu_2275
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 with Conv_2246 + Relu_2247
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 with Conv_2124 + Relu_2125
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 with Conv_2096 + Relu_2097
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 with Conv_1974 + Relu_1975
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 with Conv_1946 + Relu_1947
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 with Conv_1824 + Relu_1825
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 with Conv_1796 + Relu_1797
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 with Conv_1674 + Relu_1675
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 with Conv_1646 + Relu_1647
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_17 + QuantizeLinear_1520
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_17 + QuantizeLinear_1520 with Conv_1524 + Relu_1525
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 with Conv_1496 + Relu_1497
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_15 + QuantizeLinear_1370
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_15 + QuantizeLinear_1370 with Conv_1374 + Relu_1375
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 with Conv_1346 + Relu_1347
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 with Conv_1224 + Relu_1225
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 with Conv_1196 + Relu_1197
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 with Conv_1074 + Relu_1075
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 with Conv_1046 + Relu_1047
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 with Conv_924 + Relu_925
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 with Conv_896 + Relu_897
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 with Conv_774 + Relu_775
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 with Conv_746 + Relu_747
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 with Conv_624 + Relu_625
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 with Conv_596 + Relu_597
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 with Conv_474 + Relu_475
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 with Conv_446 + Relu_447
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 with Conv_325 + Relu_326
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 with Conv_297 + Relu_298
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_31 + QuantizeLinear_2584
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_31 + QuantizeLinear_2584 with Conv_2588
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_30 + QuantizeLinear_2556
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_30 + QuantizeLinear_2556 with Conv_2560
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_29 + QuantizeLinear_2434
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_29 + QuantizeLinear_2434 with Conv_2438
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_28 + QuantizeLinear_2406
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_28 + QuantizeLinear_2406 with Conv_2410
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_27 + QuantizeLinear_2284
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_27 + QuantizeLinear_2284 with Conv_2288
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_26 + QuantizeLinear_2256
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_26 + QuantizeLinear_2256 with Conv_2260
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_25 + QuantizeLinear_2134
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_25 + QuantizeLinear_2134 with Conv_2138
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_24 + QuantizeLinear_2106
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_24 + QuantizeLinear_2106 with Conv_2110
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_23 + QuantizeLinear_1984
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_23 + QuantizeLinear_1984 with Conv_1988
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_22 + QuantizeLinear_1956
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_22 + QuantizeLinear_1956 with Conv_1960
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_21 + QuantizeLinear_1834
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_21 + QuantizeLinear_1834 with Conv_1838
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_20 + QuantizeLinear_1806
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_20 + QuantizeLinear_1806 with Conv_1810
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_19 + QuantizeLinear_1684
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_19 + QuantizeLinear_1684 with Conv_1688
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_18 + QuantizeLinear_1656
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_18 + QuantizeLinear_1656 with Conv_1660
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_17 + QuantizeLinear_1534
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_17 + QuantizeLinear_1534 with Conv_1538
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_16 + QuantizeLinear_1506
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_16 + QuantizeLinear_1506 with Conv_1510
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_15 + QuantizeLinear_1384
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_15 + QuantizeLinear_1384 with Conv_1388
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_14 + QuantizeLinear_1356
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_14 + QuantizeLinear_1356 with Conv_1360
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_13 + QuantizeLinear_1234
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_13 + QuantizeLinear_1234 with Conv_1238
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_12 + QuantizeLinear_1206
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_12 + QuantizeLinear_1206 with Conv_1210
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_11 + QuantizeLinear_1084
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_11 + QuantizeLinear_1084 with Conv_1088
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_10 + QuantizeLinear_1056
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_10 + QuantizeLinear_1056 with Conv_1060
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_9 + QuantizeLinear_934
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_9 + QuantizeLinear_934 with Conv_938
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_8 + QuantizeLinear_906
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_8 + QuantizeLinear_906 with Conv_910
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_7 + QuantizeLinear_784
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_7 + QuantizeLinear_784 with Conv_788
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_6 + QuantizeLinear_756
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_6 + QuantizeLinear_756 with Conv_760
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_5 + QuantizeLinear_634
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_5 + QuantizeLinear_634 with Conv_638
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_4 + QuantizeLinear_606
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_4 + QuantizeLinear_606 with Conv_610
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_3 + QuantizeLinear_484
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_3 + QuantizeLinear_484 with Conv_488
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_2 + QuantizeLinear_456
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_2 + QuantizeLinear_456 with Conv_460
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_1 + QuantizeLinear_335
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_1 + QuantizeLinear_335 with Conv_339
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 with Conv_311
[03/01/2023-10:41:18] [V] [TRT] Running: ConstWeightsFusion on classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608
[03/01/2023-10:41:18] [V] [TRT] ConstWeightsFusion: Fusing classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 with Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise]
[03/01/2023-10:41:18] [V] [TRT] After dupe layer removal: 437 layers
[03/01/2023-10:41:18] [V] [TRT] After final dead-layer removal: 437 layers
[03/01/2023-10:41:18] [V] [TRT] After tensor merging: 437 layers
[03/01/2023-10:41:19] [V] [TRT] QDQ graph optimizer quantization epilogue pass
[03/01/2023-10:41:19] [V] [TRT] QDQ optimization pass
[03/01/2023-10:41:19] [V] [TRT] QDQ graph optimizer constant fold dangling QDQ pass
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_206
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_206 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_71
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_71 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_271_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_271_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_271_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_271_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_420_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_420_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_420_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_420_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_570_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_570_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_570_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_570_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_720_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_720_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_720_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_720_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_870_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_870_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_870_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_870_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1020_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1020_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1020_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1020_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1170_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1170_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1170_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1170_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1320_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1320_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1320_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1320_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1470_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1470_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1470_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1470_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1620_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1620_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1620_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1620_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1770_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1770_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1770_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1770_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1920_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1920_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1920_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1920_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2070_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2070_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2070_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2070_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2220_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2220_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2220_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2220_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2370_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2370_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2370_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2370_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2520_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2520_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2520_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2520_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_315
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_315 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_464
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_464 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_614
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_614 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_764
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_764 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_914
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_914 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1064
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1064 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1214
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1214 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1364
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1364 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1514
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1514 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1664
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1664 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1814
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1814 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1964
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1964 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2114
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2114 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2264
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2264 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2414
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2414 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2564
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2564 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_287
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_287 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_436
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_436 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_586
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_586 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_736
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_736 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_886
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_886 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1036
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1036 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1186
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1186 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1336
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1336 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1486
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1486 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1636
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1636 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1786
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1786 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_1936
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_1936 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2086
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2086 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2236
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2236 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2386
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2386 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2536
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2536 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_106_clone_1
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_106_clone_1 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_106_clone_0
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_106_clone_0 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_150
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_150 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_122
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_122 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_183
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_183 from QUANTIZE to kQDQ
[03/01/2023-10:41:19] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2598
[03/01/2023-10:41:19] [V] [TRT] Swap the layer type of QuantizeLinear_2598 from QUANTIZE to kQDQ
[03/01/2023-10:41:20] [V] [TRT] After dupe layer removal: 437 layers
[03/01/2023-10:41:20] [V] [TRT] After final dead-layer removal: 437 layers
[03/01/2023-10:41:20] [V] [TRT] After tensor merging: 437 layers
[03/01/2023-10:41:21] [V] [TRT] After vertical fusions: 437 layers
[03/01/2023-10:41:21] [V] [TRT] After dupe layer removal: 437 layers
[03/01/2023-10:41:21] [V] [TRT] After final dead-layer removal: 437 layers
[03/01/2023-10:41:21] [V] [TRT] After tensor merging: 437 layers
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_198 by retargeting 314 from 314 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_347 by retargeting 463 from 463 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_497 by retargeting 613 from 613 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_647 by retargeting 763 from 763 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_797 by retargeting 913 from 913 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_947 by retargeting 1063 from 1063 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_1097 by retargeting 1213 from 1213 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_1247 by retargeting 1363 from 1363 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_1397 by retargeting 1513 from 1513 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_1547 by retargeting 1663 from 1663 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_1697 by retargeting 1813 from 1813 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_1847 by retargeting 1963 from 1963 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_1997 by retargeting 2113 from 2113 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_2147 by retargeting 2263 from 2263 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_2297 by retargeting 2413 from 2413 to 309
[03/01/2023-10:41:21] [V] [TRT] Eliminating slice Slice_2447 by retargeting 2563 from 2563 to 309
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_203 with copy from 309 to 317
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_352 with copy from 309 to 466
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_502 with copy from 309 to 616
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_652 with copy from 309 to 766
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_802 with copy from 309 to 916
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_952 with copy from 309 to 1066
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_1102 with copy from 309 to 1216
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_1252 with copy from 309 to 1366
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_1402 with copy from 309 to 1516
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_1552 with copy from 309 to 1666
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_1702 with copy from 309 to 1816
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_1852 with copy from 309 to 1966
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_2002 with copy from 309 to 2116
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_2152 with copy from 309 to 2266
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_2302 with copy from 309 to 2416
[03/01/2023-10:41:21] [V] [TRT] Replacing slice Slice_2452 with copy from 309 to 2566
[03/01/2023-10:41:21] [V] [TRT] After slice removal: 421 layers
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_2592
[03/01/2023-10:41:21] [V] [TRT] Retargeting 2553 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 2702 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_2442
[03/01/2023-10:41:21] [V] [TRT] Retargeting 2403 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 2552 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_2292
[03/01/2023-10:41:21] [V] [TRT] Retargeting 2253 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 2402 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_2142
[03/01/2023-10:41:21] [V] [TRT] Retargeting 2103 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 2252 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1992
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1953 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 2102 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1842
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1803 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1952 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1692
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1653 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1802 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1542
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1503 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1652 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1392
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1353 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1502 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1242
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1203 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1352 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1092
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1053 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1202 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_942
[03/01/2023-10:41:21] [V] [TRT] Retargeting 903 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 1052 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_792
[03/01/2023-10:41:21] [V] [TRT] Retargeting 753 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 902 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_642
[03/01/2023-10:41:21] [V] [TRT] Retargeting 603 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 752 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_492
[03/01/2023-10:41:21] [V] [TRT] Retargeting 453 to 2703
[03/01/2023-10:41:21] [V] [TRT] Retargeting 602 to 2703
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_103
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_103_212_clone_0 to 217 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_103_213_clone_1 to 217
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_100
[03/01/2023-10:41:21] [V] [TRT] Retargeting 210 to 211
[03/01/2023-10:41:21] [V] [TRT] Generating copy for 179 to 211 because input does not support striding.
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_2517
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_2517_2626_clone_0 to 2631 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_2517_2627_clone_1 to 2631
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_2367
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_2367_2476_clone_0 to 2481 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_2367_2477_clone_1 to 2481
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_2217
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_2217_2326_clone_0 to 2331 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_2217_2327_clone_1 to 2331
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_2067
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_2067_2176_clone_0 to 2181 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_2067_2177_clone_1 to 2181
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1917
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_1917_2026_clone_0 to 2031 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_1917_2027_clone_1 to 2031
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1767
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_1767_1876_clone_0 to 1881 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_1767_1877_clone_1 to 1881
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1617
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_1617_1726_clone_0 to 1731 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_1617_1727_clone_1 to 1731
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1467
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_1467_1576_clone_0 to 1581 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_1467_1577_clone_1 to 1581
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1317
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_1317_1426_clone_0 to 1431 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_1317_1427_clone_1 to 1431
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1167
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_1167_1276_clone_0 to 1281 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_1167_1277_clone_1 to 1281
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_1017
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_1017_1126_clone_0 to 1131 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_1017_1127_clone_1 to 1131
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_867
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_867_976_clone_0 to 981 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_867_977_clone_1 to 981
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_717
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_717_826_clone_0 to 831 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_717_827_clone_1 to 831
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_567
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_567_676_clone_0 to 681 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_567_677_clone_1 to 681
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_417
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_417_526_clone_0 to 531 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_417_527_clone_1 to 531
[03/01/2023-10:41:21] [V] [TRT] Eliminating concatenation Concat_268
[03/01/2023-10:41:21] [V] [TRT] Generating copy for Concat_268_377_clone_0 to 382 because of stomping hazard.
[03/01/2023-10:41:21] [V] [TRT] Retargeting Concat_268_378_clone_1 to 382
[03/01/2023-10:41:21] [V] [TRT] After concat removal: 406 layers
[03/01/2023-10:41:21] [V] [TRT] Trying to split Reshape and strided tensor
[03/01/2023-10:41:21] [V] [TRT] Graph construction and optimization completed in 14.8618 seconds.
[03/01/2023-10:41:21] [V] [TRT] Trying to load shared library libcublas.so.11
[03/01/2023-10:41:21] [V] [TRT] Loaded shared library libcublas.so.11
[03/01/2023-10:41:24] [V] [TRT] Using cublas as plugin tactic source
[03/01/2023-10:41:24] [V] [TRT] Trying to load shared library libcublasLt.so.11
[03/01/2023-10:41:24] [V] [TRT] Loaded shared library libcublasLt.so.11
[03/01/2023-10:41:24] [V] [TRT] Using cublasLt as core library tactic source
[03/01/2023-10:41:24] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +619, GPU +258, now: CPU 1488, GPU 805 (MiB)
[03/01/2023-10:41:24] [V] [TRT] Trying to load shared library libcudnn.so.8
[03/01/2023-10:41:24] [V] [TRT] Loaded shared library libcudnn.so.8
[03/01/2023-10:41:24] [V] [TRT] Using cuDNN as plugin tactic source
[03/01/2023-10:41:25] [V] [TRT] Using cuDNN as core library tactic source
[03/01/2023-10:41:25] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +658, GPU +266, now: CPU 2146, GPU 1071 (MiB)
[03/01/2023-10:41:25] [W] [TRT] TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.1.1
[03/01/2023-10:41:25] [I] [TRT] Global timing cache in use. Profiling results in this builder pass will be stored.
[03/01/2023-10:41:25] [V] [TRT] Constructing optimization profile number 0 [1/1].
[03/01/2023-10:41:25] [V] [TRT] Using kFLOAT for region surrounded by copy operations: Reformatted input
[03/01/2023-10:41:25] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Float(3600,3600,60,1) -> Float(3600,3600,60,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Reformatting CopyNode for Network Input input (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0031358
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0087083
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00403149
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0031358
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Float(3600,3600,60,1) -> Int8(3600,3600:4,60,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: QuantizeLinear_206 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00328842
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106998
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00389832
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00328842
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Float(3600,3600,60,1) -> Int8(3600,3600:32,60,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: QuantizeLinear_206 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00541257
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108042
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0054185
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00541257
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Float(3600,3600,60,1) -> Int8(3600,3600,60,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: QuantizeLinear_206 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00407555
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114226
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00416287
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00407555
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Float(3600,3600,60,1) -> Int8(3600:32,3600,60,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: QuantizeLinear_206 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00540614
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116128
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0053865
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0053865
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Float(3600,3600,60,1) -> Int8(3600,3600,60,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00400267
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114219
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00420356
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00400267
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Float(3600,3600,60,1) -> Int8(3600,3600:4,60,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00436225
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114328
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00432834
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00432834
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Float(3600,3600,60,1) -> Int8(3600,3600:32,60,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00589824
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0174888
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00622648
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00589824
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00427644
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109087
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00431126
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00427644
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00433538
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106371
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00448914
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00433538
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00448943
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0216085
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00876908
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00448943
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00752217
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.022801
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00787609
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00752217
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00769107
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110386
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00627776
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00627776
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00641769
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0172612
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00679564
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00641769
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.006028
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0164815
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00447086
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00447086
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452114
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011264
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00492008
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00452114
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470474
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114666
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466684
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00466684
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459943
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459943
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00481768
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00481768
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_203 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488579
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00488579
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004512
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111177
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00460357
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004512
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470017
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011129
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485166
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470017
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483231
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488594
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00483231
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046198
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048128
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046198
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483733
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114099
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495874
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00483733
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00486644
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113428
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00500903
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00486644
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00455814
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011399
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00462924
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00455814
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00455314
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112415
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0046953
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00455314
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458971
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477379
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458971
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476434
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476434
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00498901
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00498901
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_352 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00514612
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00514612
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473349
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011084
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00592165
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473349
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00895114
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231967
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00863032
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00863032
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00829791
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0217966
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00498885
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00498885
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475252
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118491
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00925314
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475252
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00889761
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0234893
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00856202
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00856202
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00837917
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0230296
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00881156
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00837917
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00806146
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235938
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00818387
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00806146
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00812673
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0232803
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00839518
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00812673
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00838756
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0170829
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00519331
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00519331
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0049838
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0049838
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00515657
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00515657
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_502 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00515135
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00515135
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484236
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113428
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495354
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00484236
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488107
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00503409
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00488107
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00494849
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114775
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00517747
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00494849
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469058
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112865
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483718
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469058
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488092
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00500398
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00488092
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00490088
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113203
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00499389
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00490088
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467642
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478842
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467642
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046956
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114212
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482255
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046956
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00493289
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0222981
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00793889
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00493289
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00785299
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00785299
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00816762
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00816762
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_652 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00824914
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00824914
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00794794
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0227579
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00818387
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00794794
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00826464
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0224862
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00850178
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00826464
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00971337
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0184503
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00648706
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00648706
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00604038
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0162377
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00617428
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00604038
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00617447
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.016579
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00622668
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00617447
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00610743
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0153893
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00622668
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00610743
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00571077
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0155941
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00534739
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00534739
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484709
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115112
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0050043
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00484709
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488107
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116128
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00502447
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00488107
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00491032
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00491032
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00505978
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00505978
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_802 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00499405
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00499405
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468601
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114331
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484739
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468601
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047096
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110389
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482225
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047096
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477882
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112753
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484678
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477882
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461508
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481265
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461508
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473777
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479314
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473777
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469088
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112869
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482743
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469088
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00450743
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004553
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00450743
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463395
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112415
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477379
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463395
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468586
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048029
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468586
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473777
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473777
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488092
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00488092
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_952 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00495858
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00495858
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458971
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112302
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472376
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458971
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474736
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011129
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486659
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474736
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00486202
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112865
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00500382
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00486202
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453486
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112869
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00461508
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453486
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471889
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112302
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475694
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471889
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00493841
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453943
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471477
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453943
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465283
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011309
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477897
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465283
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470002
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113769
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482255
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470002
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460343
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00460343
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480274
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480274
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1102 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476419
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476419
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00446643
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110277
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464811
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00446643
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467642
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111177
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482255
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467642
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473821
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111515
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487619
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473821
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465755
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115116
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468114
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465755
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467642
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113094
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478872
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467642
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472848
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112753
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485653
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472848
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453057
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011398
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00462452
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453057
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457171
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011219
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474308
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457171
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462924
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470002
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462924
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467171
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467171
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480351
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480351
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1252 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00485196
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00485196
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00449371
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111293
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00459886
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00449371
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461508
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110389
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474721
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461508
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470002
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111177
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482255
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470002
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453943
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112527
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468586
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453943
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046953
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483261
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046953
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479787
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00450314
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0046198
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00450314
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00454857
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0046863
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00454857
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465755
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113544
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472804
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465755
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473335
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473335
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483246
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00483246
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1402 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480792
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480792
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453057
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111515
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00456714
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453057
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00537094
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0224862
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00889734
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00537094
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00862225
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0233012
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00936286
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00862225
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00662275
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0169204
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00608286
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00608286
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0558606
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0168229
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00632845
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00632845
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0050694
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110164
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00491551
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00491551
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467642
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112302
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474278
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467642
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472361
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047478
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472361
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469043
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011399
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468483
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00468483
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467082
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467082
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478263
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478263
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1552 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00497955
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00497955
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456271
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113192
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468055
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456271
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474249
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112415
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484617
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474249
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480244
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011264
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00503992
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480244
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453857
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112753
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00465195
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453857
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470415
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488015
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470415
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471919
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112074
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484252
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471919
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00446379
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115453
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469014
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00446379
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477364
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113312
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00489554
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477364
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469501
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115228
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483733
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469501
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00479817
[03/01/2023-10:41:25] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00479817
[03/01/2023-10:41:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:25] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:25] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00502038
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00502038
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1702 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00494266
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00494266
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461567
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474249
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461567
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477364
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112633
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00505411
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477364
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471757
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112415
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480335
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471757
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004553
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011309
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466684
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004553
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474219
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486187
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474219
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0048477
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112746
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487634
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0048477
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459929
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011399
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470975
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459929
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468453
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113997
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481722
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468453
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476922
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114328
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00490499
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476922
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00485653
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00485653
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00496394
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00496394
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_1852 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0049641
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0049641
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463897
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472804
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463897
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478293
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487055
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478293
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483642
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00493888
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00483642
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466654
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114553
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481387
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466654
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483733
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114328
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00491612
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00483733
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478431
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112865
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495858
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478431
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462407
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115903
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477379
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462407
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467613
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011444
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477912
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467613
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475665
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115116
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483246
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475665
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476892
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476892
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00491535
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00491535
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2002 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00552059
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00552059
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00772331
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0214426
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00751086
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00751086
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00766797
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0207726
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00809448
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00766797
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00775386
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0199131
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00759988
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00759988
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00729257
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.019968
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00743863
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00729257
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.008176
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231758
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00856229
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.008176
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0082814
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0228624
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00855422
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0082814
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0932453
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.022319
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0073872
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0073872
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00743794
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0198229
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00756066
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00743794
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00727017
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0162712
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00711271
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00711271
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00681426
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00681426
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0069871
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0069871
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2152 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0067493
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0067493
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00668821
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0228395
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00815213
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00668821
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00811099
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.022737
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00848403
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00811099
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00886239
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0253326
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0101818
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00886239
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00914372
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0259413
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00867415
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00867415
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00510939
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00526171
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00510939
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00510416
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114553
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00522922
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00510416
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00756764
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.021922
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00772259
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00756764
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00783013
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.024307
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00825702
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00783013
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00776132
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0219847
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00789149
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00776132
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0080546
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0080546
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00858783
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00858783
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2302 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0086919
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0086919
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00775916
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0226096
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.008128
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00775916
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00811073
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0220663
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00719703
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00719703
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00796419
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0212519
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00818464
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00796419
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00766123
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0216699
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0077837
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00766123
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00753107
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0145847
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00534163
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00534163
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00517159
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0122274
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00535331
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00517159
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00496252
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0124709
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00498412
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00496252
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480259
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113203
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0049056
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480259
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480838
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115678
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00490042
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480838
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478872
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478872
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00492832
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00492832
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600:32,3600,60,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Slice_2452 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00490956
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00490956
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(3600,3600:4,60,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(109 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472302
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116578
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00428585
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00428585
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600,60,1) -> Int8(3600,3600:32,60,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(109 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483718
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117479
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483276
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00483276
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(3600,3600,60,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(109 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00443789
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113649
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466109
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00443789
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:4,60,1) -> Int8(3600,3600:32,60,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(109 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00492847
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113533
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00431045
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00431045
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(3600,3600,60,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(109 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00446671
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471403
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00446671
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(3600,3600:32,60,1) -> Int8(3600,3600:4,60,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(109 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468041
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114113
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00632057
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468041
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(317 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00772211
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0181754
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0052031
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0052031
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(317 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00576494
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.016449
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.006188
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00576494
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(317 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00577024
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0204789
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00662296
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00577024
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(317 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00627915
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0174232
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00595448
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00595448
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(317 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00618133
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0176356
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0057355
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0057355
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(317 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00493777
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114437
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004522
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.004522
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:4,24,1) -> Int8(576,576:32,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,576:32,24,1) -> Int8(576,576:4,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(215296,3364,58,1) -> Int8(53824,3364:4,58,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(124 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476892
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110825
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00413335
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00413335
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(215296,3364,58,1) -> Int8(6728,3364:32,58,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(124 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00702846
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115348
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00704261
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00702846
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(53824,3364:4,58,1) -> Int8(215296,3364,58,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(124 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047645
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00508469
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047645
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(53824,3364:4,58,1) -> Int8(6728,3364:32,58,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(124 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00714674
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.012461
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480274
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00480274
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6728,3364:32,58,1) -> Int8(215296,3364,58,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(124 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00603429
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0128853
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00602153
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00602153
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6728,3364:32,58,1) -> Int8(53824,3364:4,58,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(124 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00513518
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.012739
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004768
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.004768
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(332 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00512506
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0853723
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00554778
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00512506
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(332 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00598514
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.016579
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00628412
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00598514
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(332 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00590446
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0160584
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00614876
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00590446
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(332 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00582126
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00452157
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00452157
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(332 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00481737
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116691
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00492847
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00481737
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(332 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00497844
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00450357
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00450357
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(30976,484,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(7744,484:4,22,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(968,484:32,22,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(137 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465283
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00438829
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00438829
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(137 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00676239
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00676177
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00676177
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(137 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00681274
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0123977
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495338
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00495338
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(137 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00521959
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0135913
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00496867
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00496867
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(345 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00528849
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.019456
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00736617
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00528849
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(345 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00829765
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.02349
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00844343
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00829765
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(345 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.008192
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0178646
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00611391
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00611391
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(345 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00655023
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0172292
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0064151
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0064151
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(25600,400,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,400:4,20,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(800,400:32,20,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(50176,784,28,1) -> Int8(12544,784:4,28,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(140 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00688348
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235729
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00768986
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00688348
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(50176,784,28,1) -> Int8(1568,784:32,28,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(140 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00701453
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0241371
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00824889
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00701453
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:4,28,1) -> Int8(50176,784,28,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(140 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0049149
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00499437
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0049149
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:4,28,1) -> Int8(1568,784:32,28,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(140 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00489128
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115348
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00463823
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00463823
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1568,784:32,28,1) -> Int8(50176,784,28,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(140 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0056095
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0234684
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00866635
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0056095
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1568,784:32,28,1) -> Int8(12544,784:4,28,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(140 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00809422
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231967
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00683363
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00683363
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(348 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.005024
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00453886
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00453886
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(348 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00492847
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116691
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00510988
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00492847
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(348 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472376
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117704
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483261
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472376
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(348 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0048128
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115221
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00451614
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00451614
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(348 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0056204
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0226952
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00774641
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0056204
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(348 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00764487
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0213786
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00715314
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00715314
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(1600,100:4,10,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(6400,100,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(200,100:32,10,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(86528,676,26,1) -> Int8(21632,676:4,26,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(155 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00972343
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.023343
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00757606
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00757606
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(86528,676,26,1) -> Int8(2704,676:32,26,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(155 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00807772
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235331
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00851899
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00807772
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(21632,676:4,26,1) -> Int8(2704,676:32,26,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(155 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00824965
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0229701
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00656312
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00656312
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2704,676:32,26,1) -> Int8(21632,676:4,26,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(155 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00487619
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115903
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00439744
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00439744
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(363 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00489966
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115791
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00441558
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00441558
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(363 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484236
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116916
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485212
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00484236
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(363 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0049152
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114785
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004467
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.004467
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(363 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473099
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00433482
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00433482
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(8192,64,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(2048,64:4,8,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(256,64:32,8,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(73728,576,24,1) -> Float(18432,1:4,768,32) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(167 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469486
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114989
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485196
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469486
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(18432,1:4,768,32) -> Float(73728,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(167 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467141
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482743
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467141
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(2304,576:32,24,1) -> Float(73728,576,24,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(167 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456229
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114662
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477867
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456229
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(2304,576:32,24,1) -> Float(18432,1:4,768,32) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(167 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112753
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481737
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(18432,144,12,1) -> Float(4608,1:4,384,32) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 168) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463425
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114775
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479909
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463425
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,384,32) -> Float(18432,144,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 168) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466271
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.012108
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479772
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466271
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(18432,144,12,1) -> Int8(18432,144,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_71 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00444689
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00465696
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00444689
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(18432,144,12,1) -> Int8(4608,144:4,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_71 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047565
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00455857
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00455857
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(18432,144,12,1) -> Int8(576,144:32,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_71 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473349
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488594
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473349
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,384,32) -> Int8(18432,144,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_71 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470017
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00489631
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470017
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,384,32) -> Int8(4608,144:4,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_71 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472273
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112527
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488594
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472273
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,384,32) -> Int8(576,144:32,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_71 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478949
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011309
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486187
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478949
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(375 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453543
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113322
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00465784
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453543
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(375 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456371
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011309
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464767
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456371
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(375 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00446116
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011354
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00461567
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00446116
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(375 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458457
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466271
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458457
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 376) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004498
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111965
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00463794
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004498
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 376) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458314
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112862
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464265
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458314
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 376) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00454029
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112865
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466153
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00454029
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 376) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459457
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480792
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459457
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 376) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479345
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 376) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471344
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115453
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480808
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471344
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 376) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00479756
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00494802
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00479756
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 376) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467672
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111167
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.005536
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467672
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(4608,36,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1:4,192,32) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(144,36:32,6,1) -> Float(1152,1:4,192,32) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461906
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00814451
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461906
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00784337
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0229022
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00801067
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00784337
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00760012
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.023074
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00794032
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00760012
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00540718
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0229055
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00791338
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00540718
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(18432,144,12,1) -> Int8(4608,144:4,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(182 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00798806
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0232594
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00740251
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00740251
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(18432,144,12,1) -> Int8(576,144:32,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(182 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00813435
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.023761
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00799543
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00799543
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(4608,144:4,12,1) -> Int8(18432,144,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(182 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00632765
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0175218
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00703499
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00632765
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(4608,144:4,12,1) -> Int8(576,144:32,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(182 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00691048
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0175218
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00651512
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00651512
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,144:32,12,1) -> Int8(18432,144,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(182 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00818489
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0239665
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00906057
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00818489
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(576,144:32,12,1) -> Int8(4608,144:4,12,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(182 -> <out>) (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00500918
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464826
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00464826
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_271_clone_1 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00493872
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117366
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00503961
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00493872
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_271_clone_1 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00497403
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118829
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495827
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00495827
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_271_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00487497
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011636
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466772
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00466772
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_271_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00486613
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119227
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00497797
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00486613
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_271_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466124
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117254
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477867
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466124
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_271_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00493856
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117816
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00515592
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00493856
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_268_377_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462393
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117366
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00462879
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462393
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_268_377_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459871
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117465
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470385
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459871
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_268_377_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465725
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117591
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485151
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465725
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_268_377_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466242
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119101
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495573
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466242
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_268_377_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464428
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117018
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478857
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00464428
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_268_377_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468055
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119832
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472686
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468055
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_268_377_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482179
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482179
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_268_377_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482758
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482758
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_420_clone_1 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047683
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116244
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00491947
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047683
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_420_clone_1 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476419
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487177
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476419
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_420_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477852
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116691
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00445008
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00445008
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_420_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473792
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118041
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0049149
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473792
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_420_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465283
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117141
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481768
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465283
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_420_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488061
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118938
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00506451
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00488061
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_417_526_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466286
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477364
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466286
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_417_526_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00479314
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117479
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00499831
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00479314
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_417_526_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477425
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119167
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486172
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477425
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_417_526_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047968
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118716
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00489539
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047968
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_417_526_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474736
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117141
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487543
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474736
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_417_526_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488137
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119832
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482575
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00482575
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_417_526_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00802235
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00802235
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_417_526_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00685344
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00685344
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_570_clone_1 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00684883
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.023136
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00804597
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00684883
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_570_clone_1 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00780752
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0233012
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00770983
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00770983
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_570_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00759246
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0219043
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00742377
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00742377
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_570_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00819987
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0243078
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00857089
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00819987
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_570_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00782195
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0242827
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00820851
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00782195
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: QuantizeLinear_570_clone_0 (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00843375
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0241608
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00889815
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00843375
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_567_676_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00794235
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0234893
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00822502
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00794235
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_567_676_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00812597
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0134051
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00503898
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00503898
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_567_676_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00492023
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119954
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00506435
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00492023
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_567_676_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00492114
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121051
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00506924
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00492114
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_567_676_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474293
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118829
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048768
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474293
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_567_676_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047242
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118607
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482225
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047242
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_567_676_clone_0 copy (Reformat)
[03/01/2023-10:41:26] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484206
[03/01/2023-10:41:26] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00484206
[03/01/2023-10:41:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:26] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:26] [V] [TRT] --------------- Timing Runner: Concat_567_676_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00486095
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00486095
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_720_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471418
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480351
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471418
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_720_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474898
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116241
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00489966
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474898
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_720_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047933
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116234
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00449186
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00449186
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_720_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484693
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115903
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482865
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00482865
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_720_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457986
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475768
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457986
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_720_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477775
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115119
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00500241
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477775
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_717_826_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470474
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117366
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484724
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470474
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_717_826_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046863
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116578
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482194
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046863
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_717_826_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466286
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474131
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466286
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_717_826_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463277
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117254
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471403
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463277
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_717_826_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457571
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116578
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464708
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457571
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_717_826_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00455343
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117816
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468896
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00455343
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_717_826_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472833
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472833
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_717_826_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467731
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467731
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_870_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463897
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115235
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00797181
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463897
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_870_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457171
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011027
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00462953
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457171
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_870_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00445174
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108774
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00434826
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00434826
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_870_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458571
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118488
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047388
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458571
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_870_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00445936
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115355
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469456
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00445936
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_870_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046863
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117254
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481676
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046863
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_867_976_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456043
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114553
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472302
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456043
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_867_976_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461375
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475163
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461375
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_867_976_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467082
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119832
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471786
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467082
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_867_976_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460771
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116691
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476892
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00460771
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_867_976_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453429
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00467156
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453429
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_867_976_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00451643
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117806
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0046428
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00451643
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_867_976_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047043
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047043
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_867_976_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468483
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468483
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1020_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004571
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114553
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469117
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004571
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1020_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461567
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473276
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461567
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1020_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469029
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115573
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00441004
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00441004
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1020_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476048
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00492863
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476048
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1020_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457514
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117141
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476389
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457514
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1020_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480747
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117827
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00491962
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480747
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1017_1126_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00449371
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470031
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00449371
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1017_1126_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462053
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117479
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471757
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462053
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1017_1126_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462466
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119581
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480183
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462466
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1017_1126_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470931
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118266
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484678
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470931
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1017_1126_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461935
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118379
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476389
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461935
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1017_1126_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471462
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119581
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00463366
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00463366
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1017_1126_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471919
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471919
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1017_1126_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469147
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469147
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1170_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453143
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011456
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470503
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453143
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1170_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477791
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118829
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00657122
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477791
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1170_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00623943
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0161077
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00600991
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00600991
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1170_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00806095
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0183011
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00821613
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00806095
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1170_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00803784
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0241859
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0081026
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00803784
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1170_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00830629
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.023843
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00877634
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00830629
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1167_1276_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00785347
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0243299
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00799746
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00785347
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1167_1276_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00768361
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0223399
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00791555
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00768361
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1167_1276_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00784409
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0216091
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00851146
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00784409
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1167_1276_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00819048
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.024403
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00844934
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00819048
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1167_1276_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00808584
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0239909
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00819302
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00808584
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1167_1276_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00802794
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0244053
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0082814
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00802794
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1167_1276_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00833829
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00833829
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1167_1276_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0055258
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0055258
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1320_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00494771
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116923
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00500445
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00494771
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1320_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00499862
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117591
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00589275
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00499862
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1320_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00734514
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0208973
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00691026
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00691026
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1320_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00743909
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0203337
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00779116
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00743909
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1320_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00781425
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0253806
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00828978
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00781425
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1320_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00820775
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0230922
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00825753
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00820775
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1317_1426_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00762971
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0218188
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00858622
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00762971
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1317_1426_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00811098
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0230073
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00793191
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00793191
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1317_1426_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00785131
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0225071
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00610819
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00610819
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1317_1426_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00814375
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0213786
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0075905
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0075905
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1317_1426_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00731497
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0209398
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0075609
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00731497
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1317_1426_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00605371
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0196389
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00798121
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00605371
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1317_1426_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00792325
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00792325
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1317_1426_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00802971
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00802971
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1470_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00766845
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0222335
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00843321
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00766845
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1470_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00824838
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0236565
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00836978
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00824838
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1470_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00806171
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0185411
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0062712
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0062712
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1470_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00641669
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0174085
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00685518
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00641669
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1470_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00651678
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0207112
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00745371
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00651678
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1470_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00754598
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0211696
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00783013
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00754598
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1467_1576_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00804673
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0218175
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0049589
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0049589
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1467_1576_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00490118
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116578
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00499941
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00490118
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1467_1576_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00490073
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117029
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00501864
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00490073
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1467_1576_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00518269
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0221956
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00810184
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00518269
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1467_1576_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00754623
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0221936
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00762947
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00754623
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1467_1576_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00775988
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0225469
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00799695
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00775988
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1467_1576_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00834641
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00834641
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1467_1576_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00848457
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00848457
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1620_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00752962
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0219011
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00776926
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00752962
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1620_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00767615
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0232993
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00833829
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00767615
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1620_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00806146
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235716
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0077991
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0077991
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1620_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00815898
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0250895
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00849291
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00815898
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1620_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00791459
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0236976
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00840578
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00791459
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1620_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00842326
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0244305
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0982674
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00842326
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1617_1726_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477394
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495354
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477394
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1617_1726_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484084
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011668
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0050292
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00484084
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1617_1726_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00489006
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119467
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00494345
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00489006
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1617_1726_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488594
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119101
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00492769
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00488594
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1617_1726_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464752
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117697
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477973
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00464752
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1617_1726_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047096
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118379
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481372
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047096
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1617_1726_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482834
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482834
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1617_1726_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00486598
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00486598
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1770_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047506
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115689
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488152
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047506
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1770_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480366
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117704
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487528
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480366
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1770_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475222
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115678
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00458886
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00458886
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1770_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474603
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118491
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00502968
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474603
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1770_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00445922
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115228
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00567719
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00445922
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1770_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00614857
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0151069
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00805384
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00614857
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1767_1876_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00711989
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0206054
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00724846
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00711989
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1767_1876_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00727794
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0207726
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00743908
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00727794
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1767_1876_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00763838
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0223197
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00776229
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00763838
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1767_1876_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.007512
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.022609
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00780632
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.007512
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1767_1876_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00512
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00492084
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00492084
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1767_1876_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476587
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117254
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00496363
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476587
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1767_1876_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00844182
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00844182
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1767_1876_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00754526
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00754526
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1920_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00666868
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0184137
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00698079
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00666868
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1920_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0067759
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0191269
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00694422
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0067759
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1920_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00751931
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235951
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00778394
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00751931
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1920_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00802184
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0238461
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00842407
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00802184
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1920_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00512523
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116135
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00491185
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00491185
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1920_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00491505
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116241
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00515641
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00491505
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1917_2026_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00807873
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0236774
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00829664
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00807873
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1917_2026_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00864861
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.024672
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0056044
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0056044
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1917_2026_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00495401
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0184491
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00707592
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00495401
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1917_2026_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00681078
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.018616
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0070498
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00681078
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1917_2026_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00784625
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.026672
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00828953
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00784625
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1917_2026_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00826464
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0245029
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00837994
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00826464
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1917_2026_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00818514
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00818514
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_1917_2026_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00814273
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00814273
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2070_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00906
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.025987
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0098307
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00906
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2070_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00917172
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0261387
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00858783
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00858783
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2070_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00807898
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0242834
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00774424
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00774424
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2070_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00821638
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0238202
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00844208
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00821638
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2070_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00799695
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0243078
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00580747
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00580747
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2070_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00830629
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0241371
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0087161
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00830629
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2067_2176_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00804571
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0249173
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00538599
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00538599
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2067_2176_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00495417
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.012032
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0051151
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00495417
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2067_2176_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00491459
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120206
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00504843
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00491459
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2067_2176_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00493241
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119345
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0253246
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00493241
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2067_2176_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474795
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117366
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478339
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474795
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2067_2176_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470474
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119054
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485669
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470474
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2067_2176_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00486187
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00486187
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2067_2176_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00493793
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00493793
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2220_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478903
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116466
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488183
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478903
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2220_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00479467
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116691
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048768
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00479467
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2220_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00479042
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120907
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00457129
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00457129
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2220_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482316
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117479
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0049786
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482316
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2220_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466669
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116916
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481722
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466669
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2220_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483246
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118829
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00503819
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00483246
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2217_2326_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475266
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114553
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466566
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00466566
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2217_2326_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459843
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117029
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473718
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459843
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2217_2326_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458971
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118266
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473718
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458971
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2217_2326_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469088
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117472
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484206
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469088
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2217_2326_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461965
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118491
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472317
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461965
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2217_2326_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466654
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119714
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477379
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466654
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2217_2326_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488488
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00488488
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2217_2326_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482225
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482225
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2370_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471934
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115678
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00489935
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471934
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2370_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471904
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117029
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00491459
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471904
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2370_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476892
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116241
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004526
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.004526
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2370_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472789
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117254
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495338
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472789
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2370_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00455743
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00462894
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00455743
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2370_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0181575
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117254
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483352
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00483352
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2367_2476_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00449286
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0046198
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00449286
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2367_2476_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458414
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116466
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483688
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458414
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2367_2476_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004603
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118266
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483078
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004603
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2367_2476_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471919
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118266
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482789
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471919
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2367_2476_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464767
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118154
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477912
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00464767
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2367_2476_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471875
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119592
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480762
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471875
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2367_2476_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484663
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00484663
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2367_2476_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00487162
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00487162
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2520_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476785
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115576
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485714
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476785
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2520_clone_1 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476358
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117029
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485638
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476358
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2520_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472863
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115457
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00447529
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00447529
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2520_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047419
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117588
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00498428
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047419
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2520_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462909
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117261
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480259
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462909
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Int8(9:32,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2520_clone_0 (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00492863
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118372
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00502447
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00492863
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2517_2626_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470415
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115344
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048221
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470415
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2517_2626_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482225
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118154
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486979
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482225
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2517_2626_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480274
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118041
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486111
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480274
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2517_2626_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482773
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119345
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487512
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482773
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2517_2626_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00479893
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117254
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484648
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00479893
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2517_2626_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469132
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119101
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482743
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469132
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2517_2626_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00487132
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00487132
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9:32,9,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Concat_2517_2626_clone_0 copy (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484785
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00484785
[03/01/2023-10:41:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,384,32) -> Float(18432,144,12,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(168 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475606
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121288
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478431
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475606
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(382 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482789
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0318456
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482789
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(382 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00487695
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115903
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00444689
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00444689
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:4,3,1) -> Int8(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(9,9:32,3,1) -> Int8(9,9:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(25600,100,10,1) -> Int8(6400,100:4,10,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(197 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470946
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115787
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00433925
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00433925
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(25600,100,10,1) -> Int8(800,100:32,10,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(197 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478811
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116353
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487147
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478811
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(6400,100:4,10,1) -> Int8(800,100:32,10,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(197 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480808
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114106
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00445132
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00445132
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Int8(800,100:32,10,1) -> Int8(6400,100:4,10,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(197 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477882
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114996
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00449014
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00449014
[03/01/2023-10:41:27] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004553
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113428
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469029
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004553
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477394
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011444
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048125
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477394
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473762
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117704
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484617
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473762
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00480747
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486004
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00480747
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462378
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011354
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048605
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462378
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00481768
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114665
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484267
[03/01/2023-10:41:27] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00481768
[03/01/2023-10:41:27] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476876
[03/01/2023-10:41:27] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112865
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485608
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476876
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478842
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048224
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478842
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475148
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113319
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485714
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475148
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046108
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472789
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046108
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483215
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114208
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482301
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00482301
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00493336
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485196
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00485196
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468159
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116916
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047478
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468159
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458957
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0046428
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458957
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047933
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011444
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486659
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047933
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047933
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113428
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488579
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047933
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472361
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0394728
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476358
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472361
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00444177
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00453514
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00444177
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046664
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111515
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476754
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046664
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(392 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464767
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114782
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048317
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00464767
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460386
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477852
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00460386
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463395
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115341
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477021
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463395
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466286
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480823
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466286
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471005
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478781
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471005
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472863
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480731
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472863
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468616
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480305
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468616
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00481737
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111965
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485196
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00481737
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475222
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116691
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483688
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475222
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478827
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00842434
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478827
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00805333
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.022737
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00824076
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00805333
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00771465
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0227997
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00804572
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00771465
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.007416
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0213995
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00766797
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.007416
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00754478
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.021295
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00812673
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00754478
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00785251
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0220904
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0065494
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0065494
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.007584
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231536
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00824127
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.007584
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(376 -> <out>) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00796394
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.020992
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00658867
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00658867
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00711271
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0201331
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00741668
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00711271
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00725577
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0205845
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00739451
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00725577
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00689067
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0181017
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00718994
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00689067
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00720411
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0176356
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00855261
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00720411
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00718903
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0206097
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00826464
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00718903
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00789149
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231967
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00738766
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00738766
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00486141
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111402
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495811
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00486141
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483688
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111515
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00492008
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00483688
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482728
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00489021
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482728
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476389
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484693
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476389
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00530929
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121173
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00501959
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00501959
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 394) (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00494329
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120198
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00500871
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00494329
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,1:4,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(9,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,1:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00450329
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0105433
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00423355
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00423355
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00444163
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0104594
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00455729
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00444163
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00445423
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011129
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471418
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00445423
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457529
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113428
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00467687
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457529
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004586
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111965
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047043
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004586
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461006
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111747
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470887
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461006
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458557
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114335
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470046
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458557
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046282
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112517
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472332
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046282
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452057
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00452057
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_315 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457629
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457629
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467701
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004516
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.004516
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475119
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487177
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475119
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458071
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111627
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466168
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458071
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462334
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112647
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468055
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462334
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462924
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112415
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482758
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462924
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00502353
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482271
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00482271
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473733
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112527
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486156
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473733
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00554075
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.021233
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0072784
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00554075
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00691026
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00691026
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_464 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00702846
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00702846
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00697361
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0196023
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00654275
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00654275
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00683428
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.017343
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00786045
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00683428
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00748983
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0211069
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00763838
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00748983
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00766075
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0214433
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00769925
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00766075
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469088
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111627
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484678
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469088
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472258
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112415
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482225
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472258
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474662
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011354
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482271
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474662
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471005
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011264
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00490073
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471005
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458114
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458114
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_614 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004681
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004681
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466138
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114328
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00453486
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00453486
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470887
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112415
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486141
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470887
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046664
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112647
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478354
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046664
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467716
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115341
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477349
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467716
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0528379
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478217
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00478217
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00449743
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109714
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00463882
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00449743
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004502
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00714469
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004502
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00786141
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0223399
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00805359
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00786141
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00762274
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00762274
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_764 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00762899
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00762899
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00788547
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0228415
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00755368
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00755368
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00779092
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0224444
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00827429
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00779092
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00789245
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0221531
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00754502
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00754502
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00761287
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0216503
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00798044
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00761287
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00755368
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0238655
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00968381
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00755368
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00955733
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0250392
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.010201
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00955733
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00876907
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0248686
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00575196
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00575196
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00793792
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0230713
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00766195
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00766195
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00604648
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00604648
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_914 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00601086
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00601086
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00611314
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0161077
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00582894
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00582894
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00756066
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0211487
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00800508
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00756066
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0075366
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0217966
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00770069
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0075366
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00776132
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0226952
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00827251
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00776132
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0079218
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0230504
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00825702
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0079218
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00806273
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0135381
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00493904
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00493904
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482164
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108983
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00504292
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482164
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00504922
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00505033
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00504922
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046723
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046723
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1064 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469501
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469501
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00703565
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0248686
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00702846
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00702846
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00768505
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0191634
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00815899
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00768505
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00730743
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0188526
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00625868
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00625868
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00668945
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0182674
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00701497
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00668945
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0066959
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0177493
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0069871
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0066959
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00775266
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235311
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0083873
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00775266
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.008176
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0229878
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00831365
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.008176
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00769179
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0214204
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00788427
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00769179
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0077606
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0077606
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1214 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00798883
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00798883
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00798045
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0234697
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00791483
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00791483
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00494392
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0158866
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00727817
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00494392
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00671044
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0158964
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0069157
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00671044
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00683341
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0161564
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00562655
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00562655
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476892
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111852
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485669
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476892
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476434
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011264
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00693812
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476434
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00554796
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00502889
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00502889
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0049056
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115787
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00703608
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0049056
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0065361
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0065361
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1364 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00641113
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00641113
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00647592
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0177981
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00522482
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00522482
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477425
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112644
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00500382
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477425
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476892
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487086
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476892
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00485669
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477425
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00477425
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468645
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112753
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484267
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468645
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469987
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115116
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00491017
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469987
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046577
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112302
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469073
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046577
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457129
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111065
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004704
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457129
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00444578
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00444578
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1514 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00451643
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00451643
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459871
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011321
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00440616
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00440616
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458486
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111852
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477867
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458486
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462304
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011309
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479284
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462304
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452629
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113533
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00462496
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00452629
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453914
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112531
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469471
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453914
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461523
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469117
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461523
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00455271
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112524
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474721
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00455271
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004512
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110614
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00463853
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004512
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00436641
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00436641
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1664 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00438358
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00438358
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453829
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108565
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00424175
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00424175
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00443733
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108049
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464324
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00443733
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00447086
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0107624
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0077837
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00447086
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00722652
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0200229
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00726377
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00722652
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00716937
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0198583
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00747543
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00716937
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0082334
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0241615
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00821663
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00821663
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00752866
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.093184
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00779164
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00752866
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00731429
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0179566
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00722743
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00722743
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00690264
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00690264
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1814 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00695837
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00695837
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00702803
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0180309
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00730697
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00702803
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00778346
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.021775
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00797232
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00778346
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00770695
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0214413
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00795332
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00770695
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00809499
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0232385
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0083388
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00809499
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00808584
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231131
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00830527
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00808584
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00841546
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0234684
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00849237
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00841546
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00794057
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0232803
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00503425
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00503425
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0049152
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112753
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0050095
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0049152
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00486111
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00486111
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1964 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482149
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482149
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00582912
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121661
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469029
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00469029
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00481189
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114208
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0049797
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00481189
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00511054
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0234488
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00772162
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00511054
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00751794
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0216085
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00767663
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00751794
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00724891
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0221727
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00832229
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00724891
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00818413
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0229878
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00879435
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00818413
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00797968
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0239909
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00792204
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00792204
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00770839
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0214413
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00782244
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00770839
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0076071
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0076071
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2114 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00744572
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00744572
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0080541
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0230498
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00764559
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00764559
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00796394
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231131
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00829714
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00796394
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00759122
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114328
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0049786
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0049786
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00488594
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00501312
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00488594
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00485699
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113537
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00502905
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00485699
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482392
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011264
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00493399
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482392
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00479269
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00492847
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00479269
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477364
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111852
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480305
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477364
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466212
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466212
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2264 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469456
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469456
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468527
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00460829
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00460829
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475222
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488122
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475222
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474691
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011174
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481859
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474691
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470916
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114335
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484663
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470916
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470459
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011174
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487604
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470459
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474706
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112753
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00491017
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474706
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470002
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111965
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479817
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470002
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478263
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110277
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00489996
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00478263
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462924
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462924
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2414 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469073
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469073
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:28] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469058
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113199
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00447529
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00447529
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477867
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482255
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477867
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466197
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114219
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476404
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466197
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473792
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112535
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483764
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473792
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471462
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113772
[03/01/2023-10:41:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0383707
[03/01/2023-10:41:28] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471462
[03/01/2023-10:41:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:28] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:28] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473335
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112527
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481707
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473335
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00454429
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110389
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0046956
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00454429
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004563
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470975
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004563
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453857
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453857
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2564 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461464
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461464
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_287 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00422575
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115787
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00448014
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00422575
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_287 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452057
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114666
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00443761
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00443761
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_287 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467259
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120808
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475193
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467259
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_287 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465268
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113428
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473674
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465268
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_287 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462481
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115228
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469102
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462481
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_287 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462024
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471418
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462024
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(423 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483231
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114328
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00443747
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00443747
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(423 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467185
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115116
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00446657
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00446657
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_436 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00428544
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.01168
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00452157
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00428544
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_436 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458943
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115791
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004503
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.004503
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_436 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462068
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116009
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483292
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462068
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_436 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00455786
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473762
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00455786
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_436 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00454457
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475163
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00454457
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_436 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461006
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474721
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461006
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_586 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00427603
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118041
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00454871
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00427603
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_586 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464369
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00446657
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00446657
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_586 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460814
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116578
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048765
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00460814
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_586 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462452
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112753
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470489
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462452
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_586 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457657
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116916
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470002
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457657
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_586 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458986
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114328
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475679
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458986
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_736 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00434452
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119167
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464811
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00434452
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_736 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460757
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115791
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00447043
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00447043
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_736 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466846
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116691
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480305
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466846
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_736 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458929
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113428
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477882
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458929
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_736 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456629
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116241
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471978
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456629
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_736 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458043
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114328
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473866
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458043
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_886 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00430669
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116916
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00451671
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00430669
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_886 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004575
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00443733
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00443733
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_886 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460371
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484236
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00460371
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_886 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458929
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115228
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473777
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458929
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_886 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004576
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470548
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004576
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_886 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046431
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115678
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474721
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046431
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1036 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00424605
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117929
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00452529
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00424605
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1036 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004598
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00447086
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00447086
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1036 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462437
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116578
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479802
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462437
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1036 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459343
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469073
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459343
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1036 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460271
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478751
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00460271
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1036 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456271
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115446
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473423
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456271
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1186 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00429405
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00539666
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00429405
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1186 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00756884
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0216085
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00706286
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00706286
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1186 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00740869
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0239421
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00815822
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00740869
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1186 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00730697
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0215876
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00769179
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00730697
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1186 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00729234
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0226952
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0076225
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00729234
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1186 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00733691
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0215876
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00773774
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00733691
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1336 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00701497
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0219847
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00825676
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00701497
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1336 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00781426
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.023343
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00764559
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00764559
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1336 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00785396
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0230504
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00770671
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00770671
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1336 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00702215
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116916
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00490453
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00490453
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1336 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484648
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116128
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00495385
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00484648
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1336 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482118
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117141
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00502432
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482118
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1486 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0043894
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.012032
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00459471
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0043894
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1486 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472347
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118041
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004476
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.004476
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1486 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467967
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484785
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467967
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1486 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456229
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115903
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475252
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456229
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1486 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462968
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469029
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462968
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1486 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459929
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117029
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474264
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459929
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1636 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00436765
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0122149
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00448014
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00436765
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1636 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00447443
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113417
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00429351
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00429351
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1636 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00446514
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113888
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00462968
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00446514
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1636 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00444509
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011444
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00458543
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00444509
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1636 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453443
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464841
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453443
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1636 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452186
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469943
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00452186
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1786 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0042205
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116691
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00439799
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0042205
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1786 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456229
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0044329
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0044329
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1786 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461065
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116364
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474795
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461065
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1786 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457186
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047276
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457186
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1786 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459443
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112418
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00457643
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00457643
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1786 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00446379
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116234
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004589
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00446379
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1936 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00418847
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116916
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004393
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00418847
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1936 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00451757
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011444
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00438843
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00438843
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1936 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458071
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116128
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479284
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458071
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1936 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452971
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113312
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476846
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00452971
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1936 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456157
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011309
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469987
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456157
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_1936 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464826
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472833
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00464826
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2086 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00436668
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115678
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00441891
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00436668
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2086 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459357
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116353
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00427267
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00427267
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2086 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459471
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120564
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00491672
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459471
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2086 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474234
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0122758
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484617
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474234
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2086 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478888
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119467
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469073
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00469073
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2086 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456243
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047744
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456243
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2236 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00431086
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117697
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00452143
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00431086
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2236 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462407
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00444204
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00444204
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2236 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0638773
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117479
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475606
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00475606
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2236 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463366
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011354
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470901
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463366
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2236 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00454886
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115228
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470017
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00454886
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2236 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457571
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115678
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475163
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457571
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2386 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00433967
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117366
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00454343
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00433967
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2386 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460992
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115116
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00449771
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00449771
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2386 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462894
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484724
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462894
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2386 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458943
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011399
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470946
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458943
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2386 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457086
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116353
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475738
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457086
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2386 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460357
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476876
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00460357
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2536 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00432753
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117479
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00453957
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00432753
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2536 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461257
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120808
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00447386
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00447386
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2536 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461314
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116466
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047744
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461314
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2536 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00454871
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112415
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471978
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00454871
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2536 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456186
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116012
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0046866
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456186
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2536 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004605
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113319
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047245
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004605
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(288,9:4,3,1) -> Int8(36,9:32,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(36,9:32,3,1) -> Int8(288,9:4,3,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16384,64,8,1) -> Float(4096,1:4,512,64) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(209 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004595
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476861
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004595
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(4096,1:4,512,64) -> Float(16384,64,8,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(209 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466242
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115453
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478339
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466242
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(512,64:32,8,1) -> Float(16384,64,8,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(209 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460343
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114666
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473792
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00460343
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(512,64:32,8,1) -> Float(4096,1:4,512,64) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(209 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467657
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113885
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004768
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467657
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) long-strided -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461449
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478354
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461449
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) long-strided -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459857
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115228
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472833
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459857
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) long-strided -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456271
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478324
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456271
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) long-strided -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465755
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474736
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465755
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) long-strided -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463454
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479314
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463454
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) long-strided -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046661
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478431
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046661
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) long-strided -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470901
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481813
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470901
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) long-strided -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047329
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481204
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047329
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(4096,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00424161
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116459
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00542358
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00424161
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(4096,16,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461021
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116128
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481813
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461021
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(4096,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461464
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113653
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468557
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461464
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(4096,16,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461006
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473305
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461006
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(4096,16,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468041
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011321
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474293
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468041
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1024,1:4,256,64) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469029
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477349
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469029
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1024,1:4,256,64) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466271
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115791
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475104
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466271
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1024,1:4,256,64) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472243
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048032
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472243
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1024,1:4,256,64) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467141
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484663
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467141
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1024,1:4,256,64) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 210) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474337
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112865
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482712
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474337
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(2048,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: 179 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00420101
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00550259
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00420101
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(2048,16,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: 179 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461508
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011354
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473644
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461508
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(2048,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: 179 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459143
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115443
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476998
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459143
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(2048,16,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: 179 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464737
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476937
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00464737
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(2048,16,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: 179 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466758
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011309
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0463543
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466758
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(398 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466787
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117152
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00423341
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00423341
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(398 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00447557
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117254
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464826
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00447557
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(398 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00447071
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116026
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00465725
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00447071
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(398 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00454743
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011636
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004384
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.004384
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(398 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004608
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0263314
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00811225
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004608
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(398 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00788379
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0240411
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00734994
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00734994
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(128,1,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(32,1:4,1,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(128,1,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(4,1:32,1,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00502274
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0122267
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00516261
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00502274
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0050095
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0123124
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00494834
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00494834
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474175
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115235
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483154
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474175
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474736
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011264
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481798
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474736
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Int8(16,16:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_106_clone_1 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474382
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004896
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474382
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Int8(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_106_clone_1 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00487116
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011884
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488594
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00487116
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Int8(16,16:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_106_clone_0 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482255
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117714
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00453071
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00453071
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Int8(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_106_clone_0 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474632
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120629
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00499831
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474632
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Int8(16,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_106_clone_0 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00450329
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011971
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00463395
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00450329
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Int8(16:32,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: QuantizeLinear_106_clone_0 (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00490118
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120517
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00496347
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00490118
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16,16:4,4,1) -> Int8(16,16:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Concat_103_212_clone_0 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453871
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115791
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470002
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453871
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16,16:4,4,1) -> Int8(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Concat_103_212_clone_0 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462009
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117704
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476419
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462009
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16,16:32,4,1) -> Int8(16,16:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Concat_103_212_clone_0 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466168
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120808
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486095
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466168
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16,16:32,4,1) -> Int8(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Concat_103_212_clone_0 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472302
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119467
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486187
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472302
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16,16,4,1) -> Int8(16,16:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Concat_103_212_clone_0 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473349
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118502
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486202
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473349
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16,16,4,1) -> Int8(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Concat_103_212_clone_0 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458014
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121059
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477379
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458014
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16:32,16,4,1) -> Int8(16,16:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Concat_103_212_clone_0 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471388
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471388
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16:32,16,4,1) -> Int8(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Concat_103_212_clone_0 copy (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469515
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469515
[03/01/2023-10:41:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(412 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004544
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118716
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00425963
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00425963
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(412 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117373
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488107
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473305
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(412 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472863
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119467
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00445991
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00445991
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(412 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466728
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117261
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00439328
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00439328
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(8,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(2,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16,16:4,4,1) -> Int8(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(217 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00805359
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0219429
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00679626
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00679626
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Int8(16,16:32,4,1) -> Int8(16,16:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(217 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00749714
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0216934
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00680249
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00680249
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Float(16,1,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0071888
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0229251
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00770767
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0071888
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Float(16,1:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00785444
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0235311
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00822502
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00785444
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Float(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00795606
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0236147
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00806171
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00795606
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00765257
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0220911
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00772235
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00765257
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,1,4,1) -> Float(16,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00702215
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0213995
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00752337
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00702215
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,1,4,1) -> Float(16,1:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00816787
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0241615
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00833092
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00816787
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,1,4,1) -> Float(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00832178
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0240744
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00887207
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00832178
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,1,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00699276
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0239192
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00827276
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00699276
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,4,1) -> Float(16,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00801194
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231948
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00837029
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00801194
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,4,1) -> Float(16,1,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00782195
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0222563
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0049838
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0049838
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,4,1) -> Float(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00513061
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118041
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00510857
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00510857
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00499862
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0415573
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00505963
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00499862
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16:32,4,1) -> Float(16,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00485059
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119467
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00494392
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00485059
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16:32,4,1) -> Float(16,1,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465784
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114553
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00465386
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00465386
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16:32,4,1) -> Float(16,1:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00484587
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00497403
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00484587
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(16,16:32,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482728
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487238
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482728
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(16,16,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475237
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114553
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00490545
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475237
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(16,1,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461582
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115678
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476876
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461582
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(16,1:4,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00487101
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112865
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00497356
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00487101
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(16,16:32,4,1) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(227 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00485242
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011444
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487665
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00485242
[03/01/2023-10:41:29] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469043
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113755
[03/01/2023-10:41:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485212
[03/01/2023-10:41:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469043
[03/01/2023-10:41:29] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047276
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114001
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481737
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047276
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469545
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115341
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484267
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469545
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470444
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011444
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484632
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470444
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476122
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116237
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488046
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476122
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477973
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488137
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477973
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00482331
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011264
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486141
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00482331
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473851
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00486674
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473851
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00502731
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00489036
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00489036
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477897
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113203
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485181
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477897
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466699
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477394
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466699
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00479756
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011309
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487589
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00479756
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473748
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113428
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483794
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473748
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474308
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112981
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485638
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474308
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474618
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484313
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474618
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(211 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471329
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488076
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471329
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467274
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113428
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483688
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467274
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047183
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481783
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047183
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470503
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485273
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470503
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472347
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114662
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483322
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472347
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475193
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011399
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487558
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475193
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00479726
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048573
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00479726
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475222
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485196
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475222
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00477852
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00488549
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00477852
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475193
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113649
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484175
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475193
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00472391
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481768
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00472391
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00481707
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115787
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047933
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0047933
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468129
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.010846
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480213
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468129
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004594
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109939
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469471
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004594
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00449729
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109192
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464369
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00449729
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00451629
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108565
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00459357
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00451629
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00443747
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108774
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00459857
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00443747
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00441032
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109819
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00458014
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00441032
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453929
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111852
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466728
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453929
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0235953
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109505
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00458914
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00458914
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 229) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00437527
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108878
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004507
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00437527
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00440575
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110284
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004476
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00440575
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0044142
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111852
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00446543
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0044142
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00438095
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011219
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00450286
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00438095
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00441531
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109407
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00454857
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00441531
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00441046
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109704
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00458014
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00441046
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00443747
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113308
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00448471
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00443747
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00434826
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110952
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00442417
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00434826
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0043973
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110277
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00449886
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0043973
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00442417
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0146871
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0063356
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00442417
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0057004
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0166278
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00579877
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0057004
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0057995
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.016254
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00519837
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00519837
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465121
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115675
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479802
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465121
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00455314
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116241
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479391
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00455314
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459543
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114887
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471934
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459543
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00475694
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480838
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00475694
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464855
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483794
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00464855
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468041
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011399
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477425
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468041
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467657
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116125
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047648
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467657
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004681
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116916
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481265
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004681
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(422 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00454757
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116241
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468114
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00454757
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464413
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113203
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481798
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00464413
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463956
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472391
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463956
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462924
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475709
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462924
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468114
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113649
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00485105
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468114
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471816
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011354
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468645
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00468645
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00450829
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115112
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464383
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00450829
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00450657
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115341
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00462009
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00450657
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00476122
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111177
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481692
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00476122
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462983
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479269
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462983
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00464693
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116016
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471491
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00464693
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467215
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112077
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00463425
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00463425
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00461552
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110491
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047186
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00461552
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00448371
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112302
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00458957
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00448371
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00448957
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011399
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00462452
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00448957
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462039
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114666
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477364
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00462039
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468129
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112524
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476196
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468129
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00460929
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00479817
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00460929
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046956
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112415
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477882
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046956
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00470459
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0048128
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00470459
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463838
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112753
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472494
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463838
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0042201
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115116
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00531488
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0042201
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00445617
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0150235
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00563692
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00445617
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0054444
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0152722
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00564308
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0054444
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00547217
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0168879
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00636005
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00547217
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0077837
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0213577
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0075763
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0075763
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00740183
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0221309
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00762875
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00740183
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00754406
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0219429
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00720549
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00720549
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00741623
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0202971
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00745326
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00741623
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00786117
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0231125
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00829054
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00786117
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00806197
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0233443
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00814425
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00806197
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00824076
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0241128
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00927029
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00824076
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00668862
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.015403
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00599219
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00599219
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00577518
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0153454
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00594524
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00577518
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00570585
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0134849
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00489509
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00489509
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00489539
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0049537
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00489539
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 453) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00483779
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114778
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00568299
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00483779
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(128,1,128,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) long-strided -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) long-strided -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1152,1,384,128) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(288,1:4,96,32) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(36,9:32,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,1,6144,2048) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(576,9:32,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Int8(1536,16:4,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00436613
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0105639
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00422911
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00422911
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Int8(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00441392
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112309
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00466168
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00441392
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Int8(1536,16:4,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463381
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0107311
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00456657
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00456657
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Int8(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00445978
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108565
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00460057
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00445978
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Int8(1536,16:4,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457643
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.010752
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00467657
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457643
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Int8(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463838
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110164
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470872
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463838
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Int8(1536,16:4,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458514
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0107938
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00460786
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458514
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Int8(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00447557
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108575
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00467023
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00447557
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Int8(1536,16:4,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00439273
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00439273
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Int8(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_150 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00444661
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00444661
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Int8(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_122 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00405143
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110277
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0042685
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00405143
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_122 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00432457
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110491
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00425102
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00425102
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_122 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00439231
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110833
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00454414
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00439231
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Int8(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_122 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00433482
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0107935
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00446614
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00433482
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_122 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00429822
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109398
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00441891
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00429822
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_122 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00436668
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011084
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00444994
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00436668
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(1536,16:4,4,1) -> Int8(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(258 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463381
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011219
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00431556
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00431556
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(192,16:32,4,1) -> Int8(1536,16:4,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(258 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456786
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011219
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00429741
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00429741
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(384,1,1,1) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(233 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00448471
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00419239
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00419239
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(384,1,1,1) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(233 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004599
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116353
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478812
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004599
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(96,1:4,1,1) -> Int8(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(233 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452957
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115446
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477288
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00452957
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(96,1:4,1,1) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(233 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00462924
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116241
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00447943
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00447943
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(12,1:32,1,1) -> Int8(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(233 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467185
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116804
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480762
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467185
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(12,1:32,1,1) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(233 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00567704
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116459
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0044559
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0044559
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(384,1,1,1) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(384,1,1,1) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(96,1:4,1,1) -> Int8(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(96,1:4,1,1) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(12,1:32,1,1) -> Int8(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(12,1:32,1,1) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(24,1,1,1) -> Int8(6,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(247 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00447957
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0042127
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0042127
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(24,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(247 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004517
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471447
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004517
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(6,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(247 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463042
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117141
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00437971
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00437971
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(6,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(247 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00455771
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115351
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00444564
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00444564
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(24,1,1,1) -> Int8(6,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(24,1,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(6,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(1,1:32,1,1) -> Int8(6,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452971
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113755
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473762
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00452971
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458529
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115355
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473305
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458529
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457129
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115453
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047329
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457129
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00473335
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483307
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00473335
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469014
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112865
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482331
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00469014
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465372
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117032
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476343
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465372
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458314
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113871
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00468041
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458314
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00467141
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484175
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00467141
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Float(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465298
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112978
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476998
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465298
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Float(384,1,384,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046344
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116684
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0046956
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046344
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00458086
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011399
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472922
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00458086
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465224
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115791
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476952
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465224
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456771
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117141
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00480808
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456771
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00456571
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114215
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00467569
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00456571
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466743
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114556
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478796
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466743
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465209
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114792
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474293
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465209
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00468159
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00477364
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00468159
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(384,1,384,384) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00465298
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115453
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471034
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00465298
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466787
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116466
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00478873
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00466787
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(257 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452086
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115116
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00469633
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00452086
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Float(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Float(384,1,384,384) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(1:4,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(384,1,384,384) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1,1,1) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(6144,1,1536,384) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1536,1:4,384,96) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(192,16:32,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,16,4,1) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_183 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459886
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115221
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00444648
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00444648
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(384,1,1,1) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_183 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.004585
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115791
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00484236
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.004585
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_183 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457986
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115228
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00471948
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457986
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(96,1:4,96,96) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_183 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046195
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115453
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00473187
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0046195
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(96,1:4,1,1) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(12,1:32,1,1) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2703 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00457614
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011354
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00472907
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00457614
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2703 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463853
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113878
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00483215
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463853
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(18432,1,6144,2048) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2703 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00455343
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011354
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00464339
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00455343
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(4608,1:4,1536,512) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2703 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00451114
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111402
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00460743
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00451114
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2703 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00446421
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111177
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00456686
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00446421
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(576,9:32,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2703 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00453486
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00475296
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00453486
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(18432,9,3,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2703 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459786
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112302
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00576158
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00459786
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1:4,9,3,1) -> Float(4608,1:4,1536,512) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2703 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00768457
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0211487
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00759074
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00759074
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 203) [ElementWise]_out_tensor -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00728434
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0216934
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00752938
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00728434
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(2048,1,1,1) -> Int8(512,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2598 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00466227
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113315
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004539
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.004539
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(2048,1,1,1) -> Int8(64,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2598 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00474839
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113765
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00496331
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00474839
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(512,1:4,512,512) -> Int8(512,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2598 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0047744
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00482194
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0047744
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(512,1:4,512,512) -> Int8(64,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2598 (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00463882
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115566
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00481813
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00463882
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(512,1:4,1,1) -> Int8(64,1:32,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2706 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0046807
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118379
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0044649
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0044649
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Int8(64,1:32,1,1) -> Int8(512,1:4,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2706 -> <out>) (Reformat)
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471403
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118716
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00448857
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00448857
[03/01/2023-10:41:30] [V] [TRT] =============== Computing reformatting costs: 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,1,1) ***************
[03/01/2023-10:41:30] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning format combination: Int8(3600,3600,60,1) -> Int8(215296,3364,58,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CaskFlattenConvolution)
[03/01/2023-10:41:30] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CaskConvolution)
[03/01/2023-10:41:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning format combination: Int8(3600,3600:4,60,1) -> Int8(53824,3364:4,58,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CudaDepthwiseConvolution)
[03/01/2023-10:41:30] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (FusedConvActConvolution)
[03/01/2023-10:41:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CaskFlattenConvolution)
[03/01/2023-10:41:30] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CaskConvolution)
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.00590373
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.00643001
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.00759916
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.00752216
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.00632845
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.00752192
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.00622668
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.00582821
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.00821638
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.00786815
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.00711924
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0072704
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.00789149
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.00722651
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0xd1d72dad018b082d Time: 0.00582821
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xd1d72dad018b082d
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning format combination: Int8(3600,3600:4,60,1) -> Int8(6728,3364:32,58,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CaskFlattenConvolution)
[03/01/2023-10:41:30] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CaskConvolution)
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.00586368
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0062716
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.00744571
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.00580023
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.00622032
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0062392
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.00740937
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.00724114
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.00605867
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.00602819
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.00602172
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.00738743
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.00611352
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.00566576
[03/01/2023-10:41:30] [V] [TRT] Fastest Tactic: 0x9fc2bcaa51428a78 Time: 0.00566576
[03/01/2023-10:41:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:30] [V] [TRT] *************** Autotuning format combination: Int8(3600,3600:32,60,1) -> Int8(6728,3364:32,58,1) ***************
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CudaGroupConvolution)
[03/01/2023-10:41:30] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CudaDepthwiseConvolution)
[03/01/2023-10:41:30] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (FusedConvActConvolution)
[03/01/2023-10:41:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CaskFlattenConvolution)
[03/01/2023-10:41:30] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:30] [V] [TRT] --------------- Timing Runner: conv1.0.weight + QuantizeLinear_8 + Conv_12 (CaskConvolution)
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[03/01/2023-10:41:30] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.0066294
[03/01/2023-10:41:30] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.00658286
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.00805384
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.00630936
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.00632845
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.007776
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.00563182
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.00644929
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.00708463
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.00560387
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00643657
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.00556448
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.00589824
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00734354
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.00749668
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0107311
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.00897829
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.00917057
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00800508
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00765305
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.00765353
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00764535
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.00905143
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.006016
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.00648785
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00643657
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.00618667
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0066294
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.00881156
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.00530963
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.00732891
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00783013
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.00912457
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0110164
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.00527151
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00642385
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.00892343
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00644929
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.00753732
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.00733006
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.00758376
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00777648
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00752216
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.00752216
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.00610743
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0105744
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00526106
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0107938
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0144238
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00618057
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0134583
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.00905172
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.00632189
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00533672
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.00880323
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.00525061
[03/01/2023-10:41:31] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.00917943
[03/01/2023-10:41:31] [V] [TRT] Fastest Tactic: 0xbb88763c3b0e94d4 Time: 0.00525061
[03/01/2023-10:41:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xbb88763c3b0e94d4
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CudaDepthwiseConvolution)
[03/01/2023-10:41:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (FusedConvActConvolution)
[03/01/2023-10:41:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.00577536
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.00641113
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.00753756
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.00742468
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.00626465
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.00748251
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.00607067
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.00932571
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.00833854
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.00776926
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.00713317
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.00720412
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.155063
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0066161
[03/01/2023-10:41:31] [V] [TRT] Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.00577536
[03/01/2023-10:41:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.00574025
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.00625868
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.00738011
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.00562637
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.00611352
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.00607695
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.00734354
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.00709834
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.00588654
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.00589788
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.00579877
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.00730788
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.00592165
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.00560387
[03/01/2023-10:41:31] [V] [TRT] Fastest Tactic: 0x9fc2bcaa51428a78 Time: 0.00560387
[03/01/2023-10:41:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CudaGroupConvolution)
[03/01/2023-10:41:31] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CudaDepthwiseConvolution)
[03/01/2023-10:41:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (FusedConvActConvolution)
[03/01/2023-10:41:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.00603429
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.00621396
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.00793981
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.00546675
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.00608914
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.00765305
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.00550451
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.00719703
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.00735749
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.00743131
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00698014
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.00762153
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.00789943
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00790616
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.00760686
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0106067
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0087083
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.00526678
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00496867
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00479787
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.006144
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00501439
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.00886319
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.0072416
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.00705655
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00703565
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.00735817
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.00758376
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.00872551
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.00760662
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.00755296
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00783783
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.00897886
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.010846
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.00635369
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00645525
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.00877714
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00737988
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.00778394
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.00772259
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.00778394
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00785371
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00529338
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.00623304
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.00570532
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0117605
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00931629
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0107833
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0142163
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00940857
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0130593
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.00889761
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.00607733
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00562637
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.00863946
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.00743131
[03/01/2023-10:41:31] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.00912457
[03/01/2023-10:41:31] [V] [TRT] Fastest Tactic: 0xee2fce9480a52be7 Time: 0.00479787
[03/01/2023-10:41:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xee2fce9480a52be7
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_1 + QuantizeLinear_361 + Conv_365 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_1 + QuantizeLinear_361 + Conv_365 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_2 + QuantizeLinear_511 + Conv_515 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_2 + QuantizeLinear_511 + Conv_515 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_3 + QuantizeLinear_661 + Conv_665 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_3 + QuantizeLinear_661 + Conv_665 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_4 + QuantizeLinear_811 + Conv_815 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_4 + QuantizeLinear_811 + Conv_815 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_5 + QuantizeLinear_961 + Conv_965 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_5 + QuantizeLinear_961 + Conv_965 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_6 + QuantizeLinear_1111 + Conv_1115 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_6 + QuantizeLinear_1111 + Conv_1115 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_7 + QuantizeLinear_1261 + Conv_1265 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_7 + QuantizeLinear_1261 + Conv_1265 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_8 + QuantizeLinear_1411 + Conv_1415 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_8 + QuantizeLinear_1411 + Conv_1415 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_9 + QuantizeLinear_1561 + Conv_1565 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_9 + QuantizeLinear_1561 + Conv_1565 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_10 + QuantizeLinear_1711 + Conv_1715 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_10 + QuantizeLinear_1711 + Conv_1715 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_11 + QuantizeLinear_1861 + Conv_1865 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_11 + QuantizeLinear_1861 + Conv_1865 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_12 + QuantizeLinear_2011 + Conv_2015 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_12 + QuantizeLinear_2011 + Conv_2015 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_13 + QuantizeLinear_2161 + Conv_2165 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_13 + QuantizeLinear_2161 + Conv_2165 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_14 + QuantizeLinear_2311 + Conv_2315 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_14 + QuantizeLinear_2311 + Conv_2315 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576,24,1) -> Int8(30976,484,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_15 + QuantizeLinear_2461 + Conv_2465 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.0.weight_clone_15 + QuantizeLinear_2461 + Conv_2465 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(7744,484:4,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:4,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(576,576:32,24,1) -> Int8(968,484:32,22,1) ***************
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(215296,3364,58,1) -> Int8(200704,3136,56,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(53824,3364:4,58,1) -> Int8(50176,3136:4,56,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CudaDepthwiseConvolution)
[03/01/2023-10:41:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (FusedConvActConvolution)
[03/01/2023-10:41:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0193097
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0172455
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0247954
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0245295
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0163677
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.024259
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0162702
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.0187246
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.015243
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.0156965
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0157257
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0201691
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.0239909
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0168061
[03/01/2023-10:41:31] [V] [TRT] Fastest Tactic: 0x8a10449e6d8c189c Time: 0.015243
[03/01/2023-10:41:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(53824,3364:4,58,1) -> Int8(6272,3136:32,56,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0200046
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0170992
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0246004
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0191086
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0162865
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0167416
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0241371
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.0239421
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.0154039
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0156379
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.0151858
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0244297
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0161564
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.0186149
[03/01/2023-10:41:31] [V] [TRT] Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0151858
[03/01/2023-10:41:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(6728,3364:32,58,1) -> Int8(6272,3136:32,56,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CudaGroupConvolution)
[03/01/2023-10:41:31] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CudaDepthwiseConvolution)
[03/01/2023-10:41:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (FusedConvActConvolution)
[03/01/2023-10:41:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv1.3.weight + QuantizeLinear_23 + Conv_27 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.00813562
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0080701
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0103755
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.00728503
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.00782244
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.00982065
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.00668239
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.00794006
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.00911543
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.00657621
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00795708
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.00625252
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.00688936
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00933486
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.00676966
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0149065
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.011971
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.00611962
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00693116
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00691069
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.00781474
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00683363
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0121173
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.00662296
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0073728
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00794032
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.00775242
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.00814324
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0119345
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.0058518
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.00950857
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00688348
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0121909
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0151259
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.0057227
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00683363
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0120438
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00795657
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.00988891
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.00939886
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.00666265
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00721189
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00600438
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.00828953
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.00678878
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.014731
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00605219
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0148475
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0229251
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00687543
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0205427
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0121783
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.00814324
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00759146
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0119223
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.007512
[03/01/2023-10:41:31] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0123368
[03/01/2023-10:41:31] [V] [TRT] Fastest Tactic: 0x2f34f689bfca5071 Time: 0.0057227
[03/01/2023-10:41:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x2f34f689bfca5071
[03/01/2023-10:41:31] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CudaDepthwiseConvolution)
[03/01/2023-10:41:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (FusedConvActConvolution)
[03/01/2023-10:41:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0190354
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0173592
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0247467
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0244785
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0164003
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0242347
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0162702
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.0185783
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.0152878
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.0155502
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0156818
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0198949
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.0239909
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0169869
[03/01/2023-10:41:31] [V] [TRT] Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0152878
[03/01/2023-10:41:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0197669
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0172292
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.024576
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0188891
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0162377
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0167741
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0241128
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.023869
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.0153902
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0155209
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.0150811
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.024259
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0161737
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.0184869
[03/01/2023-10:41:31] [V] [TRT] Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0150811
[03/01/2023-10:41:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:31] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CudaGroupConvolution)
[03/01/2023-10:41:31] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CudaDepthwiseConvolution)
[03/01/2023-10:41:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (FusedConvActConvolution)
[03/01/2023-10:41:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CaskFlattenConvolution)
[03/01/2023-10:41:31] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:31] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 (CaskConvolution)
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.00761456
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.00776854
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0103654
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.00597962
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.00762947
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.00975238
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.00625173
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.00761456
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.00904229
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.00655626
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00792253
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.00613181
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.0066826
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00930743
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.00562637
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0147749
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0118491
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.00590409
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00580462
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:41:31] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00862252
[03/01/2023-10:41:31] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.00776854
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00711924
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0119954
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.00719017
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0071754
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00790713
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.00769107
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.00809473
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0118724
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.00764487
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.00946286
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0078145
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0121307
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0150528
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.00759868
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00637297
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0119589
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00784553
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.00970362
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.00939886
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.00784553
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00779934
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00744663
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.00798883
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.00797257
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0146286
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.007584
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0148626
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0226325
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00762177
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0195657
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0120686
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.00781474
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00703565
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0117809
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.0068406
[03/01/2023-10:41:32] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.012288
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x671c943720ba8655 Time: 0.00562637
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x671c943720ba8655
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_1 + QuantizeLinear_376 + Conv_380 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_1 + QuantizeLinear_376 + Conv_380 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_2 + QuantizeLinear_526 + Conv_530 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_2 + QuantizeLinear_526 + Conv_530 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_3 + QuantizeLinear_676 + Conv_680 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_3 + QuantizeLinear_676 + Conv_680 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_4 + QuantizeLinear_826 + Conv_830 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_4 + QuantizeLinear_826 + Conv_830 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_5 + QuantizeLinear_976 + Conv_980 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_5 + QuantizeLinear_976 + Conv_980 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_6 + QuantizeLinear_1126 + Conv_1130 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_6 + QuantizeLinear_1126 + Conv_1130 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_7 + QuantizeLinear_1276 + Conv_1280 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_7 + QuantizeLinear_1276 + Conv_1280 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_8 + QuantizeLinear_1426 + Conv_1430 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_8 + QuantizeLinear_1426 + Conv_1430 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_9 + QuantizeLinear_1576 + Conv_1580 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_9 + QuantizeLinear_1576 + Conv_1580 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_10 + QuantizeLinear_1726 + Conv_1730 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_10 + QuantizeLinear_1726 + Conv_1730 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_11 + QuantizeLinear_1876 + Conv_1880 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_11 + QuantizeLinear_1876 + Conv_1880 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_12 + QuantizeLinear_2026 + Conv_2030 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_12 + QuantizeLinear_2026 + Conv_2030 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_13 + QuantizeLinear_2176 + Conv_2180 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_13 + QuantizeLinear_2176 + Conv_2180 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_14 + QuantizeLinear_2326 + Conv_2330 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_14 + QuantizeLinear_2326 + Conv_2330 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(30976,484,22,1) -> Int8(25600,400,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_15 + QuantizeLinear_2476 + Conv_2480 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv4.3.weight_clone_15 + QuantizeLinear_2476 + Conv_2480 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(6400,400:4,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(7744,484:4,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(968,484:32,22,1) -> Int8(800,400:32,20,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(12544,784:4,28,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_30 (TiledPooling)
[03/01/2023-10:41:32] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_30 (CudaPooling)
[03/01/2023-10:41:32] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_30 (CaskPooling)
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x1f6c40e3e09ec730 Time: 0.00280524
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll5_tThreads256 Tactic: 0x185e4d2f4b6d969e
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x185e4d2f4b6d969e Time: 0.00354297
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll8_tThreads128 Tactic: 0xa492ee81d8eb5052
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xa492ee81d8eb5052 Time: 0.00415425
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0xec7cf487c5e61cec
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xec7cf487c5e61cec Time: 0.00373216
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll7_tThreads256 Tactic: 0x31d506f925656f41
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x31d506f925656f41 Time: 0.00402692
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll2_tThreads256 Tactic: 0xbf6a632b19f7ef52
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xbf6a632b19f7ef52 Time: 0.00309408
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll8_tThreads256 Tactic: 0x30cc07a4cfdcf1f1
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x30cc07a4cfdcf1f1 Time: 0.00426286
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll1_tThreads128 Tactic: 0xdf1633a6804bc483
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xdf1633a6804bc483 Time: 0.00308756
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll7_tThreads128 Tactic: 0xa58befdc3252cee2
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xa58befdc3252cee2 Time: 0.00399733
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll2_tThreads128 Tactic: 0x2b348a0e0ec04ef1
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2b348a0e0ec04ef1 Time: 0.00314922
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll6_tThreads128 Tactic: 0x78221da2d2d1bd4f
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x78221da2d2d1bd4f Time: 0.0036875
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll1_tThreads256 Tactic: 0x4b48da83977c6520
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4b48da83977c6520 Time: 0.00308182
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll4_tThreads128 Tactic: 0x51a95674bcd94490
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x51a95674bcd94490 Time: 0.00324104
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll5_tThreads128 Tactic: 0x8c00a40a5c5a373d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8c00a40a5c5a373d Time: 0.00361054
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll4_tThreads256 Tactic: 0xc5f7bf51abeee533
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xc5f7bf51abeee533 Time: 0.00513845
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll3_tThreads128 Tactic: 0xf69d7870ee433d5c
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf69d7870ee433d5c Time: 0.00517845
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll3_tThreads256 Tactic: 0x62c39155f9749cff
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x62c39155f9749cff Time: 0.00515739
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x1f6c40e3e09ec730 Time: 0.00280524
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(1568,784:32,28,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_30 (TiledPooling)
[03/01/2023-10:41:32] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_30 (CudaPooling)
[03/01/2023-10:41:32] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_30 (CaskPooling)
[03/01/2023-10:41:32] [V] [TRT] MaxPool_30 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x94215b398b8eb3ba Time: 0.00518841
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x94215b398b8eb3ba Time: 0.00518841
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_234 (TiledPooling)
[03/01/2023-10:41:32] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_234 (CudaPooling)
[03/01/2023-10:41:32] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_234 (CaskPooling)
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x1f6c40e3e09ec730 Time: 0.00319908
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll5_tThreads256 Tactic: 0x185e4d2f4b6d969e
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x185e4d2f4b6d969e Time: 0.00337467
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll8_tThreads128 Tactic: 0xa492ee81d8eb5052
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xa492ee81d8eb5052 Time: 0.00413779
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0xec7cf487c5e61cec
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xec7cf487c5e61cec Time: 0.00364583
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll7_tThreads256 Tactic: 0x31d506f925656f41
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x31d506f925656f41 Time: 0.00397003
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll2_tThreads256 Tactic: 0xbf6a632b19f7ef52
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xbf6a632b19f7ef52 Time: 0.00330441
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll8_tThreads256 Tactic: 0x30cc07a4cfdcf1f1
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x30cc07a4cfdcf1f1 Time: 0.00417097
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll1_tThreads128 Tactic: 0xdf1633a6804bc483
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xdf1633a6804bc483 Time: 0.00329849
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll7_tThreads128 Tactic: 0xa58befdc3252cee2
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xa58befdc3252cee2 Time: 0.00395082
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll2_tThreads128 Tactic: 0x2b348a0e0ec04ef1
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2b348a0e0ec04ef1 Time: 0.00340321
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll6_tThreads128 Tactic: 0x78221da2d2d1bd4f
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x78221da2d2d1bd4f Time: 0.0036496
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll1_tThreads256 Tactic: 0x4b48da83977c6520
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4b48da83977c6520 Time: 0.00326587
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll4_tThreads128 Tactic: 0x51a95674bcd94490
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x51a95674bcd94490 Time: 0.0032748
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll5_tThreads128 Tactic: 0x8c00a40a5c5a373d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8c00a40a5c5a373d Time: 0.00345872
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll4_tThreads256 Tactic: 0xc5f7bf51abeee533
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xc5f7bf51abeee533 Time: 0.00331127
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll3_tThreads128 Tactic: 0xf69d7870ee433d5c
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf69d7870ee433d5c Time: 0.00333714
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll3_tThreads256 Tactic: 0x62c39155f9749cff
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x62c39155f9749cff Time: 0.00336404
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x1f6c40e3e09ec730 Time: 0.00319908
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_234 (TiledPooling)
[03/01/2023-10:41:32] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_234 (CudaPooling)
[03/01/2023-10:41:32] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: MaxPool_234 (CaskPooling)
[03/01/2023-10:41:32] [V] [TRT] MaxPool_234 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x94215b398b8eb3ba Time: 0.00331221
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x94215b398b8eb3ba Time: 0.00331221
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,400:4,20,1) -> Int8(1600,100:4,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(800,400:32,20,1) -> Int8(200,100:32,10,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(50176,784,28,1) -> Int8(86528,676,26,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(12544,784:4,28,1) -> Int8(21632,676:4,26,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CudaDepthwiseConvolution)
[03/01/2023-10:41:32] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (FusedConvActConvolution)
[03/01/2023-10:41:32] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0194194
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0172455
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0248686
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0245029
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0164018
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0243086
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0162377
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.0187063
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.0152722
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.015419
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0156512
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0202606
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.0240152
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0168879
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0152722
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(12544,784:4,28,1) -> Int8(2704,676:32,26,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0201514
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0170992
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0248442
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0191634
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0162702
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0166928
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0243322
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.0240396
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.0153161
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.015477
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.0151698
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0245516
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0161727
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.0185966
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0151698
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(1568,784:32,28,1) -> Int8(2704,676:32,26,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CudaGroupConvolution)
[03/01/2023-10:41:32] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CudaDepthwiseConvolution)
[03/01/2023-10:41:32] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (FusedConvActConvolution)
[03/01/2023-10:41:32] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv2.0.weight + QuantizeLinear_39 + Conv_43 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.00780752
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.00779116
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0102087
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.00618667
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.00770695
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.00982065
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.00699298
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.00770647
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.00917943
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.00662338
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00796444
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.00611962
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.00671626
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00941714
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.00589879
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.014731
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.011923
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.00593298
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00597352
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.0053098
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.00782989
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00541833
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.012008
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.00515135
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.00632209
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00783783
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.00764535
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.00817575
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0119341
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.00565433
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.00952808
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00693116
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0121893
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0150967
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.00532588
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00651699
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0120808
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00791483
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.00973257
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.00941772
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.00639841
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00718994
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00560897
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.00782244
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.00677569
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0146871
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00583424
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0149801
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0227997
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00529337
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0201143
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0121295
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.00769925
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00547217
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0118154
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.00529304
[03/01/2023-10:41:32] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0123246
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x4749124f62d8bd23 Time: 0.00515135
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CudaDepthwiseConvolution)
[03/01/2023-10:41:32] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (FusedConvActConvolution)
[03/01/2023-10:41:32] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0190537
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0171804
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0247223
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0242103
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.016319
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0242103
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0162215
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.0185783
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.0151552
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.0155063
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0156233
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.019968
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.023869
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0166928
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0151552
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0198217
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0170829
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0245516
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0188891
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.01619
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0165953
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0241371
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.0237819
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.01536
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0154624
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.0150382
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0241128
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0160589
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.0184503
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0150382
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CudaGroupConvolution)
[03/01/2023-10:41:32] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CudaDepthwiseConvolution)
[03/01/2023-10:41:32] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (FusedConvActConvolution)
[03/01/2023-10:41:32] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.00759916
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.00769949
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.010084
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.00595127
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.00756066
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.00968411
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.00619295
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.00751908
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.00901486
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.00650306
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00783783
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.00610209
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.00654254
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00927086
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.00564888
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0147017
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0117366
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.00591579
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00579877
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00541799
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.00772235
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00527167
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0118942
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.00504434
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.00608343
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00769155
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.0075698
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.00798045
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0117929
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.00553635
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.00941714
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00678899
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.012093
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0149925
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.00532605
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.0063672
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0119223
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00772235
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.00955733
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.009272
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.00627756
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00708397
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00740206
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.00783783
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.00946286
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0145847
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00767615
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0148041
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0185234
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00766845
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0177493
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.011971
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.00752986
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00634117
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0117816
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.00546675
[03/01/2023-10:41:32] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[03/01/2023-10:41:32] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0121905
[03/01/2023-10:41:32] [V] [TRT] Fastest Tactic: 0x4749124f62d8bd23 Time: 0.00504434
[03/01/2023-10:41:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_1 + QuantizeLinear_392 + Conv_396 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_1 + QuantizeLinear_392 + Conv_396 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_2 + QuantizeLinear_542 + Conv_546 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_2 + QuantizeLinear_542 + Conv_546 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_3 + QuantizeLinear_692 + Conv_696 (CaskFlattenConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_3 + QuantizeLinear_692 + Conv_696 (CaskConvolution)
[03/01/2023-10:41:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:32] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_4 + QuantizeLinear_842 + Conv_846 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_4 + QuantizeLinear_842 + Conv_846 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_5 + QuantizeLinear_992 + Conv_996 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_5 + QuantizeLinear_992 + Conv_996 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_6 + QuantizeLinear_1142 + Conv_1146 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_6 + QuantizeLinear_1142 + Conv_1146 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_7 + QuantizeLinear_1292 + Conv_1296 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_7 + QuantizeLinear_1292 + Conv_1296 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_8 + QuantizeLinear_1442 + Conv_1446 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_8 + QuantizeLinear_1442 + Conv_1446 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_9 + QuantizeLinear_1592 + Conv_1596 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_9 + QuantizeLinear_1592 + Conv_1596 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_10 + QuantizeLinear_1742 + Conv_1746 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_10 + QuantizeLinear_1742 + Conv_1746 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_11 + QuantizeLinear_1892 + Conv_1896 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_11 + QuantizeLinear_1892 + Conv_1896 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_12 + QuantizeLinear_2042 + Conv_2046 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_12 + QuantizeLinear_2042 + Conv_2046 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_13 + QuantizeLinear_2192 + Conv_2196 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_13 + QuantizeLinear_2192 + Conv_2196 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_14 + QuantizeLinear_2342 + Conv_2346 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_14 + QuantizeLinear_2342 + Conv_2346 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(6400,100,10,1) -> Int8(8192,64,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_15 + QuantizeLinear_2492 + Conv_2496 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.0.weight_clone_15 + QuantizeLinear_2492 + Conv_2496 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(2048,64:4,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(1600,100:4,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(200,100:32,10,1) -> Int8(256,64:32,8,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(21632,676:4,26,1) -> Float(73728,576,24,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv2.3.weight + QuantizeLinear_54 + Conv_58 (CudaDepthwiseConvolution)
[03/01/2023-10:41:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv2.3.weight + QuantizeLinear_54 + Conv_58 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv2.3.weight + QuantizeLinear_54 + Conv_58 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.04608
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0x14ef32afe5695907
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x14ef32afe5695907 Time: 0.04612
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x1b0534177b414e71 Time: 0.029813
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xfe80445f7bb61a99 Time: 0.0356645
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xa4ae2d82115c3e83 Time: 0.0345819
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x4d9d0d03129bceb1
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x4d9d0d03129bceb1 Time: 0.0283307
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xff6944b17d5b2e32 Time: 0.0277943
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.0312174
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x1db6e8cf1382fbe0
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x1db6e8cf1382fbe0 Time: 0.0452023
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x69c4e2ca38eadce2 Time: 0.0298706
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.0373029
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0x127de12a1f1a4809
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x127de12a1f1a4809 Time: 0.046592
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0xc25454de2efcccdc
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xc25454de2efcccdc Time: 0.0279406
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.030837
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0xff6944b17d5b2e32 Time: 0.0277943
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2704,676:32,26,1) -> Float(73728,576,24,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv2.3.weight + QuantizeLinear_54 + Conv_58 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv2.3.weight + QuantizeLinear_54 + Conv_58 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x85c1a5f7f239cf84 Time: 0.00786863
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0xa8b56a226b057463
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xa8b56a226b057463 Time: 0.00848457
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x2bcbba39f608bf10
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2bcbba39f608bf10 Time: 0.0108349
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0xac914b235d066808
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xac914b235d066808 Time: 0.0172617
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x64x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x23b890da05937b9e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x23b890da05937b9e Time: 0.0105404
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0x85c1a5f7f239cf84 Time: 0.00786863
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2704,676:32,26,1) -> Float(2304,576:32,24,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv2.3.weight + QuantizeLinear_54 + Conv_58 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv2.3.weight + QuantizeLinear_54 + Conv_58 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x45f7566cdb2b10fb
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x45f7566cdb2b10fb Time: 0.00595505
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea2b7420057a01c1
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xea2b7420057a01c1 Time: 0.0258438
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xad886d4d69834922
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xad886d4d69834922 Time: 0.00978164
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x991db9fd58152c33 Time: 0.0165628
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2468d082d0ff7c9a Time: 0.00607828
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x0e07dc8353bf7e9f
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0e07dc8353bf7e9f Time: 0.0161255
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x748f926574b7bdc4 Time: 0.0261364
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2d8ab2aa0639fda9
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2d8ab2aa0639fda9 Time: 0.00719726
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.018432
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.00820114
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x5f1a472d416ff35e Time: 0.00779164
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.0134583
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb5f710b331ba8377 Time: 0.0288475
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb86b920539eb9c79 Time: 0.0162052
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x55edef142e02adaa
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x55edef142e02adaa Time: 0.0158432
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x8141573686849b61 Time: 0.00992792
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x3f2b14dec582741e Time: 0.00695249
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xb936321f82fd390c
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb936321f82fd390c Time: 0.00644869
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xe742f4598442d2f1 Time: 0.0100736
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x445983715412fbda Time: 0.00592165
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd14bd6d95fefd45e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xd14bd6d95fefd45e Time: 0.00562743
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x47b1629a4bff4800
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x47b1629a4bff4800 Time: 0.0284769
[03/01/2023-10:41:33] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x0edd5d0285e564d4
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0edd5d0285e564d4 Time: 0.00962499
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0xd14bd6d95fefd45e Time: 0.00562743
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xd14bd6d95fefd45e
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 (CudaDepthwiseConvolution)
[03/01/2023-10:41:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.0454583
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0x14ef32afe5695907
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x14ef32afe5695907 Time: 0.0456411
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x1b0534177b414e71 Time: 0.0298715
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xfe80445f7bb61a99 Time: 0.0352841
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xa4ae2d82115c3e83 Time: 0.0345234
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x4d9d0d03129bceb1
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x4d9d0d03129bceb1 Time: 0.0283063
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xff6944b17d5b2e32 Time: 0.0277455
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.031627
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x1db6e8cf1382fbe0
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x1db6e8cf1382fbe0 Time: 0.0450926
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x69c4e2ca38eadce2 Time: 0.0297545
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.0371931
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0x127de12a1f1a4809
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x127de12a1f1a4809 Time: 0.0465189
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0xc25454de2efcccdc
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xc25454de2efcccdc Time: 0.027965
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.0309833
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0xff6944b17d5b2e32 Time: 0.0277455
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x85c1a5f7f239cf84 Time: 0.00789101
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0xa8b56a226b057463
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xa8b56a226b057463 Time: 0.0084843
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x2bcbba39f608bf10
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2bcbba39f608bf10 Time: 0.0105326
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0xac914b235d066808
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xac914b235d066808 Time: 0.0166441
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x64x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x23b890da05937b9e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x23b890da05937b9e Time: 0.0103027
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0x85c1a5f7f239cf84 Time: 0.00789101
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x45f7566cdb2b10fb
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x45f7566cdb2b10fb Time: 0.00583351
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea2b7420057a01c1
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xea2b7420057a01c1 Time: 0.024259
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xad886d4d69834922
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xad886d4d69834922 Time: 0.00882017
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x991db9fd58152c33 Time: 0.0143067
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2468d082d0ff7c9a Time: 0.00602153
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x0e07dc8353bf7e9f
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0e07dc8353bf7e9f Time: 0.0139092
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x748f926574b7bdc4 Time: 0.0244785
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2d8ab2aa0639fda9
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2d8ab2aa0639fda9 Time: 0.0069945
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.0162702
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.00820114
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x5f1a472d416ff35e Time: 0.00747451
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.0124225
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb5f710b331ba8377 Time: 0.0243566
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb86b920539eb9c79 Time: 0.0143653
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x55edef142e02adaa
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x55edef142e02adaa Time: 0.0141232
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x8141573686849b61 Time: 0.00924343
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x3f2b14dec582741e Time: 0.0068123
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xb936321f82fd390c
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb936321f82fd390c Time: 0.00646142
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xe742f4598442d2f1 Time: 0.00914286
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x445983715412fbda Time: 0.00575762
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd14bd6d95fefd45e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xd14bd6d95fefd45e Time: 0.00543424
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x47b1629a4bff4800
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x47b1629a4bff4800 Time: 0.0239429
[03/01/2023-10:41:33] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x0edd5d0285e564d4
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0edd5d0285e564d4 Time: 0.00888901
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0xd14bd6d95fefd45e Time: 0.00543424
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xd14bd6d95fefd45e
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(2048,64:4,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(4608,36,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(256,64:32,8,1) -> Float(144,36:32,6,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(73728,576,24,1) -> Float(18432,144,12,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: MaxPool_61 (TiledPooling)
[03/01/2023-10:41:33] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: MaxPool_61 (CudnnPooling)
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.00415425
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.00415425
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: MaxPool_61 (CaskPooling)
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll1_tThreads128 Tactic: 0x53862c46aa5b4c2b
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x53862c46aa5b4c2b Time: 0.0032613
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll7_tThreads256 Tactic: 0xbd4519190f75e7e9
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xbd4519190f75e7e9 Time: 0.00334682
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x60eceb67eff69444 Time: 0.00330244
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll3_tThreads128 Tactic: 0x7a0d6790c453b5f4
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x7a0d6790c453b5f4 Time: 0.00335458
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll8_tThreads256 Tactic: 0xbc5c1844e5cc7959
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xbc5c1844e5cc7959 Time: 0.00336159
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Max Tactic: 0xb59f9cfb90407c92
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb59f9cfb90407c92 Time: 0.00352201
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll6_tThreads128 Tactic: 0xf4b20242f8c135e7
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xf4b20242f8c135e7 Time: 0.00355378
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_nd_NCDHW_kMAX_kGENERIC_3D_POOLING_MODE_kFLOAT_0 Tactic: 0x5faf4a0a8a5670ed
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x5faf4a0a8a5670ed Time: 0.00355746
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll3_tThreads256 Tactic: 0xee538eb5d3641457
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xee538eb5d3641457 Time: 0.00355824
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll2_tThreads128 Tactic: 0xa7a495ee24d0c659
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xa7a495ee24d0c659 Time: 0.00352502
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll4_tThreads128 Tactic: 0xdd39499496c9cc38
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xdd39499496c9cc38 Time: 0.0036464
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll1_tThreads256 Tactic: 0xc7d8c563bd6ced88
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xc7d8c563bd6ced88 Time: 0.0036984
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll5_tThreads128 Tactic: 0x0090bbea764abf95
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0090bbea764abf95 Time: 0.00369055
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll5_tThreads256 Tactic: 0x94ce52cf617d1e36
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x94ce52cf617d1e36 Time: 0.00364583
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll2_tThreads256 Tactic: 0x33fa7ccb33e767fa
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x33fa7ccb33e767fa Time: 0.0037181
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll7_tThreads128 Tactic: 0x291bf03c1842464a
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x291bf03c1842464a Time: 0.00376361
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll4_tThreads256 Tactic: 0x4967a0b181fe6d9b
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x4967a0b181fe6d9b Time: 0.00374564
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll8_tThreads128 Tactic: 0x2802f161f2fbd8fa
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2802f161f2fbd8fa Time: 0.0037683
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0x53862c46aa5b4c2b Time: 0.0032613
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x53862c46aa5b4c2b
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(18432,1:4,768,32) -> Float(4608,1:4,384,32) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: MaxPool_61 (CaskPooling)
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_NOT_PROPAGATE_NAN_2D Tactic: 0xaec8628e8180bced
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xaec8628e8180bced Time: 0.00378538
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_NOT_PROPAGATE_NAN_3D Tactic: 0xfa211b1cdd504de0
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xfa211b1cdd504de0 Time: 0.00379609
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_PROPAGATE_NAN_3D Tactic: 0xd76bac5638836f8a
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xd76bac5638836f8a Time: 0.00380836
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_PROPAGATE_NAN_2D Tactic: 0x8382d5c464539e87
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x8382d5c464539e87 Time: 0.00370954
[03/01/2023-10:41:33] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NHWC_Max_CAlign4 Tactic: 0x22fb1bb4a70e340d
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x22fb1bb4a70e340d Time: 0.00372829
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0x8382d5c464539e87 Time: 0.00370954
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x8382d5c464539e87
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: MaxPool_265 (TiledPooling)
[03/01/2023-10:41:33] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: MaxPool_265 (CudnnPooling)
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.00484282
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.00484282
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: MaxPool_265 (CaskPooling)
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll1_tThreads128 Tactic: 0x53862c46aa5b4c2b
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x53862c46aa5b4c2b Time: 0.00366828
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll7_tThreads256 Tactic: 0xbd4519190f75e7e9
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xbd4519190f75e7e9 Time: 0.0036875
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x60eceb67eff69444 Time: 0.00355646
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll3_tThreads128 Tactic: 0x7a0d6790c453b5f4
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x7a0d6790c453b5f4 Time: 0.00359131
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll8_tThreads256 Tactic: 0xbc5c1844e5cc7959
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xbc5c1844e5cc7959 Time: 0.00355758
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Max Tactic: 0xb59f9cfb90407c92
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xb59f9cfb90407c92 Time: 0.00364697
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll6_tThreads128 Tactic: 0xf4b20242f8c135e7
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xf4b20242f8c135e7 Time: 0.00383531
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_nd_NCDHW_kMAX_kGENERIC_3D_POOLING_MODE_kFLOAT_0 Tactic: 0x5faf4a0a8a5670ed
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x5faf4a0a8a5670ed Time: 0.00372876
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll3_tThreads256 Tactic: 0xee538eb5d3641457
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xee538eb5d3641457 Time: 0.00369383
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll2_tThreads128 Tactic: 0xa7a495ee24d0c659
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xa7a495ee24d0c659 Time: 0.00368434
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll4_tThreads128 Tactic: 0xdd39499496c9cc38
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xdd39499496c9cc38 Time: 0.00373146
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll1_tThreads256 Tactic: 0xc7d8c563bd6ced88
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xc7d8c563bd6ced88 Time: 0.00375478
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll5_tThreads128 Tactic: 0x0090bbea764abf95
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0090bbea764abf95 Time: 0.0038305
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll5_tThreads256 Tactic: 0x94ce52cf617d1e36
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x94ce52cf617d1e36 Time: 0.00376505
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll2_tThreads256 Tactic: 0x33fa7ccb33e767fa
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x33fa7ccb33e767fa Time: 0.00383074
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll7_tThreads128 Tactic: 0x291bf03c1842464a
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x291bf03c1842464a Time: 0.00376517
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll4_tThreads256 Tactic: 0x4967a0b181fe6d9b
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x4967a0b181fe6d9b Time: 0.00385708
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll8_tThreads128 Tactic: 0x2802f161f2fbd8fa
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x2802f161f2fbd8fa Time: 0.00375478
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0x60eceb67eff69444 Time: 0.00355646
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x60eceb67eff69444
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: MaxPool_265 (CaskPooling)
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_NOT_PROPAGATE_NAN_2D Tactic: 0xaec8628e8180bced
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xaec8628e8180bced Time: 0.00380367
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_NOT_PROPAGATE_NAN_3D Tactic: 0xfa211b1cdd504de0
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xfa211b1cdd504de0 Time: 0.00384541
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_PROPAGATE_NAN_3D Tactic: 0xd76bac5638836f8a
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xd76bac5638836f8a Time: 0.00385335
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_PROPAGATE_NAN_2D Tactic: 0x8382d5c464539e87
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x8382d5c464539e87 Time: 0.00369512
[03/01/2023-10:41:33] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NHWC_Max_CAlign4 Tactic: 0x22fb1bb4a70e340d
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x22fb1bb4a70e340d Time: 0.00371704
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0x8382d5c464539e87 Time: 0.00369512
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x8382d5c464539e87
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(4608,36,6,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,1:4,192,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: ReduceMean_266 (Reduce)
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00407936
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0136711
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0136844
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0x0000000000000005 Time: 0.00407936
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000005
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: ReduceMax_267 (Reduce)
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00442403
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0136977
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0136977
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0x0000000000000005 Time: 0.00442403
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000005
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:33] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(18432,144,12,1) -> Int8(25600,100,10,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(4608,144:4,12,1) -> Int8(6400,100:4,10,1) ***************
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CudaDepthwiseConvolution)
[03/01/2023-10:41:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (FusedConvActConvolution)
[03/01/2023-10:41:33] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CaskFlattenConvolution)
[03/01/2023-10:41:33] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:33] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CaskConvolution)
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0339383
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0304567
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0447269
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0437029
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0283794
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0441794
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0277943
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.0330606
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.0257463
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.0263558
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0265996
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0364251
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.0428983
[03/01/2023-10:41:33] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[03/01/2023-10:41:33] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0292279
[03/01/2023-10:41:33] [V] [TRT] Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0257463
[03/01/2023-10:41:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:33] [V] [TRT] *************** Autotuning format combination: Int8(4608,144:4,12,1) -> Int8(800,100:32,10,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0361691
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0303397
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0445806
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0337335
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0282331
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0290523
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.044032
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.0427886
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.0261608
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0264046
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.0256
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0435931
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.027696
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.032885
[03/01/2023-10:41:34] [V] [TRT] Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0256
[03/01/2023-10:41:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(576,144:32,12,1) -> Int8(800,100:32,10,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CudaGroupConvolution)
[03/01/2023-10:41:34] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CudaDepthwiseConvolution)
[03/01/2023-10:41:34] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (FusedConvActConvolution)
[03/01/2023-10:41:34] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.0.weight + QuantizeLinear_77 + Conv_81 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.0112292
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0113653
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.016514
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.00817575
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.0112183
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.0144677
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.00861365
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.0111965
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.0138847
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.00895029
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.011399
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.00791531
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.00893257
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0140559
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.00753756
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0241615
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0190354
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.00783086
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00769155
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00565415
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.0113653
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00565978
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0191634
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.00544999
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.00825676
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0113424
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.0111181
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.011623
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0189623
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.00744594
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0145554
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00938971
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0192366
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0245029
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.00741623
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00879435
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0191086
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.0113885
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.0151401
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.0142296
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.00875187
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00957684
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00736526
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0113653
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.00927057
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0240884
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00759146
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0242103
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0322414
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00597924
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0301641
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0191634
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.0111624
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00680577
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0189446
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.00679564
[03/01/2023-10:41:34] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0193646
[03/01/2023-10:41:34] [V] [TRT] Fastest Tactic: 0x4749124f62d8bd23 Time: 0.00544999
[03/01/2023-10:41:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x4749124f62d8bd23
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Float(18432,144,12,1) -> Float(2048,16,4,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: Resize_68 (Resize)
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487223
[03/01/2023-10:41:34] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00487223
[03/01/2023-10:41:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0x0000000000000000
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 (CudaDepthwiseConvolution)
[03/01/2023-10:41:34] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.015243
[03/01/2023-10:41:34] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x1b0534177b414e71 Time: 0.012032
[03/01/2023-10:41:34] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.0130194
[03/01/2023-10:41:34] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.0124952
[03/01/2023-10:41:34] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0x127de12a1f1a4809
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x127de12a1f1a4809 Time: 0.0153746
[03/01/2023-10:41:34] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.0122392
[03/01/2023-10:41:34] [V] [TRT] Fastest Tactic: 0x1b0534177b414e71 Time: 0.012032
[03/01/2023-10:41:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1b0534177b414e71
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.0206472
[03/01/2023-10:41:34] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.00977249
[03/01/2023-10:41:34] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.0153893
[03/01/2023-10:41:34] [V] [TRT] Fastest Tactic: 0xdc1f355deb032b87 Time: 0.00977249
[03/01/2023-10:41:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xdc1f355deb032b87
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_1 + QuantizeLinear_426 + Conv_430 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_1 + QuantizeLinear_426 + Conv_430 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_2 + QuantizeLinear_576 + Conv_580 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_2 + QuantizeLinear_576 + Conv_580 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_3 + QuantizeLinear_726 + Conv_730 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_3 + QuantizeLinear_726 + Conv_730 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_4 + QuantizeLinear_876 + Conv_880 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_4 + QuantizeLinear_876 + Conv_880 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_5 + QuantizeLinear_1026 + Conv_1030 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_5 + QuantizeLinear_1026 + Conv_1030 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_6 + QuantizeLinear_1176 + Conv_1180 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_6 + QuantizeLinear_1176 + Conv_1180 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_7 + QuantizeLinear_1326 + Conv_1330 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_7 + QuantizeLinear_1326 + Conv_1330 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_8 + QuantizeLinear_1476 + Conv_1480 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_8 + QuantizeLinear_1476 + Conv_1480 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_9 + QuantizeLinear_1626 + Conv_1630 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_9 + QuantizeLinear_1626 + Conv_1630 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_10 + QuantizeLinear_1776 + Conv_1780 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_10 + QuantizeLinear_1776 + Conv_1780 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_11 + QuantizeLinear_1926 + Conv_1930 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_11 + QuantizeLinear_1926 + Conv_1930 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_12 + QuantizeLinear_2076 + Conv_2080 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_12 + QuantizeLinear_2076 + Conv_2080 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_13 + QuantizeLinear_2226 + Conv_2230 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_13 + QuantizeLinear_2226 + Conv_2230 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_14 + QuantizeLinear_2376 + Conv_2380 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_14 + QuantizeLinear_2376 + Conv_2380 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:4,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_15 + QuantizeLinear_2526 + Conv_2530 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: patchattention_spatial.conv1.weight_clone_15 + QuantizeLinear_2526 + Conv_2530 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(9,9:32,3,1) -> Float(9,9:32,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(6400,100:4,10,1) -> Float(16384,64,8,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.3.weight + QuantizeLinear_92 + Conv_96 (CudaDepthwiseConvolution)
[03/01/2023-10:41:34] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.3.weight + QuantizeLinear_92 + Conv_96 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.3.weight + QuantizeLinear_92 + Conv_96 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.0833829
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0x14ef32afe5695907
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x14ef32afe5695907 Time: 0.0843337
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x1b0534177b414e71 Time: 0.0525166
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xfe80445f7bb61a99 Time: 0.0652434
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xa4ae2d82115c3e83 Time: 0.0630004
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x4d9d0d03129bceb1
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x4d9d0d03129bceb1 Time: 0.0501318
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xff6944b17d5b2e32 Time: 0.0488594
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.0560274
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x1db6e8cf1382fbe0
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x1db6e8cf1382fbe0 Time: 0.0827977
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x69c4e2ca38eadce2 Time: 0.0529067
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.068608
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0x127de12a1f1a4809
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x127de12a1f1a4809 Time: 0.0854309
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0xc25454de2efcccdc
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xc25454de2efcccdc Time: 0.0494446
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.0546621
[03/01/2023-10:41:34] [V] [TRT] Fastest Tactic: 0xff6944b17d5b2e32 Time: 0.0488594
[03/01/2023-10:41:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(800,100:32,10,1) -> Float(16384,64,8,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.3.weight + QuantizeLinear_92 + Conv_96 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.3.weight + QuantizeLinear_92 + Conv_96 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x85c1a5f7f239cf84 Time: 0.0109208
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0xa8b56a226b057463
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xa8b56a226b057463 Time: 0.0121295
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x2bcbba39f608bf10
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x2bcbba39f608bf10 Time: 0.0152713
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0xac914b235d066808
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xac914b235d066808 Time: 0.0261851
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x64x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x23b890da05937b9e
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x23b890da05937b9e Time: 0.0150674
[03/01/2023-10:41:34] [V] [TRT] Fastest Tactic: 0x85c1a5f7f239cf84 Time: 0.0109208
[03/01/2023-10:41:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Int8(800,100:32,10,1) -> Float(512,64:32,8,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.3.weight + QuantizeLinear_92 + Conv_96 (CaskFlattenConvolution)
[03/01/2023-10:41:34] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: conv3.3.weight + QuantizeLinear_92 + Conv_96 (CaskConvolution)
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x45f7566cdb2b10fb
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x45f7566cdb2b10fb Time: 0.00797308
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea2b7420057a01c1
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xea2b7420057a01c1 Time: 0.0447634
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xad886d4d69834922
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xad886d4d69834922 Time: 0.0138307
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x991db9fd58152c33 Time: 0.024259
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x2468d082d0ff7c9a Time: 0.0080706
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x0e07dc8353bf7e9f
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x0e07dc8353bf7e9f Time: 0.0236774
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x748f926574b7bdc4 Time: 0.045056
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2d8ab2aa0639fda9
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x2d8ab2aa0639fda9 Time: 0.0102299
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.0279162
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.012349
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x5f1a472d416ff35e Time: 0.0111965
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.0202811
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xb5f710b331ba8377 Time: 0.0441783
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xb86b920539eb9c79 Time: 0.0243078
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x55edef142e02adaa
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x55edef142e02adaa Time: 0.0239909
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x8141573686849b61 Time: 0.0145115
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x3f2b14dec582741e Time: 0.00961524
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xb936321f82fd390c
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xb936321f82fd390c Time: 0.00917086
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xe742f4598442d2f1 Time: 0.0141777
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x445983715412fbda Time: 0.00760686
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd14bd6d95fefd45e
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0xd14bd6d95fefd45e Time: 0.00722606
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x47b1629a4bff4800
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x47b1629a4bff4800 Time: 0.0436663
[03/01/2023-10:41:34] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x0edd5d0285e564d4
[03/01/2023-10:41:34] [V] [TRT] Tactic: 0x0edd5d0285e564d4 Time: 0.0141764
[03/01/2023-10:41:34] [V] [TRT] Fastest Tactic: 0xd14bd6d95fefd45e Time: 0.00722606
[03/01/2023-10:41:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xd14bd6d95fefd45e
[03/01/2023-10:41:34] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:34] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:34] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_282, Mul_283) (PointWiseV2)
[03/01/2023-10:41:35] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0028587
[03/01/2023-10:41:35] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00277073
[03/01/2023-10:41:35] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00271034
[03/01/2023-10:41:35] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00285096
[03/01/2023-10:41:36] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00286683
[03/01/2023-10:41:36] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00271603
[03/01/2023-10:41:36] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00318012
[03/01/2023-10:41:36] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0030754
[03/01/2023-10:41:36] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00292571
[03/01/2023-10:41:37] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00281116
[03/01/2023-10:41:37] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00261719
[03/01/2023-10:41:37] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 0.00261719
[03/01/2023-10:41:37] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_282, Mul_283) (PointWise)
[03/01/2023-10:41:37] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[03/01/2023-10:41:37] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:37] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_282, Mul_283) (PointWiseV2)
[03/01/2023-10:41:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00256278
[03/01/2023-10:41:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00272716
[03/01/2023-10:41:37] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00273225
[03/01/2023-10:41:38] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00298667
[03/01/2023-10:41:38] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00288183
[03/01/2023-10:41:38] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00268741
[03/01/2023-10:41:38] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00325153
[03/01/2023-10:41:38] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00298943
[03/01/2023-10:41:39] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00280265
[03/01/2023-10:41:39] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.0028056
[03/01/2023-10:41:39] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00262267
[03/01/2023-10:41:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00256278
[03/01/2023-10:41:39] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_282, Mul_283) (PointWise)
[03/01/2023-10:41:39] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000000
[03/01/2023-10:41:39] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:39] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_282, Mul_283) (PointWiseV2)
[03/01/2023-10:41:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00272958
[03/01/2023-10:41:39] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00275974
[03/01/2023-10:41:40] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00322468
[03/01/2023-10:41:40] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00281959
[03/01/2023-10:41:40] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00339179
[03/01/2023-10:41:40] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00295305
[03/01/2023-10:41:41] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.003047
[03/01/2023-10:41:41] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00371317
[03/01/2023-10:41:41] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00306013
[03/01/2023-10:41:41] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00302428
[03/01/2023-10:41:41] [V] [TRT] Tactic: 0x000000000000000a Time: 0.00262251
[03/01/2023-10:41:42] [V] [TRT] Tactic: 0x000000000000000b Time: 0.00289371
[03/01/2023-10:41:42] [V] [TRT] Tactic: 0x000000000000000c Time: 0.0029704
[03/01/2023-10:41:42] [V] [TRT] Tactic: 0x000000000000000d Time: 0.00297752
[03/01/2023-10:41:42] [V] [TRT] Tactic: 0x000000000000000e Time: 0.00309379
[03/01/2023-10:41:42] [V] [TRT] Tactic: 0x000000000000000f Time: 0.00319888
[03/01/2023-10:41:43] [V] [TRT] Tactic: 0x0000000000000010 Time: 0.0031673
[03/01/2023-10:41:43] [V] [TRT] Tactic: 0x0000000000000011 Time: 0.00330109
[03/01/2023-10:41:43] [V] [TRT] Tactic: 0x0000000000000012 Time: 0.00340278
[03/01/2023-10:41:43] [V] [TRT] Tactic: 0x0000000000000013 Time: 0.00372443
[03/01/2023-10:41:44] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.00270741
[03/01/2023-10:41:44] [V] [TRT] Tactic: 0x0000000000000015 Time: 0.00279868
[03/01/2023-10:41:44] [V] [TRT] Tactic: 0x0000000000000016 Time: 0.00312288
[03/01/2023-10:41:44] [V] [TRT] Tactic: 0x0000000000000017 Time: 0.00350695
[03/01/2023-10:41:44] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00267361
[03/01/2023-10:41:45] [V] [TRT] Tactic: 0x000000000000001d Time: 0.0026637
[03/01/2023-10:41:45] [V] [TRT] Tactic: 0x000000000000001e Time: 0.00317633
[03/01/2023-10:41:45] [V] [TRT] Fastest Tactic: 0x000000000000000a Time: 0.00262251
[03/01/2023-10:41:45] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_282, Mul_283) (PointWise)
[03/01/2023-10:41:45] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000000a
[03/01/2023-10:41:45] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:45] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_282, Mul_283) (PointWiseV2)
[03/01/2023-10:41:45] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.0058165
[03/01/2023-10:41:45] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.00318212
[03/01/2023-10:41:45] [V] [TRT] Tactic: 0x000000000000001a Time: 0.00362423
[03/01/2023-10:41:46] [V] [TRT] Tactic: 0x000000000000001b Time: 0.00374341
[03/01/2023-10:41:46] [V] [TRT] Tactic: 0x000000000000001f Time: 0.00279631
[03/01/2023-10:41:46] [V] [TRT] Fastest Tactic: 0x000000000000001f Time: 0.00279631
[03/01/2023-10:41:46] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_282, Mul_283) (PointWise)
[03/01/2023-10:41:46] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001f
[03/01/2023-10:41:46] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:46] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_282, Mul_283) (PointWiseV2)
[03/01/2023-10:41:46] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00294922
[03/01/2023-10:41:46] [V] [TRT] Tactic: 0x000000000000001d Time: 0.00281448
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x000000000000001e Time: 0.00280238
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 0.00280238
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9,3,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1,3,1), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,1:4,3,1), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(9,9:32,3,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1:4,9,3,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_284 (TiledPooling)
[03/01/2023-10:41:47] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_284 (CudnnPooling)
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.00366488
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.00366488
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_284 (CaskPooling)
[03/01/2023-10:41:47] [V] [TRT] GlobalAveragePool_284 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x964fa580cb69303d Time: 0.00304671
[03/01/2023-10:41:47] [V] [TRT] GlobalAveragePool_284 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_custom_tP8_tQ16_tRS3_tUV1 Tactic: 0x9b99afa516385d34
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x9b99afa516385d34 Time: 0.0031512
[03/01/2023-10:41:47] [V] [TRT] GlobalAveragePool_284 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average_FastDiv Tactic: 0x933eceba7b866d59
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x933eceba7b866d59 Time: 0.00318618
[03/01/2023-10:41:47] [V] [TRT] GlobalAveragePool_284 Set Tactic Name: sm50_xmma_pooling_nd_NCDHW_kAVERAGE_kGENERIC_3D_POOLING_MODE_kFLOAT_0 Tactic: 0xba33c80addb15739
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xba33c80addb15739 Time: 0.00316412
[03/01/2023-10:41:47] [V] [TRT] GlobalAveragePool_284 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_custom_tP4_tQ32_tRS3_tUV1 Tactic: 0x8819e020387dbf3c
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x8819e020387dbf3c Time: 0.0049152
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x964fa580cb69303d Time: 0.00304671
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x964fa580cb69303d
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_284 (CaskPooling)
[03/01/2023-10:41:47] [V] [TRT] GlobalAveragePool_284 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NHWC_Average_FastDiv_CAlign4 Tactic: 0xfab3e2ee1c085a9a
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xfab3e2ee1c085a9a Time: 0.00487177
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0xfab3e2ee1c085a9a Time: 0.00487177
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0xfab3e2ee1c085a9a
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(1152,9,3,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(288,1:4,96,32) -> Float(32,1:4,32,32) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_312 (TiledPooling)
[03/01/2023-10:41:47] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_312 (CudaPooling)
[03/01/2023-10:41:47] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_312 (CaskPooling)
[03/01/2023-10:41:47] [V] [TRT] MaxPool_312 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x1f6c40e3e09ec730 Time: 0.00319878
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x1f6c40e3e09ec730 Time: 0.00319878
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_312 (TiledPooling)
[03/01/2023-10:41:47] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_312 (CudaPooling)
[03/01/2023-10:41:47] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_312 (CaskPooling)
[03/01/2023-10:41:47] [V] [TRT] MaxPool_312 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x94215b398b8eb3ba Time: 0.0036352
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x94215b398b8eb3ba Time: 0.0036352
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(288,9:4,3,1) -> Int8(32,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(36,9:32,3,1) -> Int8(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(16384,64,8,1) -> Float(6144,16,4,1) long-strided ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_99 (TiledPooling)
[03/01/2023-10:41:47] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_99 (CudnnPooling)
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.00377648
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.00377648
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_99 (CaskPooling)
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll1_tThreads128 Tactic: 0x53862c46aa5b4c2b
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x53862c46aa5b4c2b Time: 0.00294083
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll7_tThreads256 Tactic: 0xbd4519190f75e7e9
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xbd4519190f75e7e9 Time: 0.00280506
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x60eceb67eff69444 Time: 0.0223619
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll3_tThreads128 Tactic: 0x7a0d6790c453b5f4
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x7a0d6790c453b5f4 Time: 0.00292571
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll8_tThreads256 Tactic: 0xbc5c1844e5cc7959
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xbc5c1844e5cc7959 Time: 0.00289051
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Max Tactic: 0xb59f9cfb90407c92
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xb59f9cfb90407c92 Time: 0.00338466
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll6_tThreads128 Tactic: 0xf4b20242f8c135e7
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xf4b20242f8c135e7 Time: 0.00287012
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll3_tThreads256 Tactic: 0xee538eb5d3641457
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xee538eb5d3641457 Time: 0.00287863
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll2_tThreads128 Tactic: 0xa7a495ee24d0c659
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xa7a495ee24d0c659 Time: 0.00293187
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll4_tThreads128 Tactic: 0xdd39499496c9cc38
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xdd39499496c9cc38 Time: 0.00288768
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll1_tThreads256 Tactic: 0xc7d8c563bd6ced88
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc7d8c563bd6ced88 Time: 0.00314842
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll5_tThreads128 Tactic: 0x0090bbea764abf95
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0090bbea764abf95 Time: 0.00308795
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll5_tThreads256 Tactic: 0x94ce52cf617d1e36
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x94ce52cf617d1e36 Time: 0.00314534
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll2_tThreads256 Tactic: 0x33fa7ccb33e767fa
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x33fa7ccb33e767fa Time: 0.00309058
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll7_tThreads128 Tactic: 0x291bf03c1842464a
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x291bf03c1842464a Time: 0.00313282
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll4_tThreads256 Tactic: 0x4967a0b181fe6d9b
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x4967a0b181fe6d9b Time: 0.00307511
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll8_tThreads128 Tactic: 0x2802f161f2fbd8fa
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x2802f161f2fbd8fa Time: 0.0031356
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0xbd4519190f75e7e9 Time: 0.00280506
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0xbd4519190f75e7e9
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(16384,64,8,1) -> Float(4096,16,4,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_99 (TiledPooling)
[03/01/2023-10:41:47] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_99 (CudnnPooling)
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.00423744
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.00423744
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_99 (CaskPooling)
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll1_tThreads128 Tactic: 0x53862c46aa5b4c2b
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x53862c46aa5b4c2b Time: 0.0031356
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll7_tThreads256 Tactic: 0xbd4519190f75e7e9
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xbd4519190f75e7e9 Time: 0.00378382
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x60eceb67eff69444 Time: 0.00412121
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll3_tThreads128 Tactic: 0x7a0d6790c453b5f4
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x7a0d6790c453b5f4 Time: 0.00432753
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll8_tThreads256 Tactic: 0xbc5c1844e5cc7959
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xbc5c1844e5cc7959 Time: 0.00443747
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Max Tactic: 0xb59f9cfb90407c92
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xb59f9cfb90407c92 Time: 0.00442861
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll6_tThreads128 Tactic: 0xf4b20242f8c135e7
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xf4b20242f8c135e7 Time: 0.00477364
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_nd_NCDHW_kMAX_kGENERIC_3D_POOLING_MODE_kFLOAT_0 Tactic: 0x5faf4a0a8a5670ed
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x5faf4a0a8a5670ed Time: 0.00541748
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll3_tThreads256 Tactic: 0xee538eb5d3641457
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xee538eb5d3641457 Time: 0.00573476
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll2_tThreads128 Tactic: 0xa7a495ee24d0c659
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xa7a495ee24d0c659 Time: 0.00563833
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll4_tThreads128 Tactic: 0xdd39499496c9cc38
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xdd39499496c9cc38 Time: 0.00554092
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll1_tThreads256 Tactic: 0xc7d8c563bd6ced88
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc7d8c563bd6ced88 Time: 0.0055251
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll5_tThreads128 Tactic: 0x0090bbea764abf95
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0090bbea764abf95 Time: 0.00542358
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll5_tThreads256 Tactic: 0x94ce52cf617d1e36
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x94ce52cf617d1e36 Time: 0.00535873
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll2_tThreads256 Tactic: 0x33fa7ccb33e767fa
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x33fa7ccb33e767fa Time: 0.00535297
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll7_tThreads128 Tactic: 0x291bf03c1842464a
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x291bf03c1842464a Time: 0.00521388
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll4_tThreads256 Tactic: 0x4967a0b181fe6d9b
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x4967a0b181fe6d9b Time: 0.00373228
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll8_tThreads128 Tactic: 0x2802f161f2fbd8fa
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x2802f161f2fbd8fa Time: 0.00350383
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x53862c46aa5b4c2b Time: 0.0031356
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x53862c46aa5b4c2b
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(4096,1:4,512,64) -> Float(1536,1:4,384,96) long-strided ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_99 (CaskPooling)
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_NOT_PROPAGATE_NAN_2D Tactic: 0xaec8628e8180bced
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xaec8628e8180bced Time: 0.00363177
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_NOT_PROPAGATE_NAN_3D Tactic: 0xfa211b1cdd504de0
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xfa211b1cdd504de0 Time: 0.00358389
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_PROPAGATE_NAN_3D Tactic: 0xd76bac5638836f8a
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xd76bac5638836f8a Time: 0.0035287
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_PROPAGATE_NAN_2D Tactic: 0x8382d5c464539e87
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x8382d5c464539e87 Time: 0.0033014
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NHWC_Max_CAlign4 Tactic: 0x22fb1bb4a70e340d
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x22fb1bb4a70e340d Time: 0.0035607
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x8382d5c464539e87 Time: 0.0033014
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x8382d5c464539e87
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(4096,1:4,512,64) -> Float(1024,1:4,256,64) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: MaxPool_99 (CaskPooling)
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_NOT_PROPAGATE_NAN_2D Tactic: 0xaec8628e8180bced
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xaec8628e8180bced Time: 0.00326151
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_NOT_PROPAGATE_NAN_3D Tactic: 0xfa211b1cdd504de0
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xfa211b1cdd504de0 Time: 0.00329143
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_PROPAGATE_NAN_3D Tactic: 0xd76bac5638836f8a
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xd76bac5638836f8a Time: 0.00334076
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_max_nhwc_FP32FP32_WINDOWSIZE_0_PROPAGATE_NAN_2D Tactic: 0x8382d5c464539e87
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x8382d5c464539e87 Time: 0.00333395
[03/01/2023-10:41:47] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NHWC_Max_CAlign4 Tactic: 0x22fb1bb4a70e340d
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x22fb1bb4a70e340d Time: 0.00345165
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0xaec8628e8180bced Time: 0.00326151
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0xaec8628e8180bced
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CudaDepthwiseConvolution)
[03/01/2023-10:41:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (FusedConvActConvolution)
[03/01/2023-10:41:47] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.00857869
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.00876854
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0109296
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0110164
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.00833829
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.00828953
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.00807086
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.00817549
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.00824076
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.00889761
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.0108147
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.00863946
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x8a10449e6d8c189c Time: 0.00807086
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.00875993
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.00858783
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.00849317
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.00842434
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0108147
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.0106475
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.00805384
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.00806197
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.00789943
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0107729
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.008192
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.008192
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.00789943
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CudaGroupConvolution)
[03/01/2023-10:41:47] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CudaDepthwiseConvolution)
[03/01/2023-10:41:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (FusedConvActConvolution)
[03/01/2023-10:41:47] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x2640501019a61dc2 Time: 0.00511478
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x6106e2811713d7ee Time: 0.00607695
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.00540173
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.00671584
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xcddae68de84cc6ee Time: 0.0048128
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xb3718d2455749f91 Time: 0.00472833
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.00643021
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x79a4e52543793dbe Time: 0.00522971
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xb14c1f9154f6db4e Time: 0.00511494
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00566013
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0050292
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x764ba04bb839d539 Time: 0.00507965
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.00505442
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00607105
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x3912ca79eb9a8be1 Time: 0.00497907
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x179c6422445ceb76 Time: 0.00527151
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x5947ea3454b6a27b Time: 0.00611352
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0049384
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00504938
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.00704958
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x58e405fffd827823 Time: 0.00539107
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x15fad4362e913239 Time: 0.00524539
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xfa5f2e15625aa266 Time: 0.00496363
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x65920facc9ae819d Time: 0.00525584
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x4b8c9beb00181107 Time: 0.00492832
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x7247cc5dea3981f1 Time: 0.0073728
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xdfdddae7a4bcc830 Time: 0.00744594
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xffb9fbd2bfa6c47d Time: 0.00732891
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x01bc9ada86b72c5f Time: 0.00735886
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.007248
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x599d6bb582ecb830 Time: 0.00795581
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00757606
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xa5a7024b355e2bbc Time: 0.00763886
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xd25c9876338da5ac Time: 0.00773798
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.00759146
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xcae7b5888d47fe1f Time: 0.007776
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xea7e3523ffa8ae75 Time: 0.00776854
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xfac85bfa6e8a95c6 Time: 0.00783014
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x18f10c3bd17f3940 Time: 0.0077683
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x881d70ee6f8bc650 Time: 0.00781498
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.00762225
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00779934
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.00774544
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x70ff342513dcddd5 Time: 0.00766099
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.00784553
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x596d7302ab180539 Time: 0.00775266
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00753756
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00758376
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xfe7287378bfa0cc9 Time: 0.00774544
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xde3cb6dda9a9f049 Time: 0.00765305
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x932469cec5625217 Time: 0.00768505
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xa9815e06b127c3d5 Time: 0.00776854
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xe56748b5b7870ba4 Time: 0.00779982
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x4f35593c356e2e7e Time: 0.00783014
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00789173
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc6627e11680191d5 Time: 0.00837079
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x3ffcb62b1c6bb94f Time: 0.00987947
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00962591
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00974141
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x53604f016bff6d61 Time: 0.00985966
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00928
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.00546133
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x311b82feb19aef19 Time: 0.00551385
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xf207dff9d0b58a85 Time: 0.0055476
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00565486
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00605905
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.00754526
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.00924343
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc22b2f91e37e472a Time: 0.00471447
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc29602984551b4e8 Time: 0.00767615
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00470946
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x596666386c88024b Time: 0.00469058
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x483ad1560c6e5e27 Time: 0.00474249
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x429236a031bfe3e7 Time: 0.00483718
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xed8f60f5aa2efd98 Time: 0.00540732
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.00705654
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x716fcb85e712b30e Time: 0.00711946
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00676197
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x31de506085a332d4 Time: 0.00660966
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x5314c155321a63a7 Time: 0.00700778
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x601b41d38fc4645b Time: 0.0114215
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x5e4918ccf433630e Time: 0.0075994
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xa086b8faeb42b254 Time: 0.00717532
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.00732891
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xb2cc5e08f6b66610 Time: 0.00732891
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x596666386c88024b Time: 0.00469058
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x596666386c88024b
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_15 + QuantizeLinear_1370 + Conv_1374 + Relu_1375 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_15 + QuantizeLinear_1370 + Conv_1374 + Relu_1375 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_17 + QuantizeLinear_1520 + Conv_1524 + Relu_1525 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_17 + QuantizeLinear_1520 + Conv_1524 + Relu_1525 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(128,1,1,1) -> Int8(8,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(2,1:4,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(32,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(4,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(6144,16,4,1) -> Float(16,16,4,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: ReduceMean_101 (Reduce)
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00776084
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0402297
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0402286
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x0000000000000005 Time: 0.00776084
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000005
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Float(6144,16,4,1) -> Float(16,16,4,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: ReduceMax_102 (Reduce)
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00781474
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0403017
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0403383
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x0000000000000005 Time: 0.00781474
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000005
[03/01/2023-10:41:47] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 (CudaDepthwiseConvolution)
[03/01/2023-10:41:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.00923343
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0x14ef32afe5695907
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x14ef32afe5695907 Time: 0.00916114
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xfe80445f7bb61a99 Time: 0.00708441
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xa4ae2d82115c3e83 Time: 0.00691723
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x4d9d0d03129bceb1
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x4d9d0d03129bceb1 Time: 0.00764535
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xff6944b17d5b2e32 Time: 0.00769155
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.00776854
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu Tactic: 0xc073b0053ce90eac
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc073b0053ce90eac Time: 0.00721966
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x1db6e8cf1382fbe0
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x1db6e8cf1382fbe0 Time: 0.00917943
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x69c4e2ca38eadce2 Time: 0.00778394
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.00719726
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0xc25454de2efcccdc
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xc25454de2efcccdc Time: 0.00756836
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.00797308
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0xa4ae2d82115c3e83 Time: 0.00691723
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xa4ae2d82115c3e83
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x733ba2a91a48d431
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x733ba2a91a48d431 Time: 0.004516
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x5e4f6d7c83746fd6
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x5e4f6d7c83746fd6 Time: 0.00458071
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0xf04572b287451f42
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0xf04572b287451f42 Time: 0.00559262
[03/01/2023-10:41:47] [V] [TRT] Fastest Tactic: 0x733ba2a91a48d431 Time: 0.004516
[03/01/2023-10:41:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x733ba2a91a48d431
[03/01/2023-10:41:47] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 (CaskFlattenConvolution)
[03/01/2023-10:41:47] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:47] [V] [TRT] --------------- Timing Runner: patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 (CaskConvolution)
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x6d377e4222886190 Time: 0.0040066
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x991db9fd58152c33 Time: 0.00515755
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a
[03/01/2023-10:41:47] [V] [TRT] Tactic: 0x2468d082d0ff7c9a Time: 0.0040513
[03/01/2023-10:41:47] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x748f926574b7bdc4 Time: 0.006016
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x1e55f8b415964e81
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x1e55f8b415964e81 Time: 0.00472789
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.00530963
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.00434424
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x5f1a472d416ff35e Time: 0.00462924
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.00479772
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa71946688cad8664
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xa71946688cad8664 Time: 0.00470474
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9ec201b34455146e
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x9ec201b34455146e Time: 0.00463425
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xb5f710b331ba8377 Time: 0.00628392
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x7720f198395e7d3d
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x7720f198395e7d3d Time: 0.00456229
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcd229658c16b33cd
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xcd229658c16b33cd Time: 0.00604019
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xb86b920539eb9c79 Time: 0.00489082
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x960e9baa2a6cad5b
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x960e9baa2a6cad5b Time: 0.004512
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6e9c17a33c93d9b0
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x6e9c17a33c93d9b0 Time: 0.00463867
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x60b880e28fee7a0c
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x60b880e28fee7a0c Time: 0.0058454
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcf64a2ae51bf6b36
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xcf64a2ae51bf6b36 Time: 0.00453971
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x84942841d92b0552
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x84942841d92b0552 Time: 0.00572765
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdf7e1bd6a496d667
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xdf7e1bd6a496d667 Time: 0.00993798
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x8141573686849b61 Time: 0.00918857
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x91930a570b557437
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x91930a570b557437 Time: 0.00884598
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x3f2b14dec582741e Time: 0.0085276
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x33a5c6dd086942c1
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x33a5c6dd086942c1 Time: 0.00850151
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xe742f4598442d2f1 Time: 0.00591579
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x445983715412fbda Time: 0.00532047
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x271b998fe31732ef
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x271b998fe31732ef Time: 0.00546184
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5bd8221bd57baf93
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x5bd8221bd57baf93 Time: 0.00528278
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x65fbe45b4cb1d8a5
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x65fbe45b4cb1d8a5 Time: 0.00524033
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x844ea9c00f711f19
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x844ea9c00f711f19 Time: 0.00597886
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xbeb5d91e1874a437
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xbeb5d91e1874a437 Time: 0.00733692
[03/01/2023-10:41:48] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9003f5f7ff9b1aec
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x9003f5f7ff9b1aec Time: 0.00730697
[03/01/2023-10:41:48] [V] [TRT] Fastest Tactic: 0x6d377e4222886190 Time: 0.0040066
[03/01/2023-10:41:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x6d377e4222886190
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(2,1:4,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(128,1,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(4,1:32,1,1) ***************
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(16,16:4,4,1) -> Float(16,16,4,1) ***************
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 (CudaDepthwiseConvolution)
[03/01/2023-10:41:48] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 (CaskFlattenConvolution)
[03/01/2023-10:41:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 (CaskConvolution)
[03/01/2023-10:41:48] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.0169529
[03/01/2023-10:41:48] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x1b0534177b414e71 Time: 0.0137642
[03/01/2023-10:41:48] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.0155209
[03/01/2023-10:41:48] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.0149509
[03/01/2023-10:41:48] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0x127de12a1f1a4809
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x127de12a1f1a4809 Time: 0.0168229
[03/01/2023-10:41:48] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.0140962
[03/01/2023-10:41:48] [V] [TRT] Fastest Tactic: 0x1b0534177b414e71 Time: 0.0137642
[03/01/2023-10:41:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1b0534177b414e71
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(16,16:32,4,1) -> Float(16,16,4,1) ***************
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 (CaskFlattenConvolution)
[03/01/2023-10:41:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 (CaskConvolution)
[03/01/2023-10:41:48] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Int8(16,16:32,4,1) -> Float(16,16:32,4,1) ***************
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 (CaskFlattenConvolution)
[03/01/2023-10:41:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 (CaskConvolution)
[03/01/2023-10:41:48] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.0225698
[03/01/2023-10:41:48] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.0106266
[03/01/2023-10:41:48] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.0170667
[03/01/2023-10:41:48] [V] [TRT] Fastest Tactic: 0xdc1f355deb032b87 Time: 0.0106266
[03/01/2023-10:41:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xdc1f355deb032b87
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Float(16,16,4,1), Float(6144,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_117, Mul_118) (PointWiseV2)
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00312537
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00308425
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00319583
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00324135
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00323413
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.0031357
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.0031003
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0031514
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00318283
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00321178
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00319299
[03/01/2023-10:41:48] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.00308425
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_117, Mul_118) (PointWise)
[03/01/2023-10:41:48] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000001
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Float(16,1,4,1), Float(6144,1,1536,384) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_117, Mul_118) (PointWiseV2)
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00319238
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00320193
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00322255
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00325205
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0032449
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.0032386
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.0035607
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00330784
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00337116
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00338222
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00338785
[03/01/2023-10:41:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00319238
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_117, Mul_118) (PointWise)
[03/01/2023-10:41:48] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000000
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Float(16,1:4,4,1), Float(1536,1:4,384,96) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_117, Mul_118) (PointWiseV2)
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00567701
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00476328
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00440603
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00436668
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0060221
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00598686
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00593865
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00496867
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00355713
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00353929
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000000a Time: 0.00359177
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000000b Time: 0.00365006
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000000c Time: 0.00366875
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000000d Time: 0.00358377
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000000e Time: 0.00354676
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000000f Time: 0.00360949
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000010 Time: 0.00393785
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000011 Time: 0.00597924
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000012 Time: 0.00612591
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000013 Time: 0.00562075
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.00571059
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000015 Time: 0.00571648
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000016 Time: 0.00372103
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000017 Time: 0.00382268
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00373955
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001d Time: 0.00806984
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001e Time: 0.00681208
[03/01/2023-10:41:48] [V] [TRT] Fastest Tactic: 0x0000000000000009 Time: 0.00353929
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_117, Mul_118) (PointWise)
[03/01/2023-10:41:48] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000009
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Float(16,16:32,4,1), Float(192,16:32,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_117, Mul_118) (PointWiseV2)
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.0059981
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.00608305
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001a Time: 0.00554725
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001b Time: 0.00557574
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001f Time: 0.00614971
[03/01/2023-10:41:48] [V] [TRT] Fastest Tactic: 0x000000000000001a Time: 0.00554725
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_117, Mul_118) (PointWise)
[03/01/2023-10:41:48] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001a
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Float(1:4,16,4,1), Float(1:4,16,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_117, Mul_118) (PointWiseV2)
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00660904
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001d Time: 0.00645585
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x000000000000001e Time: 0.00396978
[03/01/2023-10:41:48] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 0.00396978
[03/01/2023-10:41:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[03/01/2023-10:41:48] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:41:48] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:41:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWiseV2)
[03/01/2023-10:41:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00295249
[03/01/2023-10:41:49] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00304087
[03/01/2023-10:41:49] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00296424
[03/01/2023-10:41:49] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00307219
[03/01/2023-10:41:49] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00307239
[03/01/2023-10:41:49] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00290212
[03/01/2023-10:41:50] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00331803
[03/01/2023-10:41:50] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00328135
[03/01/2023-10:41:50] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00336829
[03/01/2023-10:41:50] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.0031514
[03/01/2023-10:41:51] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00282228
[03/01/2023-10:41:51] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 0.00282228
[03/01/2023-10:41:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWise)
[03/01/2023-10:41:51] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[03/01/2023-10:41:51] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:41:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWiseV2)
[03/01/2023-10:41:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00279068
[03/01/2023-10:41:51] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00288183
[03/01/2023-10:41:51] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00284567
[03/01/2023-10:41:51] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00302895
[03/01/2023-10:41:52] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0031197
[03/01/2023-10:41:52] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00285705
[03/01/2023-10:41:52] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.0032879
[03/01/2023-10:41:52] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00325818
[03/01/2023-10:41:52] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00336765
[03/01/2023-10:41:53] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00314832
[03/01/2023-10:41:53] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00285842
[03/01/2023-10:41:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00279068
[03/01/2023-10:41:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWise)
[03/01/2023-10:41:53] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000000
[03/01/2023-10:41:53] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:41:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWiseV2)
[03/01/2023-10:41:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00290825
[03/01/2023-10:41:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00298362
[03/01/2023-10:41:53] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00287022
[03/01/2023-10:41:54] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00323129
[03/01/2023-10:41:54] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00307822
[03/01/2023-10:41:54] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00285824
[03/01/2023-10:41:54] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00348577
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00329454
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00324104
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00305332
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00286729
[03/01/2023-10:41:55] [V] [TRT] Fastest Tactic: 0x0000000000000005 Time: 0.00285824
[03/01/2023-10:41:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWise)
[03/01/2023-10:41:55] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000005
[03/01/2023-10:41:55] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:41:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWiseV2)
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00282236
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00298362
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00333736
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00322794
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00327127
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.0032748
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00356438
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00329143
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.003288
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.0033886
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00336457
[03/01/2023-10:41:55] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00282236
[03/01/2023-10:41:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWise)
[03/01/2023-10:41:55] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000000
[03/01/2023-10:41:55] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:41:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWiseV2)
[03/01/2023-10:41:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00295855
[03/01/2023-10:41:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00308124
[03/01/2023-10:41:56] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00443761
[03/01/2023-10:41:56] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00323495
[03/01/2023-10:41:56] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00324703
[03/01/2023-10:41:57] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00313242
[03/01/2023-10:41:57] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.0034412
[03/01/2023-10:41:57] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00352513
[03/01/2023-10:41:57] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0033786
[03/01/2023-10:41:58] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00339243
[03/01/2023-10:41:58] [V] [TRT] Tactic: 0x000000000000000a Time: 0.00288448
[03/01/2023-10:41:58] [V] [TRT] Tactic: 0x000000000000000b Time: 0.00317356
[03/01/2023-10:41:58] [V] [TRT] Tactic: 0x000000000000000c Time: 0.00346199
[03/01/2023-10:41:59] [V] [TRT] Tactic: 0x000000000000000d Time: 0.00332694
[03/01/2023-10:41:59] [V] [TRT] Tactic: 0x000000000000000e Time: 0.00354654
[03/01/2023-10:41:59] [V] [TRT] Tactic: 0x000000000000000f Time: 0.00388992
[03/01/2023-10:41:59] [V] [TRT] Tactic: 0x0000000000000010 Time: 0.00354698
[03/01/2023-10:41:59] [V] [TRT] Tactic: 0x0000000000000011 Time: 0.00376433
[03/01/2023-10:42:00] [V] [TRT] Tactic: 0x0000000000000012 Time: 0.00423785
[03/01/2023-10:42:00] [V] [TRT] Tactic: 0x0000000000000013 Time: 0.00343075
[03/01/2023-10:42:00] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.00284522
[03/01/2023-10:42:00] [V] [TRT] Tactic: 0x0000000000000015 Time: 0.00309379
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x0000000000000016 Time: 0.00346884
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x0000000000000017 Time: 0.00362034
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x000000000000001c Time: 0.0029704
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x000000000000001d Time: 0.00288494
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x000000000000001e Time: 0.0028454
[03/01/2023-10:42:01] [V] [TRT] Fastest Tactic: 0x0000000000000014 Time: 0.00284522
[03/01/2023-10:42:01] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWise)
[03/01/2023-10:42:01] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:42:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000014
[03/01/2023-10:42:01] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:01] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWiseV2)
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00305021
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00335437
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00448
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00346895
[03/01/2023-10:42:01] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00361692
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00349279
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00354654
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0034967
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00337467
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00335777
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000000a Time: 0.00347603
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000000b Time: 0.00341682
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000000c Time: 0.00370579
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000000d Time: 0.00344816
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000000e Time: 0.00354297
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000000f Time: 0.00390215
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000010 Time: 0.00359474
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000011 Time: 0.00376108
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000012 Time: 0.00419605
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000013 Time: 0.00345861
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.00350038
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000015 Time: 0.00350027
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000016 Time: 0.00352156
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000017 Time: 0.00362046
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00355022
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000001d Time: 0.00358777
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000001e Time: 0.0036208
[03/01/2023-10:42:02] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00305021
[03/01/2023-10:42:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWise)
[03/01/2023-10:42:02] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:42:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000000
[03/01/2023-10:42:02] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWiseV2)
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.0030019
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.00325486
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000001a Time: 0.0032881
[03/01/2023-10:42:02] [V] [TRT] Tactic: 0x000000000000001b Time: 0.00356794
[03/01/2023-10:42:03] [V] [TRT] Tactic: 0x000000000000001f Time: 0.00297743
[03/01/2023-10:42:03] [V] [TRT] Fastest Tactic: 0x000000000000001f Time: 0.00297743
[03/01/2023-10:42:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWise)
[03/01/2023-10:42:03] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:42:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001f
[03/01/2023-10:42:03] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWiseV2)
[03/01/2023-10:42:03] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.00303238
[03/01/2023-10:42:03] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.00318578
[03/01/2023-10:42:03] [V] [TRT] Tactic: 0x000000000000001a Time: 0.00323423
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0x000000000000001b Time: 0.00352513
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0x000000000000001f Time: 0.0029467
[03/01/2023-10:42:04] [V] [TRT] Fastest Tactic: 0x000000000000001f Time: 0.0029467
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWise)
[03/01/2023-10:42:04] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001f
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_340, Sigmoid_341), Mul_342) (PointWiseV2)
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00312268
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0x000000000000001d Time: 0.00295258
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0x000000000000001e Time: 0.00287269
[03/01/2023-10:42:04] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 0.00287269
[03/01/2023-10:42:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(18432,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1), Float(128,1,1,1), Float(1152,9,3,1) -> Float(1152,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(18432,1,6144,2048) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128), Float(128,1,128,128), Float(1152,1,384,128) -> Float(1152,1,384,128) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(4608,1:4,1536,512) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32), Float(32,1:4,32,32), Float(288,1:4,96,32) -> Float(288,1:4,96,32) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(576,9:32,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1), Float(4,1:32,1,1), Float(36,9:32,3,1) -> Float(36,9:32,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) long-strided ***************
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,9,3,1) -> Float(1:4,9,3,1) ***************
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(6144,16,4,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_119 (TiledPooling)
[03/01/2023-10:42:04] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_119 (CudnnPooling)
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.00449843
[03/01/2023-10:42:04] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.00449843
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_119 (CaskPooling)
[03/01/2023-10:42:04] [V] [TRT] GlobalAveragePool_119 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average_FastDiv Tactic: 0x933eceba7b866d59
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0x933eceba7b866d59 Time: 0.00360229
[03/01/2023-10:42:04] [V] [TRT] GlobalAveragePool_119 Set Tactic Name: sm50_xmma_pooling_nd_NCDHW_kAVERAGE_kGENERIC_3D_POOLING_MODE_kFLOAT_0 Tactic: 0xba33c80addb15739
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0xba33c80addb15739 Time: 0.00364583
[03/01/2023-10:42:04] [V] [TRT] Fastest Tactic: 0x933eceba7b866d59 Time: 0.00360229
[03/01/2023-10:42:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x933eceba7b866d59
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Float(1536,1:4,384,96) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_119 (CaskPooling)
[03/01/2023-10:42:04] [V] [TRT] GlobalAveragePool_119 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NHWC_Average_FastDiv_CAlign4 Tactic: 0xfab3e2ee1c085a9a
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0xfab3e2ee1c085a9a Time: 0.00335819
[03/01/2023-10:42:04] [V] [TRT] Fastest Tactic: 0xfab3e2ee1c085a9a Time: 0.00335819
[03/01/2023-10:42:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0xfab3e2ee1c085a9a
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Int8(1536,16:4,4,1) -> Int8(96,1:4,1,1) ***************
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: MaxPool_147 (TiledPooling)
[03/01/2023-10:42:04] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: MaxPool_147 (CudaPooling)
[03/01/2023-10:42:04] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: MaxPool_147 (CaskPooling)
[03/01/2023-10:42:04] [V] [TRT] MaxPool_147 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0x1f6c40e3e09ec730 Time: 0.00347244
[03/01/2023-10:42:04] [V] [TRT] Fastest Tactic: 0x1f6c40e3e09ec730 Time: 0.00347244
[03/01/2023-10:42:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Int8(192,16:32,4,1) -> Int8(12,1:32,1,1) ***************
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: MaxPool_147 (TiledPooling)
[03/01/2023-10:42:04] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: MaxPool_147 (CudaPooling)
[03/01/2023-10:42:04] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: MaxPool_147 (CaskPooling)
[03/01/2023-10:42:04] [V] [TRT] MaxPool_147 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:04] [V] [TRT] Tactic: 0x94215b398b8eb3ba Time: 0.0042119
[03/01/2023-10:42:04] [V] [TRT] Fastest Tactic: 0x94215b398b8eb3ba Time: 0.0042119
[03/01/2023-10:42:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:04] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Int8(384,1,1,1) -> Int8(24,1,1,1) ***************
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CaskFlattenConvolution)
[03/01/2023-10:42:04] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CaskConvolution)
[03/01/2023-10:42:04] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] *************** Autotuning format combination: Int8(96,1:4,1,1) -> Int8(6,1:4,1,1) ***************
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CudaDepthwiseConvolution)
[03/01/2023-10:42:04] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (FusedConvActConvolution)
[03/01/2023-10:42:04] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:04] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CaskFlattenConvolution)
[03/01/2023-10:42:04] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0156672
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0152283
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0208372
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0209398
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0144384
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.0151854
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.013578
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.0138041
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0139237
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0164815
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.0206054
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0149797
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x8a10449e6d8c189c Time: 0.013578
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(96,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.016254
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0150674
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0155063
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0147753
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0207935
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.02048
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.0136179
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0137908
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.0134184
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0207726
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0142562
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.0150235
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0134184
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(12,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CudaGroupConvolution)
[03/01/2023-10:42:05] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CudaDepthwiseConvolution)
[03/01/2023-10:42:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (FusedConvActConvolution)
[03/01/2023-10:42:05] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2640501019a61dc2 Time: 0.00607086
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6106e2811713d7ee Time: 0.0088718
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.00718263
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.00990842
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xcddae68de84cc6ee Time: 0.00542882
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb3718d2455749f91 Time: 0.00577554
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.00903314
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x79a4e52543793dbe Time: 0.00731429
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb14c1f9154f6db4e Time: 0.00693812
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00746057
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.00605219
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x764ba04bb839d539 Time: 0.00689589
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.00644293
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00863086
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x3912ca79eb9a8be1 Time: 0.00613181
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x179c6422445ceb76 Time: 0.00711902
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5947ea3454b6a27b Time: 0.00872551
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00595109
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00595505
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0107729
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x58e405fffd827823 Time: 0.00720457
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x15fad4362e913239 Time: 0.00707744
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xfa5f2e15625aa266 Time: 0.00599162
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x65920facc9ae819d Time: 0.00731428
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x4b8c9beb00181107 Time: 0.00697295
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x7247cc5dea3981f1 Time: 0.0131258
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xdfdddae7a4bcc830 Time: 0.0129463
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xffb9fbd2bfa6c47d Time: 0.00639205
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x01bc9ada86b72c5f Time: 0.0105326
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0066693
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x599d6bb582ecb830 Time: 0.00625212
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00729966
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa5a7024b355e2bbc Time: 0.00595505
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xd25c9876338da5ac Time: 0.0103549
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.00756812
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xcae7b5888d47fe1f Time: 0.00591579
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xea7e3523ffa8ae75 Time: 0.0106266
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xfac85bfa6e8a95c6 Time: 0.00643657
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x18f10c3bd17f3940 Time: 0.00627756
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x881d70ee6f8bc650 Time: 0.00606476
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.00874272
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00668925
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0108983
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x70ff342513dcddd5 Time: 0.0127634
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0134192
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x596d7302ab180539 Time: 0.010334
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00642385
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00725577
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xfe7287378bfa0cc9 Time: 0.0130327
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xde3cb6dda9a9f049 Time: 0.00694509
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x932469cec5625217 Time: 0.00676239
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa9815e06b127c3d5 Time: 0.0104594
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xe56748b5b7870ba4 Time: 0.00864807
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x4f35593c356e2e7e Time: 0.00835454
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00785323
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc6627e11680191d5 Time: 0.0105639
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x3ffcb62b1c6bb94f Time: 0.00600991
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00534755
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00644293
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x53604f016bff6d61 Time: 0.0105744
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.005483
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0073216
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x311b82feb19aef19 Time: 0.00532047
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xf207dff9d0b58a85 Time: 0.00533672
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00710531
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00563763
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0132189
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0162052
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc22b2f91e37e472a Time: 0.00514612
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc29602984551b4e8 Time: 0.0133112
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00546133
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x596666386c88024b Time: 0.00556448
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x483ad1560c6e5e27 Time: 0.0053909
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x429236a031bfe3e7 Time: 0.00704958
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xed8f60f5aa2efd98 Time: 0.00551385
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0108669
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x716fcb85e712b30e Time: 0.0126777
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00548842
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x31de506085a332d4 Time: 0.00511478
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5314c155321a63a7 Time: 0.00672249
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x601b41d38fc4645b Time: 0.00841573
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5e4918ccf433630e Time: 0.00833829
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa086b8faeb42b254 Time: 0.00763765
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0110052
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb2cc5e08f6b66610 Time: 0.0103445
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x31de506085a332d4 Time: 0.00511478
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x31de506085a332d4
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(384,1,1,1) -> Int8(24,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161 (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161 (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(96,1:4,1,1) -> Int8(6,1:4,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(96,1:4,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(12,1:32,1,1) -> Int8(1,1:32,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(6,1:4,1,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 (CudaDepthwiseConvolution)
[03/01/2023-10:42:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.0100352
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0x14ef32afe5695907
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x14ef32afe5695907 Time: 0.00997669
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xfe80445f7bb61a99 Time: 0.00806197
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa4ae2d82115c3e83 Time: 0.00794819
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x4d9d0d03129bceb1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x4d9d0d03129bceb1 Time: 0.00815949
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xff6944b17d5b2e32 Time: 0.00840793
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.00840713
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu Tactic: 0xc073b0053ce90eac
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc073b0053ce90eac Time: 0.00608248
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x1db6e8cf1382fbe0
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x1db6e8cf1382fbe0 Time: 0.00992792
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x69c4e2ca38eadce2 Time: 0.00845876
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.00766845
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0xc25454de2efcccdc
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc25454de2efcccdc Time: 0.00824889
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.00794006
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0xc073b0053ce90eac Time: 0.00608248
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc073b0053ce90eac
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x733ba2a91a48d431
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x733ba2a91a48d431 Time: 0.00709834
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x5e4f6d7c83746fd6
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5e4f6d7c83746fd6 Time: 0.00763765
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0xf04572b287451f42
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xf04572b287451f42 Time: 0.00766845
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x733ba2a91a48d431 Time: 0.00709834
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x733ba2a91a48d431
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6d377e4222886190 Time: 0.00524114
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x991db9fd58152c33 Time: 0.00528196
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2468d082d0ff7c9a Time: 0.00522498
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x748f926574b7bdc4 Time: 0.00586313
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x1e55f8b415964e81
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x1e55f8b415964e81 Time: 0.00483231
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.00520882
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.00463941
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5f1a472d416ff35e Time: 0.00472317
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.00932514
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa71946688cad8664
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa71946688cad8664 Time: 0.0080386
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9ec201b34455146e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x9ec201b34455146e Time: 0.00769251
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb5f710b331ba8377 Time: 0.00780704
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x7720f198395e7d3d
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x7720f198395e7d3d Time: 0.0077914
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcd229658c16b33cd
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xcd229658c16b33cd Time: 0.00787633
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb86b920539eb9c79 Time: 0.00873412
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x960e9baa2a6cad5b
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x960e9baa2a6cad5b Time: 0.00713339
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6e9c17a33c93d9b0
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6e9c17a33c93d9b0 Time: 0.0079487
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x60b880e28fee7a0c
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x60b880e28fee7a0c Time: 0.00756836
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcf64a2ae51bf6b36
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xcf64a2ae51bf6b36 Time: 0.0071968
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x84942841d92b0552
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x84942841d92b0552 Time: 0.0073584
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdf7e1bd6a496d667
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xdf7e1bd6a496d667 Time: 0.00746788
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x8141573686849b61 Time: 0.00705698
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x91930a570b557437
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x91930a570b557437 Time: 0.00780704
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x3f2b14dec582741e Time: 0.00753804
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x33a5c6dd086942c1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x33a5c6dd086942c1 Time: 0.00755344
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xe742f4598442d2f1 Time: 0.00789269
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x445983715412fbda Time: 0.00766845
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x271b998fe31732ef
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x271b998fe31732ef Time: 0.0079647
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5bd8221bd57baf93
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5bd8221bd57baf93 Time: 0.00717486
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x65fbe45b4cb1d8a5
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x65fbe45b4cb1d8a5 Time: 0.00724754
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x844ea9c00f711f19
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x844ea9c00f711f19 Time: 0.00732868
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xbeb5d91e1874a437
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xbeb5d91e1874a437 Time: 0.00689633
[03/01/2023-10:42:05] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9003f5f7ff9b1aec
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x9003f5f7ff9b1aec Time: 0.00798883
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0xdc1f355deb032b87 Time: 0.00463941
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xdc1f355deb032b87
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(6,1:4,1,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(1,1:32,1,1) -> Float(12,1:32,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(384,1,1,1), Float(384,1,1,1), Float(6144,16,4,1) -> Float(6144,16,4,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_175, Sigmoid_176), Mul_177) (PointWiseV2)
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00376926
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00374822
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00384638
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0036725
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00389832
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00378454
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00378418
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00376878
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00377636
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00381522
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00381402
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.0036725
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_175, Sigmoid_176), Mul_177) (PointWise)
[03/01/2023-10:42:05] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000003
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(384,1,384,384), Float(384,1,384,384), Float(6144,1,1536,384) -> Float(6144,1,1536,384) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_175, Sigmoid_176), Mul_177) (PointWiseV2)
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00376602
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00376938
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00377648
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00379561
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00376914
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00380066
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00374377
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00378851
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00379609
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00385732
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001c Time: 0.003792
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x0000000000000006 Time: 0.00374377
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_175, Sigmoid_176), Mul_177) (PointWise)
[03/01/2023-10:42:05] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000006
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(96,1:4,96,96), Float(96,1:4,96,96), Float(1536,1:4,384,96) -> Float(1536,1:4,384,96) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_175, Sigmoid_176), Mul_177) (PointWiseV2)
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00383483
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.00380343
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.00474249
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.00386669
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.00533147
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.00666909
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.00660114
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.00650909
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.00546726
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.00535314
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000000a Time: 0.00547132
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000000b Time: 0.00411272
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000000c Time: 0.00394601
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000000d Time: 0.0038867
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000000e Time: 0.00401892
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000000f Time: 0.00442403
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000010 Time: 0.00418795
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000011 Time: 0.00490057
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000012 Time: 0.00568826
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000013 Time: 0.00435754
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.00389028
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000015 Time: 0.00412473
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000016 Time: 0.00416313
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000017 Time: 0.00413348
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00401117
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001d Time: 0.00380367
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001e Time: 0.00380752
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.00380343
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_175, Sigmoid_176), Mul_177) (PointWise)
[03/01/2023-10:42:05] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000001
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(12,1:32,1,1), Float(12,1:32,1,1), Float(192,16:32,4,1) -> Float(192,16:32,4,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_175, Sigmoid_176), Mul_177) (PointWiseV2)
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.00377744
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.0037766
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001a Time: 0.00378851
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001b Time: 0.00379994
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001f Time: 0.00608895
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x0000000000000019 Time: 0.0037766
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_175, Sigmoid_176), Mul_177) (PointWise)
[03/01/2023-10:42:05] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000019
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(1:4,1,1,1), Float(1:4,1,1,1), Float(1:4,16,4,1) -> Float(1:4,16,4,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(Add_175, Sigmoid_176), Mul_177) (PointWiseV2)
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001c Time: 0.00654469
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001d Time: 0.00637992
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x000000000000001e Time: 0.00616781
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 0.00616781
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(6144,16,4,1) -> Float(384,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(1536,1:4,384,96) -> Float(96,1:4,96,96) ***************
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(96,1:4,1,1) -> Float(6,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (CudaDepthwiseConvolution)
[03/01/2023-10:42:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.0209816
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0x14ef32afe5695907
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x14ef32afe5695907 Time: 0.0209202
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xfe80445f7bb61a99 Time: 0.0155072
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa4ae2d82115c3e83 Time: 0.0150821
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x4d9d0d03129bceb1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x4d9d0d03129bceb1 Time: 0.0141897
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xff6944b17d5b2e32 Time: 0.0141224
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.0153147
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu Tactic: 0xc073b0053ce90eac
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc073b0053ce90eac Time: 0.0062716
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x1db6e8cf1382fbe0
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x1db6e8cf1382fbe0 Time: 0.0207726
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x69c4e2ca38eadce2 Time: 0.0147749
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.016255
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0xc25454de2efcccdc
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc25454de2efcccdc Time: 0.01407
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.0152576
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0xc073b0053ce90eac Time: 0.0062716
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc073b0053ce90eac
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(12,1:32,1,1) -> Float(6,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x733ba2a91a48d431
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x733ba2a91a48d431 Time: 0.00508469
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x5e4f6d7c83746fd6
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5e4f6d7c83746fd6 Time: 0.00505963
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0xf04572b287451f42
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xf04572b287451f42 Time: 0.00675574
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x5e4f6d7c83746fd6 Time: 0.00505963
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x5e4f6d7c83746fd6
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(12,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6d377e4222886190 Time: 0.00494329
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x991db9fd58152c33 Time: 0.00797257
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2468d082d0ff7c9a Time: 0.00476434
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x748f926574b7bdc4 Time: 0.0115562
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x1e55f8b415964e81
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x1e55f8b415964e81 Time: 0.00738743
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.00895086
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.00540732
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5f1a472d416ff35e Time: 0.00543949
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.0072704
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa71946688cad8664
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa71946688cad8664 Time: 0.00516735
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9ec201b34455146e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x9ec201b34455146e Time: 0.00702171
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb5f710b331ba8377 Time: 0.0117366
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x7720f198395e7d3d
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x7720f198395e7d3d Time: 0.00773774
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcd229658c16b33cd
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xcd229658c16b33cd Time: 0.0114546
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb86b920539eb9c79 Time: 0.0080701
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x960e9baa2a6cad5b
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x960e9baa2a6cad5b Time: 0.00813536
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6e9c17a33c93d9b0
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6e9c17a33c93d9b0 Time: 0.00534755
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x60b880e28fee7a0c
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x60b880e28fee7a0c Time: 0.0113315
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcf64a2ae51bf6b36
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xcf64a2ae51bf6b36 Time: 0.00496867
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x84942841d92b0552
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x84942841d92b0552 Time: 0.00770695
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdf7e1bd6a496d667
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xdf7e1bd6a496d667 Time: 0.00744549
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x8141573686849b61 Time: 0.00566031
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x91930a570b557437
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x91930a570b557437 Time: 0.0110952
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x3f2b14dec582741e Time: 0.00528114
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x33a5c6dd086942c1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x33a5c6dd086942c1 Time: 0.00519314
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xe742f4598442d2f1 Time: 0.00592128
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x445983715412fbda Time: 0.00521404
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x271b998fe31732ef
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x271b998fe31732ef Time: 0.00564888
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5bd8221bd57baf93
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5bd8221bd57baf93 Time: 0.00512555
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x65fbe45b4cb1d8a5
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x65fbe45b4cb1d8a5 Time: 0.00512
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x844ea9c00f711f19
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x844ea9c00f711f19 Time: 0.00548284
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xbeb5d91e1874a437
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xbeb5d91e1874a437 Time: 0.00727771
[03/01/2023-10:42:05] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9003f5f7ff9b1aec
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x9003f5f7ff9b1aec Time: 0.0111852
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x2468d082d0ff7c9a Time: 0.00476434
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x2468d082d0ff7c9a
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(18432,9,3,1) -> Float(2048,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_2593 (TiledPooling)
[03/01/2023-10:42:05] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_2593 (CudnnPooling)
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.00482316
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.00482316
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_2593 (CaskPooling)
[03/01/2023-10:42:05] [V] [TRT] GlobalAveragePool_2593 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x964fa580cb69303d Time: 0.00362789
[03/01/2023-10:42:05] [V] [TRT] GlobalAveragePool_2593 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_custom_tP8_tQ16_tRS3_tUV1 Tactic: 0x9b99afa516385d34
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x9b99afa516385d34 Time: 0.00549644
[03/01/2023-10:42:05] [V] [TRT] GlobalAveragePool_2593 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average_FastDiv Tactic: 0x933eceba7b866d59
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x933eceba7b866d59 Time: 0.00576951
[03/01/2023-10:42:05] [V] [TRT] GlobalAveragePool_2593 Set Tactic Name: sm50_xmma_pooling_nd_NCDHW_kAVERAGE_kGENERIC_3D_POOLING_MODE_kFLOAT_0 Tactic: 0xba33c80addb15739
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xba33c80addb15739 Time: 0.00566031
[03/01/2023-10:42:05] [V] [TRT] GlobalAveragePool_2593 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_custom_tP4_tQ32_tRS3_tUV1 Tactic: 0x8819e020387dbf3c
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x8819e020387dbf3c Time: 0.00581047
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x964fa580cb69303d Time: 0.00362789
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(4608,1:4,1536,512) -> Float(512,1:4,512,512) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_2593 (CaskPooling)
[03/01/2023-10:42:05] [V] [TRT] GlobalAveragePool_2593 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NHWC_Average_FastDiv_CAlign4 Tactic: 0xfab3e2ee1c085a9a
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xfab3e2ee1c085a9a Time: 0.00581632
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0xfab3e2ee1c085a9a Time: 0.00581632
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0xfab3e2ee1c085a9a
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(6,1,1,1) -> Float(6,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: copied_squeeze_after_(Unnamed Layer* 203) [ElementWise] (Shuffle)
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00531539
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0189623
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00531539
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(512,1:4,1,1) -> Float(6,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] (CudaDepthwiseConvolution)
[03/01/2023-10:42:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.0785554
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0x14ef32afe5695907
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x14ef32afe5695907 Time: 0.0789943
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xfe80445f7bb61a99 Time: 0.0553448
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa4ae2d82115c3e83 Time: 0.0536381
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x4d9d0d03129bceb1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x4d9d0d03129bceb1 Time: 0.0472137
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xff6944b17d5b2e32 Time: 0.04608
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.0527116
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu Tactic: 0xc073b0053ce90eac
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc073b0053ce90eac Time: 0.00691723
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x1db6e8cf1382fbe0
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x1db6e8cf1382fbe0 Time: 0.077824
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x69c4e2ca38eadce2 Time: 0.0497371
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.0587581
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0xc25454de2efcccdc
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xc25454de2efcccdc Time: 0.0466651
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.0520777
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0xc073b0053ce90eac Time: 0.00691723
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc073b0053ce90eac
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(64,1:32,1,1) -> Float(6,1,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x733ba2a91a48d431
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x733ba2a91a48d431 Time: 0.00938057
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x5e4f6d7c83746fd6
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5e4f6d7c83746fd6 Time: 0.00901457
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0xf04572b287451f42
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xf04572b287451f42 Time: 0.0138307
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x5e4f6d7c83746fd6 Time: 0.00901457
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x5e4f6d7c83746fd6
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Int8(64,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] (CaskFlattenConvolution)
[03/01/2023-10:42:05] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[03/01/2023-10:42:05] [V] [TRT] --------------- Timing Runner: classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] (CaskConvolution)
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6d377e4222886190 Time: 0.00637933
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x991db9fd58152c33 Time: 0.0221936
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x2468d082d0ff7c9a Time: 0.00748251
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x748f926574b7bdc4 Time: 0.0400823
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x1e55f8b415964e81
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x1e55f8b415964e81 Time: 0.0216503
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.0256244
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.0111627
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5f1a472d416ff35e Time: 0.00995718
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.0186686
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa71946688cad8664
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xa71946688cad8664 Time: 0.008192
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9ec201b34455146e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x9ec201b34455146e Time: 0.00790809
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb5f710b331ba8377 Time: 0.0403017
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x7720f198395e7d3d
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x7720f198395e7d3d Time: 0.0125196
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcd229658c16b33cd
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xcd229658c16b33cd Time: 0.0400091
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xb86b920539eb9c79 Time: 0.0219011
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x960e9baa2a6cad5b
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x960e9baa2a6cad5b Time: 0.00815949
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6e9c17a33c93d9b0
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x6e9c17a33c93d9b0 Time: 0.0125078
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x60b880e28fee7a0c
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x60b880e28fee7a0c Time: 0.0398263
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcf64a2ae51bf6b36
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xcf64a2ae51bf6b36 Time: 0.00702171
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x84942841d92b0552
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x84942841d92b0552 Time: 0.0219429
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdf7e1bd6a496d667
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xdf7e1bd6a496d667 Time: 0.0217548
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x8141573686849b61 Time: 0.0127756
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x91930a570b557437
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x91930a570b557437 Time: 0.0396434
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x3f2b14dec582741e Time: 0.00905143
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x33a5c6dd086942c1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x33a5c6dd086942c1 Time: 0.00800508
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xe742f4598442d2f1 Time: 0.0130469
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x445983715412fbda Time: 0.00724091
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x271b998fe31732ef
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x271b998fe31732ef Time: 0.0127627
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5bd8221bd57baf93
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x5bd8221bd57baf93 Time: 0.00639284
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x65fbe45b4cb1d8a5
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x65fbe45b4cb1d8a5 Time: 0.00689633
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x844ea9c00f711f19
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x844ea9c00f711f19 Time: 0.0120808
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xbeb5d91e1874a437
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0xbeb5d91e1874a437 Time: 0.0205002
[03/01/2023-10:42:05] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9003f5f7ff9b1aec
[03/01/2023-10:42:05] [V] [TRT] Tactic: 0x9003f5f7ff9b1aec Time: 0.037888
[03/01/2023-10:42:05] [V] [TRT] Fastest Tactic: 0x6d377e4222886190 Time: 0.00637933
[03/01/2023-10:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x6d377e4222886190
[03/01/2023-10:42:05] [V] [TRT] =============== Computing costs for 
[03/01/2023-10:42:05] [V] [TRT] *************** Autotuning format combination: Float(6,1,1,1) -> Float(6,1) ***************
[03/01/2023-10:42:05] [I] [TRT] [GraphReduction] The approximate region cut reduction algorithm is called.
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (398) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326 (426) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447 (547) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475 (575) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597 (697) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625 (725) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747 (847) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775 (875) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897 (997) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925 (1025) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047 (1147) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075 (1175) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197 (1297) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225 (1325) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347 (1447) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497 (1597) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647 (1747) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675 (1775) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797 (1897) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825 (1925) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947 (2047) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975 (2075) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097 (2197) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125 (2225) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247 (2347) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275 (2375) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397 (2497) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425 (2525) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547 (2647) from Int8(128,1,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575 (2675) from Int8(32,1:4,1,1) to Int8(4,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_340, Sigmoid_341), Mul_342) (422) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_340, Sigmoid_341), Mul_342) (450) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_489, Sigmoid_490), Mul_491) (571) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_489, Sigmoid_490), Mul_491) (599) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_639, Sigmoid_640), Mul_641) (721) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_639, Sigmoid_640), Mul_641) (749) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_789, Sigmoid_790), Mul_791) (871) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_789, Sigmoid_790), Mul_791) (899) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_939, Sigmoid_940), Mul_941) (1021) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_939, Sigmoid_940), Mul_941) (1049) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091) (1171) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091) (1199) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241) (1321) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241) (1349) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391) (1471) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391) (1499) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541) (1621) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541) (1649) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691) (1771) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691) (1799) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841) (1921) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841) (1949) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991) (2071) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991) (2099) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141) (2221) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141) (2249) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291) (2371) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291) (2399) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441) (2521) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441) (2549) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591) (2671) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591) (2699) from Float(4,1:32,1,1) to Float(128,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (233) from Int8(384,1,1,1) to Int8(12,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161 (261) from Int8(96,1:4,1,1) to Int8(12,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Add_175, Sigmoid_176), Mul_177) (257) from Float(12,1:32,1,1) to Float(384,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Add_175, Sigmoid_176), Mul_177) (285) from Float(12,1:32,1,1) to Float(384,1,1,1)
[03/01/2023-10:42:05] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (291) from Int8(96,1:4,1,1) to Int8(12,1:32,1,1)
[03/01/2023-10:42:05] [V] [TRT] Formats and tactics selection completed in 40.7386 seconds.
[03/01/2023-10:42:05] [V] [TRT] After reformat layers: 474 layers
[03/01/2023-10:42:05] [V] [TRT] Total number of blocks in pre-optimized block assignment: 440
[03/01/2023-10:42:05] [I] [TRT] Total Activation Memory: 8593210880
[03/01/2023-10:42:05] [I] [TRT] Detected 1 inputs and 2 output network tensors.
[03/01/2023-10:42:05] [V] [TRT] conv1.0.weight + QuantizeLinear_8 + Conv_12 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_1 + QuantizeLinear_361 + Conv_365 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_2 + QuantizeLinear_511 + Conv_515 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_3 + QuantizeLinear_661 + Conv_665 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_4 + QuantizeLinear_811 + Conv_815 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_5 + QuantizeLinear_961 + Conv_965 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_6 + QuantizeLinear_1111 + Conv_1115 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_7 + QuantizeLinear_1261 + Conv_1265 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_8 + QuantizeLinear_1411 + Conv_1415 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_9 + QuantizeLinear_1561 + Conv_1565 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_10 + QuantizeLinear_1711 + Conv_1715 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_11 + QuantizeLinear_1861 + Conv_1865 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_12 + QuantizeLinear_2011 + Conv_2015 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_13 + QuantizeLinear_2161 + Conv_2165 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_14 + QuantizeLinear_2311 + Conv_2315 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv4.0.weight_clone_15 + QuantizeLinear_2461 + Conv_2465 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[03/01/2023-10:42:05] [V] [TRT] conv1.3.weight + QuantizeLinear_23 + Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_1 + QuantizeLinear_376 + Conv_380 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_2 + QuantizeLinear_526 + Conv_530 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_3 + QuantizeLinear_676 + Conv_680 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_4 + QuantizeLinear_826 + Conv_830 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_5 + QuantizeLinear_976 + Conv_980 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_6 + QuantizeLinear_1126 + Conv_1130 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_7 + QuantizeLinear_1276 + Conv_1280 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_8 + QuantizeLinear_1426 + Conv_1430 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:05] [V] [TRT] conv4.3.weight_clone_9 + QuantizeLinear_1576 + Conv_1580 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:06] [V] [TRT] conv4.3.weight_clone_10 + QuantizeLinear_1726 + Conv_1730 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:06] [V] [TRT] conv4.3.weight_clone_11 + QuantizeLinear_1876 + Conv_1880 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:06] [V] [TRT] conv4.3.weight_clone_12 + QuantizeLinear_2026 + Conv_2030 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:06] [V] [TRT] conv4.3.weight_clone_13 + QuantizeLinear_2176 + Conv_2180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:06] [V] [TRT] conv4.3.weight_clone_14 + QuantizeLinear_2326 + Conv_2330 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:06] [V] [TRT] conv4.3.weight_clone_15 + QuantizeLinear_2476 + Conv_2480 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[03/01/2023-10:42:06] [V] [TRT] MaxPool_30 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_234 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_383 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_533 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_683 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_833 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_983 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1133 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1283 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1433 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1583 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1733 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1883 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2033 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2183 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2333 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2483 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] conv2.0.weight + QuantizeLinear_39 + Conv_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_1 + QuantizeLinear_392 + Conv_396 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_2 + QuantizeLinear_542 + Conv_546 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_3 + QuantizeLinear_692 + Conv_696 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_4 + QuantizeLinear_842 + Conv_846 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_5 + QuantizeLinear_992 + Conv_996 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_6 + QuantizeLinear_1142 + Conv_1146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_7 + QuantizeLinear_1292 + Conv_1296 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_8 + QuantizeLinear_1442 + Conv_1446 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_9 + QuantizeLinear_1592 + Conv_1596 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_10 + QuantizeLinear_1742 + Conv_1746 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_11 + QuantizeLinear_1892 + Conv_1896 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_12 + QuantizeLinear_2042 + Conv_2046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_13 + QuantizeLinear_2192 + Conv_2196 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_14 + QuantizeLinear_2342 + Conv_2346 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv5.0.weight_clone_15 + QuantizeLinear_2492 + Conv_2496 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] conv2.3.weight + QuantizeLinear_54 + Conv_58 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_1 + QuantizeLinear_407 + Conv_411 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_2 + QuantizeLinear_557 + Conv_561 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_3 + QuantizeLinear_707 + Conv_711 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_4 + QuantizeLinear_857 + Conv_861 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_5 + QuantizeLinear_1007 + Conv_1011 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_6 + QuantizeLinear_1157 + Conv_1161 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_7 + QuantizeLinear_1307 + Conv_1311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_8 + QuantizeLinear_1457 + Conv_1461 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_9 + QuantizeLinear_1607 + Conv_1611 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_10 + QuantizeLinear_1757 + Conv_1761 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_11 + QuantizeLinear_1907 + Conv_1911 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_12 + QuantizeLinear_2057 + Conv_2061 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_13 + QuantizeLinear_2207 + Conv_2211 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_14 + QuantizeLinear_2357 + Conv_2361 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] conv5.3.weight_clone_15 + QuantizeLinear_2507 + Conv_2511 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] MaxPool_61 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ16_tR2_tS2_tU2_tV2_tUnroll1_tThreads128 Tactic: 0x53862c46aa5b4c2b
[03/01/2023-10:42:06] [V] [TRT] MaxPool_265 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_414 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_564 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_714 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_864 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1014 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1164 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1314 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1464 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1614 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1764 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1914 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2064 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2214 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2364 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2514 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll6_tThreads256 Tactic: 0x60eceb67eff69444
[03/01/2023-10:42:06] [V] [TRT] conv3.0.weight + QuantizeLinear_77 + Conv_81 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_1 + QuantizeLinear_426 + Conv_430 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_2 + QuantizeLinear_576 + Conv_580 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_3 + QuantizeLinear_726 + Conv_730 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_4 + QuantizeLinear_876 + Conv_880 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_5 + QuantizeLinear_1026 + Conv_1030 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_6 + QuantizeLinear_1176 + Conv_1180 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_7 + QuantizeLinear_1326 + Conv_1330 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_8 + QuantizeLinear_1476 + Conv_1480 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_9 + QuantizeLinear_1626 + Conv_1630 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_10 + QuantizeLinear_1776 + Conv_1780 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_11 + QuantizeLinear_1926 + Conv_1930 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_12 + QuantizeLinear_2076 + Conv_2080 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_13 + QuantizeLinear_2226 + Conv_2230 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_14 + QuantizeLinear_2376 + Conv_2380 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] patchattention_spatial.conv1.weight_clone_15 + QuantizeLinear_2526 + Conv_2530 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] conv3.3.weight + QuantizeLinear_92 + Conv_96 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_alignc4 Tactic: 0x85c1a5f7f239cf84
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_284 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_433 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_583 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_733 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_883 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_1033 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_1183 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_1333 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_1483 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_1633 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_1783 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_1933 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_2083 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_2233 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_2383 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_2533 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] MaxPool_312 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_461 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_611 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_761 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_911 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1061 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1211 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1361 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1511 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1661 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1811 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_1961 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2111 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2261 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2411 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_2561 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] MaxPool_99 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kMAX_tP2_tQ32_tR2_tS2_tU2_tV2_tUnroll7_tThreads256 Tactic: 0xbd4519190f75e7e9
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_15 + QuantizeLinear_1370 + Conv_1374 + Relu_1375 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_17 + QuantizeLinear_1520 + Conv_1524 + Relu_1525 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_1 + QuantizeLinear_335 + Conv_339 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_2 + QuantizeLinear_456 + Conv_460 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_3 + QuantizeLinear_484 + Conv_488 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_4 + QuantizeLinear_606 + Conv_610 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_5 + QuantizeLinear_634 + Conv_638 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_6 + QuantizeLinear_756 + Conv_760 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_7 + QuantizeLinear_784 + Conv_788 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_8 + QuantizeLinear_906 + Conv_910 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_9 + QuantizeLinear_934 + Conv_938 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_10 + QuantizeLinear_1056 + Conv_1060 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_11 + QuantizeLinear_1084 + Conv_1088 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_12 + QuantizeLinear_1206 + Conv_1210 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_13 + QuantizeLinear_1234 + Conv_1238 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_14 + QuantizeLinear_1356 + Conv_1360 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_15 + QuantizeLinear_1384 + Conv_1388 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_16 + QuantizeLinear_1506 + Conv_1510 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_17 + QuantizeLinear_1534 + Conv_1538 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_18 + QuantizeLinear_1656 + Conv_1660 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_19 + QuantizeLinear_1684 + Conv_1688 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_20 + QuantizeLinear_1806 + Conv_1810 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_21 + QuantizeLinear_1834 + Conv_1838 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_22 + QuantizeLinear_1956 + Conv_1960 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_23 + QuantizeLinear_1984 + Conv_1988 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_24 + QuantizeLinear_2106 + Conv_2110 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_25 + QuantizeLinear_2134 + Conv_2138 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_26 + QuantizeLinear_2256 + Conv_2260 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_27 + QuantizeLinear_2284 + Conv_2288 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_28 + QuantizeLinear_2406 + Conv_2410 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_29 + QuantizeLinear_2434 + Conv_2438 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_30 + QuantizeLinear_2556 + Conv_2560 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] patchattention_channel.fc.2.weight_clone_31 + QuantizeLinear_2584 + Conv_2588 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[03/01/2023-10:42:06] [V] [TRT] attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0x1b0534177b414e71
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_119 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average_FastDiv Tactic: 0x933eceba7b866d59
[03/01/2023-10:42:06] [V] [TRT] MaxPool_147 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730
[03/01/2023-10:42:06] [V] [TRT] attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4
[03/01/2023-10:42:06] [V] [TRT] attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4
[03/01/2023-10:42:06] [V] [TRT] attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:42:06] [V] [TRT] attention_channel.fc.2.weight_clone_1 + QuantizeLinear_170 + Conv_174 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_178 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average_FastDiv Tactic: 0x933eceba7b866d59
[03/01/2023-10:42:06] [V] [TRT] classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x5e4f6d7c83746fd6
[03/01/2023-10:42:06] [V] [TRT] GlobalAveragePool_2593 Set Tactic Name: sm50_xmma_pooling_tiled_FP32NCHW_kAVERAGE_tP1_tQ1_tR3_tS3_tU1_tV1_tUnroll1_tThreads9 Tactic: 0x964fa580cb69303d
[03/01/2023-10:42:06] [V] [TRT] classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set Tactic Name: sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu Tactic: 0xc073b0053ce90eac
[03/01/2023-10:42:06] [V] [TRT] Layer: conv1.0.weight + QuantizeLinear_8 + Conv_12 Host Persistent: 3200 Device Persistent: 20480 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_1 + QuantizeLinear_361 + Conv_365 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_2 + QuantizeLinear_511 + Conv_515 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_3 + QuantizeLinear_661 + Conv_665 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_4 + QuantizeLinear_811 + Conv_815 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_5 + QuantizeLinear_961 + Conv_965 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_6 + QuantizeLinear_1111 + Conv_1115 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_7 + QuantizeLinear_1261 + Conv_1265 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_8 + QuantizeLinear_1411 + Conv_1415 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_9 + QuantizeLinear_1561 + Conv_1565 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_10 + QuantizeLinear_1711 + Conv_1715 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_11 + QuantizeLinear_1861 + Conv_1865 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_12 + QuantizeLinear_2011 + Conv_2015 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_13 + QuantizeLinear_2161 + Conv_2165 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_14 + QuantizeLinear_2311 + Conv_2315 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.0.weight_clone_15 + QuantizeLinear_2461 + Conv_2465 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv1.3.weight + QuantizeLinear_23 + Conv_27 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_1 + QuantizeLinear_376 + Conv_380 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_2 + QuantizeLinear_526 + Conv_530 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_3 + QuantizeLinear_676 + Conv_680 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_4 + QuantizeLinear_826 + Conv_830 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_5 + QuantizeLinear_976 + Conv_980 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_6 + QuantizeLinear_1126 + Conv_1130 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_7 + QuantizeLinear_1276 + Conv_1280 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_8 + QuantizeLinear_1426 + Conv_1430 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_9 + QuantizeLinear_1576 + Conv_1580 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_10 + QuantizeLinear_1726 + Conv_1730 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_11 + QuantizeLinear_1876 + Conv_1880 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_12 + QuantizeLinear_2026 + Conv_2030 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_13 + QuantizeLinear_2176 + Conv_2180 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_14 + QuantizeLinear_2326 + Conv_2330 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv4.3.weight_clone_15 + QuantizeLinear_2476 + Conv_2480 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_30 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_234 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_383 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_533 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_683 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_833 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_983 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1133 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1283 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1433 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1583 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1733 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1883 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2033 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2183 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2333 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2483 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv2.0.weight + QuantizeLinear_39 + Conv_43 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_1 + QuantizeLinear_392 + Conv_396 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_2 + QuantizeLinear_542 + Conv_546 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_3 + QuantizeLinear_692 + Conv_696 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_4 + QuantizeLinear_842 + Conv_846 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_5 + QuantizeLinear_992 + Conv_996 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_6 + QuantizeLinear_1142 + Conv_1146 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_7 + QuantizeLinear_1292 + Conv_1296 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_8 + QuantizeLinear_1442 + Conv_1446 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_9 + QuantizeLinear_1592 + Conv_1596 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_10 + QuantizeLinear_1742 + Conv_1746 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_11 + QuantizeLinear_1892 + Conv_1896 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_12 + QuantizeLinear_2042 + Conv_2046 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_13 + QuantizeLinear_2192 + Conv_2196 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_14 + QuantizeLinear_2342 + Conv_2346 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.0.weight_clone_15 + QuantizeLinear_2492 + Conv_2496 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv2.3.weight + QuantizeLinear_54 + Conv_58 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_1 + QuantizeLinear_407 + Conv_411 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_2 + QuantizeLinear_557 + Conv_561 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_3 + QuantizeLinear_707 + Conv_711 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_4 + QuantizeLinear_857 + Conv_861 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_5 + QuantizeLinear_1007 + Conv_1011 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_6 + QuantizeLinear_1157 + Conv_1161 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_7 + QuantizeLinear_1307 + Conv_1311 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_8 + QuantizeLinear_1457 + Conv_1461 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_9 + QuantizeLinear_1607 + Conv_1611 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_10 + QuantizeLinear_1757 + Conv_1761 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_11 + QuantizeLinear_1907 + Conv_1911 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_12 + QuantizeLinear_2057 + Conv_2061 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_13 + QuantizeLinear_2207 + Conv_2211 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_14 + QuantizeLinear_2357 + Conv_2361 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv5.3.weight_clone_15 + QuantizeLinear_2507 + Conv_2511 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_61 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_265 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_414 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_564 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_714 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_864 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1014 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1164 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1314 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1464 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1614 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1764 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1914 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2064 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2214 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2364 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2514 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv3.0.weight + QuantizeLinear_77 + Conv_81 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_1 + QuantizeLinear_426 + Conv_430 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_2 + QuantizeLinear_576 + Conv_580 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_3 + QuantizeLinear_726 + Conv_730 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_4 + QuantizeLinear_876 + Conv_880 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_5 + QuantizeLinear_1026 + Conv_1030 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_6 + QuantizeLinear_1176 + Conv_1180 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_7 + QuantizeLinear_1326 + Conv_1330 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_8 + QuantizeLinear_1476 + Conv_1480 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_9 + QuantizeLinear_1626 + Conv_1630 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_10 + QuantizeLinear_1776 + Conv_1780 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_11 + QuantizeLinear_1926 + Conv_1930 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_12 + QuantizeLinear_2076 + Conv_2080 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_13 + QuantizeLinear_2226 + Conv_2230 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_14 + QuantizeLinear_2376 + Conv_2380 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_spatial.conv1.weight_clone_15 + QuantizeLinear_2526 + Conv_2530 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: conv3.3.weight + QuantizeLinear_92 + Conv_96 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_282, Mul_283) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_431, Mul_432) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_581, Mul_582) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_731, Mul_732) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_881, Mul_882) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_1031, Mul_1032) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_1181, Mul_1182) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_1331, Mul_1332) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_1481, Mul_1482) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_1631, Mul_1632) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_1781, Mul_1782) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_1931, Mul_1932) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_2081, Mul_2082) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_2231, Mul_2232) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_2381, Mul_2382) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_2531, Mul_2532) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_284 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_433 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_583 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_733 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_883 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_1033 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_1183 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_1333 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_1483 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_1633 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_1783 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_1933 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_2083 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_2233 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_2383 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_2533 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_312 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_461 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_611 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_761 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_911 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1061 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1211 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1361 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1511 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1661 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1811 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_1961 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2111 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2261 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2411 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_2561 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_99 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_15 + QuantizeLinear_1370 + Conv_1374 + Relu_1375 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_17 + QuantizeLinear_1520 + Conv_1524 + Relu_1525 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_1 + QuantizeLinear_335 + Conv_339 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_2 + QuantizeLinear_456 + Conv_460 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_3 + QuantizeLinear_484 + Conv_488 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_4 + QuantizeLinear_606 + Conv_610 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_5 + QuantizeLinear_634 + Conv_638 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_6 + QuantizeLinear_756 + Conv_760 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_7 + QuantizeLinear_784 + Conv_788 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_8 + QuantizeLinear_906 + Conv_910 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_9 + QuantizeLinear_934 + Conv_938 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_10 + QuantizeLinear_1056 + Conv_1060 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_11 + QuantizeLinear_1084 + Conv_1088 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_12 + QuantizeLinear_1206 + Conv_1210 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_13 + QuantizeLinear_1234 + Conv_1238 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_14 + QuantizeLinear_1356 + Conv_1360 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_15 + QuantizeLinear_1384 + Conv_1388 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_16 + QuantizeLinear_1506 + Conv_1510 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_17 + QuantizeLinear_1534 + Conv_1538 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_18 + QuantizeLinear_1656 + Conv_1660 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_19 + QuantizeLinear_1684 + Conv_1688 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_20 + QuantizeLinear_1806 + Conv_1810 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_21 + QuantizeLinear_1834 + Conv_1838 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_22 + QuantizeLinear_1956 + Conv_1960 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_23 + QuantizeLinear_1984 + Conv_1988 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_24 + QuantizeLinear_2106 + Conv_2110 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_25 + QuantizeLinear_2134 + Conv_2138 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_26 + QuantizeLinear_2256 + Conv_2260 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_27 + QuantizeLinear_2284 + Conv_2288 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_28 + QuantizeLinear_2406 + Conv_2410 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_29 + QuantizeLinear_2434 + Conv_2438 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_30 + QuantizeLinear_2556 + Conv_2560 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: patchattention_channel.fc.2.weight_clone_31 + QuantizeLinear_2584 + Conv_2588 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Host Persistent: 4224 Device Persistent: 512 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(Sigmoid_117, Mul_118) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_340, Sigmoid_341), Mul_342) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_489, Sigmoid_490), Mul_491) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_639, Sigmoid_640), Mul_641) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_789, Sigmoid_790), Mul_791) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_939, Sigmoid_940), Mul_941) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_119 Host Persistent: 1408 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: MaxPool_147 Host Persistent: 1280 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Host Persistent: 2560 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: attention_channel.fc.2.weight_clone_1 + QuantizeLinear_170 + Conv_174 Host Persistent: 2560 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: PWN(PWN(Add_175, Sigmoid_176), Mul_177) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_178 Host Persistent: 1408 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: GlobalAveragePool_2593 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Layer: classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Host Persistent: 2880 Device Persistent: 0 Scratch Memory: 0
[03/01/2023-10:42:06] [V] [TRT] Skipped printing memory information for 212 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
[03/01/2023-10:42:06] [I] [TRT] Total Host Persistent Memory: 575264
[03/01/2023-10:42:06] [I] [TRT] Total Device Persistent Memory: 29184
[03/01/2023-10:42:06] [I] [TRT] Total Scratch Memory: 0
[03/01/2023-10:42:06] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 26 MiB, GPU 4 MiB
[03/01/2023-10:42:06] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 439 steps to complete.
[03/01/2023-10:42:06] [V] [TRT] STILL ALIVE: Started step 26 of 439
[03/01/2023-10:42:06] [V] [TRT] STILL ALIVE: Started step 151 of 439
[03/01/2023-10:42:06] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 179.167ms to assign 64 blocks to 439 nodes requiring 1132032 bytes.
[03/01/2023-10:42:06] [V] [TRT] Total number of blocks in optimized block assignment: 64
[03/01/2023-10:42:06] [I] [TRT] Total Activation Memory: 1132032
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv1.0.weight + QuantizeLinear_8 + Conv_12 Set kernel index: 0
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_1 + QuantizeLinear_361 + Conv_365 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_2 + QuantizeLinear_511 + Conv_515 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_3 + QuantizeLinear_661 + Conv_665 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_4 + QuantizeLinear_811 + Conv_815 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_5 + QuantizeLinear_961 + Conv_965 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_6 + QuantizeLinear_1111 + Conv_1115 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_7 + QuantizeLinear_1261 + Conv_1265 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_8 + QuantizeLinear_1411 + Conv_1415 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_9 + QuantizeLinear_1561 + Conv_1565 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_10 + QuantizeLinear_1711 + Conv_1715 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_11 + QuantizeLinear_1861 + Conv_1865 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_12 + QuantizeLinear_2011 + Conv_2015 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_13 + QuantizeLinear_2161 + Conv_2165 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_14 + QuantizeLinear_2311 + Conv_2315 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.0.weight_clone_15 + QuantizeLinear_2461 + Conv_2465 Set kernel index: 1
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv1.3.weight + QuantizeLinear_23 + Conv_27 Set kernel index: 2
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_1 + QuantizeLinear_376 + Conv_380 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_2 + QuantizeLinear_526 + Conv_530 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_3 + QuantizeLinear_676 + Conv_680 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_4 + QuantizeLinear_826 + Conv_830 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_5 + QuantizeLinear_976 + Conv_980 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_6 + QuantizeLinear_1126 + Conv_1130 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_7 + QuantizeLinear_1276 + Conv_1280 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_8 + QuantizeLinear_1426 + Conv_1430 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_9 + QuantizeLinear_1576 + Conv_1580 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_10 + QuantizeLinear_1726 + Conv_1730 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_11 + QuantizeLinear_1876 + Conv_1880 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_12 + QuantizeLinear_2026 + Conv_2030 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_13 + QuantizeLinear_2176 + Conv_2180 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_14 + QuantizeLinear_2326 + Conv_2330 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv4.3.weight_clone_15 + QuantizeLinear_2476 + Conv_2480 Set kernel index: 3
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_30 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_234 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_383 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_533 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_683 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_833 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_983 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1133 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1283 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1433 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1583 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1733 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1883 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2033 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2183 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2333 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2483 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv2.0.weight + QuantizeLinear_39 + Conv_43 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_1 + QuantizeLinear_392 + Conv_396 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_2 + QuantizeLinear_542 + Conv_546 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_3 + QuantizeLinear_692 + Conv_696 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_4 + QuantizeLinear_842 + Conv_846 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_5 + QuantizeLinear_992 + Conv_996 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_6 + QuantizeLinear_1142 + Conv_1146 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_7 + QuantizeLinear_1292 + Conv_1296 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_8 + QuantizeLinear_1442 + Conv_1446 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_9 + QuantizeLinear_1592 + Conv_1596 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_10 + QuantizeLinear_1742 + Conv_1746 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_11 + QuantizeLinear_1892 + Conv_1896 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_12 + QuantizeLinear_2042 + Conv_2046 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_13 + QuantizeLinear_2192 + Conv_2196 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_14 + QuantizeLinear_2342 + Conv_2346 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.0.weight_clone_15 + QuantizeLinear_2492 + Conv_2496 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv2.3.weight + QuantizeLinear_54 + Conv_58 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_1 + QuantizeLinear_407 + Conv_411 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_2 + QuantizeLinear_557 + Conv_561 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_3 + QuantizeLinear_707 + Conv_711 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_4 + QuantizeLinear_857 + Conv_861 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_5 + QuantizeLinear_1007 + Conv_1011 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_6 + QuantizeLinear_1157 + Conv_1161 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_7 + QuantizeLinear_1307 + Conv_1311 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_8 + QuantizeLinear_1457 + Conv_1461 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_9 + QuantizeLinear_1607 + Conv_1611 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_10 + QuantizeLinear_1757 + Conv_1761 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_11 + QuantizeLinear_1907 + Conv_1911 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_12 + QuantizeLinear_2057 + Conv_2061 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_13 + QuantizeLinear_2207 + Conv_2211 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_14 + QuantizeLinear_2357 + Conv_2361 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv5.3.weight_clone_15 + QuantizeLinear_2507 + Conv_2511 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_61 Set kernel index: 7
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_265 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_414 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_564 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_714 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_864 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1014 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1164 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1314 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1464 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1614 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1764 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1914 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2064 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2214 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2364 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2514 Set kernel index: 8
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv3.0.weight + QuantizeLinear_77 + Conv_81 Set kernel index: 5
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_1 + QuantizeLinear_426 + Conv_430 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_2 + QuantizeLinear_576 + Conv_580 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_3 + QuantizeLinear_726 + Conv_730 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_4 + QuantizeLinear_876 + Conv_880 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_5 + QuantizeLinear_1026 + Conv_1030 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_6 + QuantizeLinear_1176 + Conv_1180 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_7 + QuantizeLinear_1326 + Conv_1330 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_8 + QuantizeLinear_1476 + Conv_1480 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_9 + QuantizeLinear_1626 + Conv_1630 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_10 + QuantizeLinear_1776 + Conv_1780 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_11 + QuantizeLinear_1926 + Conv_1930 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_12 + QuantizeLinear_2076 + Conv_2080 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_13 + QuantizeLinear_2226 + Conv_2230 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_14 + QuantizeLinear_2376 + Conv_2380 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_spatial.conv1.weight_clone_15 + QuantizeLinear_2526 + Conv_2530 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: conv3.3.weight + QuantizeLinear_92 + Conv_96 Set kernel index: 6
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_282, Mul_283) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_431, Mul_432) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_581, Mul_582) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_731, Mul_732) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_881, Mul_882) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_1031, Mul_1032) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_1181, Mul_1182) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_1331, Mul_1332) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_1481, Mul_1482) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_1631, Mul_1632) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_1781, Mul_1782) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_1931, Mul_1932) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_2081, Mul_2082) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_2231, Mul_2232) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_2381, Mul_2382) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_2531, Mul_2532) Set kernel index: 10
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_284 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_433 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_583 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_733 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_883 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_1033 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_1183 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_1333 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_1483 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_1633 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_1783 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_1933 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_2083 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_2233 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_2383 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_2533 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_312 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_461 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_611 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_761 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_911 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1061 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1211 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1361 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1511 Set kernel index: 4
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1661 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1811 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_1961 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2111 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2261 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2411 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_2561 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_99 Set kernel index: 13
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_15 + QuantizeLinear_1370 + Conv_1374 + Relu_1375 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_17 + QuantizeLinear_1520 + Conv_1524 + Relu_1525 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575 Set kernel index: 14
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_1 + QuantizeLinear_335 + Conv_339 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_2 + QuantizeLinear_456 + Conv_460 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_3 + QuantizeLinear_484 + Conv_488 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_4 + QuantizeLinear_606 + Conv_610 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_5 + QuantizeLinear_634 + Conv_638 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_6 + QuantizeLinear_756 + Conv_760 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_7 + QuantizeLinear_784 + Conv_788 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_8 + QuantizeLinear_906 + Conv_910 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_9 + QuantizeLinear_934 + Conv_938 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_10 + QuantizeLinear_1056 + Conv_1060 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_11 + QuantizeLinear_1084 + Conv_1088 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_12 + QuantizeLinear_1206 + Conv_1210 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_13 + QuantizeLinear_1234 + Conv_1238 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_14 + QuantizeLinear_1356 + Conv_1360 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_15 + QuantizeLinear_1384 + Conv_1388 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_16 + QuantizeLinear_1506 + Conv_1510 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_17 + QuantizeLinear_1534 + Conv_1538 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_18 + QuantizeLinear_1656 + Conv_1660 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_19 + QuantizeLinear_1684 + Conv_1688 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_20 + QuantizeLinear_1806 + Conv_1810 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_21 + QuantizeLinear_1834 + Conv_1838 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_22 + QuantizeLinear_1956 + Conv_1960 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_23 + QuantizeLinear_1984 + Conv_1988 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_24 + QuantizeLinear_2106 + Conv_2110 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_25 + QuantizeLinear_2134 + Conv_2138 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_26 + QuantizeLinear_2256 + Conv_2260 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_27 + QuantizeLinear_2284 + Conv_2288 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_28 + QuantizeLinear_2406 + Conv_2410 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_29 + QuantizeLinear_2434 + Conv_2438 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_30 + QuantizeLinear_2556 + Conv_2560 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: patchattention_channel.fc.2.weight_clone_31 + QuantizeLinear_2584 + Conv_2588 Set kernel index: 15
[03/01/2023-10:42:06] [V] [TRT] Finalize: attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116 Set kernel index: 9
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(Sigmoid_117, Mul_118) Set kernel index: 16
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_340, Sigmoid_341), Mul_342) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_489, Sigmoid_490), Mul_491) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_639, Sigmoid_640), Mul_641) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_789, Sigmoid_790), Mul_791) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_939, Sigmoid_940), Mul_941) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591) Set kernel index: 17
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_119 Set kernel index: 18
[03/01/2023-10:42:06] [V] [TRT] Finalize: MaxPool_147 Set kernel index: 12
[03/01/2023-10:42:06] [V] [TRT] Finalize: attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 Set kernel index: 19
[03/01/2023-10:42:06] [V] [TRT] Finalize: attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161 Set kernel index: 19
[03/01/2023-10:42:06] [V] [TRT] Finalize: attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146 Set kernel index: 20
[03/01/2023-10:42:06] [V] [TRT] Finalize: attention_channel.fc.2.weight_clone_1 + QuantizeLinear_170 + Conv_174 Set kernel index: 20
[03/01/2023-10:42:06] [V] [TRT] Finalize: PWN(PWN(Add_175, Sigmoid_176), Mul_177) Set kernel index: 21
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_178 Set kernel index: 18
[03/01/2023-10:42:06] [V] [TRT] Finalize: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] Set kernel index: 22
[03/01/2023-10:42:06] [V] [TRT] Finalize: GlobalAveragePool_2593 Set kernel index: 11
[03/01/2023-10:42:06] [V] [TRT] Finalize: classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise] Set kernel index: 23
[03/01/2023-10:42:06] [V] [TRT] Total number of generated kernels selected for the engine: 24
[03/01/2023-10:42:06] [V] [TRT] Kernel: 0 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 1 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 2 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 3 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 4 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 5 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 6 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 7 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 8 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 9 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 10 TRT_SERIALIZABLE:generatedNativePointwise
[03/01/2023-10:42:06] [V] [TRT] Kernel: 11 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 12 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 13 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 14 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 15 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 16 TRT_SERIALIZABLE:generatedNativePointwise
[03/01/2023-10:42:06] [V] [TRT] Kernel: 17 TRT_SERIALIZABLE:generatedNativePointwise
[03/01/2023-10:42:06] [V] [TRT] Kernel: 18 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 19 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 20 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 21 TRT_SERIALIZABLE:generatedNativePointwise
[03/01/2023-10:42:06] [V] [TRT] Kernel: 22 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Kernel: 23 CASK_STATIC
[03/01/2023-10:42:06] [V] [TRT] Disabling unused tactic source: CUDNN
[03/01/2023-10:42:06] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT
[03/01/2023-10:42:06] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS
[03/01/2023-10:42:06] [V] [TRT] Engine generation completed in 44.6815 seconds.
[03/01/2023-10:42:06] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[03/01/2023-10:42:06] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[03/01/2023-10:42:06] [W] [TRT] Check verbose logs for the list of affected weights.
[03/01/2023-10:42:06] [W] [TRT] - 17 weights are affected by this issue: Detected values which are outside of int8_t range and clipped them to int8_t range.
[03/01/2023-10:42:06] [V] [TRT]   List of affected weights: classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise].weight, conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262.weight, conv5.3.weight_clone_1 + QuantizeLinear_407 + Conv_411.weight, conv5.3.weight_clone_10 + QuantizeLinear_1757 + Conv_1761.weight, conv5.3.weight_clone_11 + QuantizeLinear_1907 + Conv_1911.weight, conv5.3.weight_clone_12 + QuantizeLinear_2057 + Conv_2061.weight, conv5.3.weight_clone_13 + QuantizeLinear_2207 + Conv_2211.weight, conv5.3.weight_clone_14 + QuantizeLinear_2357 + Conv_2361.weight, conv5.3.weight_clone_15 + QuantizeLinear_2507 + Conv_2511.weight, conv5.3.weight_clone_2 + QuantizeLinear_557 + Conv_561.weight, conv5.3.weight_clone_3 + QuantizeLinear_707 + Conv_711.weight, conv5.3.weight_clone_4 + QuantizeLinear_857 + Conv_861.weight, conv5.3.weight_clone_5 + QuantizeLinear_1007 + Conv_1011.weight, conv5.3.weight_clone_6 + QuantizeLinear_1157 + Conv_1161.weight, conv5.3.weight_clone_7 + QuantizeLinear_1307 + Conv_1311.weight, conv5.3.weight_clone_8 + QuantizeLinear_1457 + Conv_1461.weight, conv5.3.weight_clone_9 + QuantizeLinear_1607 + Conv_1611.weight
[03/01/2023-10:42:06] [V] [TRT] Engine Layer Information:
Layer(NoOp): Reformatting CopyNode for Network Input input, Tactic: 0x0000000000000000, input (Float[1,1,60,60]) -> Reformatted input (Float[1,1,60,60])
Layer(Reformat): QuantizeLinear_206, Tactic: 0x00000000000003e8, Reformatted input (Float[1,1,60,60]) -> 309 (Int8[1,1,60,60])
Layer(Reformat): QuantizeLinear_2, Tactic: 0x0000000000000000, Reformatted input (Float[1,1,60,60]) -> 109 (Int8[1,1:4,60,60])
Layer(Reformat): Slice_203, Tactic: 0x0000000000000000, 309 (Int8[1,1,24,24]) -> 317 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_352, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 466 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_502, Tactic: 0x0000000000000000, 309 (Int8[1,1,24,24]) -> 616 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_652, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 766 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_802, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 916 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_952, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 1066 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_1102, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 1216 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_1252, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 1366 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_1402, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 1516 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_1552, Tactic: 0x0000000000000000, 309 (Int8[1,1,24,24]) -> 1666 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_1702, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 1816 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_1852, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 1966 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_2002, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 2116 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_2152, Tactic: 0x0000000000000000, 309 (Int8[1,1,24,24]) -> 2266 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_2302, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 2416 (Int8[1,1:32,24,24])
Layer(Reformat): Slice_2452, Tactic: 0x00000000000003e8, 309 (Int8[1,1,24,24]) -> 2566 (Int8[1,1:32,24,24])
Layer(CaskConvolution): conv1.0.weight + QuantizeLinear_8 + Conv_12, Tactic: 0x9fc2bcaa51428a78, 109 (Int8[1,1:4,60,60]) -> 124 (Int8[1,64:32,58,58])
Layer(CaskConvolution): conv4.0.weight_clone_0 + QuantizeLinear_212 + Conv_216, Tactic: 0xee2fce9480a52be7, 317 (Int8[1,1:32,24,24]) -> 332 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_1 + QuantizeLinear_361 + Conv_365, Tactic: 0xee2fce9480a52be7, 466 (Int8[1,1:32,24,24]) -> 481 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_2 + QuantizeLinear_511 + Conv_515, Tactic: 0xee2fce9480a52be7, 616 (Int8[1,1:32,24,24]) -> 631 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_3 + QuantizeLinear_661 + Conv_665, Tactic: 0xee2fce9480a52be7, 766 (Int8[1,1:32,24,24]) -> 781 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_4 + QuantizeLinear_811 + Conv_815, Tactic: 0xee2fce9480a52be7, 916 (Int8[1,1:32,24,24]) -> 931 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_5 + QuantizeLinear_961 + Conv_965, Tactic: 0xee2fce9480a52be7, 1066 (Int8[1,1:32,24,24]) -> 1081 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_6 + QuantizeLinear_1111 + Conv_1115, Tactic: 0xee2fce9480a52be7, 1216 (Int8[1,1:32,24,24]) -> 1231 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_7 + QuantizeLinear_1261 + Conv_1265, Tactic: 0xee2fce9480a52be7, 1366 (Int8[1,1:32,24,24]) -> 1381 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_8 + QuantizeLinear_1411 + Conv_1415, Tactic: 0xee2fce9480a52be7, 1516 (Int8[1,1:32,24,24]) -> 1531 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_9 + QuantizeLinear_1561 + Conv_1565, Tactic: 0xee2fce9480a52be7, 1666 (Int8[1,1:32,24,24]) -> 1681 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_10 + QuantizeLinear_1711 + Conv_1715, Tactic: 0xee2fce9480a52be7, 1816 (Int8[1,1:32,24,24]) -> 1831 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_11 + QuantizeLinear_1861 + Conv_1865, Tactic: 0xee2fce9480a52be7, 1966 (Int8[1,1:32,24,24]) -> 1981 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_12 + QuantizeLinear_2011 + Conv_2015, Tactic: 0xee2fce9480a52be7, 2116 (Int8[1,1:32,24,24]) -> 2131 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_13 + QuantizeLinear_2161 + Conv_2165, Tactic: 0xee2fce9480a52be7, 2266 (Int8[1,1:32,24,24]) -> 2281 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_14 + QuantizeLinear_2311 + Conv_2315, Tactic: 0xee2fce9480a52be7, 2416 (Int8[1,1:32,24,24]) -> 2431 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv4.0.weight_clone_15 + QuantizeLinear_2461 + Conv_2465, Tactic: 0xee2fce9480a52be7, 2566 (Int8[1,1:32,24,24]) -> 2581 (Int8[1,64:32,22,22])
Layer(CaskConvolution): conv1.3.weight + QuantizeLinear_23 + Conv_27, Tactic: 0x2f34f689bfca5071, 124 (Int8[1,64:32,58,58]) -> 137 (Int8[1,64:32,56,56])
Layer(CaskConvolution): conv4.3.weight_clone_0 + QuantizeLinear_227 + Conv_231, Tactic: 0x671c943720ba8655, 332 (Int8[1,64:32,22,22]) -> 345 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_1 + QuantizeLinear_376 + Conv_380, Tactic: 0x671c943720ba8655, 481 (Int8[1,64:32,22,22]) -> 494 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_2 + QuantizeLinear_526 + Conv_530, Tactic: 0x671c943720ba8655, 631 (Int8[1,64:32,22,22]) -> 644 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_3 + QuantizeLinear_676 + Conv_680, Tactic: 0x671c943720ba8655, 781 (Int8[1,64:32,22,22]) -> 794 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_4 + QuantizeLinear_826 + Conv_830, Tactic: 0x671c943720ba8655, 931 (Int8[1,64:32,22,22]) -> 944 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_5 + QuantizeLinear_976 + Conv_980, Tactic: 0x671c943720ba8655, 1081 (Int8[1,64:32,22,22]) -> 1094 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_6 + QuantizeLinear_1126 + Conv_1130, Tactic: 0x671c943720ba8655, 1231 (Int8[1,64:32,22,22]) -> 1244 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_7 + QuantizeLinear_1276 + Conv_1280, Tactic: 0x671c943720ba8655, 1381 (Int8[1,64:32,22,22]) -> 1394 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_8 + QuantizeLinear_1426 + Conv_1430, Tactic: 0x671c943720ba8655, 1531 (Int8[1,64:32,22,22]) -> 1544 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_9 + QuantizeLinear_1576 + Conv_1580, Tactic: 0x671c943720ba8655, 1681 (Int8[1,64:32,22,22]) -> 1694 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_10 + QuantizeLinear_1726 + Conv_1730, Tactic: 0x671c943720ba8655, 1831 (Int8[1,64:32,22,22]) -> 1844 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_11 + QuantizeLinear_1876 + Conv_1880, Tactic: 0x671c943720ba8655, 1981 (Int8[1,64:32,22,22]) -> 1994 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_12 + QuantizeLinear_2026 + Conv_2030, Tactic: 0x671c943720ba8655, 2131 (Int8[1,64:32,22,22]) -> 2144 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_13 + QuantizeLinear_2176 + Conv_2180, Tactic: 0x671c943720ba8655, 2281 (Int8[1,64:32,22,22]) -> 2294 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_14 + QuantizeLinear_2326 + Conv_2330, Tactic: 0x671c943720ba8655, 2431 (Int8[1,64:32,22,22]) -> 2444 (Int8[1,64:32,20,20])
Layer(CaskConvolution): conv4.3.weight_clone_15 + QuantizeLinear_2476 + Conv_2480, Tactic: 0x671c943720ba8655, 2581 (Int8[1,64:32,22,22]) -> 2594 (Int8[1,64:32,20,20])
Layer(CaskPooling): MaxPool_30, Tactic: 0x94215b398b8eb3ba, 137 (Int8[1,64:32,56,56]) -> 140 (Int8[1,64:32,28,28])
Layer(CaskPooling): MaxPool_234, Tactic: 0x94215b398b8eb3ba, 345 (Int8[1,64:32,20,20]) -> 348 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_383, Tactic: 0x94215b398b8eb3ba, 494 (Int8[1,64:32,20,20]) -> 497 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_533, Tactic: 0x94215b398b8eb3ba, 644 (Int8[1,64:32,20,20]) -> 647 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_683, Tactic: 0x94215b398b8eb3ba, 794 (Int8[1,64:32,20,20]) -> 797 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_833, Tactic: 0x94215b398b8eb3ba, 944 (Int8[1,64:32,20,20]) -> 947 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_983, Tactic: 0x94215b398b8eb3ba, 1094 (Int8[1,64:32,20,20]) -> 1097 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_1133, Tactic: 0x94215b398b8eb3ba, 1244 (Int8[1,64:32,20,20]) -> 1247 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_1283, Tactic: 0x94215b398b8eb3ba, 1394 (Int8[1,64:32,20,20]) -> 1397 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_1433, Tactic: 0x94215b398b8eb3ba, 1544 (Int8[1,64:32,20,20]) -> 1547 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_1583, Tactic: 0x94215b398b8eb3ba, 1694 (Int8[1,64:32,20,20]) -> 1697 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_1733, Tactic: 0x94215b398b8eb3ba, 1844 (Int8[1,64:32,20,20]) -> 1847 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_1883, Tactic: 0x94215b398b8eb3ba, 1994 (Int8[1,64:32,20,20]) -> 1997 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_2033, Tactic: 0x94215b398b8eb3ba, 2144 (Int8[1,64:32,20,20]) -> 2147 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_2183, Tactic: 0x94215b398b8eb3ba, 2294 (Int8[1,64:32,20,20]) -> 2297 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_2333, Tactic: 0x94215b398b8eb3ba, 2444 (Int8[1,64:32,20,20]) -> 2447 (Int8[1,64:32,10,10])
Layer(CaskPooling): MaxPool_2483, Tactic: 0x94215b398b8eb3ba, 2594 (Int8[1,64:32,20,20]) -> 2597 (Int8[1,64:32,10,10])
Layer(CaskConvolution): conv2.0.weight + QuantizeLinear_39 + Conv_43, Tactic: 0x4749124f62d8bd23, 140 (Int8[1,64:32,28,28]) -> 155 (Int8[1,128:32,26,26])
Layer(CaskConvolution): conv5.0.weight_clone_0 + QuantizeLinear_243 + Conv_247, Tactic: 0x4749124f62d8bd23, 348 (Int8[1,64:32,10,10]) -> 363 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_1 + QuantizeLinear_392 + Conv_396, Tactic: 0x4749124f62d8bd23, 497 (Int8[1,64:32,10,10]) -> 512 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_2 + QuantizeLinear_542 + Conv_546, Tactic: 0x4749124f62d8bd23, 647 (Int8[1,64:32,10,10]) -> 662 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_3 + QuantizeLinear_692 + Conv_696, Tactic: 0x4749124f62d8bd23, 797 (Int8[1,64:32,10,10]) -> 812 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_4 + QuantizeLinear_842 + Conv_846, Tactic: 0x4749124f62d8bd23, 947 (Int8[1,64:32,10,10]) -> 962 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_5 + QuantizeLinear_992 + Conv_996, Tactic: 0x4749124f62d8bd23, 1097 (Int8[1,64:32,10,10]) -> 1112 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_6 + QuantizeLinear_1142 + Conv_1146, Tactic: 0x4749124f62d8bd23, 1247 (Int8[1,64:32,10,10]) -> 1262 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_7 + QuantizeLinear_1292 + Conv_1296, Tactic: 0x4749124f62d8bd23, 1397 (Int8[1,64:32,10,10]) -> 1412 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_8 + QuantizeLinear_1442 + Conv_1446, Tactic: 0x4749124f62d8bd23, 1547 (Int8[1,64:32,10,10]) -> 1562 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_9 + QuantizeLinear_1592 + Conv_1596, Tactic: 0x4749124f62d8bd23, 1697 (Int8[1,64:32,10,10]) -> 1712 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_10 + QuantizeLinear_1742 + Conv_1746, Tactic: 0x4749124f62d8bd23, 1847 (Int8[1,64:32,10,10]) -> 1862 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_11 + QuantizeLinear_1892 + Conv_1896, Tactic: 0x4749124f62d8bd23, 1997 (Int8[1,64:32,10,10]) -> 2012 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_12 + QuantizeLinear_2042 + Conv_2046, Tactic: 0x4749124f62d8bd23, 2147 (Int8[1,64:32,10,10]) -> 2162 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_13 + QuantizeLinear_2192 + Conv_2196, Tactic: 0x4749124f62d8bd23, 2297 (Int8[1,64:32,10,10]) -> 2312 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_14 + QuantizeLinear_2342 + Conv_2346, Tactic: 0x4749124f62d8bd23, 2447 (Int8[1,64:32,10,10]) -> 2462 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv5.0.weight_clone_15 + QuantizeLinear_2492 + Conv_2496, Tactic: 0x4749124f62d8bd23, 2597 (Int8[1,64:32,10,10]) -> 2612 (Int8[1,128:32,8,8])
Layer(CaskConvolution): conv2.3.weight + QuantizeLinear_54 + Conv_58, Tactic: 0x85c1a5f7f239cf84, 155 (Int8[1,128:32,26,26]) -> 167 (Float[1,128,24,24])
Layer(CaskConvolution): conv5.3.weight_clone_0 + QuantizeLinear_258 + Conv_262, Tactic: 0x85c1a5f7f239cf84, 363 (Int8[1,128:32,8,8]) -> 375 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_1 + QuantizeLinear_407 + Conv_411, Tactic: 0x85c1a5f7f239cf84, 512 (Int8[1,128:32,8,8]) -> 524 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_2 + QuantizeLinear_557 + Conv_561, Tactic: 0x85c1a5f7f239cf84, 662 (Int8[1,128:32,8,8]) -> 674 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_3 + QuantizeLinear_707 + Conv_711, Tactic: 0x85c1a5f7f239cf84, 812 (Int8[1,128:32,8,8]) -> 824 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_4 + QuantizeLinear_857 + Conv_861, Tactic: 0x85c1a5f7f239cf84, 962 (Int8[1,128:32,8,8]) -> 974 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_5 + QuantizeLinear_1007 + Conv_1011, Tactic: 0x85c1a5f7f239cf84, 1112 (Int8[1,128:32,8,8]) -> 1124 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_6 + QuantizeLinear_1157 + Conv_1161, Tactic: 0x85c1a5f7f239cf84, 1262 (Int8[1,128:32,8,8]) -> 1274 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_7 + QuantizeLinear_1307 + Conv_1311, Tactic: 0x85c1a5f7f239cf84, 1412 (Int8[1,128:32,8,8]) -> 1424 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_8 + QuantizeLinear_1457 + Conv_1461, Tactic: 0x85c1a5f7f239cf84, 1562 (Int8[1,128:32,8,8]) -> 1574 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_9 + QuantizeLinear_1607 + Conv_1611, Tactic: 0x85c1a5f7f239cf84, 1712 (Int8[1,128:32,8,8]) -> 1724 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_10 + QuantizeLinear_1757 + Conv_1761, Tactic: 0x85c1a5f7f239cf84, 1862 (Int8[1,128:32,8,8]) -> 1874 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_11 + QuantizeLinear_1907 + Conv_1911, Tactic: 0x85c1a5f7f239cf84, 2012 (Int8[1,128:32,8,8]) -> 2024 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_12 + QuantizeLinear_2057 + Conv_2061, Tactic: 0x85c1a5f7f239cf84, 2162 (Int8[1,128:32,8,8]) -> 2174 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_13 + QuantizeLinear_2207 + Conv_2211, Tactic: 0x85c1a5f7f239cf84, 2312 (Int8[1,128:32,8,8]) -> 2324 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_14 + QuantizeLinear_2357 + Conv_2361, Tactic: 0x85c1a5f7f239cf84, 2462 (Int8[1,128:32,8,8]) -> 2474 (Float[1,128,6,6])
Layer(CaskConvolution): conv5.3.weight_clone_15 + QuantizeLinear_2507 + Conv_2511, Tactic: 0x85c1a5f7f239cf84, 2612 (Int8[1,128:32,8,8]) -> 2624 (Float[1,128,6,6])
Layer(CaskPooling): MaxPool_61, Tactic: 0x53862c46aa5b4c2b, 167 (Float[1,128,24,24]) -> 168 (Float[1,128,12,12])
Layer(Reformat): QuantizeLinear_71, Tactic: 0x00000000000003e8, 168 (Float[1,128,12,12]) -> 182 (Int8[1,128:32,12,12])
Layer(CaskPooling): MaxPool_265, Tactic: 0x60eceb67eff69444, 375 (Float[1,128,6,6]) -> 376 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_414, Tactic: 0x60eceb67eff69444, 524 (Float[1,128,6,6]) -> 525 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_564, Tactic: 0x60eceb67eff69444, 674 (Float[1,128,6,6]) -> 675 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_714, Tactic: 0x60eceb67eff69444, 824 (Float[1,128,6,6]) -> 825 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_864, Tactic: 0x60eceb67eff69444, 974 (Float[1,128,6,6]) -> 975 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_1014, Tactic: 0x60eceb67eff69444, 1124 (Float[1,128,6,6]) -> 1125 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_1164, Tactic: 0x60eceb67eff69444, 1274 (Float[1,128,6,6]) -> 1275 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_1314, Tactic: 0x60eceb67eff69444, 1424 (Float[1,128,6,6]) -> 1425 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_1464, Tactic: 0x60eceb67eff69444, 1574 (Float[1,128,6,6]) -> 1575 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_1614, Tactic: 0x60eceb67eff69444, 1724 (Float[1,128,6,6]) -> 1725 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_1764, Tactic: 0x60eceb67eff69444, 1874 (Float[1,128,6,6]) -> 1875 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_1914, Tactic: 0x60eceb67eff69444, 2024 (Float[1,128,6,6]) -> 2025 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_2064, Tactic: 0x60eceb67eff69444, 2174 (Float[1,128,6,6]) -> 2175 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_2214, Tactic: 0x60eceb67eff69444, 2324 (Float[1,128,6,6]) -> 2325 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_2364, Tactic: 0x60eceb67eff69444, 2474 (Float[1,128,6,6]) -> 2475 (Float[1,128,3,3])
Layer(CaskPooling): MaxPool_2514, Tactic: 0x60eceb67eff69444, 2624 (Float[1,128,6,6]) -> 2625 (Float[1,128,3,3])
Layer(Reduce): ReduceMean_266, Tactic: 0x0000000000000005, 376 (Float[1,128,3,3]) -> 377 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_267, Tactic: 0x0000000000000005, 376 (Float[1,128,3,3]) -> 378 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_415, Tactic: 0x0000000000000005, 525 (Float[1,128,3,3]) -> 526 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_416, Tactic: 0x0000000000000005, 525 (Float[1,128,3,3]) -> 527 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_565, Tactic: 0x0000000000000005, 675 (Float[1,128,3,3]) -> 676 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_566, Tactic: 0x0000000000000005, 675 (Float[1,128,3,3]) -> 677 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_715, Tactic: 0x0000000000000005, 825 (Float[1,128,3,3]) -> 826 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_716, Tactic: 0x0000000000000005, 825 (Float[1,128,3,3]) -> 827 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_865, Tactic: 0x0000000000000005, 975 (Float[1,128,3,3]) -> 976 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_866, Tactic: 0x0000000000000005, 975 (Float[1,128,3,3]) -> 977 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_1015, Tactic: 0x0000000000000005, 1125 (Float[1,128,3,3]) -> 1126 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_1016, Tactic: 0x0000000000000005, 1125 (Float[1,128,3,3]) -> 1127 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_1165, Tactic: 0x0000000000000005, 1275 (Float[1,128,3,3]) -> 1276 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_1166, Tactic: 0x0000000000000005, 1275 (Float[1,128,3,3]) -> 1277 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_1315, Tactic: 0x0000000000000005, 1425 (Float[1,128,3,3]) -> 1426 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_1316, Tactic: 0x0000000000000005, 1425 (Float[1,128,3,3]) -> 1427 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_1465, Tactic: 0x0000000000000005, 1575 (Float[1,128,3,3]) -> 1576 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_1466, Tactic: 0x0000000000000005, 1575 (Float[1,128,3,3]) -> 1577 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_1615, Tactic: 0x0000000000000005, 1725 (Float[1,128,3,3]) -> 1726 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_1616, Tactic: 0x0000000000000005, 1725 (Float[1,128,3,3]) -> 1727 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_1765, Tactic: 0x0000000000000005, 1875 (Float[1,128,3,3]) -> 1876 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_1766, Tactic: 0x0000000000000005, 1875 (Float[1,128,3,3]) -> 1877 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_1915, Tactic: 0x0000000000000005, 2025 (Float[1,128,3,3]) -> 2026 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_1916, Tactic: 0x0000000000000005, 2025 (Float[1,128,3,3]) -> 2027 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_2065, Tactic: 0x0000000000000005, 2175 (Float[1,128,3,3]) -> 2176 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_2066, Tactic: 0x0000000000000005, 2175 (Float[1,128,3,3]) -> 2177 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_2215, Tactic: 0x0000000000000005, 2325 (Float[1,128,3,3]) -> 2326 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_2216, Tactic: 0x0000000000000005, 2325 (Float[1,128,3,3]) -> 2327 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_2365, Tactic: 0x0000000000000005, 2475 (Float[1,128,3,3]) -> 2476 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_2366, Tactic: 0x0000000000000005, 2475 (Float[1,128,3,3]) -> 2477 (Float[1,1,3,3])
Layer(Reduce): ReduceMean_2515, Tactic: 0x0000000000000005, 2625 (Float[1,128,3,3]) -> 2626 (Float[1,1,3,3])
Layer(Reduce): ReduceMax_2516, Tactic: 0x0000000000000005, 2625 (Float[1,128,3,3]) -> 2627 (Float[1,1,3,3])
Layer(CaskConvolution): conv3.0.weight + QuantizeLinear_77 + Conv_81, Tactic: 0x4749124f62d8bd23, 182 (Int8[1,128:32,12,12]) -> 197 (Int8[1,256:32,10,10])
Layer(Reformat): QuantizeLinear_271_clone_1, Tactic: 0x00000000000003e8, 378 (Float[1,1,3,3]) -> 382 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_271_clone_0, Tactic: 0x0000000000000000, 377 (Float[1,1,3,3]) -> Concat_268_377_clone_0 (Int8[1,1:4,3,3])
Layer(Reformat): Concat_268_377_clone_0 copy, Tactic: 0x00000000000003e8, Concat_268_377_clone_0 (Int8[1,1:4,3,3]) -> 382 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_420_clone_1, Tactic: 0x00000000000003e8, 527 (Float[1,1,3,3]) -> 531 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_420_clone_0, Tactic: 0x0000000000000000, 526 (Float[1,1,3,3]) -> Concat_417_526_clone_0 (Int8[1,1:4,3,3])
Layer(Reformat): Concat_417_526_clone_0 copy, Tactic: 0x00000000000003e8, Concat_417_526_clone_0 (Int8[1,1:4,3,3]) -> 531 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_570_clone_1, Tactic: 0x00000000000003e8, 677 (Float[1,1,3,3]) -> 681 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_570_clone_0, Tactic: 0x00000000000003e8, 676 (Float[1,1,3,3]) -> Concat_567_676_clone_0 (Int8[1,1,3,3])
Layer(Reformat): Concat_567_676_clone_0 copy, Tactic: 0x00000000000003e8, Concat_567_676_clone_0 (Int8[1,1,3,3]) -> 681 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_720_clone_1, Tactic: 0x00000000000003e8, 827 (Float[1,1,3,3]) -> 831 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_720_clone_0, Tactic: 0x00000000000003e8, 826 (Float[1,1,3,3]) -> Concat_717_826_clone_0 (Int8[1,1,3,3])
Layer(Reformat): Concat_717_826_clone_0 copy, Tactic: 0x00000000000003e8, Concat_717_826_clone_0 (Int8[1,1,3,3]) -> 831 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_870_clone_1, Tactic: 0x00000000000003e8, 977 (Float[1,1,3,3]) -> 981 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_870_clone_0, Tactic: 0x0000000000000000, 976 (Float[1,1,3,3]) -> Concat_867_976_clone_0 (Int8[1,1:4,3,3])
Layer(Reformat): Concat_867_976_clone_0 copy, Tactic: 0x00000000000003e8, Concat_867_976_clone_0 (Int8[1,1:4,3,3]) -> 981 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1020_clone_1, Tactic: 0x00000000000003e8, 1127 (Float[1,1,3,3]) -> 1131 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1020_clone_0, Tactic: 0x0000000000000000, 1126 (Float[1,1,3,3]) -> Concat_1017_1126_clone_0 (Int8[1,1:4,3,3])
Layer(Reformat): Concat_1017_1126_clone_0 copy, Tactic: 0x00000000000003e8, Concat_1017_1126_clone_0 (Int8[1,1:4,3,3]) -> 1131 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1170_clone_1, Tactic: 0x00000000000003e8, 1277 (Float[1,1,3,3]) -> 1281 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1170_clone_0, Tactic: 0x0000000000000000, 1276 (Float[1,1,3,3]) -> Concat_1167_1276_clone_0 (Int8[1,1:4,3,3])
Layer(Reformat): Concat_1167_1276_clone_0 copy, Tactic: 0x00000000000003e8, Concat_1167_1276_clone_0 (Int8[1,1:4,3,3]) -> 1281 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1320_clone_1, Tactic: 0x00000000000003e8, 1427 (Float[1,1,3,3]) -> 1431 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1320_clone_0, Tactic: 0x00000000000003e8, 1426 (Float[1,1,3,3]) -> Concat_1317_1426_clone_0 (Int8[1,1:32,3,3])
Layer(Reformat): Concat_1317_1426_clone_0 copy, Tactic: 0x0000000000000000, Concat_1317_1426_clone_0 (Int8[1,1:32,3,3]) -> 1431 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1470_clone_1, Tactic: 0x00000000000003e8, 1577 (Float[1,1,3,3]) -> 1581 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1470_clone_0, Tactic: 0x0000000000000000, 1576 (Float[1,1,3,3]) -> Concat_1467_1576_clone_0 (Int8[1,1:4,3,3])
Layer(Reformat): Concat_1467_1576_clone_0 copy, Tactic: 0x0000000000000000, Concat_1467_1576_clone_0 (Int8[1,1:4,3,3]) -> 1581 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1620_clone_1, Tactic: 0x00000000000003e8, 1727 (Float[1,1,3,3]) -> 1731 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1620_clone_0, Tactic: 0x00000000000003e8, 1726 (Float[1,1,3,3]) -> Concat_1617_1726_clone_0 (Int8[1,1,3,3])
Layer(Reformat): Concat_1617_1726_clone_0 copy, Tactic: 0x00000000000003e8, Concat_1617_1726_clone_0 (Int8[1,1,3,3]) -> 1731 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1770_clone_1, Tactic: 0x00000000000003e8, 1877 (Float[1,1,3,3]) -> 1881 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1770_clone_0, Tactic: 0x00000000000003e8, 1876 (Float[1,1,3,3]) -> Concat_1767_1876_clone_0 (Int8[1,1,3,3])
Layer(Reformat): Concat_1767_1876_clone_0 copy, Tactic: 0x0000000000000000, Concat_1767_1876_clone_0 (Int8[1,1,3,3]) -> 1881 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1920_clone_1, Tactic: 0x00000000000003e8, 2027 (Float[1,1,3,3]) -> 2031 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_1920_clone_0, Tactic: 0x0000000000000000, 2026 (Float[1,1,3,3]) -> Concat_1917_2026_clone_0 (Int8[1,1,3,3])
Layer(Reformat): Concat_1917_2026_clone_0 copy, Tactic: 0x00000000000003e8, Concat_1917_2026_clone_0 (Int8[1,1,3,3]) -> 2031 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_2070_clone_1, Tactic: 0x00000000000003e8, 2177 (Float[1,1,3,3]) -> 2181 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_2070_clone_0, Tactic: 0x0000000000000000, 2176 (Float[1,1,3,3]) -> Concat_2067_2176_clone_0 (Int8[1,1,3,3])
Layer(Reformat): Concat_2067_2176_clone_0 copy, Tactic: 0x00000000000003e8, Concat_2067_2176_clone_0 (Int8[1,1,3,3]) -> 2181 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_2220_clone_1, Tactic: 0x00000000000003e8, 2327 (Float[1,1,3,3]) -> 2331 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_2220_clone_0, Tactic: 0x0000000000000000, 2326 (Float[1,1,3,3]) -> Concat_2217_2326_clone_0 (Int8[1,1:4,3,3])
Layer(Reformat): Concat_2217_2326_clone_0 copy, Tactic: 0x0000000000000000, Concat_2217_2326_clone_0 (Int8[1,1:4,3,3]) -> 2331 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_2370_clone_1, Tactic: 0x00000000000003e8, 2477 (Float[1,1,3,3]) -> 2481 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_2370_clone_0, Tactic: 0x0000000000000000, 2476 (Float[1,1,3,3]) -> Concat_2367_2476_clone_0 (Int8[1,1:4,3,3])
Layer(Reformat): Concat_2367_2476_clone_0 copy, Tactic: 0x00000000000003e8, Concat_2367_2476_clone_0 (Int8[1,1:4,3,3]) -> 2481 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_2520_clone_1, Tactic: 0x00000000000003e8, 2627 (Float[1,1,3,3]) -> 2631 (Int8[1,1:4,3,3])
Layer(Reformat): QuantizeLinear_2520_clone_0, Tactic: 0x0000000000000000, 2626 (Float[1,1,3,3]) -> Concat_2517_2626_clone_0 (Int8[1,1:4,3,3])
Layer(Reformat): Concat_2517_2626_clone_0 copy, Tactic: 0x00000000000003e8, Concat_2517_2626_clone_0 (Int8[1,1:4,3,3]) -> 2631 (Int8[1,1:4,3,3])
Layer(Resize): Resize_68, Tactic: 0x0000000000000000, 168 (Float[1,128,12,12]) -> 179 (Float[1,128,4,4])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_0 + QuantizeLinear_277 + Conv_281, Tactic: 0x1b0534177b414e71, 382 (Int8[1,2:4,3,3]) -> 392 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_1 + QuantizeLinear_426 + Conv_430, Tactic: 0x1b0534177b414e71, 531 (Int8[1,2:4,3,3]) -> 541 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_2 + QuantizeLinear_576 + Conv_580, Tactic: 0x1b0534177b414e71, 681 (Int8[1,2:4,3,3]) -> 691 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_3 + QuantizeLinear_726 + Conv_730, Tactic: 0x1b0534177b414e71, 831 (Int8[1,2:4,3,3]) -> 841 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_4 + QuantizeLinear_876 + Conv_880, Tactic: 0x1b0534177b414e71, 981 (Int8[1,2:4,3,3]) -> 991 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_5 + QuantizeLinear_1026 + Conv_1030, Tactic: 0x1b0534177b414e71, 1131 (Int8[1,2:4,3,3]) -> 1141 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_6 + QuantizeLinear_1176 + Conv_1180, Tactic: 0x1b0534177b414e71, 1281 (Int8[1,2:4,3,3]) -> 1291 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_7 + QuantizeLinear_1326 + Conv_1330, Tactic: 0x1b0534177b414e71, 1431 (Int8[1,2:4,3,3]) -> 1441 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_8 + QuantizeLinear_1476 + Conv_1480, Tactic: 0x1b0534177b414e71, 1581 (Int8[1,2:4,3,3]) -> 1591 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_9 + QuantizeLinear_1626 + Conv_1630, Tactic: 0x1b0534177b414e71, 1731 (Int8[1,2:4,3,3]) -> 1741 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_10 + QuantizeLinear_1776 + Conv_1780, Tactic: 0x1b0534177b414e71, 1881 (Int8[1,2:4,3,3]) -> 1891 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_11 + QuantizeLinear_1926 + Conv_1930, Tactic: 0x1b0534177b414e71, 2031 (Int8[1,2:4,3,3]) -> 2041 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_12 + QuantizeLinear_2076 + Conv_2080, Tactic: 0x1b0534177b414e71, 2181 (Int8[1,2:4,3,3]) -> 2191 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_13 + QuantizeLinear_2226 + Conv_2230, Tactic: 0x1b0534177b414e71, 2331 (Int8[1,2:4,3,3]) -> 2341 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_14 + QuantizeLinear_2376 + Conv_2380, Tactic: 0x1b0534177b414e71, 2481 (Int8[1,2:4,3,3]) -> 2491 (Float[1,1,3,3])
Layer(CaskConvolution): patchattention_spatial.conv1.weight_clone_15 + QuantizeLinear_2526 + Conv_2530, Tactic: 0x1b0534177b414e71, 2631 (Int8[1,2:4,3,3]) -> 2641 (Float[1,1,3,3])
Layer(CaskConvolution): conv3.3.weight + QuantizeLinear_92 + Conv_96, Tactic: 0x85c1a5f7f239cf84, 197 (Int8[1,256:32,10,10]) -> 209 (Float[1,256,8,8])
Layer(PointWiseV2): PWN(Sigmoid_282, Mul_283), Tactic: 0x000000000000001c, 392 (Float[1,1,3,3]), 376 (Float[1,128,3,3]) -> 394 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_431, Mul_432), Tactic: 0x000000000000001c, 541 (Float[1,1,3,3]), 525 (Float[1,128,3,3]) -> 543 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_581, Mul_582), Tactic: 0x000000000000001c, 691 (Float[1,1,3,3]), 675 (Float[1,128,3,3]) -> 693 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_731, Mul_732), Tactic: 0x000000000000001c, 841 (Float[1,1,3,3]), 825 (Float[1,128,3,3]) -> 843 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_881, Mul_882), Tactic: 0x000000000000001c, 991 (Float[1,1,3,3]), 975 (Float[1,128,3,3]) -> 993 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_1031, Mul_1032), Tactic: 0x000000000000001c, 1141 (Float[1,1,3,3]), 1125 (Float[1,128,3,3]) -> 1143 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_1181, Mul_1182), Tactic: 0x000000000000001c, 1291 (Float[1,1,3,3]), 1275 (Float[1,128,3,3]) -> 1293 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_1331, Mul_1332), Tactic: 0x000000000000001c, 1441 (Float[1,1,3,3]), 1425 (Float[1,128,3,3]) -> 1443 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_1481, Mul_1482), Tactic: 0x000000000000001c, 1591 (Float[1,1,3,3]), 1575 (Float[1,128,3,3]) -> 1593 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_1631, Mul_1632), Tactic: 0x000000000000001c, 1741 (Float[1,1,3,3]), 1725 (Float[1,128,3,3]) -> 1743 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_1781, Mul_1782), Tactic: 0x000000000000001c, 1891 (Float[1,1,3,3]), 1875 (Float[1,128,3,3]) -> 1893 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_1931, Mul_1932), Tactic: 0x000000000000001c, 2041 (Float[1,1,3,3]), 2025 (Float[1,128,3,3]) -> 2043 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_2081, Mul_2082), Tactic: 0x000000000000001c, 2191 (Float[1,1,3,3]), 2175 (Float[1,128,3,3]) -> 2193 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_2231, Mul_2232), Tactic: 0x000000000000001c, 2341 (Float[1,1,3,3]), 2325 (Float[1,128,3,3]) -> 2343 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_2381, Mul_2382), Tactic: 0x000000000000001c, 2491 (Float[1,1,3,3]), 2475 (Float[1,128,3,3]) -> 2493 (Float[1,128,3,3])
Layer(PointWiseV2): PWN(Sigmoid_2531, Mul_2532), Tactic: 0x000000000000001c, 2641 (Float[1,1,3,3]), 2625 (Float[1,128,3,3]) -> 2643 (Float[1,128,3,3])
Layer(CaskPooling): GlobalAveragePool_284, Tactic: 0x964fa580cb69303d, 394 (Float[1,128,3,3]) -> 395 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_315, Tactic: 0x0000000000000000, 394 (Float[1,128,3,3]) -> 423 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_433, Tactic: 0x964fa580cb69303d, 543 (Float[1,128,3,3]) -> 544 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_464, Tactic: 0x0000000000000000, 543 (Float[1,128,3,3]) -> 572 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_583, Tactic: 0x964fa580cb69303d, 693 (Float[1,128,3,3]) -> 694 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_614, Tactic: 0x0000000000000000, 693 (Float[1,128,3,3]) -> 722 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_733, Tactic: 0x964fa580cb69303d, 843 (Float[1,128,3,3]) -> 844 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_764, Tactic: 0x0000000000000000, 843 (Float[1,128,3,3]) -> 872 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_883, Tactic: 0x964fa580cb69303d, 993 (Float[1,128,3,3]) -> 994 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_914, Tactic: 0x0000000000000000, 993 (Float[1,128,3,3]) -> 1022 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_1033, Tactic: 0x964fa580cb69303d, 1143 (Float[1,128,3,3]) -> 1144 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_1064, Tactic: 0x0000000000000000, 1143 (Float[1,128,3,3]) -> 1172 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_1183, Tactic: 0x964fa580cb69303d, 1293 (Float[1,128,3,3]) -> 1294 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_1214, Tactic: 0x0000000000000000, 1293 (Float[1,128,3,3]) -> 1322 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_1333, Tactic: 0x964fa580cb69303d, 1443 (Float[1,128,3,3]) -> 1444 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_1364, Tactic: 0x00000000000003e8, 1443 (Float[1,128,3,3]) -> 1472 (Int8[1,128:32,3,3])
Layer(CaskPooling): GlobalAveragePool_1483, Tactic: 0x964fa580cb69303d, 1593 (Float[1,128,3,3]) -> 1594 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_1514, Tactic: 0x00000000000003e8, 1593 (Float[1,128,3,3]) -> 1622 (Int8[1,128:32,3,3])
Layer(CaskPooling): GlobalAveragePool_1633, Tactic: 0x964fa580cb69303d, 1743 (Float[1,128,3,3]) -> 1744 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_1664, Tactic: 0x0000000000000000, 1743 (Float[1,128,3,3]) -> 1772 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_1783, Tactic: 0x964fa580cb69303d, 1893 (Float[1,128,3,3]) -> 1894 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_1814, Tactic: 0x0000000000000000, 1893 (Float[1,128,3,3]) -> 1922 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_1933, Tactic: 0x964fa580cb69303d, 2043 (Float[1,128,3,3]) -> 2044 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_1964, Tactic: 0x00000000000003e8, 2043 (Float[1,128,3,3]) -> 2072 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_2083, Tactic: 0x964fa580cb69303d, 2193 (Float[1,128,3,3]) -> 2194 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_2114, Tactic: 0x0000000000000000, 2193 (Float[1,128,3,3]) -> 2222 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_2233, Tactic: 0x964fa580cb69303d, 2343 (Float[1,128,3,3]) -> 2344 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_2264, Tactic: 0x0000000000000000, 2343 (Float[1,128,3,3]) -> 2372 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_2383, Tactic: 0x964fa580cb69303d, 2493 (Float[1,128,3,3]) -> 2494 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_2414, Tactic: 0x0000000000000000, 2493 (Float[1,128,3,3]) -> 2522 (Int8[1,128:4,3,3])
Layer(CaskPooling): GlobalAveragePool_2533, Tactic: 0x964fa580cb69303d, 2643 (Float[1,128,3,3]) -> 2644 (Float[1,128,1,1])
Layer(Reformat): QuantizeLinear_2564, Tactic: 0x0000000000000000, 2643 (Float[1,128,3,3]) -> 2672 (Int8[1,128:4,3,3])
Layer(Reformat): QuantizeLinear_287, Tactic: 0x00000000000003e8, 395 (Float[1,128,1,1]) -> 398 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_312, Tactic: 0x1f6c40e3e09ec730, 423 (Int8[1,128:4,3,3]) -> 426 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_436, Tactic: 0x00000000000003e8, 544 (Float[1,128,1,1]) -> 547 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_461, Tactic: 0x1f6c40e3e09ec730, 572 (Int8[1,128:4,3,3]) -> 575 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_586, Tactic: 0x00000000000003e8, 694 (Float[1,128,1,1]) -> 697 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_611, Tactic: 0x1f6c40e3e09ec730, 722 (Int8[1,128:4,3,3]) -> 725 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_736, Tactic: 0x00000000000003e8, 844 (Float[1,128,1,1]) -> 847 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_761, Tactic: 0x1f6c40e3e09ec730, 872 (Int8[1,128:4,3,3]) -> 875 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_886, Tactic: 0x00000000000003e8, 994 (Float[1,128,1,1]) -> 997 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_911, Tactic: 0x1f6c40e3e09ec730, 1022 (Int8[1,128:4,3,3]) -> 1025 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_1036, Tactic: 0x00000000000003e8, 1144 (Float[1,128,1,1]) -> 1147 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_1061, Tactic: 0x1f6c40e3e09ec730, 1172 (Int8[1,128:4,3,3]) -> 1175 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_1186, Tactic: 0x00000000000003e8, 1294 (Float[1,128,1,1]) -> 1297 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_1211, Tactic: 0x1f6c40e3e09ec730, 1322 (Int8[1,128:4,3,3]) -> 1325 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_1336, Tactic: 0x00000000000003e8, 1444 (Float[1,128,1,1]) -> 1447 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_1361, Tactic: 0x94215b398b8eb3ba, 1472 (Int8[1,128:32,3,3]) -> 1475 (Int8[1,128:32,1,1])
Layer(Reformat): QuantizeLinear_1486, Tactic: 0x00000000000003e8, 1594 (Float[1,128,1,1]) -> 1597 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_1511, Tactic: 0x94215b398b8eb3ba, 1622 (Int8[1,128:32,3,3]) -> 1625 (Int8[1,128:32,1,1])
Layer(Reformat): QuantizeLinear_1636, Tactic: 0x0000000000000000, 1744 (Float[1,128,1,1]) -> 1747 (Int8[1,128:4,1,1])
Layer(CaskPooling): MaxPool_1661, Tactic: 0x1f6c40e3e09ec730, 1772 (Int8[1,128:4,3,3]) -> 1775 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_1786, Tactic: 0x00000000000003e8, 1894 (Float[1,128,1,1]) -> 1897 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_1811, Tactic: 0x1f6c40e3e09ec730, 1922 (Int8[1,128:4,3,3]) -> 1925 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_1936, Tactic: 0x00000000000003e8, 2044 (Float[1,128,1,1]) -> 2047 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_1961, Tactic: 0x1f6c40e3e09ec730, 2072 (Int8[1,128:4,3,3]) -> 2075 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_2086, Tactic: 0x0000000000000000, 2194 (Float[1,128,1,1]) -> 2197 (Int8[1,128:4,1,1])
Layer(CaskPooling): MaxPool_2111, Tactic: 0x1f6c40e3e09ec730, 2222 (Int8[1,128:4,3,3]) -> 2225 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_2236, Tactic: 0x00000000000003e8, 2344 (Float[1,128,1,1]) -> 2347 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_2261, Tactic: 0x1f6c40e3e09ec730, 2372 (Int8[1,128:4,3,3]) -> 2375 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_2386, Tactic: 0x00000000000003e8, 2494 (Float[1,128,1,1]) -> 2497 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_2411, Tactic: 0x1f6c40e3e09ec730, 2522 (Int8[1,128:4,3,3]) -> 2525 (Int8[1,128:4,1,1])
Layer(Reformat): QuantizeLinear_2536, Tactic: 0x00000000000003e8, 2644 (Float[1,128,1,1]) -> 2647 (Int8[1,128,1,1])
Layer(CaskPooling): MaxPool_2561, Tactic: 0x1f6c40e3e09ec730, 2672 (Int8[1,128:4,3,3]) -> 2675 (Int8[1,128:4,1,1])
Layer(CaskPooling): MaxPool_99, Tactic: 0xbd4519190f75e7e9, 209 (Float[1,256,8,8]) -> 211 (Float[1,256,4,4])
Layer(Reformat): 179 copy, Tactic: 0x00000000000003e8, 179 (Float[1,128,4,4]) -> 211 (Float[1,128,4,4])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298, Tactic: 0x0000000000000000, 398 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_0 + QuantizeLinear_293 + Conv_297 + Relu_298 (Int8[1,128:32,1,1]) -> 412 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326, Tactic: 0x0000000000000000, 426 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_1 + QuantizeLinear_321 + Conv_325 + Relu_326 (Int8[1,128:32,1,1]) -> 440 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447, Tactic: 0x0000000000000000, 547 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_2 + QuantizeLinear_442 + Conv_446 + Relu_447 (Int8[1,128:32,1,1]) -> 561 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475, Tactic: 0x0000000000000000, 575 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_3 + QuantizeLinear_470 + Conv_474 + Relu_475 (Int8[1,128:32,1,1]) -> 589 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597, Tactic: 0x0000000000000000, 697 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_4 + QuantizeLinear_592 + Conv_596 + Relu_597 (Int8[1,128:32,1,1]) -> 711 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625, Tactic: 0x0000000000000000, 725 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_5 + QuantizeLinear_620 + Conv_624 + Relu_625 (Int8[1,128:32,1,1]) -> 739 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747, Tactic: 0x0000000000000000, 847 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_6 + QuantizeLinear_742 + Conv_746 + Relu_747 (Int8[1,128:32,1,1]) -> 861 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775, Tactic: 0x0000000000000000, 875 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_7 + QuantizeLinear_770 + Conv_774 + Relu_775 (Int8[1,128:32,1,1]) -> 889 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897, Tactic: 0x0000000000000000, 997 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_8 + QuantizeLinear_892 + Conv_896 + Relu_897 (Int8[1,128:32,1,1]) -> 1011 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925, Tactic: 0x0000000000000000, 1025 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_9 + QuantizeLinear_920 + Conv_924 + Relu_925 (Int8[1,128:32,1,1]) -> 1039 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047, Tactic: 0x0000000000000000, 1147 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_10 + QuantizeLinear_1042 + Conv_1046 + Relu_1047 (Int8[1,128:32,1,1]) -> 1161 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075, Tactic: 0x0000000000000000, 1175 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_11 + QuantizeLinear_1070 + Conv_1074 + Relu_1075 (Int8[1,128:32,1,1]) -> 1189 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197, Tactic: 0x0000000000000000, 1297 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_12 + QuantizeLinear_1192 + Conv_1196 + Relu_1197 (Int8[1,128:32,1,1]) -> 1311 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225, Tactic: 0x0000000000000000, 1325 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_13 + QuantizeLinear_1220 + Conv_1224 + Relu_1225 (Int8[1,128:32,1,1]) -> 1339 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347, Tactic: 0x0000000000000000, 1447 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_14 + QuantizeLinear_1342 + Conv_1346 + Relu_1347 (Int8[1,128:32,1,1]) -> 1461 (Int8[1,8:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_15 + QuantizeLinear_1370 + Conv_1374 + Relu_1375, Tactic: 0x596666386c88024b, 1475 (Int8[1,128:32,1,1]) -> 1489 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497, Tactic: 0x0000000000000000, 1597 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_16 + QuantizeLinear_1492 + Conv_1496 + Relu_1497 (Int8[1,128:32,1,1]) -> 1611 (Int8[1,8:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_17 + QuantizeLinear_1520 + Conv_1524 + Relu_1525, Tactic: 0x596666386c88024b, 1625 (Int8[1,128:32,1,1]) -> 1639 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647, Tactic: 0x0000000000000000, 1747 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_18 + QuantizeLinear_1642 + Conv_1646 + Relu_1647 (Int8[1,128:32,1,1]) -> 1761 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675, Tactic: 0x0000000000000000, 1775 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_19 + QuantizeLinear_1670 + Conv_1674 + Relu_1675 (Int8[1,128:32,1,1]) -> 1789 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797, Tactic: 0x0000000000000000, 1897 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_20 + QuantizeLinear_1792 + Conv_1796 + Relu_1797 (Int8[1,128:32,1,1]) -> 1911 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825, Tactic: 0x0000000000000000, 1925 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_21 + QuantizeLinear_1820 + Conv_1824 + Relu_1825 (Int8[1,128:32,1,1]) -> 1939 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947, Tactic: 0x0000000000000000, 2047 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_22 + QuantizeLinear_1942 + Conv_1946 + Relu_1947 (Int8[1,128:32,1,1]) -> 2061 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975, Tactic: 0x0000000000000000, 2075 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_23 + QuantizeLinear_1970 + Conv_1974 + Relu_1975 (Int8[1,128:32,1,1]) -> 2089 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097, Tactic: 0x0000000000000000, 2197 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_24 + QuantizeLinear_2092 + Conv_2096 + Relu_2097 (Int8[1,128:32,1,1]) -> 2211 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125, Tactic: 0x0000000000000000, 2225 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_25 + QuantizeLinear_2120 + Conv_2124 + Relu_2125 (Int8[1,128:32,1,1]) -> 2239 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247, Tactic: 0x0000000000000000, 2347 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_26 + QuantizeLinear_2242 + Conv_2246 + Relu_2247 (Int8[1,128:32,1,1]) -> 2361 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275, Tactic: 0x0000000000000000, 2375 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_27 + QuantizeLinear_2270 + Conv_2274 + Relu_2275 (Int8[1,128:32,1,1]) -> 2389 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397, Tactic: 0x0000000000000000, 2497 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_28 + QuantizeLinear_2392 + Conv_2396 + Relu_2397 (Int8[1,128:32,1,1]) -> 2511 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425, Tactic: 0x0000000000000000, 2525 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_29 + QuantizeLinear_2420 + Conv_2424 + Relu_2425 (Int8[1,128:32,1,1]) -> 2539 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547, Tactic: 0x0000000000000000, 2647 (Int8[1,128,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_30 + QuantizeLinear_2542 + Conv_2546 + Relu_2547 (Int8[1,128:32,1,1]) -> 2661 (Int8[1,8:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575, Tactic: 0x0000000000000000, 2675 (Int8[1,128:4,1,1]) -> Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575 (Int8[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575, Tactic: 0x596666386c88024b, Reformatted Input Tensor 0 to patchattention_channel.fc.0.weight_clone_31 + QuantizeLinear_2570 + Conv_2574 + Relu_2575 (Int8[1,128:32,1,1]) -> 2689 (Int8[1,8:32,1,1])
Layer(Reduce): ReduceMean_101, Tactic: 0x0000000000000005, 211 (Float[1,384,4,4]) -> 212 (Float[1,1,4,4])
Layer(Reduce): ReduceMax_102, Tactic: 0x0000000000000005, 211 (Float[1,384,4,4]) -> 213 (Float[1,1,4,4])
Layer(Reformat): QuantizeLinear_106_clone_1, Tactic: 0x00000000000003e8, 213 (Float[1,1,4,4]) -> 217 (Int8[1,1:4,4,4])
Layer(Reformat): QuantizeLinear_106_clone_0, Tactic: 0x0000000000000000, 212 (Float[1,1,4,4]) -> Concat_103_212_clone_0 (Int8[1,1:4,4,4])
Layer(Reformat): Concat_103_212_clone_0 copy, Tactic: 0x00000000000003e8, Concat_103_212_clone_0 (Int8[1,1:4,4,4]) -> 217 (Int8[1,1:4,4,4])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_0 + QuantizeLinear_307 + Conv_311, Tactic: 0x6d377e4222886190, 412 (Int8[1,8:32,1,1]) -> 422 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_1 + QuantizeLinear_335 + Conv_339, Tactic: 0x6d377e4222886190, 440 (Int8[1,8:32,1,1]) -> 450 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_2 + QuantizeLinear_456 + Conv_460, Tactic: 0x6d377e4222886190, 561 (Int8[1,8:32,1,1]) -> 571 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_3 + QuantizeLinear_484 + Conv_488, Tactic: 0x6d377e4222886190, 589 (Int8[1,8:32,1,1]) -> 599 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_4 + QuantizeLinear_606 + Conv_610, Tactic: 0x6d377e4222886190, 711 (Int8[1,8:32,1,1]) -> 721 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_5 + QuantizeLinear_634 + Conv_638, Tactic: 0x6d377e4222886190, 739 (Int8[1,8:32,1,1]) -> 749 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_6 + QuantizeLinear_756 + Conv_760, Tactic: 0x6d377e4222886190, 861 (Int8[1,8:32,1,1]) -> 871 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_7 + QuantizeLinear_784 + Conv_788, Tactic: 0x6d377e4222886190, 889 (Int8[1,8:32,1,1]) -> 899 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_8 + QuantizeLinear_906 + Conv_910, Tactic: 0x6d377e4222886190, 1011 (Int8[1,8:32,1,1]) -> 1021 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_9 + QuantizeLinear_934 + Conv_938, Tactic: 0x6d377e4222886190, 1039 (Int8[1,8:32,1,1]) -> 1049 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_10 + QuantizeLinear_1056 + Conv_1060, Tactic: 0x6d377e4222886190, 1161 (Int8[1,8:32,1,1]) -> 1171 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_11 + QuantizeLinear_1084 + Conv_1088, Tactic: 0x6d377e4222886190, 1189 (Int8[1,8:32,1,1]) -> 1199 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_12 + QuantizeLinear_1206 + Conv_1210, Tactic: 0x6d377e4222886190, 1311 (Int8[1,8:32,1,1]) -> 1321 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_13 + QuantizeLinear_1234 + Conv_1238, Tactic: 0x6d377e4222886190, 1339 (Int8[1,8:32,1,1]) -> 1349 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_14 + QuantizeLinear_1356 + Conv_1360, Tactic: 0x6d377e4222886190, 1461 (Int8[1,8:32,1,1]) -> 1471 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_15 + QuantizeLinear_1384 + Conv_1388, Tactic: 0x6d377e4222886190, 1489 (Int8[1,8:32,1,1]) -> 1499 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_16 + QuantizeLinear_1506 + Conv_1510, Tactic: 0x6d377e4222886190, 1611 (Int8[1,8:32,1,1]) -> 1621 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_17 + QuantizeLinear_1534 + Conv_1538, Tactic: 0x6d377e4222886190, 1639 (Int8[1,8:32,1,1]) -> 1649 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_18 + QuantizeLinear_1656 + Conv_1660, Tactic: 0x6d377e4222886190, 1761 (Int8[1,8:32,1,1]) -> 1771 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_19 + QuantizeLinear_1684 + Conv_1688, Tactic: 0x6d377e4222886190, 1789 (Int8[1,8:32,1,1]) -> 1799 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_20 + QuantizeLinear_1806 + Conv_1810, Tactic: 0x6d377e4222886190, 1911 (Int8[1,8:32,1,1]) -> 1921 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_21 + QuantizeLinear_1834 + Conv_1838, Tactic: 0x6d377e4222886190, 1939 (Int8[1,8:32,1,1]) -> 1949 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_22 + QuantizeLinear_1956 + Conv_1960, Tactic: 0x6d377e4222886190, 2061 (Int8[1,8:32,1,1]) -> 2071 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_23 + QuantizeLinear_1984 + Conv_1988, Tactic: 0x6d377e4222886190, 2089 (Int8[1,8:32,1,1]) -> 2099 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_24 + QuantizeLinear_2106 + Conv_2110, Tactic: 0x6d377e4222886190, 2211 (Int8[1,8:32,1,1]) -> 2221 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_25 + QuantizeLinear_2134 + Conv_2138, Tactic: 0x6d377e4222886190, 2239 (Int8[1,8:32,1,1]) -> 2249 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_26 + QuantizeLinear_2256 + Conv_2260, Tactic: 0x6d377e4222886190, 2361 (Int8[1,8:32,1,1]) -> 2371 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_27 + QuantizeLinear_2284 + Conv_2288, Tactic: 0x6d377e4222886190, 2389 (Int8[1,8:32,1,1]) -> 2399 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_28 + QuantizeLinear_2406 + Conv_2410, Tactic: 0x6d377e4222886190, 2511 (Int8[1,8:32,1,1]) -> 2521 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_29 + QuantizeLinear_2434 + Conv_2438, Tactic: 0x6d377e4222886190, 2539 (Int8[1,8:32,1,1]) -> 2549 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_30 + QuantizeLinear_2556 + Conv_2560, Tactic: 0x6d377e4222886190, 2661 (Int8[1,8:32,1,1]) -> 2671 (Float[1,128:32,1,1])
Layer(CaskConvolution): patchattention_channel.fc.2.weight_clone_31 + QuantizeLinear_2584 + Conv_2588, Tactic: 0x6d377e4222886190, 2689 (Int8[1,8:32,1,1]) -> 2699 (Float[1,128:32,1,1])
Layer(CaskConvolution): attention_spatial.conv1.weight + QuantizeLinear_112 + Conv_116, Tactic: 0x1b0534177b414e71, 217 (Int8[1,2:4,4,4]) -> 227 (Float[1,1,4,4])
Layer(PointWiseV2): PWN(Sigmoid_117, Mul_118), Tactic: 0x0000000000000001, 227 (Float[1,1,4,4]), 211 (Float[1,384,4,4]) -> 229 (Float[1,384,4,4])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_340, Sigmoid_341), Mul_342), Tactic: 0x0000000000000000, 422 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_340, Sigmoid_341), Mul_342) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_340, Sigmoid_341), Mul_342), Tactic: 0x0000000000000000, 450 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_340, Sigmoid_341), Mul_342) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_340, Sigmoid_341), Mul_342), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_340, Sigmoid_341), Mul_342) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_340, Sigmoid_341), Mul_342) (Float[1,128,1,1]), 394 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_489, Sigmoid_490), Mul_491), Tactic: 0x0000000000000000, 571 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_489, Sigmoid_490), Mul_491) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_489, Sigmoid_490), Mul_491), Tactic: 0x0000000000000000, 599 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_489, Sigmoid_490), Mul_491) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_489, Sigmoid_490), Mul_491), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_489, Sigmoid_490), Mul_491) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_489, Sigmoid_490), Mul_491) (Float[1,128,1,1]), 543 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_639, Sigmoid_640), Mul_641), Tactic: 0x0000000000000000, 721 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_639, Sigmoid_640), Mul_641) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_639, Sigmoid_640), Mul_641), Tactic: 0x0000000000000000, 749 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_639, Sigmoid_640), Mul_641) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_639, Sigmoid_640), Mul_641), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_639, Sigmoid_640), Mul_641) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_639, Sigmoid_640), Mul_641) (Float[1,128,1,1]), 693 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_789, Sigmoid_790), Mul_791), Tactic: 0x0000000000000000, 871 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_789, Sigmoid_790), Mul_791) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_789, Sigmoid_790), Mul_791), Tactic: 0x0000000000000000, 899 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_789, Sigmoid_790), Mul_791) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_789, Sigmoid_790), Mul_791), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_789, Sigmoid_790), Mul_791) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_789, Sigmoid_790), Mul_791) (Float[1,128,1,1]), 843 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_939, Sigmoid_940), Mul_941), Tactic: 0x0000000000000000, 1021 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_939, Sigmoid_940), Mul_941) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_939, Sigmoid_940), Mul_941), Tactic: 0x0000000000000000, 1049 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_939, Sigmoid_940), Mul_941) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_939, Sigmoid_940), Mul_941), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_939, Sigmoid_940), Mul_941) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_939, Sigmoid_940), Mul_941) (Float[1,128,1,1]), 993 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091), Tactic: 0x0000000000000000, 1171 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091), Tactic: 0x0000000000000000, 1199 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_1089, Sigmoid_1090), Mul_1091) (Float[1,128,1,1]), 1143 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241), Tactic: 0x0000000000000000, 1321 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241), Tactic: 0x0000000000000000, 1349 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_1239, Sigmoid_1240), Mul_1241) (Float[1,128,1,1]), 1293 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391), Tactic: 0x0000000000000000, 1471 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391), Tactic: 0x0000000000000000, 1499 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_1389, Sigmoid_1390), Mul_1391) (Float[1,128,1,1]), 1443 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541), Tactic: 0x0000000000000000, 1621 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541), Tactic: 0x0000000000000000, 1649 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_1539, Sigmoid_1540), Mul_1541) (Float[1,128,1,1]), 1593 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691), Tactic: 0x0000000000000000, 1771 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691), Tactic: 0x0000000000000000, 1799 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_1689, Sigmoid_1690), Mul_1691) (Float[1,128,1,1]), 1743 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841), Tactic: 0x0000000000000000, 1921 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841), Tactic: 0x0000000000000000, 1949 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_1839, Sigmoid_1840), Mul_1841) (Float[1,128,1,1]), 1893 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991), Tactic: 0x0000000000000000, 2071 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991), Tactic: 0x0000000000000000, 2099 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_1989, Sigmoid_1990), Mul_1991) (Float[1,128,1,1]), 2043 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141), Tactic: 0x0000000000000000, 2221 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141), Tactic: 0x0000000000000000, 2249 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_2139, Sigmoid_2140), Mul_2141) (Float[1,128,1,1]), 2193 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291), Tactic: 0x0000000000000000, 2371 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291), Tactic: 0x0000000000000000, 2399 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_2289, Sigmoid_2290), Mul_2291) (Float[1,128,1,1]), 2343 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441), Tactic: 0x0000000000000000, 2521 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441), Tactic: 0x0000000000000000, 2549 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_2439, Sigmoid_2440), Mul_2441) (Float[1,128,1,1]), 2493 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591), Tactic: 0x0000000000000000, 2671 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591) (Float[1,128,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591), Tactic: 0x0000000000000000, 2699 (Float[1,128:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591) (Float[1,128,1,1])
Layer(PointWiseV2): PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591), Tactic: 0x000000000000001c, Reformatted Input Tensor 0 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591) (Float[1,128,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_2589, Sigmoid_2590), Mul_2591) (Float[1,128,1,1]), 2643 (Float[1,128,3,3]) -> 2703 (Float[1,128,3,3])
Layer(CaskPooling): GlobalAveragePool_119, Tactic: 0x933eceba7b866d59, 229 (Float[1,384,4,4]) -> 230 (Float[1,384,1,1])
Layer(Reformat): QuantizeLinear_150, Tactic: 0x0000000000000000, 229 (Float[1,384,4,4]) -> 258 (Int8[1,384:4,4,4])
Layer(Reformat): QuantizeLinear_122, Tactic: 0x00000000000003e8, 230 (Float[1,384,1,1]) -> 233 (Int8[1,384,1,1])
Layer(CaskPooling): MaxPool_147, Tactic: 0x1f6c40e3e09ec730, 258 (Int8[1,384:4,4,4]) -> 261 (Int8[1,384:4,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133, Tactic: 0x0000000000000000, 233 (Int8[1,384,1,1]) -> Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (Int8[1,384:32,1,1])
Layer(CaskConvolution): attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133, Tactic: 0x31de506085a332d4, Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_0 + QuantizeLinear_128 + Conv_132 + Relu_133 (Int8[1,384:32,1,1]) -> 247 (Int8[1,24:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161, Tactic: 0x0000000000000000, 261 (Int8[1,384:4,1,1]) -> Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161 (Int8[1,384:32,1,1])
Layer(CaskConvolution): attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161, Tactic: 0x31de506085a332d4, Reformatted Input Tensor 0 to attention_channel.fc.0.weight_clone_1 + QuantizeLinear_156 + Conv_160 + Relu_161 (Int8[1,384:32,1,1]) -> 275 (Int8[1,24:32,1,1])
Layer(CaskConvolution): attention_channel.fc.2.weight_clone_0 + QuantizeLinear_142 + Conv_146, Tactic: 0xdc1f355deb032b87, 247 (Int8[1,24:32,1,1]) -> 257 (Float[1,384:32,1,1])
Layer(CaskConvolution): attention_channel.fc.2.weight_clone_1 + QuantizeLinear_170 + Conv_174, Tactic: 0xdc1f355deb032b87, 275 (Int8[1,24:32,1,1]) -> 285 (Float[1,384:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Add_175, Sigmoid_176), Mul_177), Tactic: 0x0000000000000000, 257 (Float[1,384:32,1,1]) -> Reformatted Input Tensor 0 to PWN(PWN(Add_175, Sigmoid_176), Mul_177) (Float[1,384,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Add_175, Sigmoid_176), Mul_177), Tactic: 0x0000000000000000, 285 (Float[1,384:32,1,1]) -> Reformatted Input Tensor 1 to PWN(PWN(Add_175, Sigmoid_176), Mul_177) (Float[1,384,1,1])
Layer(PointWiseV2): PWN(PWN(Add_175, Sigmoid_176), Mul_177), Tactic: 0x0000000000000003, Reformatted Input Tensor 0 to PWN(PWN(Add_175, Sigmoid_176), Mul_177) (Float[1,384,1,1]), Reformatted Input Tensor 1 to PWN(PWN(Add_175, Sigmoid_176), Mul_177) (Float[1,384,1,1]), 229 (Float[1,384,4,4]) -> 288 (Float[1,384,4,4])
Layer(CaskPooling): GlobalAveragePool_178, Tactic: 0x933eceba7b866d59, 288 (Float[1,384,4,4]) -> 289 (Float[1,384,1,1])
Layer(Reformat): QuantizeLinear_183, Tactic: 0x0000000000000000, 289 (Float[1,384,1,1]) -> 291 (Int8[1,384:4,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise], Tactic: 0x0000000000000000, 291 (Int8[1,384:4,1,1]) -> Reformatted Input Tensor 0 to classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (Int8[1,384:32,1,1])
Layer(CaskConvolution): classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise], Tactic: 0x5e4f6d7c83746fd6, Reformatted Input Tensor 0 to classfier1.weight + QuantizeLinear_189 + transpose_before_Gemm_193 + Gemm_193 + classfier1.bias + (Unnamed Layer* 202) [Shuffle] + unsqueeze_node_after_classfier1.bias + (Unnamed Layer* 202) [Shuffle]_(Unnamed Layer* 202) [Shuffle]_output + (Unnamed Layer* 203) [ElementWise] (Int8[1,384:32,1,1]) -> (Unnamed Layer* 203) [ElementWise]_out_tensor (Float[1,6,1,1])
Layer(CaskPooling): GlobalAveragePool_2593, Tactic: 0x964fa580cb69303d, 2703 (Float[1,2048,3,3]) -> 2704 (Float[1,2048,1,1])
Layer(NoOp): copied_squeeze_after_(Unnamed Layer* 203) [ElementWise], Tactic: 0x0000000000000000, (Unnamed Layer* 203) [ElementWise]_out_tensor (Float[1,6,1,1]) -> output (Float[1,6])
Layer(Reformat): QuantizeLinear_2598, Tactic: 0x0000000000000000, 2704 (Float[1,2048,1,1]) -> 2706 (Int8[1,2048:4,1,1])
Layer(CaskConvolution): classfier2.weight + QuantizeLinear_2604 + transpose_before_Gemm_2608 + Gemm_2608 + classfier2.bias + (Unnamed Layer* 2499) [Shuffle] + unsqueeze_node_after_classfier2.bias + (Unnamed Layer* 2499) [Shuffle]_(Unnamed Layer* 2499) [Shuffle]_output + (Unnamed Layer* 2500) [ElementWise], Tactic: 0xc073b0053ce90eac, 2706 (Int8[1,2048:4,1,1]) -> (Unnamed Layer* 2500) [ElementWise]_out_tensor (Float[1,6,1,1])
Layer(NoOp): copied_squeeze_after_(Unnamed Layer* 2500) [ElementWise], Tactic: 0x0000000000000000, (Unnamed Layer* 2500) [ElementWise]_out_tensor (Float[1,6,1,1]) -> 2719 (Float[1,6])
[03/01/2023-10:42:06] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +5, GPU +4, now: CPU 5, GPU 4 (MiB)
[03/01/2023-10:42:06] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2146, GPU 1055 (MiB)
[03/01/2023-10:42:06] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars
[03/01/2023-10:42:06] [V] Trying to set exclusive file lock ./timing.cache.lock
[03/01/2023-10:42:06] [V] File locked in 2.208e-06 seconds.
[03/01/2023-10:42:06] [V] [TRT] Serializing timing cache. UUID = GPU-c94e814d-ce6c-645c-4739-209145a3094e, commit ID = 1724c471ee7f0c9b
[03/01/2023-10:42:06] [V] [TRT] Serialized 59 bytes of code generator cache.
[03/01/2023-10:42:06] [V] [TRT] Serialized 59 bytes of code generator cache.
[03/01/2023-10:42:06] [V] [TRT] Serialized 434 timing cache entries
[03/01/2023-10:42:06] [I] Saved 45341 bytes of timing cache to ./timing.cache
[03/01/2023-10:42:06] [V] Trying to remove exclusive file lock ./timing.cache.lock
[03/01/2023-10:42:06] [V] File unlocked in 3.091e-06 seconds.
[03/01/2023-10:42:06] [V] [TRT] Deleting timing cache: 434 entries, served 0 hits since creation.
[03/01/2023-10:42:06] [V] [TRT] Deleting timing cache: 434 entries, served 4570 hits since creation.
[03/01/2023-10:42:06] [I] Engine built in 82.4334 sec.
[03/01/2023-10:42:06] [I] [TRT] Loaded engine size: 4 MiB
[03/01/2023-10:42:06] [V] [TRT] Deserialization required 11358 microseconds.
[03/01/2023-10:42:06] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[03/01/2023-10:42:06] [I] Engine deserialized in 0.0117068 sec.
[03/01/2023-10:42:06] [I] Skipped inference phase since --buildOnly is added.
&&&& PASSED TensorRT.trtexec [TensorRT v8503] # trtexec --verbose --nvtxMode=verbose --buildOnly --workspace=8192 --onnx=/home/developers/liuchang/quantize/py-quant-ptq/param_test/int8_histogram_percentile99.9999_mffcnn.onnx --saveEngine=/home/developers/liuchang/quantize/py-quant-ptq/param_test/int8_histogram_percentile99.9999_mffcnn.onnx.engine --timingCacheFile=./timing.cache --profilingVerbosity=detailed --int8
